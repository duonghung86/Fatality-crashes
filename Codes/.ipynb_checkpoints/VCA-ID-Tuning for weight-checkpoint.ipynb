{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:44:40.812597Z",
     "start_time": "2020-05-21T20:44:39.241218Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1QxOQkOlJ1S_"
   },
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cq34ehtsJ1Th"
   },
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-21T20:44:40.751Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10148,
     "status": "ok",
     "timestamp": 1589212832817,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "_v04MZq4J1To",
    "outputId": "0dd4542d-a365-47ce-8669-1d559fef6985"
   },
   "outputs": [],
   "source": [
    "link='https://github.com/duonghung86/Fatality-crashes/raw/master/Codes/final%20data.zip'\n",
    "url = urllib.request.urlopen(link)\n",
    "with ZipFile(BytesIO(url.read())) as my_zip_file:\n",
    "    for contained_file in my_zip_file.namelist():\n",
    "        fzip=my_zip_file.open(contained_file)\n",
    "        data=fzip.read()\n",
    "\n",
    "s=str(data,'utf-8')\n",
    "data = StringIO(s)\n",
    "df=pd.read_csv(data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:07:55.028769Z",
     "start_time": "2020-05-11T19:07:54.946916Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10132,
     "status": "ok",
     "timestamp": 1589212832818,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "0yIHRk4sJ1Tx",
    "outputId": "d91e40bd-c01e-4fd0-86d0-bdbcd3ed9f69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.where(df['Injury Severity']=='KILLED',1,0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:07:55.054716Z",
     "start_time": "2020-05-11T19:07:55.033255Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10117,
     "status": "ok",
     "timestamp": 1589212832820,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "0Ba_lXcHJ1UI",
    "outputId": "b43fce0d-8bd8-477b-aa39-501a76edc1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 488849\n",
      "    Positive: 1494 (0.31% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(y)\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:07:56.015103Z",
     "start_time": "2020-05-11T19:07:55.058708Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11433,
     "status": "ok",
     "timestamp": 1589212834154,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "Cl4mz5NYJ1UV",
    "outputId": "65dad35a-0845-4226-f71e-61010fc5228e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crash_Month</th>\n",
       "      <th>Crash_Day</th>\n",
       "      <th>Crash_Minute</th>\n",
       "      <th>Crash_AM/PM</th>\n",
       "      <th>Crash_Hour</th>\n",
       "      <th>Unit_Nbr</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Toll_Road_Fl</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Constr_Zone_Fl</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_Cntl_ID_STOP SIGN</th>\n",
       "      <th>Traffic_Cntl_ID_WARNING SIGN</th>\n",
       "      <th>Traffic_Cntl_ID_YIELD SIGN</th>\n",
       "      <th>Unit_Desc_ID_MOTORIZED CONVEYANCE</th>\n",
       "      <th>Unit_Desc_ID_NON-CONTACT</th>\n",
       "      <th>Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)</th>\n",
       "      <th>Unit_Desc_ID_PEDALCYCLIST</th>\n",
       "      <th>Unit_Desc_ID_PEDESTRIAN</th>\n",
       "      <th>Unit_Desc_ID_TOWED/PUSHED/TRAILER</th>\n",
       "      <th>Unit_Desc_ID_TRAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488844</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488845</th>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488846</th>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488847</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488848</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488849 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Crash_Month  Crash_Day  Crash_Minute  Crash_AM/PM  Crash_Hour  \\\n",
       "0                 7         20            37            0           3   \n",
       "1                 7         27            45            0          11   \n",
       "2                 8         10             5            1           5   \n",
       "3                 7         21            17            1           6   \n",
       "4                 8         27            26            0           7   \n",
       "...             ...        ...           ...          ...         ...   \n",
       "488844           11         29            13            0          11   \n",
       "488845           11         25             6            0          11   \n",
       "488846           11         25             6            0          11   \n",
       "488847            9          3            15            1           4   \n",
       "488848            9          3            15            1           4   \n",
       "\n",
       "        Unit_Nbr  Prsn_Age  Toll_Road_Fl  Crash_Speed_Limit  \\\n",
       "0              3        26             0                 55   \n",
       "1              3        61             0                 75   \n",
       "2              2        55             0                 55   \n",
       "3              2        84             0                 65   \n",
       "4              2        78             0                 75   \n",
       "...          ...       ...           ...                ...   \n",
       "488844         1        68             0                 70   \n",
       "488845         1        44             0                 55   \n",
       "488846         2        57             0                 55   \n",
       "488847         1        16             0                 40   \n",
       "488848         2        16             0                 40   \n",
       "\n",
       "        Road_Constr_Zone_Fl  ...  Traffic_Cntl_ID_STOP SIGN  \\\n",
       "0                         0  ...                          0   \n",
       "1                         0  ...                          0   \n",
       "2                         0  ...                          0   \n",
       "3                         0  ...                          0   \n",
       "4                         0  ...                          0   \n",
       "...                     ...  ...                        ...   \n",
       "488844                    0  ...                          0   \n",
       "488845                    0  ...                          1   \n",
       "488846                    0  ...                          1   \n",
       "488847                    0  ...                          1   \n",
       "488848                    0  ...                          1   \n",
       "\n",
       "        Traffic_Cntl_ID_WARNING SIGN  Traffic_Cntl_ID_YIELD SIGN  \\\n",
       "0                                  0                           0   \n",
       "1                                  0                           0   \n",
       "2                                  0                           0   \n",
       "3                                  0                           0   \n",
       "4                                  0                           0   \n",
       "...                              ...                         ...   \n",
       "488844                             0                           0   \n",
       "488845                             0                           0   \n",
       "488846                             0                           0   \n",
       "488847                             0                           0   \n",
       "488848                             0                           0   \n",
       "\n",
       "        Unit_Desc_ID_MOTORIZED CONVEYANCE  Unit_Desc_ID_NON-CONTACT  \\\n",
       "0                                       0                         0   \n",
       "1                                       0                         0   \n",
       "2                                       0                         0   \n",
       "3                                       0                         0   \n",
       "4                                       0                         0   \n",
       "...                                   ...                       ...   \n",
       "488844                                  0                         0   \n",
       "488845                                  0                         0   \n",
       "488846                                  0                         0   \n",
       "488847                                  0                         0   \n",
       "488848                                  0                         0   \n",
       "\n",
       "        Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)  Unit_Desc_ID_PEDALCYCLIST  \\\n",
       "0                                               0                          0   \n",
       "1                                               0                          0   \n",
       "2                                               0                          0   \n",
       "3                                               0                          0   \n",
       "4                                               0                          0   \n",
       "...                                           ...                        ...   \n",
       "488844                                          0                          0   \n",
       "488845                                          0                          0   \n",
       "488846                                          0                          0   \n",
       "488847                                          0                          0   \n",
       "488848                                          0                          0   \n",
       "\n",
       "        Unit_Desc_ID_PEDESTRIAN  Unit_Desc_ID_TOWED/PUSHED/TRAILER  \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  0   \n",
       "4                             0                                  0   \n",
       "...                         ...                                ...   \n",
       "488844                        0                                  0   \n",
       "488845                        0                                  0   \n",
       "488846                        0                                  0   \n",
       "488847                        0                                  0   \n",
       "488848                        0                                  0   \n",
       "\n",
       "        Unit_Desc_ID_TRAIN  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "488844                   0  \n",
       "488845                   0  \n",
       "488846                   0  \n",
       "488847                   0  \n",
       "488848                   0  \n",
       "\n",
       "[488849 rows x 133 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,1:].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "548Mc3Y4J1Ui"
   },
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:07:57.176979Z",
     "start_time": "2020-05-11T19:07:56.018424Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5ERPlNBhJ1Ul"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:01.463123Z",
     "start_time": "2020-05-11T19:07:57.180475Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13534,
     "status": "ok",
     "timestamp": 1589212836277,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "6dDdGqNSJ1Uo",
    "outputId": "2750b62b-92b8-453e-98ba-cc5a1d23821f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (312863, 133)\n",
      "Validation features shape: (78216, 133)\n",
      "Test features shape: (97770, 133)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2,stratify=y_train, random_state=48)\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "X_val=np.array(X_val)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:01.483088Z",
     "start_time": "2020-05-11T19:08:01.468613Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13523,
     "status": "ok",
     "timestamp": 1589212836278,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "Ut-NVd4nJ1Uv",
    "outputId": "d5511c3a-2bc8-4caa-f7e8-fdb612ad8ac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (312863, 1)\n",
      "Validation features shape: (78216, 1)\n",
      "Test features shape: (97770, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train=np.array(y_train).reshape(len(y_train),1)\n",
    "y_test=np.array(y_test).reshape(len(y_test),1)\n",
    "y_val=np.array(y_val).reshape(len(y_val),1)\n",
    "\n",
    "print('Training features shape:', y_train.shape)\n",
    "print('Validation features shape:', y_val.shape)\n",
    "print('Test features shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:01.502051Z",
     "start_time": "2020-05-11T19:08:01.486579Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Lj2Ka9kMJ1U2"
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:03.667026Z",
     "start_time": "2020-05-11T19:08:01.506048Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BiA2g-qsJ1U6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcaKVTGuJ1Vm"
   },
   "source": [
    "# MLP simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HquajIY-J1Vn"
   },
   "source": [
    "## Mini functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Z54FMlfJ1Vp"
   },
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:10.280676Z",
     "start_time": "2020-05-11T19:08:03.672018Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15926,
     "status": "ok",
     "timestamp": 1589212838693,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "dBEUbS6cYuve",
    "outputId": "511d15ce-1237-4747-9635-9a334cac1bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-11T19:02:23.809Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "          keras.metrics.Precision(name='precision'),\n",
    "          keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:15:13.889796Z",
     "start_time": "2020-05-11T19:15:13.859856Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.BinaryAccuracy(name='accuracy'),keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:39.733552Z",
     "start_time": "2020-05-11T19:08:39.724072Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yIup1KAaJ1Vr"
   },
   "outputs": [],
   "source": [
    "def create_model(nodes=20,actih='relu',actio='sigmoid',lr=1e-3,output_bias=None,logits=False):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(nodes, activation=actih,input_dim=X_train.shape[1]))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation=actio,bias_initializer=output_bias))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=logits),\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXXqeCA-J1Vu"
   },
   "source": [
    "### Show confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:39.760501Z",
     "start_time": "2020-05-11T19:08:39.737045Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BCMLDgLcYo6T"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:39.779467Z",
     "start_time": "2020-05-11T19:08:39.763996Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZhneEw4cRND_"
   },
   "outputs": [],
   "source": [
    "def CI(arr):\n",
    "    op=[arr[0,0],arr[1,1]]/arr.sum(axis=0)\n",
    "    op=np.append(op,(arr[0,0]+arr[1,1])/arr.sum())\n",
    "    op=pd.DataFrame(op,columns=['Precision'],index=['0','1','Global'])\n",
    "    op['n_p']=np.append(arr.sum(axis=0),arr.sum())\n",
    "    op['CI_p']=196*np.sqrt(op.Precision*(1-op.Precision)/op.n_p)\n",
    "    op['Precision']=op.Precision*100\n",
    "\n",
    "    op['Recall']=np.append([arr[0,0],arr[1,1]]/arr.sum(axis=1),(arr[0,0]+arr[1,1])/arr.sum())\n",
    "    op['n_r']=np.append(arr.sum(axis=1),arr.sum())\n",
    "    op['CI_r']=196*np.sqrt(op.Recall*(1-op.Recall)/op.n_r)\n",
    "    op['Recall']=op.Recall*100\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:39.792941Z",
     "start_time": "2020-05-11T19:08:39.783958Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uFfBF83bJ1V0"
   },
   "outputs": [],
   "source": [
    "def show_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    print(cm)\n",
    "    pcm=classification_report(labels, predictions > p, target_names=['Class 0','Class 1']) \n",
    "    print(pcm)\n",
    "    return CI(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7vWECLdJ1V_"
   },
   "source": [
    "### Plot ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:39.805919Z",
     "start_time": "2020-05-11T19:08:39.797433Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "C3yM0beyZCHc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:39.822886Z",
     "start_time": "2020-05-11T19:08:39.809912Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tuV1U8jcJ1WG"
   },
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name + ' (area = %0.2f)' % auc(fp, tp), linewidth=1.5, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([0,100.5])\n",
    "  plt.ylim([0,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:40.172529Z",
     "start_time": "2020-05-11T19:08:39.826380Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1508,
     "status": "ok",
     "timestamp": 1589212863809,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "gS6h-0G3J1WN",
    "outputId": "b164d038-a489-4aaa-8869-9fd59a9d66f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((133,), (1,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:40.252880Z",
     "start_time": "2020-05-11T19:08:40.177020Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1497,
     "status": "ok",
     "timestamp": 1589212863810,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "ruuam0vyJ1WT",
    "outputId": "78563a28-99b6-48f3-f572-a6ab749a9e9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((133,), (1,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:40.266852Z",
     "start_time": "2020-05-11T19:08:40.256871Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1589212863811,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "XkkyFt4uJ1WZ",
    "outputId": "0b58a826-057b-4f6a-fad5-5977d5d47db2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.78753572])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:40.277833Z",
     "start_time": "2020-05-11T19:08:40.270347Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3VS51FQTJ1Wk"
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:40.296298Z",
     "start_time": "2020-05-11T19:08:40.281825Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CA3Zf0VHJ1Wo"
   },
   "outputs": [],
   "source": [
    "batch_size=2048\n",
    "data_train = data_train.shuffle(len(X_train)).batch(batch_size)\n",
    "data_val = data_val.shuffle(len(X_val)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:40.305780Z",
     "start_time": "2020-05-11T19:08:40.300291Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wOnyvd3jK739"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:47:44.768449Z",
     "start_time": "2020-05-08T22:47:44.455029Z"
    },
    "colab_type": "text",
    "id": "loWcs-MKJ1XR"
   },
   "source": [
    "## Class weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDLuSQMabKFn"
   },
   "source": [
    "### Class weight estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:08:40.323747Z",
     "start_time": "2020-05-11T19:08:40.311769Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1589212863815,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "y1tT_8gBbIl_",
    "outputId": "28410c3a-2595-4278-ed44-eca0b117068c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.50\n",
      "Weight for class 1: 163.60\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-G092TzzbPWJ"
   },
   "source": [
    "### Run model with class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:11:00.195583Z",
     "start_time": "2020-05-11T19:08:40.329237Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79639,
     "status": "ok",
     "timestamp": 1589212942074,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "s1fC3msPblwo",
    "outputId": "a782bb12-0d03-44b5-f7e4-31e3e555cd3d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 153 steps, validate for 39 steps\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 7s 48ms/step - loss: 0.7412 - auc: 0.6969 - val_loss: 0.4821 - val_auc: 0.9054\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 5s 33ms/step - loss: 0.5057 - auc: 0.8567 - val_loss: 0.4038 - val_auc: 0.9251\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.4394 - auc: 0.8935 - val_loss: 0.3663 - val_auc: 0.9299\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3913 - auc: 0.9130 - val_loss: 0.3437 - val_auc: 0.9334\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 6s 38ms/step - loss: 0.3686 - auc: 0.9195 - val_loss: 0.3349 - val_auc: 0.9341\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 7s 47ms/step - loss: 0.3512 - auc: 0.9294 - val_loss: 0.3284 - val_auc: 0.9339\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 7s 48ms/step - loss: 0.3371 - auc: 0.9333 - val_loss: 0.3232 - val_auc: 0.9351\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 7s 47ms/step - loss: 0.3290 - auc: 0.9360 - val_loss: 0.3215 - val_auc: 0.9362\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 8s 50ms/step - loss: 0.3257 - auc: 0.9367 - val_loss: 0.3197 - val_auc: 0.9361\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 7s 43ms/step - loss: 0.3074 - auc: 0.9447 - val_loss: 0.3177 - val_auc: 0.9366\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 6s 38ms/step - loss: 0.3141 - auc: 0.9414 - val_loss: 0.3134 - val_auc: 0.9381\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 6s 39ms/step - loss: 0.2991 - auc: 0.9469 - val_loss: 0.3379 - val_auc: 0.9384\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3007 - auc: 0.9465 - val_loss: 0.3188 - val_auc: 0.9372\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 6s 38ms/step - loss: 0.2966 - auc: 0.9475 - val_loss: 0.3867 - val_auc: 0.9352\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 5s 36ms/step - loss: 0.2870 - auc: 0.9509 - val_loss: 0.3290 - val_auc: 0.9367\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 6s 37ms/step - loss: 0.2939 - auc: 0.9484 - val_loss: 0.3259 - val_auc: 0.9357\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.2892 - auc: 0.9505 - val_loss: 0.3265 - val_auc: 0.9357\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 6s 39ms/step - loss: 0.2853 - auc: 0.9515 - val_loss: 0.3334 - val_auc: 0.9351\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 7s 48ms/step - loss: 0.2819 - auc: 0.9526 - val_loss: 0.3373 - val_auc: 0.9343\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 7s 46ms/step - loss: 0.2851 - auc: 0.9516 - val_loss: 0.3371 - val_auc: 0.9345\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 7s 46ms/step - loss: 0.2816 - auc: 0.9528 - val_loss: 0.3421 - val_auc: 0.9337\n",
      "Epoch 22/100\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.2767 - auc: 0.9541- ETA: 0s - loss: 0.2742 - auc: 0Restoring model weights from the end of the best epoch.\n",
      "153/153 [==============================] - 8s 51ms/step - loss: 0.2768 - auc: 0.9545 - val_loss: 0.3517 - val_auc: 0.9334\n",
      "Epoch 00022: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "139.8513741493225"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "wei_model=create_model()\n",
    "Monitor = wei_model.fit(data_train, epochs=100,callbacks=[es],validation_data = data_val,class_weight=class_weight, verbose = 1)\n",
    "end_time=time.time()\n",
    "end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:11:03.284390Z",
     "start_time": "2020-05-11T19:11:00.202073Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80136,
     "status": "ok",
     "timestamp": 1589212942584,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "gbJOrd5cb8dr",
    "outputId": "31c9319c-6bb8-4250-b977-0f828684e420"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.DataFrame(Monitor.history)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,4),dpi=150)\n",
    "hist[['loss','val_loss']].plot(ax=axes[0])\n",
    "hist[['auc','val_auc']].plot(ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGzf8FEoedp4"
   },
   "source": [
    "### Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:11:14.502192Z",
     "start_time": "2020-05-11T19:11:03.287882Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tNkmcPN9b8aA"
   },
   "outputs": [],
   "source": [
    "y_pred_train_b = wei_model.predict(X_train)\n",
    "y_pred_test_b = wei_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:11:15.985452Z",
     "start_time": "2020-05-11T19:11:14.505663Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87565,
     "status": "ok",
     "timestamp": 1589212950043,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "g1AwenWlcgTC",
    "outputId": "a4a70811-abfe-43b4-c30e-1418753a6ff5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(len(y_test)),y_pred_test_b,s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:11:16.549147Z",
     "start_time": "2020-05-11T19:11:15.988427Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87816,
     "status": "ok",
     "timestamp": 1589212950314,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "5kiSMFi8b8Xp",
    "outputId": "d107db44-9db4-4e01-ddaf-54159c8a4beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86026 11445]\n",
      " [   24   275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.88      0.94     97471\n",
      "     Class 1       0.02      0.92      0.05       299\n",
      "\n",
      "    accuracy                           0.88     97770\n",
      "   macro avg       0.51      0.90      0.49     97770\n",
      "weighted avg       1.00      0.88      0.93     97770\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>n_p</th>\n",
       "      <th>CI_p</th>\n",
       "      <th>Recall</th>\n",
       "      <th>n_r</th>\n",
       "      <th>CI_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.972109</td>\n",
       "      <td>86050</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>88.258046</td>\n",
       "      <td>97471</td>\n",
       "      <td>0.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.346416</td>\n",
       "      <td>11720</td>\n",
       "      <td>0.274056</td>\n",
       "      <td>91.973244</td>\n",
       "      <td>299</td>\n",
       "      <td>3.079791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global</th>\n",
       "      <td>88.269408</td>\n",
       "      <td>97770</td>\n",
       "      <td>0.201706</td>\n",
       "      <td>88.269408</td>\n",
       "      <td>97770</td>\n",
       "      <td>0.201706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Precision    n_p      CI_p     Recall    n_r      CI_r\n",
       "0       99.972109  86050  0.011157  88.258046  97471  0.202100\n",
       "1        2.346416  11720  0.274056  91.973244    299  3.079791\n",
       "Global  88.269408  97770  0.201706  88.269408  97770  0.201706"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_cm(y_test,y_pred_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:11:17.050890Z",
     "start_time": "2020-05-11T19:11:16.552637Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1589213180188,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "l3yBCZz7b8So",
    "outputId": "c6a139fd-2956-47d0-e10b-f8ee4d54f91e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_roc('Base model - train',y_train,y_pred_train_b)\n",
    "plot_roc('Base model - test',y_test,y_pred_test_b)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iaw83EYPd20X"
   },
   "source": [
    "# Tuning parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T19:12:00.230006Z",
     "start_time": "2020-05-11T19:12:00.220545Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1589213605661,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "91RuQ-tob8Lt",
    "outputId": "8c7ccd57-0239-48ec-ec01-f64d6f119f52"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T23:04:21.133394Z",
     "start_time": "2020-05-11T23:04:20.347691Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ijqe1QW9clTc"
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.1,0.01,0.001]\n",
    "nodes = [10,20,30,40]\n",
    "batches=[1024,2048,4096]\n",
    "param_options = {'lr': learning_rates,'nodes': nodes,'batch_size':batches}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T23:04:24.385087Z",
     "start_time": "2020-05-11T23:04:24.290723Z"
    }
   },
   "outputs": [],
   "source": [
    "scores={'BA':'balanced_accuracy','AUC':'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T01:12:25.657649Z",
     "start_time": "2020-05-11T23:04:48.979672Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uetpo3uQfuSu",
    "outputId": "d2c9d310-5b2f-4ab7-8730-03f602afd365",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 23s 94us/sample - loss: 0.9076 - accuracy: 0.7581 - auc: 0.7681 - val_loss: 0.9801 - val_accuracy: 0.7746 - val_auc: 0.8600\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0237 - accuracy: 0.8450 - auc: 0.7602 - val_loss: 1.1512 - val_accuracy: 0.3095 - val_auc: 0.6706\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7229 - accuracy: 0.8629 - auc: 0.7633 - val_loss: 0.8350 - val_accuracy: 0.8806 - val_auc: 0.9075\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6390 - accuracy: 0.7895 - auc: 0.7987 - val_loss: 0.9540 - val_accuracy: 0.5927 - val_auc: 0.8664\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5501 - accuracy: 0.5342 - auc: 0.7902 - val_loss: 0.8401 - val_accuracy: 0.6173 - val_auc: 0.9081\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 1.3273 - accuracy: 0.5341 - auc: 0.7519 - val_loss: 1.2430 - val_accuracy: 0.5362 - val_auc: 0.7737\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 1.0429 - accuracy: 0.3987 - auc: 0.6972 - val_loss: 2.1717 - val_accuracy: 0.4782 - val_auc: 0.8941\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.7099 - accuracy: 0.3919 - auc: 0.6832 - val_loss: 1.8114 - val_accuracy: 0.4391 - val_auc: 0.7168\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 1.2056 - accuracy: 0.3996 - auc: 0.6186 - val_loss: 0.9072 - val_accuracy: 0.1485 - val_auc: 0.5277\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.6667 - accuracy: 0.4172 - auc: 0.6631 - val_loss: 1.5879 - val_accuracy: 0.4063 - val_auc: 0.6984\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6587 - accuracy: 0.2938 - auc: 0.6301 - val_loss: 1.3251 - val_accuracy: 0.4122 - val_auc: 0.7011\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.6410 - accuracy: 0.2754 - auc: 0.6381 - val_loss: 1.7482 - val_accuracy: 0.4199 - val_auc: 0.7088\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7169 - accuracy: 0.3016 - auc: 0.6325 - val_loss: 1.4370 - val_accuracy: 0.4439 - val_auc: 0.7198\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6840 - accuracy: 0.2910 - auc: 0.6516 - val_loss: 2.0751 - val_accuracy: 0.4273 - val_auc: 0.7065\n",
      "Epoch 15/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.5926 - accuracy: 0.2925 - auc: 0.6402Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.5922 - accuracy: 0.2927 - auc: 0.6405 - val_loss: 1.9495 - val_accuracy: 0.4364 - val_auc: 0.7073\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 123s 489us/sample - loss: 1.0262 - accuracy: 0.7866 - auc: 0.7593 - val_loss: 0.6041 - val_accuracy: 0.8010 - val_auc: 0.8970\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6490 - accuracy: 0.8719 - auc: 0.8224 - val_loss: 0.6355 - val_accuracy: 0.9270 - val_auc: 0.9051\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6770 - accuracy: 0.8852 - auc: 0.8034 - val_loss: 0.7043 - val_accuracy: 0.8459 - val_auc: 0.8683\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.9759 - accuracy: 0.8158 - auc: 0.7796 - val_loss: 1.8214 - val_accuracy: 0.8835 - val_auc: 0.8961\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 1.2616 - accuracy: 0.5638 - auc: 0.6921 - val_loss: 1.2617 - val_accuracy: 0.4763 - val_auc: 0.8586\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6939 - accuracy: 0.4552 - auc: 0.7168 - val_loss: 1.8176 - val_accuracy: 0.4838 - val_auc: 0.7392\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.6917 - accuracy: 0.3397 - auc: 0.6456 - val_loss: 1.3403 - val_accuracy: 0.4732 - val_auc: 0.7294\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.6364 - accuracy: 0.3308 - auc: 0.6603 - val_loss: 1.3092 - val_accuracy: 0.5427 - val_auc: 0.7624\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5760 - accuracy: 0.3545 - auc: 0.6684 - val_loss: 1.0948 - val_accuracy: 0.5356 - val_auc: 0.7625\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5719 - accuracy: 0.3676 - auc: 0.6762 - val_loss: 1.0197 - val_accuracy: 0.5811 - val_auc: 0.7716\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5962 - accuracy: 0.3846 - auc: 0.6795 - val_loss: 1.0380 - val_accuracy: 0.5852 - val_auc: 0.7741\n",
      "Epoch 12/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.5836 - accuracy: 0.3853 - auc: 0.6833Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5821 - accuracy: 0.3852 - auc: 0.6839 - val_loss: 1.1423 - val_accuracy: 0.5657 - val_auc: 0.7648\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 21us/sample - loss: 0.9311 - accuracy: 0.7703 - auc: 0.7471 - val_loss: 0.4676 - val_accuracy: 0.9160 - val_auc: 0.9097\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9120 - accuracy: 0.7535 - auc: 0.7506 - val_loss: 0.8368 - val_accuracy: 0.3980 - val_auc: 0.7217\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.7652 - accuracy: 0.4066 - auc: 0.6974 - val_loss: 0.8334 - val_accuracy: 0.5219 - val_auc: 0.7756\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.7794 - accuracy: 0.4100 - auc: 0.7103 - val_loss: 1.0729 - val_accuracy: 0.5829 - val_auc: 0.7952\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.7739 - accuracy: 0.4634 - auc: 0.7335 - val_loss: 0.9828 - val_accuracy: 0.5826 - val_auc: 0.8206\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.8565 - accuracy: 0.4905 - auc: 0.7597 - val_loss: 3.8370 - val_accuracy: 0.6236 - val_auc: 0.7827\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8424 - accuracy: 0.4599 - auc: 0.7188 - val_loss: 3.0033 - val_accuracy: 0.6004 - val_auc: 0.7833\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.6316 - accuracy: 0.4741 - auc: 0.7316 - val_loss: 1.8873 - val_accuracy: 0.5459 - val_auc: 0.7433\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.9923 - accuracy: 0.4608 - auc: 0.7059 - val_loss: 5.8153 - val_accuracy: 0.5728 - val_auc: 0.7629\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 1.0550 - accuracy: 0.4429 - auc: 0.7068 - val_loss: 5.1177 - val_accuracy: 0.5629 - val_auc: 0.7656\n",
      "Epoch 11/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.7301 - accuracy: 0.4388 - auc: 0.7167Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.7296 - accuracy: 0.4388 - auc: 0.7168 - val_loss: 3.3410 - val_accuracy: 0.5399 - val_auc: 0.7858\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 25us/sample - loss: 1.2010 - accuracy: 0.7358 - auc: 0.7434 - val_loss: 1.6773 - val_accuracy: 0.9262 - val_auc: 0.8500\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0522 - accuracy: 0.8522 - auc: 0.7576 - val_loss: 1.3798 - val_accuracy: 0.6464 - val_auc: 0.8389\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.9036 - accuracy: 0.8627 - auc: 0.7538 - val_loss: 1.1111 - val_accuracy: 0.9518 - val_auc: 0.8874\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.9084 - accuracy: 0.8859 - auc: 0.7490 - val_loss: 1.8000 - val_accuracy: 0.9329 - val_auc: 0.8966\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.6478 - accuracy: 0.8807 - auc: 0.7732 - val_loss: 1.3542 - val_accuracy: 0.9225 - val_auc: 0.8771\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 3s 12us/sample - loss: 0.7363 - accuracy: 0.9372 - auc: 0.7372 - val_loss: 0.8197 - val_accuracy: 0.8903 - val_auc: 0.8894\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 0.8503 - accuracy: 0.6847 - auc: 0.7217 - val_loss: 3.0707 - val_accuracy: 0.4862 - val_auc: 0.7475\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6796 - accuracy: 0.3802 - auc: 0.7002 - val_loss: 1.5583 - val_accuracy: 0.5950 - val_auc: 0.8283\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7290 - accuracy: 0.4978 - auc: 0.7057 - val_loss: 1.0935 - val_accuracy: 0.1450 - val_auc: 0.6676\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6823 - accuracy: 0.7384 - auc: 0.7398 - val_loss: 3.7978 - val_accuracy: 0.9297 - val_auc: 0.8719\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6984 - accuracy: 0.5577 - auc: 0.7331 - val_loss: 5.2208 - val_accuracy: 0.4900 - val_auc: 0.7799\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8744 - accuracy: 0.3685 - auc: 0.6900 - val_loss: 5.6038 - val_accuracy: 0.4816 - val_auc: 0.7543\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7830 - accuracy: 0.3636 - auc: 0.6709 - val_loss: 4.5064 - val_accuracy: 0.4580 - val_auc: 0.7674\n",
      "Epoch 14/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.6431 - accuracy: 0.3564 - auc: 0.6749Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6406 - accuracy: 0.3550 - auc: 0.6744 - val_loss: 6.3867 - val_accuracy: 0.4634 - val_auc: 0.7711\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 24us/sample - loss: 1.2016 - accuracy: 0.7351 - auc: 0.7150 - val_loss: 0.8824 - val_accuracy: 0.7780 - val_auc: 0.8585\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0795 - accuracy: 0.7895 - auc: 0.7706 - val_loss: 1.0131 - val_accuracy: 0.8825 - val_auc: 0.8849\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0447 - accuracy: 0.8497 - auc: 0.7944 - val_loss: 0.8425 - val_accuracy: 0.8495 - val_auc: 0.9089\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.7655 - accuracy: 0.7994 - auc: 0.8229 - val_loss: 1.0876 - val_accuracy: 0.5512 - val_auc: 0.8909\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7055 - accuracy: 0.6580 - auc: 0.7959 - val_loss: 1.3617 - val_accuracy: 0.8904 - val_auc: 0.9008\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5953 - accuracy: 0.7216 - auc: 0.8195 - val_loss: 1.1226 - val_accuracy: 0.5994 - val_auc: 0.8920\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.6981 - accuracy: 0.5278 - auc: 0.7751 - val_loss: 1.7599 - val_accuracy: 0.5777 - val_auc: 0.8724\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 0.7346 - accuracy: 0.5326 - auc: 0.7586 - val_loss: 1.5647 - val_accuracy: 0.6040 - val_auc: 0.7822\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.8396 - accuracy: 0.4452 - auc: 0.7039 - val_loss: 2.9434 - val_accuracy: 0.5792 - val_auc: 0.7751\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.6279 - accuracy: 0.4417 - auc: 0.7141 - val_loss: 2.5329 - val_accuracy: 0.5430 - val_auc: 0.7705\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.6103 - accuracy: 0.4329 - auc: 0.7217 - val_loss: 3.6586 - val_accuracy: 0.5694 - val_auc: 0.7760\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 0.6964 - accuracy: 0.4461 - auc: 0.7282 - val_loss: 3.4986 - val_accuracy: 0.9943 - val_auc: 0.7901\n",
      "Epoch 13/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.5909 - accuracy: 0.4469 - auc: 0.7409Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.6052 - accuracy: 0.4470 - auc: 0.7406 - val_loss: 2.6078 - val_accuracy: 0.5649 - val_auc: 0.7894\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 2.3565 - accuracy: 0.7003 - auc: 0.7472 - val_loss: 2.5874 - val_accuracy: 0.5473 - val_auc: 0.7651\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 2.2961 - accuracy: 0.7945 - auc: 0.7599 - val_loss: 1.7050 - val_accuracy: 0.7991 - val_auc: 0.8251\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 1.6910 - accuracy: 0.8403 - auc: 0.7530 - val_loss: 2.9643 - val_accuracy: 0.8981 - val_auc: 0.8881\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4406 - accuracy: 0.8894 - auc: 0.7922 - val_loss: 3.4559 - val_accuracy: 0.8542 - val_auc: 0.8809\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9744 - accuracy: 0.8887 - auc: 0.7428 - val_loss: 1.4964 - val_accuracy: 0.9173 - val_auc: 0.8778\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.7106 - accuracy: 0.8780 - auc: 0.7587 - val_loss: 3.5346 - val_accuracy: 0.6112 - val_auc: 0.8121\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3434 - accuracy: 0.8272 - auc: 0.7346 - val_loss: 1.8590 - val_accuracy: 0.9188 - val_auc: 0.8375\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3609 - accuracy: 0.5207 - auc: 0.7148 - val_loss: 3.8512 - val_accuracy: 0.5171 - val_auc: 0.7641\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3412 - accuracy: 0.3596 - auc: 0.6681 - val_loss: 3.3585 - val_accuracy: 0.5087 - val_auc: 0.7417\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2353 - accuracy: 0.4242 - auc: 0.6866 - val_loss: 1.4902 - val_accuracy: 0.8846 - val_auc: 0.7592\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0114 - accuracy: 0.5509 - auc: 0.7181 - val_loss: 2.9813 - val_accuracy: 0.3530 - val_auc: 0.7479\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2617 - accuracy: 0.3872 - auc: 0.6917 - val_loss: 1.7796 - val_accuracy: 0.9812 - val_auc: 0.7917\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244736/250290 [============================>.] - ETA: 0s - loss: 1.0711 - accuracy: 0.3703 - auc: 0.6796Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0612 - accuracy: 0.3700 - auc: 0.6787 - val_loss: 3.1325 - val_accuracy: 0.4959 - val_auc: 0.7529\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 2.3528 - accuracy: 0.7243 - auc: 0.7558 - val_loss: 2.4196 - val_accuracy: 0.8174 - val_auc: 0.8840\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0898 - accuracy: 0.8019 - auc: 0.7895 - val_loss: 1.5835 - val_accuracy: 0.9147 - val_auc: 0.9112\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.8599 - accuracy: 0.8662 - auc: 0.8293 - val_loss: 2.8013 - val_accuracy: 0.4721 - val_auc: 0.7570\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.3236 - accuracy: 0.8777 - auc: 0.7918 - val_loss: 2.8682 - val_accuracy: 0.9190 - val_auc: 0.8838\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4713 - accuracy: 0.9195 - auc: 0.7830 - val_loss: 2.2914 - val_accuracy: 0.9471 - val_auc: 0.9053\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7774 - accuracy: 0.9250 - auc: 0.8274 - val_loss: 1.5351 - val_accuracy: 0.8945 - val_auc: 0.9125\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5994 - accuracy: 0.9268 - auc: 0.8316 - val_loss: 1.3146 - val_accuracy: 0.9364 - val_auc: 0.9110\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6342 - accuracy: 0.9304 - auc: 0.8325 - val_loss: 1.8091 - val_accuracy: 0.8937 - val_auc: 0.9156\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.4915 - accuracy: 0.8520 - auc: 0.7333 - val_loss: 2.2100 - val_accuracy: 0.9077 - val_auc: 0.7458\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1953 - accuracy: 0.6741 - auc: 0.5993 - val_loss: 2.1701 - val_accuracy: 0.1918 - val_auc: 0.6054\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.9853 - accuracy: 0.5561 - auc: 0.5020 - val_loss: 2.7141 - val_accuracy: 0.0033 - val_auc: 0.5643\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1043 - accuracy: 0.7495 - auc: 0.5485 - val_loss: 2.2035 - val_accuracy: 0.9813 - val_auc: 0.5829\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0309 - accuracy: 0.6629 - auc: 0.5952 - val_loss: 2.9077 - val_accuracy: 0.2320 - val_auc: 0.5732\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9807 - accuracy: 0.2845 - auc: 0.5759 - val_loss: 1.8557 - val_accuracy: 0.3269 - val_auc: 0.6726\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0543 - accuracy: 0.3099 - auc: 0.6078 - val_loss: 2.0372 - val_accuracy: 0.9913 - val_auc: 0.7199\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8135 - accuracy: 0.2762 - auc: 0.6040 - val_loss: 2.0114 - val_accuracy: 0.3704 - val_auc: 0.7054\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6825 - accuracy: 0.3345 - auc: 0.6321 - val_loss: 1.9003 - val_accuracy: 0.4005 - val_auc: 0.7148\n",
      "Epoch 18/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.9341 - accuracy: 0.3316 - auc: 0.6149Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9338 - accuracy: 0.3315 - auc: 0.6148 - val_loss: 2.0546 - val_accuracy: 0.3669 - val_auc: 0.6967\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 2.1327 - accuracy: 0.7150 - auc: 0.7539 - val_loss: 1.1063 - val_accuracy: 0.6735 - val_auc: 0.9014\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6800 - accuracy: 0.7876 - auc: 0.7758 - val_loss: 1.6875 - val_accuracy: 0.8976 - val_auc: 0.8931\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3664 - accuracy: 0.8233 - auc: 0.7784 - val_loss: 1.8349 - val_accuracy: 0.5280 - val_auc: 0.8745\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8803 - accuracy: 0.7412 - auc: 0.7935 - val_loss: 1.1287 - val_accuracy: 0.6318 - val_auc: 0.7866\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1099 - accuracy: 0.7274 - auc: 0.7740 - val_loss: 3.4190 - val_accuracy: 0.6102 - val_auc: 0.8646\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0141 - accuracy: 0.5318 - auc: 0.7908 - val_loss: 2.2389 - val_accuracy: 0.6115 - val_auc: 0.7332\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9456 - accuracy: 0.4469 - auc: 0.7341 - val_loss: 3.2116 - val_accuracy: 0.5638 - val_auc: 0.8386\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2544 - accuracy: 0.4435 - auc: 0.7336 - val_loss: 10.3072 - val_accuracy: 0.5310 - val_auc: 0.7756\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0356 - accuracy: 0.4148 - auc: 0.6842 - val_loss: 3.2481 - val_accuracy: 0.5292 - val_auc: 0.7261\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.7550 - accuracy: 0.4276 - auc: 0.6857 - val_loss: 8.1730 - val_accuracy: 0.6193 - val_auc: 0.7817\n",
      "Epoch 11/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 1.2249 - accuracy: 0.4505 - auc: 0.7033Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2129 - accuracy: 0.4505 - auc: 0.7032 - val_loss: 7.1278 - val_accuracy: 0.5478 - val_auc: 0.7980\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 2.2214 - accuracy: 0.7122 - auc: 0.7608 - val_loss: 1.0624 - val_accuracy: 0.7688 - val_auc: 0.8731\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.8134 - accuracy: 0.8028 - auc: 0.8012 - val_loss: 2.7551 - val_accuracy: 0.9052 - val_auc: 0.8725\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4904 - accuracy: 0.8842 - auc: 0.8003 - val_loss: 1.2753 - val_accuracy: 0.8823 - val_auc: 0.8875\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5459 - accuracy: 0.8143 - auc: 0.7309 - val_loss: 1.3632 - val_accuracy: 0.9470 - val_auc: 0.8337\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.5115 - accuracy: 0.4425 - auc: 0.7080 - val_loss: 1.7345 - val_accuracy: 0.4786 - val_auc: 0.8327\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9186 - accuracy: 0.5930 - auc: 0.7550 - val_loss: 1.2218 - val_accuracy: 0.4254 - val_auc: 0.7389\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7283 - accuracy: 0.4531 - auc: 0.7507 - val_loss: 2.4322 - val_accuracy: 0.5147 - val_auc: 0.8827\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6835 - accuracy: 0.8324 - auc: 0.8043 - val_loss: 1.8401 - val_accuracy: 0.5107 - val_auc: 0.8936\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8599 - accuracy: 0.5147 - auc: 0.7567 - val_loss: 2.5349 - val_accuracy: 0.4963 - val_auc: 0.7686\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7184 - accuracy: 0.4079 - auc: 0.7216 - val_loss: 2.7116 - val_accuracy: 0.5110 - val_auc: 0.7360\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9958 - accuracy: 0.4331 - auc: 0.7406 - val_loss: 4.2624 - val_accuracy: 0.5743 - val_auc: 0.7765\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9618 - accuracy: 0.4713 - auc: 0.7481 - val_loss: 7.2379 - val_accuracy: 0.5904 - val_auc: 0.7686\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7846 - accuracy: 0.4597 - auc: 0.7220 - val_loss: 8.9867 - val_accuracy: 0.5649 - val_auc: 0.7558\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9140 - accuracy: 0.4599 - auc: 0.7161 - val_loss: 6.7379 - val_accuracy: 0.4935 - val_auc: 0.6824\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9563 - accuracy: 0.4347 - auc: 0.7117 - val_loss: 6.4512 - val_accuracy: 0.5818 - val_auc: 0.8159\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8470 - accuracy: 0.4393 - auc: 0.7460 - val_loss: 7.6772 - val_accuracy: 0.5768 - val_auc: 0.7973\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1467 - accuracy: 0.4672 - auc: 0.7510 - val_loss: 18.0192 - val_accuracy: 0.5324 - val_auc: 0.7754\n",
      "Epoch 18/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 1.3139 - accuracy: 0.4177 - auc: 0.7263Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2942 - accuracy: 0.4183 - auc: 0.7262 - val_loss: 25.6179 - val_accuracy: 0.5248 - val_auc: 0.7724\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 2.0269 - accuracy: 0.7015 - auc: 0.7632 - val_loss: 1.3235 - val_accuracy: 0.7648 - val_auc: 0.8923\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4605 - accuracy: 0.8303 - auc: 0.7933 - val_loss: 0.8984 - val_accuracy: 0.8387 - val_auc: 0.8715\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.9369 - accuracy: 0.7832 - auc: 0.7169 - val_loss: 1.9906 - val_accuracy: 0.7513 - val_auc: 0.7798\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2566 - accuracy: 0.9204 - auc: 0.7335 - val_loss: 2.0612 - val_accuracy: 0.9232 - val_auc: 0.8284\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.5232 - accuracy: 0.8808 - auc: 0.7447 - val_loss: 2.1019 - val_accuracy: 0.9287 - val_auc: 0.8526\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.5296 - accuracy: 0.7938 - auc: 0.7217 - val_loss: 4.3502 - val_accuracy: 0.3188 - val_auc: 0.7456\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2314 - accuracy: 0.7202 - auc: 0.7076 - val_loss: 2.9018 - val_accuracy: 0.7654 - val_auc: 0.7900\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4077 - accuracy: 0.5631 - auc: 0.6655 - val_loss: 4.3923 - val_accuracy: 0.3518 - val_auc: 0.7420\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9468 - accuracy: 0.4759 - auc: 0.6924 - val_loss: 4.7908 - val_accuracy: 0.8786 - val_auc: 0.8486\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.1510 - accuracy: 0.6938 - auc: 0.6761 - val_loss: 3.5385 - val_accuracy: 0.2137 - val_auc: 0.6203\n",
      "Epoch 11/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 1.0632 - accuracy: 0.4799 - auc: 0.6390Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1546 - accuracy: 0.4755 - auc: 0.6373 - val_loss: 2.8693 - val_accuracy: 0.0351 - val_auc: 0.5229\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 3.1953 - accuracy: 0.6964 - auc: 0.7481 - val_loss: 3.7000 - val_accuracy: 0.4893 - val_auc: 0.8103\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 5.0216 - accuracy: 0.7460 - auc: 0.7752 - val_loss: 6.3202 - val_accuracy: 0.9433 - val_auc: 0.8169\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 4.5357 - accuracy: 0.7949 - auc: 0.7885 - val_loss: 3.7621 - val_accuracy: 0.8614 - val_auc: 0.7967\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.7469 - accuracy: 0.8636 - auc: 0.7747 - val_loss: 4.7137 - val_accuracy: 0.9454 - val_auc: 0.8613\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.7514 - accuracy: 0.8819 - auc: 0.7746 - val_loss: 3.4369 - val_accuracy: 0.7089 - val_auc: 0.7463\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.8378 - accuracy: 0.8277 - auc: 0.7909 - val_loss: 5.2186 - val_accuracy: 0.8927 - val_auc: 0.8638\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.5791 - accuracy: 0.8337 - auc: 0.7956 - val_loss: 5.6271 - val_accuracy: 0.4782 - val_auc: 0.8315\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.8188 - accuracy: 0.8067 - auc: 0.7803 - val_loss: 5.7676 - val_accuracy: 0.9178 - val_auc: 0.8733\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2821 - accuracy: 0.8075 - auc: 0.7957 - val_loss: 7.7406 - val_accuracy: 0.9344 - val_auc: 0.8601\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.6234 - accuracy: 0.6347 - auc: 0.7676 - val_loss: 5.9174 - val_accuracy: 0.9602 - val_auc: 0.8609\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2953 - accuracy: 0.6765 - auc: 0.7936 - val_loss: 7.7640 - val_accuracy: 0.5033 - val_auc: 0.8404\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1331 - accuracy: 0.5870 - auc: 0.7867 - val_loss: 8.5200 - val_accuracy: 0.5351 - val_auc: 0.8180\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8798 - accuracy: 0.6372 - auc: 0.8040 - val_loss: 6.5011 - val_accuracy: 0.5137 - val_auc: 0.8598\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2419 - accuracy: 0.5142 - auc: 0.7740 - val_loss: 6.5322 - val_accuracy: 0.5518 - val_auc: 0.8536\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8195 - accuracy: 0.4600 - auc: 0.7867 - val_loss: 7.9976 - val_accuracy: 0.9307 - val_auc: 0.8824\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1671 - accuracy: 0.6237 - auc: 0.8146 - val_loss: 12.4615 - val_accuracy: 0.5449 - val_auc: 0.8902\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2876 - accuracy: 0.5826 - auc: 0.7814 - val_loss: 12.6365 - val_accuracy: 0.4966 - val_auc: 0.8520\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0029 - accuracy: 0.4968 - auc: 0.7422 - val_loss: 13.4151 - val_accuracy: 0.5061 - val_auc: 0.7949\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9235 - accuracy: 0.4317 - auc: 0.7297 - val_loss: 16.5793 - val_accuracy: 0.5112 - val_auc: 0.7782\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3903 - accuracy: 0.4297 - auc: 0.7415 - val_loss: 21.1846 - val_accuracy: 0.4987 - val_auc: 0.7646\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9088 - accuracy: 0.3926 - auc: 0.7100 - val_loss: 21.1744 - val_accuracy: 0.5031 - val_auc: 0.7628\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8341 - accuracy: 0.3907 - auc: 0.7187 - val_loss: 12.6172 - val_accuracy: 0.4956 - val_auc: 0.8350\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7857 - accuracy: 0.3888 - auc: 0.7115 - val_loss: 14.5472 - val_accuracy: 0.4998 - val_auc: 0.7624\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6805 - accuracy: 0.3908 - auc: 0.7071 - val_loss: 10.9348 - val_accuracy: 0.4741 - val_auc: 0.7310\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6825 - accuracy: 0.4187 - auc: 0.7074 - val_loss: 12.1676 - val_accuracy: 0.5001 - val_auc: 0.7442\n",
      "Epoch 26/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.6062 - accuracy: 0.4008 - auc: 0.6975Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6047 - accuracy: 0.4008 - auc: 0.6976 - val_loss: 20.8955 - val_accuracy: 0.5108 - val_auc: 0.7441\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 3.8437 - accuracy: 0.6791 - auc: 0.7511 - val_loss: 3.0410 - val_accuracy: 0.8862 - val_auc: 0.8533\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.0444 - accuracy: 0.7587 - auc: 0.7817 - val_loss: 2.5280 - val_accuracy: 0.7095 - val_auc: 0.8542\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.2486 - accuracy: 0.8342 - auc: 0.8184 - val_loss: 2.1055 - val_accuracy: 0.9131 - val_auc: 0.8758\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.3953 - accuracy: 0.8482 - auc: 0.8216 - val_loss: 6.1457 - val_accuracy: 0.9251 - val_auc: 0.8711\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.0989 - accuracy: 0.8354 - auc: 0.7976 - val_loss: 3.9007 - val_accuracy: 0.8353 - val_auc: 0.8888\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6184 - accuracy: 0.8904 - auc: 0.8272 - val_loss: 3.8609 - val_accuracy: 0.9199 - val_auc: 0.8794\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 3.0612 - accuracy: 0.8744 - auc: 0.8167 - val_loss: 3.3235 - val_accuracy: 0.8935 - val_auc: 0.8932\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3519 - accuracy: 0.9073 - auc: 0.8228 - val_loss: 2.7273 - val_accuracy: 0.8875 - val_auc: 0.8756\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7179 - accuracy: 0.9132 - auc: 0.8546 - val_loss: 2.3240 - val_accuracy: 0.9138 - val_auc: 0.9088\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 1.1880 - accuracy: 0.8910 - auc: 0.7933 - val_loss: 3.0894 - val_accuracy: 0.9169 - val_auc: 0.8899\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 1.1738 - accuracy: 0.8612 - auc: 0.7795 - val_loss: 5.2457 - val_accuracy: 0.9449 - val_auc: 0.8764\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.7971 - accuracy: 0.8049 - auc: 0.7732 - val_loss: 4.9991 - val_accuracy: 0.4550 - val_auc: 0.8057\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.7612 - accuracy: 0.4034 - auc: 0.7135 - val_loss: 3.0839 - val_accuracy: 0.4661 - val_auc: 0.7781\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1085 - accuracy: 0.5453 - auc: 0.7442 - val_loss: 5.2660 - val_accuracy: 0.9143 - val_auc: 0.8784\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6910 - accuracy: 0.5549 - auc: 0.7657 - val_loss: 4.4059 - val_accuracy: 0.4897 - val_auc: 0.8792\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7954 - accuracy: 0.5385 - auc: 0.7664 - val_loss: 4.7308 - val_accuracy: 0.9445 - val_auc: 0.8827\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7325 - accuracy: 0.5618 - auc: 0.7605 - val_loss: 5.1571 - val_accuracy: 0.5096 - val_auc: 0.7360\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9912 - accuracy: 0.3803 - auc: 0.6835 - val_loss: 6.0384 - val_accuracy: 0.5032 - val_auc: 0.7267\n",
      "Epoch 19/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 1.1763 - accuracy: 0.4137 - auc: 0.7012Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1738 - accuracy: 0.4137 - auc: 0.7001 - val_loss: 9.1843 - val_accuracy: 0.5470 - val_auc: 0.7623\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 3.5950 - accuracy: 0.6939 - auc: 0.7317 - val_loss: 1.4351 - val_accuracy: 0.7664 - val_auc: 0.8545\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.2118 - accuracy: 0.7712 - auc: 0.7857 - val_loss: 4.0093 - val_accuracy: 0.8239 - val_auc: 0.8467\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.8782 - accuracy: 0.8147 - auc: 0.7787 - val_loss: 1.9589 - val_accuracy: 0.9007 - val_auc: 0.8687\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8951 - accuracy: 0.8548 - auc: 0.8061 - val_loss: 6.2507 - val_accuracy: 0.9261 - val_auc: 0.8911\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5336 - accuracy: 0.9007 - auc: 0.8254 - val_loss: 4.6395 - val_accuracy: 0.9009 - val_auc: 0.9086\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2952 - accuracy: 0.8232 - auc: 0.8056 - val_loss: 3.1569 - val_accuracy: 0.4208 - val_auc: 0.7865\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2710 - accuracy: 0.5122 - auc: 0.7487 - val_loss: 2.2995 - val_accuracy: 0.3874 - val_auc: 0.7148\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1002 - accuracy: 0.4497 - auc: 0.7292 - val_loss: 4.9545 - val_accuracy: 0.5321 - val_auc: 0.7901\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8591 - accuracy: 0.4275 - auc: 0.7229 - val_loss: 3.6161 - val_accuracy: 0.4961 - val_auc: 0.7996\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6771 - accuracy: 0.4187 - auc: 0.7454 - val_loss: 6.7252 - val_accuracy: 0.5340 - val_auc: 0.7564\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4095 - accuracy: 0.3801 - auc: 0.6849 - val_loss: 8.8230 - val_accuracy: 0.4746 - val_auc: 0.7435\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9399 - accuracy: 0.3830 - auc: 0.7121 - val_loss: 8.8820 - val_accuracy: 0.4497 - val_auc: 0.6899\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8204 - accuracy: 0.3585 - auc: 0.6977 - val_loss: 8.0806 - val_accuracy: 0.4779 - val_auc: 0.7400\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8795 - accuracy: 0.3807 - auc: 0.7011 - val_loss: 9.5519 - val_accuracy: 0.4887 - val_auc: 0.7342\n",
      "Epoch 15/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.7514 - accuracy: 0.3791 - auc: 0.6977Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7494 - accuracy: 0.3787 - auc: 0.6980 - val_loss: 9.2591 - val_accuracy: 0.4891 - val_auc: 0.7336\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 3.1313 - accuracy: 0.7070 - auc: 0.7489 - val_loss: 3.8436 - val_accuracy: 0.7694 - val_auc: 0.8029\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.3564 - accuracy: 0.7716 - auc: 0.7861 - val_loss: 4.9502 - val_accuracy: 0.4748 - val_auc: 0.7227\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.2189 - accuracy: 0.7957 - auc: 0.8096 - val_loss: 3.1424 - val_accuracy: 0.8164 - val_auc: 0.8613\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.0338 - accuracy: 0.8455 - auc: 0.7979 - val_loss: 5.3639 - val_accuracy: 0.9236 - val_auc: 0.8773\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 3.3249 - accuracy: 0.8382 - auc: 0.7879 - val_loss: 5.8274 - val_accuracy: 0.8956 - val_auc: 0.8524\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.0972 - accuracy: 0.8534 - auc: 0.7837 - val_loss: 5.3019 - val_accuracy: 0.8732 - val_auc: 0.7649\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4475 - accuracy: 0.7434 - auc: 0.7827 - val_loss: 7.0692 - val_accuracy: 0.8379 - val_auc: 0.8263\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.3949 - accuracy: 0.6702 - auc: 0.7561 - val_loss: 7.5590 - val_accuracy: 0.4792 - val_auc: 0.7881\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9073 - accuracy: 0.4800 - auc: 0.7396 - val_loss: 9.9276 - val_accuracy: 0.4688 - val_auc: 0.7755\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.2134 - accuracy: 0.4330 - auc: 0.7093 - val_loss: 7.8603 - val_accuracy: 0.4560 - val_auc: 0.7401\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8496 - accuracy: 0.4027 - auc: 0.7168 - val_loss: 14.1582 - val_accuracy: 0.4733 - val_auc: 0.7611\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.8759 - accuracy: 0.4623 - auc: 0.7319 - val_loss: 12.7585 - val_accuracy: 0.4946 - val_auc: 0.7632\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0256 - accuracy: 0.4291 - auc: 0.7387 - val_loss: 11.6227 - val_accuracy: 0.4818 - val_auc: 0.7713\n",
      "Epoch 14/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.9190 - accuracy: 0.4460 - auc: 0.7417Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9130 - accuracy: 0.4513 - auc: 0.7425 - val_loss: 9.2302 - val_accuracy: 0.9839 - val_auc: 0.7721\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 4.3853 - accuracy: 0.6560 - auc: 0.7386 - val_loss: 2.7294 - val_accuracy: 0.8002 - val_auc: 0.8533\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.7572 - accuracy: 0.7706 - auc: 0.7820 - val_loss: 2.9656 - val_accuracy: 0.7169 - val_auc: 0.8327\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 3.0983 - accuracy: 0.8261 - auc: 0.7930 - val_loss: 2.0546 - val_accuracy: 0.8293 - val_auc: 0.8318\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.2341 - accuracy: 0.8535 - auc: 0.7892 - val_loss: 1.6548 - val_accuracy: 0.8555 - val_auc: 0.8964\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2590 - accuracy: 0.8717 - auc: 0.8313 - val_loss: 2.6760 - val_accuracy: 0.8904 - val_auc: 0.8753\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1144 - accuracy: 0.8767 - auc: 0.8317 - val_loss: 4.3676 - val_accuracy: 0.8941 - val_auc: 0.8695\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7614 - accuracy: 0.6730 - auc: 0.7909 - val_loss: 5.5805 - val_accuracy: 0.5145 - val_auc: 0.7683\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3591 - accuracy: 0.4829 - auc: 0.7692 - val_loss: 3.3151 - val_accuracy: 0.5521 - val_auc: 0.8397\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9802 - accuracy: 0.6087 - auc: 0.7996 - val_loss: 7.8676 - val_accuracy: 0.5306 - val_auc: 0.8943\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0746 - accuracy: 0.7203 - auc: 0.8263 - val_loss: 4.8639 - val_accuracy: 0.9644 - val_auc: 0.8543\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6696 - accuracy: 0.5053 - auc: 0.7572 - val_loss: 13.0185 - val_accuracy: 0.9737 - val_auc: 0.8180\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1599 - accuracy: 0.4483 - auc: 0.7515 - val_loss: 12.7057 - val_accuracy: 0.5119 - val_auc: 0.8102\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3721 - accuracy: 0.4292 - auc: 0.7467 - val_loss: 10.9244 - val_accuracy: 0.4822 - val_auc: 0.8065\n",
      "Epoch 14/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 1.2483 - accuracy: 0.4231 - auc: 0.7529Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2334 - accuracy: 0.4229 - auc: 0.7543 - val_loss: 14.7870 - val_accuracy: 0.5162 - val_auc: 0.8546\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 4.1724 - accuracy: 0.6909 - auc: 0.7525 - val_loss: 3.0336 - val_accuracy: 0.7139 - val_auc: 0.8308\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 7.4291 - accuracy: 0.7275 - auc: 0.7681 - val_loss: 16.0261 - val_accuracy: 0.7062 - val_auc: 0.8098\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 9.9431 - accuracy: 0.7650 - auc: 0.7910 - val_loss: 9.6664 - val_accuracy: 0.8428 - val_auc: 0.8441\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 7.8343 - accuracy: 0.8141 - auc: 0.8160 - val_loss: 6.7736 - val_accuracy: 0.8851 - val_auc: 0.8428\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 7.6123 - accuracy: 0.8215 - auc: 0.7902 - val_loss: 13.6928 - val_accuracy: 0.9091 - val_auc: 0.8676\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 5.7495 - accuracy: 0.8477 - auc: 0.7810 - val_loss: 5.4530 - val_accuracy: 0.6032 - val_auc: 0.7063\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 6.6515 - accuracy: 0.8064 - auc: 0.7628 - val_loss: 5.5893 - val_accuracy: 0.7350 - val_auc: 0.7376\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.6190 - accuracy: 0.7108 - auc: 0.7827 - val_loss: 10.4993 - val_accuracy: 0.8952 - val_auc: 0.8251\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.2304 - accuracy: 0.5523 - auc: 0.7573 - val_loss: 16.0128 - val_accuracy: 0.5005 - val_auc: 0.8200\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.7473 - accuracy: 0.5749 - auc: 0.7485 - val_loss: 39.4077 - val_accuracy: 0.9448 - val_auc: 0.7891\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 5.6271 - accuracy: 0.5512 - auc: 0.7240 - val_loss: 28.2675 - val_accuracy: 0.4762 - val_auc: 0.7733\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.1353 - accuracy: 0.4848 - auc: 0.7417 - val_loss: 22.6362 - val_accuracy: 0.4876 - val_auc: 0.7860\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0701 - accuracy: 0.4314 - auc: 0.7471 - val_loss: 9.3758 - val_accuracy: 0.4318 - val_auc: 0.7847\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.3239 - accuracy: 0.4717 - auc: 0.7449 - val_loss: 18.8601 - val_accuracy: 0.5039 - val_auc: 0.7912\n",
      "Epoch 15/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 3.6736 - accuracy: 0.4636 - auc: 0.7354Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.6727 - accuracy: 0.4666 - auc: 0.7361 - val_loss: 23.0076 - val_accuracy: 0.9751 - val_auc: 0.8073\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 6.9976 - accuracy: 0.6793 - auc: 0.7625 - val_loss: 4.3592 - val_accuracy: 0.8506 - val_auc: 0.8807\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 8.0732 - accuracy: 0.7711 - auc: 0.7958 - val_loss: 5.1943 - val_accuracy: 0.6486 - val_auc: 0.8403\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.0518 - accuracy: 0.7846 - auc: 0.8059 - val_loss: 4.8659 - val_accuracy: 0.7989 - val_auc: 0.8614\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.5483 - accuracy: 0.8066 - auc: 0.8162 - val_loss: 4.2998 - val_accuracy: 0.6972 - val_auc: 0.8166\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.5635 - accuracy: 0.8480 - auc: 0.8102 - val_loss: 7.8232 - val_accuracy: 0.8137 - val_auc: 0.7997\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.4618 - accuracy: 0.8889 - auc: 0.8203 - val_loss: 6.3793 - val_accuracy: 0.8699 - val_auc: 0.8684\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.6969 - accuracy: 0.9084 - auc: 0.8484 - val_loss: 5.7276 - val_accuracy: 0.8015 - val_auc: 0.8189\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.2736 - accuracy: 0.9054 - auc: 0.8422 - val_loss: 8.9862 - val_accuracy: 0.8636 - val_auc: 0.8752\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8046 - accuracy: 0.8893 - auc: 0.8354 - val_loss: 6.2276 - val_accuracy: 0.9274 - val_auc: 0.8601\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.4637 - accuracy: 0.7785 - auc: 0.7890 - val_loss: 6.3300 - val_accuracy: 0.4328 - val_auc: 0.7439\n",
      "Epoch 11/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 1.9952 - accuracy: 0.4456 - auc: 0.7187Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9922 - accuracy: 0.4501 - auc: 0.7190 - val_loss: 6.6389 - val_accuracy: 0.9234 - val_auc: 0.7611\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 4.4259 - accuracy: 0.6745 - auc: 0.7550 - val_loss: 2.4737 - val_accuracy: 0.6411 - val_auc: 0.8609\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.3357 - accuracy: 0.7482 - auc: 0.7733 - val_loss: 4.3948 - val_accuracy: 0.8149 - val_auc: 0.8389\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 10.0854 - accuracy: 0.7523 - auc: 0.7709 - val_loss: 11.6030 - val_accuracy: 0.8968 - val_auc: 0.8589\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 7.1901 - accuracy: 0.8205 - auc: 0.7940 - val_loss: 6.2656 - val_accuracy: 0.8060 - val_auc: 0.8364\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.6879 - accuracy: 0.8120 - auc: 0.7795 - val_loss: 7.2386 - val_accuracy: 0.8762 - val_auc: 0.8492\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.4275 - accuracy: 0.8957 - auc: 0.7931 - val_loss: 11.7225 - val_accuracy: 0.9184 - val_auc: 0.8577\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.4993 - accuracy: 0.7952 - auc: 0.7962 - val_loss: 7.3421 - val_accuracy: 0.8890 - val_auc: 0.8006\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0537 - accuracy: 0.7132 - auc: 0.7832 - val_loss: 8.0701 - val_accuracy: 0.9415 - val_auc: 0.8139\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.7533 - accuracy: 0.6229 - auc: 0.7553 - val_loss: 20.3413 - val_accuracy: 0.5189 - val_auc: 0.8165\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.8519 - accuracy: 0.4251 - auc: 0.7364 - val_loss: 5.9929 - val_accuracy: 0.3090 - val_auc: 0.7017\n",
      "Epoch 11/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 3.3301 - accuracy: 0.5675 - auc: 0.7474Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.3235 - accuracy: 0.5699 - auc: 0.7462 - val_loss: 20.1672 - val_accuracy: 0.9691 - val_auc: 0.8205\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 6.1031 - accuracy: 0.6769 - auc: 0.7595 - val_loss: 8.7847 - val_accuracy: 0.5219 - val_auc: 0.7422\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 9.5974 - accuracy: 0.7211 - auc: 0.7727 - val_loss: 7.5283 - val_accuracy: 0.6479 - val_auc: 0.8223\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 6.5682 - accuracy: 0.7855 - auc: 0.7958 - val_loss: 3.4056 - val_accuracy: 0.8694 - val_auc: 0.8776\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 7.3317 - accuracy: 0.7896 - auc: 0.8030 - val_loss: 5.7805 - val_accuracy: 0.7851 - val_auc: 0.8622\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.8731 - accuracy: 0.8396 - auc: 0.8115 - val_loss: 3.2979 - val_accuracy: 0.7755 - val_auc: 0.8269\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.4253 - accuracy: 0.8691 - auc: 0.8056 - val_loss: 10.3209 - val_accuracy: 0.8918 - val_auc: 0.8895\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.7465 - accuracy: 0.8844 - auc: 0.8107 - val_loss: 6.6995 - val_accuracy: 0.8559 - val_auc: 0.8480\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8293 - accuracy: 0.8799 - auc: 0.8117 - val_loss: 8.1065 - val_accuracy: 0.9060 - val_auc: 0.8396\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.3791 - accuracy: 0.7800 - auc: 0.7859 - val_loss: 23.5931 - val_accuracy: 0.5050 - val_auc: 0.8269\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.4506 - accuracy: 0.5897 - auc: 0.7600 - val_loss: 9.3027 - val_accuracy: 0.9425 - val_auc: 0.7768\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8079 - accuracy: 0.4712 - auc: 0.7434 - val_loss: 8.2010 - val_accuracy: 0.4497 - val_auc: 0.7386\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 7.1424 - accuracy: 0.5562 - auc: 0.7165 - val_loss: 17.7206 - val_accuracy: 0.4434 - val_auc: 0.8081\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3676 - accuracy: 0.5133 - auc: 0.7487 - val_loss: 16.4725 - val_accuracy: 0.9753 - val_auc: 0.8222\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.8392 - accuracy: 0.6358 - auc: 0.7597 - val_loss: 16.1175 - val_accuracy: 0.4455 - val_auc: 0.8196\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9414 - accuracy: 0.5422 - auc: 0.7615 - val_loss: 18.0625 - val_accuracy: 0.9665 - val_auc: 0.8379\n",
      "Epoch 16/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 1.0587 - accuracy: 0.6559 - auc: 0.7519Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0607 - accuracy: 0.6553 - auc: 0.7517 - val_loss: 18.9510 - val_accuracy: 0.4363 - val_auc: 0.8213\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 5.4942 - accuracy: 0.6600 - auc: 0.7453 - val_loss: 5.3417 - val_accuracy: 0.7081 - val_auc: 0.8177\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 8.7988 - accuracy: 0.7383 - auc: 0.7697 - val_loss: 6.0851 - val_accuracy: 0.6589 - val_auc: 0.8311\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 7.2497 - accuracy: 0.7608 - auc: 0.7809 - val_loss: 3.7420 - val_accuracy: 0.8889 - val_auc: 0.8905\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 5.3465 - accuracy: 0.8157 - auc: 0.7976 - val_loss: 2.6891 - val_accuracy: 0.8267 - val_auc: 0.8750\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.7118 - accuracy: 0.8243 - auc: 0.7790 - val_loss: 6.8637 - val_accuracy: 0.8786 - val_auc: 0.8642\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.3205 - accuracy: 0.8707 - auc: 0.8152 - val_loss: 7.9038 - val_accuracy: 0.8722 - val_auc: 0.8479\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 3.1949 - accuracy: 0.8674 - auc: 0.7784 - val_loss: 8.7844 - val_accuracy: 0.9578 - val_auc: 0.8470\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.3012 - accuracy: 0.8450 - auc: 0.8018 - val_loss: 4.3324 - val_accuracy: 0.8790 - val_auc: 0.8808\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6072 - accuracy: 0.9123 - auc: 0.8149 - val_loss: 4.0934 - val_accuracy: 0.8561 - val_auc: 0.8387\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 2.4656 - accuracy: 0.8112 - auc: 0.7714 - val_loss: 7.9291 - val_accuracy: 0.9491 - val_auc: 0.8618\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4380 - accuracy: 0.7598 - auc: 0.7806 - val_loss: 3.0121 - val_accuracy: 0.4913 - val_auc: 0.8788\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.9869 - accuracy: 0.7355 - auc: 0.7797 - val_loss: 7.2645 - val_accuracy: 0.9567 - val_auc: 0.8532\n",
      "Epoch 13/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 1.4932 - accuracy: 0.5724 - auc: 0.7361Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4913 - accuracy: 0.5720 - auc: 0.7362 - val_loss: 9.5382 - val_accuracy: 0.4505 - val_auc: 0.7539\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.5997 - accuracy: 0.8566 - auc: 0.8052 - val_loss: 0.3465 - val_accuracy: 0.8971 - val_auc: 0.9387\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4131 - accuracy: 0.8923 - auc: 0.8999 - val_loss: 0.3240 - val_accuracy: 0.9034 - val_auc: 0.9410\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3870 - accuracy: 0.9043 - auc: 0.9158 - val_loss: 0.3189 - val_accuracy: 0.8862 - val_auc: 0.9400\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4005 - accuracy: 0.8973 - auc: 0.9088 - val_loss: 0.3503 - val_accuracy: 0.8999 - val_auc: 0.9272\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3871 - accuracy: 0.9011 - auc: 0.9168 - val_loss: 0.3303 - val_accuracy: 0.8930 - val_auc: 0.9346\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3670 - accuracy: 0.8996 - auc: 0.9257 - val_loss: 0.3416 - val_accuracy: 0.9258 - val_auc: 0.9341\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3585 - accuracy: 0.9034 - auc: 0.9307 - val_loss: 0.3373 - val_accuracy: 0.9124 - val_auc: 0.9322\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3537 - accuracy: 0.9011 - auc: 0.9294 - val_loss: 0.3460 - val_accuracy: 0.9058 - val_auc: 0.9294\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3392 - accuracy: 0.9022 - auc: 0.9361 - val_loss: 0.3525 - val_accuracy: 0.8913 - val_auc: 0.9298\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3383 - accuracy: 0.8973 - auc: 0.9359 - val_loss: 0.3708 - val_accuracy: 0.9151 - val_auc: 0.9274\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3426 - accuracy: 0.9002 - auc: 0.9354 - val_loss: 0.3899 - val_accuracy: 0.8741 - val_auc: 0.9289\n",
      "Epoch 12/100\n",
      "242688/250290 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.9001 - auc: 0.9423Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3244 - accuracy: 0.9002 - auc: 0.9418 - val_loss: 0.3701 - val_accuracy: 0.8986 - val_auc: 0.9318\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.6043 - accuracy: 0.8341 - auc: 0.8234 - val_loss: 0.3835 - val_accuracy: 0.8763 - val_auc: 0.9290\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4186 - accuracy: 0.8949 - auc: 0.9017 - val_loss: 0.3395 - val_accuracy: 0.9104 - val_auc: 0.9406\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3893 - accuracy: 0.9059 - auc: 0.9141 - val_loss: 0.3374 - val_accuracy: 0.8998 - val_auc: 0.9298\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3863 - accuracy: 0.9086 - auc: 0.9120 - val_loss: 0.3373 - val_accuracy: 0.9058 - val_auc: 0.9319\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3796 - accuracy: 0.9071 - auc: 0.9197 - val_loss: 0.3377 - val_accuracy: 0.9004 - val_auc: 0.9286\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3716 - accuracy: 0.9043 - auc: 0.9223 - val_loss: 0.3231 - val_accuracy: 0.9146 - val_auc: 0.9362\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3514 - accuracy: 0.9072 - auc: 0.9306 - val_loss: 0.3319 - val_accuracy: 0.8860 - val_auc: 0.9385\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3405 - accuracy: 0.9047 - auc: 0.9354 - val_loss: 0.3475 - val_accuracy: 0.9159 - val_auc: 0.9323\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3453 - accuracy: 0.9003 - auc: 0.9344 - val_loss: 0.3385 - val_accuracy: 0.8989 - val_auc: 0.9368\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3346 - accuracy: 0.9010 - auc: 0.9372 - val_loss: 0.3440 - val_accuracy: 0.9044 - val_auc: 0.9355\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3395 - accuracy: 0.9006 - auc: 0.9370 - val_loss: 0.3487 - val_accuracy: 0.8965 - val_auc: 0.9354\n",
      "Epoch 12/100\n",
      "242688/250290 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.9039 - auc: 0.9356Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3332 - accuracy: 0.9041 - auc: 0.9364 - val_loss: 0.3884 - val_accuracy: 0.9156 - val_auc: 0.9328\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5382 - accuracy: 0.8474 - auc: 0.8398 - val_loss: 0.3631 - val_accuracy: 0.9101 - val_auc: 0.9348\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4004 - accuracy: 0.8983 - auc: 0.9072 - val_loss: 0.3391 - val_accuracy: 0.8760 - val_auc: 0.9452\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3828 - accuracy: 0.9044 - auc: 0.9169 - val_loss: 0.3385 - val_accuracy: 0.8988 - val_auc: 0.9356\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3728 - accuracy: 0.9046 - auc: 0.9195 - val_loss: 0.3278 - val_accuracy: 0.9022 - val_auc: 0.9362\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3740 - accuracy: 0.9012 - auc: 0.9205 - val_loss: 0.3236 - val_accuracy: 0.9070 - val_auc: 0.9357\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3494 - accuracy: 0.9031 - auc: 0.9290 - val_loss: 0.3380 - val_accuracy: 0.8871 - val_auc: 0.9310\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3508 - accuracy: 0.8993 - auc: 0.9305 - val_loss: 0.3337 - val_accuracy: 0.9171 - val_auc: 0.9334\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3434 - accuracy: 0.9014 - auc: 0.9331 - val_loss: 0.3280 - val_accuracy: 0.9048 - val_auc: 0.9363\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3331 - accuracy: 0.9014 - auc: 0.9359 - val_loss: 0.3393 - val_accuracy: 0.9096 - val_auc: 0.9346\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3481 - accuracy: 0.8999 - auc: 0.9308 - val_loss: 0.3281 - val_accuracy: 0.9077 - val_auc: 0.9405\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3308 - accuracy: 0.9054 - auc: 0.9370 - val_loss: 0.3545 - val_accuracy: 0.8857 - val_auc: 0.9328\n",
      "Epoch 12/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.3318 - accuracy: 0.8976 - auc: 0.9384Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3319 - accuracy: 0.8977 - auc: 0.9385 - val_loss: 0.3484 - val_accuracy: 0.9079 - val_auc: 0.9356\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5083 - accuracy: 0.7031 - auc: 0.8534 - val_loss: 0.3393 - val_accuracy: 0.8702 - val_auc: 0.9380\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3719 - accuracy: 0.8859 - auc: 0.9194 - val_loss: 0.3290 - val_accuracy: 0.9018 - val_auc: 0.9377\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3680 - accuracy: 0.8945 - auc: 0.9207 - val_loss: 0.3284 - val_accuracy: 0.9105 - val_auc: 0.9369\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3489 - accuracy: 0.8942 - auc: 0.9311 - val_loss: 0.3104 - val_accuracy: 0.8842 - val_auc: 0.9423\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3466 - accuracy: 0.8984 - auc: 0.9305 - val_loss: 0.3164 - val_accuracy: 0.8958 - val_auc: 0.9399\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3343 - accuracy: 0.8970 - auc: 0.9376 - val_loss: 0.3138 - val_accuracy: 0.8983 - val_auc: 0.9411\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3250 - accuracy: 0.8936 - auc: 0.9364 - val_loss: 0.3275 - val_accuracy: 0.8891 - val_auc: 0.9386\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3244 - accuracy: 0.8859 - auc: 0.9379 - val_loss: 0.3367 - val_accuracy: 0.8930 - val_auc: 0.9367\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3155 - accuracy: 0.8907 - auc: 0.9419 - val_loss: 0.3642 - val_accuracy: 0.8917 - val_auc: 0.9341\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3132 - accuracy: 0.8920 - auc: 0.9418 - val_loss: 0.3710 - val_accuracy: 0.8753 - val_auc: 0.9330\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3214 - accuracy: 0.8929 - auc: 0.9408 - val_loss: 0.3745 - val_accuracy: 0.8890 - val_auc: 0.9328\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3053 - accuracy: 0.8912 - auc: 0.9440 - val_loss: 0.3860 - val_accuracy: 0.8922 - val_auc: 0.9352\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3128 - accuracy: 0.8959 - auc: 0.9424 - val_loss: 0.3950 - val_accuracy: 0.8860 - val_auc: 0.9321\n",
      "Epoch 14/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.8906 - auc: 0.9439Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3094 - accuracy: 0.8912 - auc: 0.9444 - val_loss: 0.4403 - val_accuracy: 0.9144 - val_auc: 0.9307\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.5822 - accuracy: 0.8526 - auc: 0.8009 - val_loss: 0.3502 - val_accuracy: 0.9017 - val_auc: 0.9414\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4303 - accuracy: 0.8946 - auc: 0.8943 - val_loss: 0.3329 - val_accuracy: 0.8895 - val_auc: 0.9397\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3889 - accuracy: 0.8986 - auc: 0.9179 - val_loss: 0.3217 - val_accuracy: 0.9088 - val_auc: 0.9413\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3710 - accuracy: 0.9044 - auc: 0.9246 - val_loss: 0.3203 - val_accuracy: 0.8766 - val_auc: 0.9431\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3767 - accuracy: 0.8984 - auc: 0.9232 - val_loss: 0.3216 - val_accuracy: 0.8924 - val_auc: 0.9443\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3554 - accuracy: 0.9046 - auc: 0.9335 - val_loss: 0.3047 - val_accuracy: 0.9228 - val_auc: 0.9445\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3524 - accuracy: 0.9042 - auc: 0.9338 - val_loss: 0.3141 - val_accuracy: 0.8955 - val_auc: 0.9404\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3569 - accuracy: 0.9023 - auc: 0.9305 - val_loss: 0.3173 - val_accuracy: 0.9043 - val_auc: 0.9390\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3591 - accuracy: 0.9026 - auc: 0.9308 - val_loss: 0.3337 - val_accuracy: 0.8769 - val_auc: 0.9378\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3533 - accuracy: 0.9034 - auc: 0.9316 - val_loss: 0.3096 - val_accuracy: 0.9101 - val_auc: 0.9415\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3591 - accuracy: 0.9011 - auc: 0.9309 - val_loss: 0.3445 - val_accuracy: 0.8947 - val_auc: 0.9346\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3432 - accuracy: 0.9074 - auc: 0.9371 - val_loss: 0.3328 - val_accuracy: 0.8897 - val_auc: 0.9365\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3363 - accuracy: 0.9039 - auc: 0.9384 - val_loss: 0.3236 - val_accuracy: 0.9057 - val_auc: 0.9379\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3461 - accuracy: 0.9057 - auc: 0.9351 - val_loss: 0.3324 - val_accuracy: 0.9077 - val_auc: 0.9361\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3471 - accuracy: 0.9082 - auc: 0.9332 - val_loss: 0.3718 - val_accuracy: 0.8928 - val_auc: 0.9326\n",
      "Epoch 16/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.3338 - accuracy: 0.9024 - auc: 0.9388Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3323 - accuracy: 0.9027 - auc: 0.9395 - val_loss: 0.3753 - val_accuracy: 0.9106 - val_auc: 0.9345\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5178 - accuracy: 0.7400 - auc: 0.8610 - val_loss: 0.3472 - val_accuracy: 0.8608 - val_auc: 0.9317\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3730 - accuracy: 0.8648 - auc: 0.9216 - val_loss: 0.3129 - val_accuracy: 0.9073 - val_auc: 0.9434\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3578 - accuracy: 0.8804 - auc: 0.9275 - val_loss: 0.3315 - val_accuracy: 0.8934 - val_auc: 0.9341\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3488 - accuracy: 0.8906 - auc: 0.9300 - val_loss: 0.3457 - val_accuracy: 0.8889 - val_auc: 0.9313\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3268 - accuracy: 0.8895 - auc: 0.9396 - val_loss: 0.3292 - val_accuracy: 0.8891 - val_auc: 0.9360\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3233 - accuracy: 0.8908 - auc: 0.9420 - val_loss: 0.3339 - val_accuracy: 0.8578 - val_auc: 0.9419\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3171 - accuracy: 0.8904 - auc: 0.9435 - val_loss: 0.3561 - val_accuracy: 0.9070 - val_auc: 0.9336\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3183 - accuracy: 0.8912 - auc: 0.9437 - val_loss: 0.3678 - val_accuracy: 0.9092 - val_auc: 0.9282\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3082 - accuracy: 0.8907 - auc: 0.9466 - val_loss: 0.4246 - val_accuracy: 0.8934 - val_auc: 0.9250\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3183 - accuracy: 0.8910 - auc: 0.9442 - val_loss: 0.3940 - val_accuracy: 0.9081 - val_auc: 0.9287\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3318 - accuracy: 0.8908 - auc: 0.9399 - val_loss: 0.3548 - val_accuracy: 0.8960 - val_auc: 0.9359\n",
      "Epoch 12/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2995 - accuracy: 0.8952 - auc: 0.9501Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2985 - accuracy: 0.8954 - auc: 0.9503 - val_loss: 0.4179 - val_accuracy: 0.9151 - val_auc: 0.9264\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5204 - accuracy: 0.7055 - auc: 0.8616 - val_loss: 0.3413 - val_accuracy: 0.8458 - val_auc: 0.9424\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3697 - accuracy: 0.8781 - auc: 0.9232 - val_loss: 0.3116 - val_accuracy: 0.8812 - val_auc: 0.9413\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3459 - accuracy: 0.8837 - auc: 0.9309 - val_loss: 0.3217 - val_accuracy: 0.8941 - val_auc: 0.9385\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3420 - accuracy: 0.8859 - auc: 0.9327 - val_loss: 0.3430 - val_accuracy: 0.8721 - val_auc: 0.9306\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3449 - accuracy: 0.8885 - auc: 0.9348 - val_loss: 0.3442 - val_accuracy: 0.8798 - val_auc: 0.9331\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3173 - accuracy: 0.8918 - auc: 0.9418 - val_loss: 0.3867 - val_accuracy: 0.8793 - val_auc: 0.9264\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3315 - accuracy: 0.8854 - auc: 0.9372 - val_loss: 0.3574 - val_accuracy: 0.8845 - val_auc: 0.9288\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3065 - accuracy: 0.8915 - auc: 0.9472 - val_loss: 0.3996 - val_accuracy: 0.8819 - val_auc: 0.9254\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3207 - accuracy: 0.8916 - auc: 0.9426 - val_loss: 0.4023 - val_accuracy: 0.8762 - val_auc: 0.9268\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3057 - accuracy: 0.8918 - auc: 0.9469 - val_loss: 0.3864 - val_accuracy: 0.8774 - val_auc: 0.9292\n",
      "Epoch 11/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3057 - accuracy: 0.8928 - auc: 0.9475Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3054 - accuracy: 0.8924 - auc: 0.9475 - val_loss: 0.4332 - val_accuracy: 0.8748 - val_auc: 0.9258\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5286 - accuracy: 0.6811 - auc: 0.8557 - val_loss: 0.3362 - val_accuracy: 0.8401 - val_auc: 0.9404\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3747 - accuracy: 0.8515 - auc: 0.9166 - val_loss: 0.3290 - val_accuracy: 0.8747 - val_auc: 0.9359\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3496 - accuracy: 0.8787 - auc: 0.9286 - val_loss: 0.3138 - val_accuracy: 0.8802 - val_auc: 0.9400\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3273 - accuracy: 0.8791 - auc: 0.9378 - val_loss: 0.3488 - val_accuracy: 0.8714 - val_auc: 0.9321\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3285 - accuracy: 0.8773 - auc: 0.9388 - val_loss: 0.3418 - val_accuracy: 0.9014 - val_auc: 0.9334\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3341 - accuracy: 0.8810 - auc: 0.9364 - val_loss: 0.3575 - val_accuracy: 0.8983 - val_auc: 0.9295\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3210 - accuracy: 0.8833 - auc: 0.9394 - val_loss: 0.3403 - val_accuracy: 0.8903 - val_auc: 0.9320\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3249 - accuracy: 0.8881 - auc: 0.9382 - val_loss: 0.3433 - val_accuracy: 0.8859 - val_auc: 0.9338\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3020 - accuracy: 0.8894 - auc: 0.9472 - val_loss: 0.3689 - val_accuracy: 0.8857 - val_auc: 0.9279\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3122 - accuracy: 0.8870 - auc: 0.9445 - val_loss: 0.3717 - val_accuracy: 0.8939 - val_auc: 0.9310\n",
      "Epoch 11/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3085 - accuracy: 0.8853 - auc: 0.9439Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3082 - accuracy: 0.8852 - auc: 0.9439 - val_loss: 0.3944 - val_accuracy: 0.8777 - val_auc: 0.9309\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5708 - accuracy: 0.8440 - auc: 0.8318 - val_loss: 0.3438 - val_accuracy: 0.8988 - val_auc: 0.9327\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3666 - accuracy: 0.8949 - auc: 0.9244 - val_loss: 0.3253 - val_accuracy: 0.9047 - val_auc: 0.9367\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3722 - accuracy: 0.8996 - auc: 0.9239 - val_loss: 0.3301 - val_accuracy: 0.8926 - val_auc: 0.9393\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3688 - accuracy: 0.8999 - auc: 0.9287 - val_loss: 0.3245 - val_accuracy: 0.9158 - val_auc: 0.9406\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3775 - accuracy: 0.8932 - auc: 0.9228 - val_loss: 0.3717 - val_accuracy: 0.8487 - val_auc: 0.9397\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3502 - accuracy: 0.8995 - auc: 0.9354 - val_loss: 0.3286 - val_accuracy: 0.9139 - val_auc: 0.9334\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3389 - accuracy: 0.9017 - auc: 0.9380 - val_loss: 0.3346 - val_accuracy: 0.8925 - val_auc: 0.9332\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3321 - accuracy: 0.9053 - auc: 0.9401 - val_loss: 0.3674 - val_accuracy: 0.9508 - val_auc: 0.9302\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3403 - accuracy: 0.8991 - auc: 0.9434 - val_loss: 0.3101 - val_accuracy: 0.8981 - val_auc: 0.9447\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3277 - accuracy: 0.9030 - auc: 0.9415 - val_loss: 0.3560 - val_accuracy: 0.8886 - val_auc: 0.9308\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3108 - accuracy: 0.9033 - auc: 0.9467 - val_loss: 0.3894 - val_accuracy: 0.8890 - val_auc: 0.9292\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3033 - accuracy: 0.9015 - auc: 0.9491 - val_loss: 0.3939 - val_accuracy: 0.8860 - val_auc: 0.9307\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2967 - accuracy: 0.9001 - auc: 0.9509 - val_loss: 0.4025 - val_accuracy: 0.9197 - val_auc: 0.9301\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3158 - accuracy: 0.8997 - auc: 0.9451 - val_loss: 0.3979 - val_accuracy: 0.8797 - val_auc: 0.9291\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2990 - accuracy: 0.8972 - auc: 0.9504 - val_loss: 0.3979 - val_accuracy: 0.9177 - val_auc: 0.9296\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3044 - accuracy: 0.9020 - auc: 0.9489 - val_loss: 0.3739 - val_accuracy: 0.9022 - val_auc: 0.9319\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2886 - accuracy: 0.9008 - auc: 0.9538 - val_loss: 0.4154 - val_accuracy: 0.9194 - val_auc: 0.9308\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2995 - accuracy: 0.8994 - auc: 0.9498 - val_loss: 0.4208 - val_accuracy: 0.9003 - val_auc: 0.9305\n",
      "Epoch 19/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.8977 - auc: 0.9505Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3065 - accuracy: 0.8980 - auc: 0.9504 - val_loss: 0.3965 - val_accuracy: 0.9062 - val_auc: 0.9322\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.5256 - accuracy: 0.7645 - auc: 0.8607 - val_loss: 0.3513 - val_accuracy: 0.8737 - val_auc: 0.9321\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3840 - accuracy: 0.8751 - auc: 0.9183 - val_loss: 0.3212 - val_accuracy: 0.8871 - val_auc: 0.9394\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3639 - accuracy: 0.8849 - auc: 0.9269 - val_loss: 0.3511 - val_accuracy: 0.8586 - val_auc: 0.9357\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3570 - accuracy: 0.8907 - auc: 0.9294 - val_loss: 0.3173 - val_accuracy: 0.9105 - val_auc: 0.9388\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3513 - accuracy: 0.8927 - auc: 0.9337 - val_loss: 0.3453 - val_accuracy: 0.8783 - val_auc: 0.9337\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3252 - accuracy: 0.8940 - auc: 0.9412 - val_loss: 0.3666 - val_accuracy: 0.8984 - val_auc: 0.9318\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3327 - accuracy: 0.8921 - auc: 0.9380 - val_loss: 0.3582 - val_accuracy: 0.9342 - val_auc: 0.9300\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3187 - accuracy: 0.8948 - auc: 0.9436 - val_loss: 0.3719 - val_accuracy: 0.9024 - val_auc: 0.9309\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3101 - accuracy: 0.8908 - auc: 0.9452 - val_loss: 0.4074 - val_accuracy: 0.8986 - val_auc: 0.9314\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3016 - accuracy: 0.8880 - auc: 0.9488 - val_loss: 0.4320 - val_accuracy: 0.9178 - val_auc: 0.9293\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3037 - accuracy: 0.8963 - auc: 0.9487 - val_loss: 0.4291 - val_accuracy: 0.8432 - val_auc: 0.9297\n",
      "Epoch 12/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3084 - accuracy: 0.8867 - auc: 0.9464Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3085 - accuracy: 0.8871 - auc: 0.9462 - val_loss: 0.4111 - val_accuracy: 0.9090 - val_auc: 0.9341\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5815 - accuracy: 0.8418 - auc: 0.8444 - val_loss: 0.3777 - val_accuracy: 0.8731 - val_auc: 0.9278\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3734 - accuracy: 0.8902 - auc: 0.9259 - val_loss: 0.3761 - val_accuracy: 0.9233 - val_auc: 0.9223\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3609 - accuracy: 0.8937 - auc: 0.9324 - val_loss: 0.3195 - val_accuracy: 0.9008 - val_auc: 0.9427\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3489 - accuracy: 0.8957 - auc: 0.9339 - val_loss: 0.3409 - val_accuracy: 0.9246 - val_auc: 0.9309\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3554 - accuracy: 0.8965 - auc: 0.9325 - val_loss: 0.3423 - val_accuracy: 0.8717 - val_auc: 0.9361\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3743 - accuracy: 0.8887 - auc: 0.9344 - val_loss: 0.3650 - val_accuracy: 0.9056 - val_auc: 0.9241\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3533 - accuracy: 0.8989 - auc: 0.9368 - val_loss: 0.3633 - val_accuracy: 0.8678 - val_auc: 0.9337\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3351 - accuracy: 0.8941 - auc: 0.9413 - val_loss: 0.3707 - val_accuracy: 0.8982 - val_auc: 0.9255\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3353 - accuracy: 0.8975 - auc: 0.9417 - val_loss: 0.3473 - val_accuracy: 0.8990 - val_auc: 0.9327\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3293 - accuracy: 0.9007 - auc: 0.9430 - val_loss: 0.3472 - val_accuracy: 0.8862 - val_auc: 0.9335\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3220 - accuracy: 0.8985 - auc: 0.9451 - val_loss: 0.3401 - val_accuracy: 0.8874 - val_auc: 0.9341\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3344 - accuracy: 0.8953 - auc: 0.9416 - val_loss: 0.3684 - val_accuracy: 0.8998 - val_auc: 0.9289\n",
      "Epoch 13/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3146 - accuracy: 0.8991 - auc: 0.9485Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3143 - accuracy: 0.8992 - auc: 0.9485 - val_loss: 0.3769 - val_accuracy: 0.9191 - val_auc: 0.9293\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5105 - accuracy: 0.7342 - auc: 0.8670 - val_loss: 0.3245 - val_accuracy: 0.8757 - val_auc: 0.9377\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3687 - accuracy: 0.8425 - auc: 0.9240 - val_loss: 0.3516 - val_accuracy: 0.8228 - val_auc: 0.9313\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3428 - accuracy: 0.8656 - auc: 0.9328 - val_loss: 0.3431 - val_accuracy: 0.8875 - val_auc: 0.9349\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3312 - accuracy: 0.8722 - auc: 0.9370 - val_loss: 0.3502 - val_accuracy: 0.8920 - val_auc: 0.9300\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3260 - accuracy: 0.8715 - auc: 0.9414 - val_loss: 0.3534 - val_accuracy: 0.8880 - val_auc: 0.9384\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3269 - accuracy: 0.8785 - auc: 0.9407 - val_loss: 0.3596 - val_accuracy: 0.8749 - val_auc: 0.9363\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3348 - accuracy: 0.8787 - auc: 0.9399 - val_loss: 0.3744 - val_accuracy: 0.8641 - val_auc: 0.9291\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3367 - accuracy: 0.8733 - auc: 0.9429 - val_loss: 0.4156 - val_accuracy: 0.8783 - val_auc: 0.9309\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3320 - accuracy: 0.8733 - auc: 0.9418 - val_loss: 0.3993 - val_accuracy: 0.8933 - val_auc: 0.9279\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3067 - accuracy: 0.8874 - auc: 0.9481 - val_loss: 0.4320 - val_accuracy: 0.8902 - val_auc: 0.9314\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2961 - accuracy: 0.8847 - auc: 0.9514 - val_loss: 0.4565 - val_accuracy: 0.8858 - val_auc: 0.9275\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3060 - accuracy: 0.8832 - auc: 0.9494 - val_loss: 0.4682 - val_accuracy: 0.9058 - val_auc: 0.9253\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3016 - accuracy: 0.8827 - auc: 0.9513 - val_loss: 0.5103 - val_accuracy: 0.9065 - val_auc: 0.9239\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3023 - accuracy: 0.8878 - auc: 0.9500 - val_loss: 0.4794 - val_accuracy: 0.8777 - val_auc: 0.9262\n",
      "Epoch 15/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8773 - auc: 0.9498Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3046 - accuracy: 0.8775 - auc: 0.9499 - val_loss: 0.5296 - val_accuracy: 0.9004 - val_auc: 0.9259\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.5060 - accuracy: 0.7942 - auc: 0.8643 - val_loss: 0.3181 - val_accuracy: 0.8802 - val_auc: 0.9429\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3762 - accuracy: 0.8708 - auc: 0.9208 - val_loss: 0.3220 - val_accuracy: 0.8900 - val_auc: 0.9373\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3439 - accuracy: 0.8807 - auc: 0.9300 - val_loss: 0.3397 - val_accuracy: 0.8714 - val_auc: 0.9320\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3449 - accuracy: 0.8815 - auc: 0.9338 - val_loss: 0.3094 - val_accuracy: 0.8730 - val_auc: 0.9431\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3241 - accuracy: 0.8858 - auc: 0.9385 - val_loss: 0.3472 - val_accuracy: 0.9183 - val_auc: 0.9314\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3196 - accuracy: 0.8879 - auc: 0.9409 - val_loss: 0.3670 - val_accuracy: 0.8691 - val_auc: 0.9381\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3171 - accuracy: 0.8922 - auc: 0.9436 - val_loss: 0.3475 - val_accuracy: 0.8859 - val_auc: 0.9326\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3107 - accuracy: 0.8849 - auc: 0.9441 - val_loss: 0.3337 - val_accuracy: 0.8841 - val_auc: 0.9392\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3066 - accuracy: 0.8891 - auc: 0.9464 - val_loss: 0.4037 - val_accuracy: 0.8969 - val_auc: 0.9253\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3002 - accuracy: 0.8900 - auc: 0.9478 - val_loss: 0.3646 - val_accuracy: 0.8814 - val_auc: 0.9316\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3075 - accuracy: 0.8866 - auc: 0.9462 - val_loss: 0.3786 - val_accuracy: 0.8916 - val_auc: 0.9294\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2957 - accuracy: 0.8928 - auc: 0.9501 - val_loss: 0.3911 - val_accuracy: 0.8946 - val_auc: 0.9281\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2744 - accuracy: 0.8925 - auc: 0.9561 - val_loss: 0.4867 - val_accuracy: 0.9135 - val_auc: 0.9253\n",
      "Epoch 14/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2964 - accuracy: 0.8906 - auc: 0.9506Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2969 - accuracy: 0.8906 - auc: 0.9504 - val_loss: 0.4827 - val_accuracy: 0.8886 - val_auc: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 0.5322 - accuracy: 0.7051 - auc: 0.8677 - val_loss: 0.3349 - val_accuracy: 0.8625 - val_auc: 0.9339\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3761 - accuracy: 0.8120 - auc: 0.9220 - val_loss: 0.3114 - val_accuracy: 0.8740 - val_auc: 0.9433\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3332 - accuracy: 0.8545 - auc: 0.9342 - val_loss: 0.3168 - val_accuracy: 0.8676 - val_auc: 0.9417\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3132 - accuracy: 0.8699 - auc: 0.9426 - val_loss: 0.3139 - val_accuracy: 0.8689 - val_auc: 0.9444\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3346 - accuracy: 0.8684 - auc: 0.9367 - val_loss: 0.2945 - val_accuracy: 0.8702 - val_auc: 0.9481\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3172 - accuracy: 0.8764 - auc: 0.9418 - val_loss: 0.3229 - val_accuracy: 0.8974 - val_auc: 0.9402\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3288 - accuracy: 0.8837 - auc: 0.9408 - val_loss: 0.3209 - val_accuracy: 0.8827 - val_auc: 0.9416\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3063 - accuracy: 0.8856 - auc: 0.9464 - val_loss: 0.3341 - val_accuracy: 0.8861 - val_auc: 0.9380\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3097 - accuracy: 0.8815 - auc: 0.9457 - val_loss: 0.3704 - val_accuracy: 0.9214 - val_auc: 0.9329\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3122 - accuracy: 0.8873 - auc: 0.9465 - val_loss: 0.3934 - val_accuracy: 0.8909 - val_auc: 0.9345\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2932 - accuracy: 0.8901 - auc: 0.9507 - val_loss: 0.3858 - val_accuracy: 0.8782 - val_auc: 0.9346\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2833 - accuracy: 0.8909 - auc: 0.9531 - val_loss: 0.4224 - val_accuracy: 0.8818 - val_auc: 0.9319\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2908 - accuracy: 0.8844 - auc: 0.9514 - val_loss: 0.4326 - val_accuracy: 0.9069 - val_auc: 0.9318\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3141 - accuracy: 0.8860 - auc: 0.9466 - val_loss: 0.3633 - val_accuracy: 0.8918 - val_auc: 0.9337\n",
      "Epoch 15/100\n",
      "248832/250291 [============================>.] - ETA: 0s - loss: 0.2861 - accuracy: 0.8932 - auc: 0.9524Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2857 - accuracy: 0.8932 - auc: 0.9525 - val_loss: 0.4107 - val_accuracy: 0.8968 - val_auc: 0.9340\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.5643 - accuracy: 0.6917 - auc: 0.8557 - val_loss: 0.3520 - val_accuracy: 0.8306 - val_auc: 0.9378\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3792 - accuracy: 0.8258 - auc: 0.9223 - val_loss: 0.3317 - val_accuracy: 0.8960 - val_auc: 0.9340\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3543 - accuracy: 0.8646 - auc: 0.9274 - val_loss: 0.3326 - val_accuracy: 0.8594 - val_auc: 0.9363\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3288 - accuracy: 0.8747 - auc: 0.9404 - val_loss: 0.3406 - val_accuracy: 0.8784 - val_auc: 0.9390\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3344 - accuracy: 0.8678 - auc: 0.9364 - val_loss: 0.3455 - val_accuracy: 0.8838 - val_auc: 0.9322\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3431 - accuracy: 0.8711 - auc: 0.9354 - val_loss: 0.3579 - val_accuracy: 0.8670 - val_auc: 0.9299\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3206 - accuracy: 0.8807 - auc: 0.9418 - val_loss: 0.4186 - val_accuracy: 0.8748 - val_auc: 0.9274\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3159 - accuracy: 0.8765 - auc: 0.9441 - val_loss: 0.3917 - val_accuracy: 0.8657 - val_auc: 0.9311\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3148 - accuracy: 0.8803 - auc: 0.9442 - val_loss: 0.4006 - val_accuracy: 0.8797 - val_auc: 0.9271\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2925 - accuracy: 0.8848 - auc: 0.9509 - val_loss: 0.3935 - val_accuracy: 0.8689 - val_auc: 0.9341\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2908 - accuracy: 0.8803 - auc: 0.9510 - val_loss: 0.4895 - val_accuracy: 0.8793 - val_auc: 0.9292\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2934 - accuracy: 0.8753 - auc: 0.9506 - val_loss: 0.4388 - val_accuracy: 0.8843 - val_auc: 0.9324\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2917 - accuracy: 0.8788 - auc: 0.9514 - val_loss: 0.4441 - val_accuracy: 0.8934 - val_auc: 0.9256\n",
      "Epoch 14/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8802 - auc: 0.9483Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3022 - accuracy: 0.8806 - auc: 0.9487 - val_loss: 0.4926 - val_accuracy: 0.9011 - val_auc: 0.9295\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5017 - accuracy: 0.7403 - auc: 0.8760 - val_loss: 0.3561 - val_accuracy: 0.8729 - val_auc: 0.9277\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4017 - accuracy: 0.8307 - auc: 0.9144 - val_loss: 0.3399 - val_accuracy: 0.8854 - val_auc: 0.9328\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3373 - accuracy: 0.8706 - auc: 0.9341 - val_loss: 0.3088 - val_accuracy: 0.8774 - val_auc: 0.9444\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3250 - accuracy: 0.8712 - auc: 0.9393 - val_loss: 0.3227 - val_accuracy: 0.8891 - val_auc: 0.9407\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3188 - accuracy: 0.8790 - auc: 0.9433 - val_loss: 0.3295 - val_accuracy: 0.8704 - val_auc: 0.9391\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3194 - accuracy: 0.8765 - auc: 0.9435 - val_loss: 0.3778 - val_accuracy: 0.8874 - val_auc: 0.9347\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3131 - accuracy: 0.8791 - auc: 0.9457 - val_loss: 0.4172 - val_accuracy: 0.9107 - val_auc: 0.9330\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3256 - accuracy: 0.8788 - auc: 0.9436 - val_loss: 0.3781 - val_accuracy: 0.8931 - val_auc: 0.9293\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3131 - accuracy: 0.8789 - auc: 0.9454 - val_loss: 0.4358 - val_accuracy: 0.9004 - val_auc: 0.9217\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3213 - accuracy: 0.8850 - auc: 0.9436 - val_loss: 0.3923 - val_accuracy: 0.8548 - val_auc: 0.9253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3093 - accuracy: 0.8836 - auc: 0.9473 - val_loss: 0.5285 - val_accuracy: 0.8926 - val_auc: 0.9208\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3147 - accuracy: 0.8864 - auc: 0.9461 - val_loss: 0.4893 - val_accuracy: 0.8979 - val_auc: 0.9183\n",
      "Epoch 13/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.8886 - auc: 0.9492Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3056 - accuracy: 0.8876 - auc: 0.9489 - val_loss: 0.4518 - val_accuracy: 0.8740 - val_auc: 0.9223\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 0.4870 - accuracy: 0.8505 - auc: 0.8690 - val_loss: 0.3462 - val_accuracy: 0.8726 - val_auc: 0.9378\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3588 - accuracy: 0.8915 - auc: 0.9281 - val_loss: 0.3246 - val_accuracy: 0.9029 - val_auc: 0.9400\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3466 - accuracy: 0.8962 - auc: 0.9316 - val_loss: 0.3286 - val_accuracy: 0.9050 - val_auc: 0.9416\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3327 - accuracy: 0.8975 - auc: 0.9412 - val_loss: 0.3652 - val_accuracy: 0.8453 - val_auc: 0.9358\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3650 - accuracy: 0.8905 - auc: 0.9286 - val_loss: 0.3666 - val_accuracy: 0.9500 - val_auc: 0.9325\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3375 - accuracy: 0.8957 - auc: 0.9407 - val_loss: 0.4095 - val_accuracy: 0.8564 - val_auc: 0.9353\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3518 - accuracy: 0.8917 - auc: 0.9379 - val_loss: 0.3550 - val_accuracy: 0.9281 - val_auc: 0.9280\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3713 - accuracy: 0.8899 - auc: 0.9323 - val_loss: 0.3466 - val_accuracy: 0.9271 - val_auc: 0.9315\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3114 - accuracy: 0.8995 - auc: 0.9481 - val_loss: 0.3807 - val_accuracy: 0.8791 - val_auc: 0.9302\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3308 - accuracy: 0.8953 - auc: 0.9450 - val_loss: 0.3921 - val_accuracy: 0.9005 - val_auc: 0.9279\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3128 - accuracy: 0.8980 - auc: 0.9476 - val_loss: 0.3806 - val_accuracy: 0.9160 - val_auc: 0.9270\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3142 - accuracy: 0.9022 - auc: 0.9491 - val_loss: 0.3793 - val_accuracy: 0.8653 - val_auc: 0.9277\n",
      "Epoch 13/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.8990 - auc: 0.9467Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3129 - accuracy: 0.8990 - auc: 0.9469 - val_loss: 0.3942 - val_accuracy: 0.8910 - val_auc: 0.9285\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.5248 - accuracy: 0.8194 - auc: 0.8545 - val_loss: 0.3378 - val_accuracy: 0.8785 - val_auc: 0.9346\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3720 - accuracy: 0.8810 - auc: 0.9235 - val_loss: 0.3419 - val_accuracy: 0.8931 - val_auc: 0.9348\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3490 - accuracy: 0.8885 - auc: 0.9324 - val_loss: 0.3281 - val_accuracy: 0.8705 - val_auc: 0.9393\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3449 - accuracy: 0.8915 - auc: 0.9352 - val_loss: 0.3435 - val_accuracy: 0.8600 - val_auc: 0.9410\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3536 - accuracy: 0.8893 - auc: 0.9317 - val_loss: 0.3499 - val_accuracy: 0.8849 - val_auc: 0.9332\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3371 - accuracy: 0.8913 - auc: 0.9383 - val_loss: 0.3397 - val_accuracy: 0.8678 - val_auc: 0.9374\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3497 - accuracy: 0.8891 - auc: 0.9326 - val_loss: 0.3414 - val_accuracy: 0.9125 - val_auc: 0.9326\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3370 - accuracy: 0.8906 - auc: 0.9378 - val_loss: 0.3559 - val_accuracy: 0.8865 - val_auc: 0.9346\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3441 - accuracy: 0.8886 - auc: 0.9370 - val_loss: 0.3600 - val_accuracy: 0.8988 - val_auc: 0.9344\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3159 - accuracy: 0.8967 - auc: 0.9454 - val_loss: 0.4229 - val_accuracy: 0.9111 - val_auc: 0.9248\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3252 - accuracy: 0.8965 - auc: 0.9418 - val_loss: 0.4209 - val_accuracy: 0.8802 - val_auc: 0.9279\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3204 - accuracy: 0.8907 - auc: 0.9421 - val_loss: 0.3956 - val_accuracy: 0.8995 - val_auc: 0.9313\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3201 - accuracy: 0.8940 - auc: 0.9440 - val_loss: 0.4375 - val_accuracy: 0.9137 - val_auc: 0.9245\n",
      "Epoch 14/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.8951 - auc: 0.9456Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3112 - accuracy: 0.8951 - auc: 0.9460 - val_loss: 0.4248 - val_accuracy: 0.8960 - val_auc: 0.9273\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5689 - accuracy: 0.8307 - auc: 0.8556 - val_loss: 0.3677 - val_accuracy: 0.8780 - val_auc: 0.9230\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3705 - accuracy: 0.8882 - auc: 0.9211 - val_loss: 0.3435 - val_accuracy: 0.8853 - val_auc: 0.9299\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3433 - accuracy: 0.8886 - auc: 0.9356 - val_loss: 0.3345 - val_accuracy: 0.9007 - val_auc: 0.9288\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3549 - accuracy: 0.8872 - auc: 0.9347 - val_loss: 0.3353 - val_accuracy: 0.8844 - val_auc: 0.9360\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3540 - accuracy: 0.8907 - auc: 0.9352 - val_loss: 0.3563 - val_accuracy: 0.8776 - val_auc: 0.9303\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3415 - accuracy: 0.8946 - auc: 0.9361 - val_loss: 0.3482 - val_accuracy: 0.9054 - val_auc: 0.9354\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3313 - accuracy: 0.8975 - auc: 0.9417 - val_loss: 0.3380 - val_accuracy: 0.8916 - val_auc: 0.9341\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3340 - accuracy: 0.8877 - auc: 0.9401 - val_loss: 0.3973 - val_accuracy: 0.9049 - val_auc: 0.9295\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2982 - accuracy: 0.8991 - auc: 0.9514 - val_loss: 0.3741 - val_accuracy: 0.8956 - val_auc: 0.9344\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3309 - accuracy: 0.8900 - auc: 0.9431 - val_loss: 0.4332 - val_accuracy: 0.9278 - val_auc: 0.9267\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3216 - accuracy: 0.8964 - auc: 0.9455 - val_loss: 0.3808 - val_accuracy: 0.8993 - val_auc: 0.9260\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3367 - accuracy: 0.8949 - auc: 0.9458 - val_loss: 0.3588 - val_accuracy: 0.8752 - val_auc: 0.9327\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3139 - accuracy: 0.8944 - auc: 0.9475 - val_loss: 0.4203 - val_accuracy: 0.9197 - val_auc: 0.9302\n",
      "Epoch 14/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.2860 - accuracy: 0.9035 - auc: 0.9543Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2856 - accuracy: 0.9030 - auc: 0.9545 - val_loss: 0.4685 - val_accuracy: 0.8856 - val_auc: 0.9294\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.5378 - accuracy: 0.7451 - auc: 0.8687 - val_loss: 0.3428 - val_accuracy: 0.8570 - val_auc: 0.9306\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3962 - accuracy: 0.8425 - auc: 0.9143 - val_loss: 0.3296 - val_accuracy: 0.8708 - val_auc: 0.9338\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3583 - accuracy: 0.8667 - auc: 0.9295 - val_loss: 0.3283 - val_accuracy: 0.8983 - val_auc: 0.9346\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3581 - accuracy: 0.8692 - auc: 0.9309 - val_loss: 0.3679 - val_accuracy: 0.8446 - val_auc: 0.9323\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3381 - accuracy: 0.8762 - auc: 0.9374 - val_loss: 0.3120 - val_accuracy: 0.8937 - val_auc: 0.9429\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3196 - accuracy: 0.8855 - auc: 0.9428 - val_loss: 0.3449 - val_accuracy: 0.8847 - val_auc: 0.9356\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3280 - accuracy: 0.8764 - auc: 0.9402 - val_loss: 0.3536 - val_accuracy: 0.9009 - val_auc: 0.9341\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3350 - accuracy: 0.8824 - auc: 0.9402 - val_loss: 0.3709 - val_accuracy: 0.8873 - val_auc: 0.9291\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3184 - accuracy: 0.8829 - auc: 0.9431 - val_loss: 0.3536 - val_accuracy: 0.9142 - val_auc: 0.9330\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2975 - accuracy: 0.8897 - auc: 0.9498 - val_loss: 0.3694 - val_accuracy: 0.8822 - val_auc: 0.9302\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2965 - accuracy: 0.8849 - auc: 0.9494 - val_loss: 0.4038 - val_accuracy: 0.8987 - val_auc: 0.9310\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2866 - accuracy: 0.8871 - auc: 0.9530 - val_loss: 0.4328 - val_accuracy: 0.8919 - val_auc: 0.9267\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2983 - accuracy: 0.8823 - auc: 0.9507 - val_loss: 0.4568 - val_accuracy: 0.9067 - val_auc: 0.9229\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2885 - accuracy: 0.8879 - auc: 0.9538 - val_loss: 0.4882 - val_accuracy: 0.8896 - val_auc: 0.9213\n",
      "Epoch 15/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.3092 - accuracy: 0.8821 - auc: 0.9481Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3092 - accuracy: 0.8820 - auc: 0.9482 - val_loss: 0.3973 - val_accuracy: 0.8870 - val_auc: 0.9288\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.7497 - accuracy: 0.3409 - auc: 0.7130 - val_loss: 0.4907 - val_accuracy: 0.6036 - val_auc: 0.8999\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5070 - accuracy: 0.6063 - auc: 0.8673 - val_loss: 0.3827 - val_accuracy: 0.8031 - val_auc: 0.9311\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4343 - accuracy: 0.7139 - auc: 0.8954 - val_loss: 0.3439 - val_accuracy: 0.8446 - val_auc: 0.9372\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4167 - accuracy: 0.7565 - auc: 0.9037 - val_loss: 0.3308 - val_accuracy: 0.8593 - val_auc: 0.9382\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3810 - accuracy: 0.7811 - auc: 0.9182 - val_loss: 0.3246 - val_accuracy: 0.8665 - val_auc: 0.9378\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3686 - accuracy: 0.7875 - auc: 0.9210 - val_loss: 0.3170 - val_accuracy: 0.8701 - val_auc: 0.9394\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3545 - accuracy: 0.7969 - auc: 0.9268 - val_loss: 0.3141 - val_accuracy: 0.8755 - val_auc: 0.9397\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3486 - accuracy: 0.8036 - auc: 0.9306 - val_loss: 0.3142 - val_accuracy: 0.8770 - val_auc: 0.9394\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3353 - accuracy: 0.8296 - auc: 0.9347 - val_loss: 0.3130 - val_accuracy: 0.8818 - val_auc: 0.9399\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3490 - accuracy: 0.8580 - auc: 0.9294 - val_loss: 0.3145 - val_accuracy: 0.8786 - val_auc: 0.9395\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3269 - accuracy: 0.8630 - auc: 0.9370 - val_loss: 0.3136 - val_accuracy: 0.8816 - val_auc: 0.9403\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3335 - accuracy: 0.8654 - auc: 0.9348 - val_loss: 0.3147 - val_accuracy: 0.8763 - val_auc: 0.9402\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3244 - accuracy: 0.8676 - auc: 0.9383 - val_loss: 0.3156 - val_accuracy: 0.8783 - val_auc: 0.9398\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3332 - accuracy: 0.8669 - auc: 0.9354 - val_loss: 0.3121 - val_accuracy: 0.8812 - val_auc: 0.9414\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3243 - accuracy: 0.8698 - auc: 0.9384 - val_loss: 0.3165 - val_accuracy: 0.8778 - val_auc: 0.9402\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3218 - accuracy: 0.8683 - auc: 0.9391 - val_loss: 0.3162 - val_accuracy: 0.8799 - val_auc: 0.9405\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3207 - accuracy: 0.8721 - auc: 0.9392 - val_loss: 0.3224 - val_accuracy: 0.8794 - val_auc: 0.9392\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3199 - accuracy: 0.8690 - auc: 0.9398 - val_loss: 0.3254 - val_accuracy: 0.8791 - val_auc: 0.9396\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3052 - accuracy: 0.8745 - auc: 0.9457 - val_loss: 0.3283 - val_accuracy: 0.8762 - val_auc: 0.9387\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3138 - accuracy: 0.8749 - auc: 0.9420 - val_loss: 0.3342 - val_accuracy: 0.8767 - val_auc: 0.9373\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3154 - accuracy: 0.8719 - auc: 0.9400 - val_loss: 0.3433 - val_accuracy: 0.8768 - val_auc: 0.9354\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3014 - accuracy: 0.8759 - auc: 0.9462 - val_loss: 0.3399 - val_accuracy: 0.8830 - val_auc: 0.9375\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3027 - accuracy: 0.8769 - auc: 0.9459 - val_loss: 0.3447 - val_accuracy: 0.8846 - val_auc: 0.9371\n",
      "Epoch 24/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2982 - accuracy: 0.8771 - auc: 0.9487Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2971 - accuracy: 0.8771 - auc: 0.9488 - val_loss: 0.3482 - val_accuracy: 0.8860 - val_auc: 0.9366\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.9141 - accuracy: 0.8881 - auc: 0.6616 - val_loss: 0.6412 - val_accuracy: 0.9191 - val_auc: 0.8669\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6222 - accuracy: 0.8690 - auc: 0.8040 - val_loss: 0.5527 - val_accuracy: 0.9035 - val_auc: 0.8965\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5179 - accuracy: 0.8816 - auc: 0.8438 - val_loss: 0.4949 - val_accuracy: 0.9053 - val_auc: 0.9089\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4927 - accuracy: 0.8910 - auc: 0.8623 - val_loss: 0.4634 - val_accuracy: 0.8999 - val_auc: 0.9132\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4118 - accuracy: 0.8946 - auc: 0.9017 - val_loss: 0.4479 - val_accuracy: 0.9047 - val_auc: 0.9154\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4244 - accuracy: 0.8976 - auc: 0.9009 - val_loss: 0.4224 - val_accuracy: 0.8949 - val_auc: 0.9208\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4113 - accuracy: 0.8959 - auc: 0.9074 - val_loss: 0.3988 - val_accuracy: 0.9034 - val_auc: 0.9232\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3891 - accuracy: 0.8999 - auc: 0.9138 - val_loss: 0.3901 - val_accuracy: 0.8976 - val_auc: 0.9245\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3734 - accuracy: 0.9026 - auc: 0.9187 - val_loss: 0.3698 - val_accuracy: 0.9047 - val_auc: 0.9250\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3803 - accuracy: 0.9030 - auc: 0.9181 - val_loss: 0.3548 - val_accuracy: 0.8981 - val_auc: 0.9266\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3631 - accuracy: 0.9029 - auc: 0.9234 - val_loss: 0.3462 - val_accuracy: 0.9052 - val_auc: 0.9271\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3578 - accuracy: 0.9061 - auc: 0.9260 - val_loss: 0.3560 - val_accuracy: 0.9046 - val_auc: 0.9273\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3635 - accuracy: 0.9046 - auc: 0.9238 - val_loss: 0.3462 - val_accuracy: 0.9058 - val_auc: 0.9286\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3616 - accuracy: 0.9072 - auc: 0.9250 - val_loss: 0.3367 - val_accuracy: 0.9029 - val_auc: 0.9308\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3446 - accuracy: 0.9069 - auc: 0.9329 - val_loss: 0.3412 - val_accuracy: 0.8994 - val_auc: 0.9291\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3377 - accuracy: 0.9019 - auc: 0.9342 - val_loss: 0.3417 - val_accuracy: 0.9019 - val_auc: 0.9307\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3387 - accuracy: 0.9064 - auc: 0.9345 - val_loss: 0.3532 - val_accuracy: 0.9002 - val_auc: 0.9283\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3401 - accuracy: 0.9061 - auc: 0.9319 - val_loss: 0.3380 - val_accuracy: 0.9009 - val_auc: 0.9327\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3271 - accuracy: 0.9028 - auc: 0.9393 - val_loss: 0.3420 - val_accuracy: 0.9006 - val_auc: 0.9329\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3248 - accuracy: 0.9041 - auc: 0.9396 - val_loss: 0.3445 - val_accuracy: 0.8963 - val_auc: 0.9313\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3281 - accuracy: 0.8999 - auc: 0.9367 - val_loss: 0.3555 - val_accuracy: 0.8941 - val_auc: 0.9293\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3122 - accuracy: 0.8998 - auc: 0.9445 - val_loss: 0.3536 - val_accuracy: 0.9005 - val_auc: 0.9305\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3164 - accuracy: 0.9001 - auc: 0.9414 - val_loss: 0.3646 - val_accuracy: 0.9028 - val_auc: 0.9287\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3047 - accuracy: 0.9000 - auc: 0.9461 - val_loss: 0.3566 - val_accuracy: 0.9001 - val_auc: 0.9313\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3078 - accuracy: 0.9002 - auc: 0.9448 - val_loss: 0.3543 - val_accuracy: 0.8998 - val_auc: 0.9327\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3086 - accuracy: 0.9020 - auc: 0.9438 - val_loss: 0.3708 - val_accuracy: 0.9005 - val_auc: 0.9289\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2979 - accuracy: 0.8983 - auc: 0.9485 - val_loss: 0.3739 - val_accuracy: 0.9007 - val_auc: 0.9295\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2978 - accuracy: 0.8978 - auc: 0.9486 - val_loss: 0.3801 - val_accuracy: 0.9000 - val_auc: 0.9288\n",
      "Epoch 29/100\n",
      "242688/250290 [============================>.] - ETA: 0s - loss: 0.2955 - accuracy: 0.9004 - auc: 0.9465Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2998 - accuracy: 0.9004 - auc: 0.9464 - val_loss: 0.3886 - val_accuracy: 0.9006 - val_auc: 0.9281\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6883 - accuracy: 0.8149 - auc: 0.7294 - val_loss: 0.4273 - val_accuracy: 0.8975 - val_auc: 0.9057\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5007 - accuracy: 0.8615 - auc: 0.8452 - val_loss: 0.3823 - val_accuracy: 0.8932 - val_auc: 0.9268\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4554 - accuracy: 0.8754 - auc: 0.8683 - val_loss: 0.3659 - val_accuracy: 0.8959 - val_auc: 0.9315\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4159 - accuracy: 0.8860 - auc: 0.8953 - val_loss: 0.3538 - val_accuracy: 0.9043 - val_auc: 0.9329\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3911 - accuracy: 0.8927 - auc: 0.9109 - val_loss: 0.3435 - val_accuracy: 0.8992 - val_auc: 0.9340\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3735 - accuracy: 0.8948 - auc: 0.9175 - val_loss: 0.3437 - val_accuracy: 0.9017 - val_auc: 0.9328\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3675 - accuracy: 0.8978 - auc: 0.9262 - val_loss: 0.3401 - val_accuracy: 0.9020 - val_auc: 0.9338\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3687 - accuracy: 0.8975 - auc: 0.9274 - val_loss: 0.3356 - val_accuracy: 0.8993 - val_auc: 0.9337\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3592 - accuracy: 0.8987 - auc: 0.9268 - val_loss: 0.3333 - val_accuracy: 0.9035 - val_auc: 0.9329\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3528 - accuracy: 0.9034 - auc: 0.9293 - val_loss: 0.3288 - val_accuracy: 0.9032 - val_auc: 0.9338\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3391 - accuracy: 0.9018 - auc: 0.9362 - val_loss: 0.3256 - val_accuracy: 0.9077 - val_auc: 0.9352\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3318 - accuracy: 0.9066 - auc: 0.9417 - val_loss: 0.3210 - val_accuracy: 0.9038 - val_auc: 0.9376\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3443 - accuracy: 0.9038 - auc: 0.9335 - val_loss: 0.3178 - val_accuracy: 0.9042 - val_auc: 0.9383\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3466 - accuracy: 0.9035 - auc: 0.9344 - val_loss: 0.3178 - val_accuracy: 0.9005 - val_auc: 0.9383\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3349 - accuracy: 0.8999 - auc: 0.9400 - val_loss: 0.3159 - val_accuracy: 0.9023 - val_auc: 0.9393\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3311 - accuracy: 0.9041 - auc: 0.9388 - val_loss: 0.3158 - val_accuracy: 0.9050 - val_auc: 0.9386\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3282 - accuracy: 0.9027 - auc: 0.9393 - val_loss: 0.3177 - val_accuracy: 0.9025 - val_auc: 0.9385\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3152 - accuracy: 0.9028 - auc: 0.9434 - val_loss: 0.3165 - val_accuracy: 0.9078 - val_auc: 0.9390\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3215 - accuracy: 0.9064 - auc: 0.9416 - val_loss: 0.3263 - val_accuracy: 0.9010 - val_auc: 0.9356\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3257 - accuracy: 0.9019 - auc: 0.9410 - val_loss: 0.3249 - val_accuracy: 0.9012 - val_auc: 0.9371\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3140 - accuracy: 0.9027 - auc: 0.9454 - val_loss: 0.3232 - val_accuracy: 0.9057 - val_auc: 0.9384\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3149 - accuracy: 0.9050 - auc: 0.9447 - val_loss: 0.3320 - val_accuracy: 0.9013 - val_auc: 0.9375\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3214 - accuracy: 0.9036 - auc: 0.9413 - val_loss: 0.3362 - val_accuracy: 0.9057 - val_auc: 0.9373\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3184 - accuracy: 0.9056 - auc: 0.9432 - val_loss: 0.3366 - val_accuracy: 0.9060 - val_auc: 0.9385\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3086 - accuracy: 0.9040 - auc: 0.9467 - val_loss: 0.3314 - val_accuracy: 0.9046 - val_auc: 0.9398\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3134 - accuracy: 0.9037 - auc: 0.9443 - val_loss: 0.3415 - val_accuracy: 0.9018 - val_auc: 0.9379\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3123 - accuracy: 0.9025 - auc: 0.9449 - val_loss: 0.3394 - val_accuracy: 0.9057 - val_auc: 0.9383\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3023 - accuracy: 0.9057 - auc: 0.9487 - val_loss: 0.3459 - val_accuracy: 0.9005 - val_auc: 0.9378\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3058 - accuracy: 0.9044 - auc: 0.9459 - val_loss: 0.3532 - val_accuracy: 0.9025 - val_auc: 0.9367\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3114 - accuracy: 0.9041 - auc: 0.9443 - val_loss: 0.3600 - val_accuracy: 0.9042 - val_auc: 0.9354\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3138 - accuracy: 0.9045 - auc: 0.9434 - val_loss: 0.3726 - val_accuracy: 0.9047 - val_auc: 0.9340\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3089 - accuracy: 0.9037 - auc: 0.9458 - val_loss: 0.3717 - val_accuracy: 0.9015 - val_auc: 0.9340\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3035 - accuracy: 0.9046 - auc: 0.9460 - val_loss: 0.3725 - val_accuracy: 0.9025 - val_auc: 0.9324\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2992 - accuracy: 0.9032 - auc: 0.9485 - val_loss: 0.3650 - val_accuracy: 0.9039 - val_auc: 0.9356\n",
      "Epoch 35/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.3013 - accuracy: 0.9039 - auc: 0.9470Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3014 - accuracy: 0.9039 - auc: 0.9471 - val_loss: 0.3754 - val_accuracy: 0.9025 - val_auc: 0.9339\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.8652 - accuracy: 0.9050 - auc: 0.5907 - val_loss: 0.5415 - val_accuracy: 0.9134 - val_auc: 0.8566\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5580 - accuracy: 0.8684 - auc: 0.8068 - val_loss: 0.4273 - val_accuracy: 0.8829 - val_auc: 0.9110\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4656 - accuracy: 0.8682 - auc: 0.8657 - val_loss: 0.3885 - val_accuracy: 0.8763 - val_auc: 0.9259\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4234 - accuracy: 0.8766 - auc: 0.8925 - val_loss: 0.3669 - val_accuracy: 0.8810 - val_auc: 0.9303\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3993 - accuracy: 0.8858 - auc: 0.9098 - val_loss: 0.3487 - val_accuracy: 0.8896 - val_auc: 0.9351\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3831 - accuracy: 0.8923 - auc: 0.9128 - val_loss: 0.3351 - val_accuracy: 0.8963 - val_auc: 0.9401\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3683 - accuracy: 0.8964 - auc: 0.9249 - val_loss: 0.3304 - val_accuracy: 0.8923 - val_auc: 0.9393\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3555 - accuracy: 0.8962 - auc: 0.9305 - val_loss: 0.3236 - val_accuracy: 0.8948 - val_auc: 0.9414\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3480 - accuracy: 0.8973 - auc: 0.9338 - val_loss: 0.3202 - val_accuracy: 0.8957 - val_auc: 0.9408\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3386 - accuracy: 0.8993 - auc: 0.9372 - val_loss: 0.3158 - val_accuracy: 0.8977 - val_auc: 0.9424\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3458 - accuracy: 0.8990 - auc: 0.9311 - val_loss: 0.3118 - val_accuracy: 0.9015 - val_auc: 0.9436\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3310 - accuracy: 0.9029 - auc: 0.9379 - val_loss: 0.3116 - val_accuracy: 0.9010 - val_auc: 0.9423\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3278 - accuracy: 0.8994 - auc: 0.9405 - val_loss: 0.3070 - val_accuracy: 0.9027 - val_auc: 0.9440\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3240 - accuracy: 0.9001 - auc: 0.9420 - val_loss: 0.3078 - val_accuracy: 0.9033 - val_auc: 0.9441\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3202 - accuracy: 0.9020 - auc: 0.9427 - val_loss: 0.3088 - val_accuracy: 0.9011 - val_auc: 0.9436\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3288 - accuracy: 0.9023 - auc: 0.9385 - val_loss: 0.3058 - val_accuracy: 0.9024 - val_auc: 0.9444\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3099 - accuracy: 0.9043 - auc: 0.9474 - val_loss: 0.3067 - val_accuracy: 0.9003 - val_auc: 0.9441\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3124 - accuracy: 0.9016 - auc: 0.9459 - val_loss: 0.3034 - val_accuracy: 0.9029 - val_auc: 0.9448\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3082 - accuracy: 0.9025 - auc: 0.9467 - val_loss: 0.3074 - val_accuracy: 0.9065 - val_auc: 0.9446\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3194 - accuracy: 0.9031 - auc: 0.9416 - val_loss: 0.3091 - val_accuracy: 0.9043 - val_auc: 0.9440\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3125 - accuracy: 0.9069 - auc: 0.9457 - val_loss: 0.3114 - val_accuracy: 0.9036 - val_auc: 0.9442\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3134 - accuracy: 0.9019 - auc: 0.9435 - val_loss: 0.3111 - val_accuracy: 0.9084 - val_auc: 0.9441\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3141 - accuracy: 0.9049 - auc: 0.9440 - val_loss: 0.3124 - val_accuracy: 0.9021 - val_auc: 0.9432\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3083 - accuracy: 0.9020 - auc: 0.9467 - val_loss: 0.3161 - val_accuracy: 0.8993 - val_auc: 0.9430\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3036 - accuracy: 0.9049 - auc: 0.9471 - val_loss: 0.3258 - val_accuracy: 0.9020 - val_auc: 0.9416\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2975 - accuracy: 0.9035 - auc: 0.9500 - val_loss: 0.3246 - val_accuracy: 0.9007 - val_auc: 0.9423\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3009 - accuracy: 0.9034 - auc: 0.9473 - val_loss: 0.3232 - val_accuracy: 0.9049 - val_auc: 0.9437\n",
      "Epoch 28/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.9055 - auc: 0.9497Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2972 - accuracy: 0.9055 - auc: 0.9496 - val_loss: 0.3224 - val_accuracy: 0.9039 - val_auc: 0.9442\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.8756 - accuracy: 0.7403 - auc: 0.6439 - val_loss: 0.4817 - val_accuracy: 0.8055 - val_auc: 0.8649\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5927 - accuracy: 0.8058 - auc: 0.8153 - val_loss: 0.4048 - val_accuracy: 0.8397 - val_auc: 0.9149\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4842 - accuracy: 0.8390 - auc: 0.8693 - val_loss: 0.3802 - val_accuracy: 0.8614 - val_auc: 0.9249\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4454 - accuracy: 0.8592 - auc: 0.8887 - val_loss: 0.3646 - val_accuracy: 0.8713 - val_auc: 0.9304\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4158 - accuracy: 0.8711 - auc: 0.9041 - val_loss: 0.3566 - val_accuracy: 0.8819 - val_auc: 0.9325\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3914 - accuracy: 0.8834 - auc: 0.9132 - val_loss: 0.3467 - val_accuracy: 0.8808 - val_auc: 0.9335\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3850 - accuracy: 0.8824 - auc: 0.9138 - val_loss: 0.3368 - val_accuracy: 0.8936 - val_auc: 0.9331\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3727 - accuracy: 0.8903 - auc: 0.9220 - val_loss: 0.3339 - val_accuracy: 0.8936 - val_auc: 0.9337\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3756 - accuracy: 0.8918 - auc: 0.9216 - val_loss: 0.3313 - val_accuracy: 0.8926 - val_auc: 0.9338\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3468 - accuracy: 0.8921 - auc: 0.9314 - val_loss: 0.3300 - val_accuracy: 0.8951 - val_auc: 0.9340\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3675 - accuracy: 0.8919 - auc: 0.9239 - val_loss: 0.3357 - val_accuracy: 0.8922 - val_auc: 0.9332\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3358 - accuracy: 0.8900 - auc: 0.9355 - val_loss: 0.3375 - val_accuracy: 0.8865 - val_auc: 0.9329\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3363 - accuracy: 0.8904 - auc: 0.9347 - val_loss: 0.3355 - val_accuracy: 0.8934 - val_auc: 0.9327\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3454 - accuracy: 0.8887 - auc: 0.9319 - val_loss: 0.3373 - val_accuracy: 0.8896 - val_auc: 0.9334\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3306 - accuracy: 0.8872 - auc: 0.9367 - val_loss: 0.3417 - val_accuracy: 0.8932 - val_auc: 0.9329\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.3235 - accuracy: 0.8909 - auc: 0.9404 - val_loss: 0.3374 - val_accuracy: 0.8891 - val_auc: 0.9332\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.3227 - accuracy: 0.8908 - auc: 0.9402 - val_loss: 0.3373 - val_accuracy: 0.8896 - val_auc: 0.9345\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 3s 12us/sample - loss: 0.3252 - accuracy: 0.8916 - auc: 0.9401 - val_loss: 0.3418 - val_accuracy: 0.8825 - val_auc: 0.9343\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 0.3255 - accuracy: 0.8873 - auc: 0.9374 - val_loss: 0.3433 - val_accuracy: 0.8890 - val_auc: 0.9337\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3157 - accuracy: 0.8893 - auc: 0.9422 - val_loss: 0.3476 - val_accuracy: 0.8910 - val_auc: 0.9338\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3103 - accuracy: 0.8900 - auc: 0.9425 - val_loss: 0.3486 - val_accuracy: 0.8911 - val_auc: 0.9333\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.3104 - accuracy: 0.8908 - auc: 0.9427 - val_loss: 0.3518 - val_accuracy: 0.8891 - val_auc: 0.9328\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3088 - accuracy: 0.8869 - auc: 0.9434 - val_loss: 0.3633 - val_accuracy: 0.8889 - val_auc: 0.9323\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3096 - accuracy: 0.8844 - auc: 0.9450 - val_loss: 0.3629 - val_accuracy: 0.8880 - val_auc: 0.9320\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3079 - accuracy: 0.8868 - auc: 0.9452 - val_loss: 0.3687 - val_accuracy: 0.8859 - val_auc: 0.9319\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3086 - accuracy: 0.8848 - auc: 0.9427 - val_loss: 0.3771 - val_accuracy: 0.8882 - val_auc: 0.9314\n",
      "Epoch 27/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.8872 - auc: 0.9471Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2968 - accuracy: 0.8871 - auc: 0.9469 - val_loss: 0.3744 - val_accuracy: 0.8864 - val_auc: 0.9313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.8972 - accuracy: 0.6307 - auc: 0.6614 - val_loss: 0.5644 - val_accuracy: 0.7088 - val_auc: 0.8813\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5375 - accuracy: 0.6997 - auc: 0.8599 - val_loss: 0.4419 - val_accuracy: 0.8132 - val_auc: 0.9146\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4428 - accuracy: 0.8001 - auc: 0.8983 - val_loss: 0.3903 - val_accuracy: 0.8556 - val_auc: 0.9227\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3851 - accuracy: 0.8412 - auc: 0.9155 - val_loss: 0.3689 - val_accuracy: 0.8719 - val_auc: 0.9266\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3746 - accuracy: 0.8569 - auc: 0.9193 - val_loss: 0.3472 - val_accuracy: 0.8772 - val_auc: 0.9306\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3450 - accuracy: 0.8645 - auc: 0.9312 - val_loss: 0.3369 - val_accuracy: 0.8792 - val_auc: 0.9342\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3319 - accuracy: 0.8718 - auc: 0.9389 - val_loss: 0.3285 - val_accuracy: 0.8874 - val_auc: 0.9353\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3310 - accuracy: 0.8766 - auc: 0.9372 - val_loss: 0.3310 - val_accuracy: 0.8854 - val_auc: 0.9354\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3118 - accuracy: 0.8784 - auc: 0.9433 - val_loss: 0.3274 - val_accuracy: 0.8867 - val_auc: 0.9358\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3192 - accuracy: 0.8797 - auc: 0.9404 - val_loss: 0.3302 - val_accuracy: 0.8885 - val_auc: 0.9357\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2949 - accuracy: 0.8815 - auc: 0.9496 - val_loss: 0.3228 - val_accuracy: 0.8952 - val_auc: 0.9392\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3059 - accuracy: 0.8844 - auc: 0.9451 - val_loss: 0.3293 - val_accuracy: 0.8909 - val_auc: 0.9384\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2918 - accuracy: 0.8835 - auc: 0.9500 - val_loss: 0.3277 - val_accuracy: 0.8918 - val_auc: 0.9390\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3057 - accuracy: 0.8853 - auc: 0.9456 - val_loss: 0.3298 - val_accuracy: 0.8873 - val_auc: 0.9384\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2881 - accuracy: 0.8850 - auc: 0.9516 - val_loss: 0.3428 - val_accuracy: 0.8878 - val_auc: 0.9355\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2807 - accuracy: 0.8852 - auc: 0.9541 - val_loss: 0.3456 - val_accuracy: 0.8923 - val_auc: 0.9349\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2797 - accuracy: 0.8859 - auc: 0.9540 - val_loss: 0.3419 - val_accuracy: 0.8942 - val_auc: 0.9360\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2817 - accuracy: 0.8869 - auc: 0.9533 - val_loss: 0.3617 - val_accuracy: 0.8919 - val_auc: 0.9326\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2795 - accuracy: 0.8850 - auc: 0.9543 - val_loss: 0.3592 - val_accuracy: 0.8976 - val_auc: 0.9341\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2787 - accuracy: 0.8882 - auc: 0.9544 - val_loss: 0.3699 - val_accuracy: 0.9005 - val_auc: 0.9327\n",
      "Epoch 21/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.8936 - auc: 0.9573Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2707 - accuracy: 0.8932 - auc: 0.9568 - val_loss: 0.3899 - val_accuracy: 0.8906 - val_auc: 0.9301\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.8157 - accuracy: 0.5046 - auc: 0.6698 - val_loss: 0.4834 - val_accuracy: 0.6681 - val_auc: 0.8841\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4933 - accuracy: 0.7254 - auc: 0.8649 - val_loss: 0.3798 - val_accuracy: 0.8426 - val_auc: 0.9214\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4230 - accuracy: 0.8255 - auc: 0.8983 - val_loss: 0.3432 - val_accuracy: 0.8672 - val_auc: 0.9322\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3900 - accuracy: 0.8477 - auc: 0.9134 - val_loss: 0.3314 - val_accuracy: 0.8830 - val_auc: 0.9341\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3557 - accuracy: 0.8653 - auc: 0.9260 - val_loss: 0.3287 - val_accuracy: 0.8813 - val_auc: 0.9340\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3457 - accuracy: 0.8700 - auc: 0.9306 - val_loss: 0.3239 - val_accuracy: 0.8869 - val_auc: 0.9346\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3258 - accuracy: 0.8738 - auc: 0.9387 - val_loss: 0.3152 - val_accuracy: 0.8903 - val_auc: 0.9382\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3229 - accuracy: 0.8802 - auc: 0.9385 - val_loss: 0.3241 - val_accuracy: 0.8879 - val_auc: 0.9347\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3096 - accuracy: 0.8809 - auc: 0.9437 - val_loss: 0.3332 - val_accuracy: 0.8861 - val_auc: 0.9325\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3027 - accuracy: 0.8805 - auc: 0.9464 - val_loss: 0.3360 - val_accuracy: 0.8870 - val_auc: 0.9317\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2960 - accuracy: 0.8821 - auc: 0.9486 - val_loss: 0.3371 - val_accuracy: 0.8926 - val_auc: 0.9327\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3038 - accuracy: 0.8848 - auc: 0.9457 - val_loss: 0.3395 - val_accuracy: 0.8856 - val_auc: 0.9328\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2980 - accuracy: 0.8826 - auc: 0.9475 - val_loss: 0.3399 - val_accuracy: 0.8909 - val_auc: 0.9335\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2903 - accuracy: 0.8826 - auc: 0.9504 - val_loss: 0.3455 - val_accuracy: 0.8956 - val_auc: 0.9330\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2953 - accuracy: 0.8872 - auc: 0.9484 - val_loss: 0.3578 - val_accuracy: 0.8927 - val_auc: 0.9298\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2917 - accuracy: 0.8867 - auc: 0.9497 - val_loss: 0.3640 - val_accuracy: 0.8918 - val_auc: 0.9293\n",
      "Epoch 17/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2793 - accuracy: 0.8829 - auc: 0.9534Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2846 - accuracy: 0.8829 - auc: 0.9521 - val_loss: 0.3625 - val_accuracy: 0.8907 - val_auc: 0.9303\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.7741 - accuracy: 0.3529 - auc: 0.7156 - val_loss: 0.4649 - val_accuracy: 0.6073 - val_auc: 0.9120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4943 - accuracy: 0.6287 - auc: 0.8755 - val_loss: 0.3709 - val_accuracy: 0.8034 - val_auc: 0.9301\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4172 - accuracy: 0.7559 - auc: 0.8984 - val_loss: 0.3422 - val_accuracy: 0.8483 - val_auc: 0.9355\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3846 - accuracy: 0.7909 - auc: 0.9172 - val_loss: 0.3267 - val_accuracy: 0.8724 - val_auc: 0.9369\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3607 - accuracy: 0.8255 - auc: 0.9247 - val_loss: 0.3230 - val_accuracy: 0.8791 - val_auc: 0.9377\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3353 - accuracy: 0.8419 - auc: 0.9332 - val_loss: 0.3198 - val_accuracy: 0.8800 - val_auc: 0.9378\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3273 - accuracy: 0.8413 - auc: 0.9360 - val_loss: 0.3225 - val_accuracy: 0.8846 - val_auc: 0.9369\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3131 - accuracy: 0.8540 - auc: 0.9405 - val_loss: 0.3257 - val_accuracy: 0.8840 - val_auc: 0.9358\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3169 - accuracy: 0.8514 - auc: 0.9391 - val_loss: 0.3246 - val_accuracy: 0.8821 - val_auc: 0.9364\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2994 - accuracy: 0.8578 - auc: 0.9460 - val_loss: 0.3347 - val_accuracy: 0.8876 - val_auc: 0.9334\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3004 - accuracy: 0.8613 - auc: 0.9454 - val_loss: 0.3406 - val_accuracy: 0.8819 - val_auc: 0.9326\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2942 - accuracy: 0.8615 - auc: 0.9479 - val_loss: 0.3418 - val_accuracy: 0.8842 - val_auc: 0.9327\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2992 - accuracy: 0.8615 - auc: 0.9465 - val_loss: 0.3464 - val_accuracy: 0.8837 - val_auc: 0.9320\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2887 - accuracy: 0.8667 - auc: 0.9496 - val_loss: 0.3510 - val_accuracy: 0.8841 - val_auc: 0.9303\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2899 - accuracy: 0.8659 - auc: 0.9491 - val_loss: 0.3554 - val_accuracy: 0.8871 - val_auc: 0.9296\n",
      "Epoch 16/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.2849 - accuracy: 0.8684 - auc: 0.9510Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2834 - accuracy: 0.8685 - auc: 0.9512 - val_loss: 0.3601 - val_accuracy: 0.8867 - val_auc: 0.9293\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.7074 - accuracy: 0.4115 - auc: 0.7695 - val_loss: 0.4004 - val_accuracy: 0.7398 - val_auc: 0.9360\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4747 - accuracy: 0.7134 - auc: 0.8817 - val_loss: 0.3290 - val_accuracy: 0.8370 - val_auc: 0.9446\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3832 - accuracy: 0.7912 - auc: 0.9175 - val_loss: 0.3098 - val_accuracy: 0.8751 - val_auc: 0.9439\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3657 - accuracy: 0.8229 - auc: 0.9238 - val_loss: 0.3074 - val_accuracy: 0.8697 - val_auc: 0.9433\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3354 - accuracy: 0.8295 - auc: 0.9346 - val_loss: 0.3098 - val_accuracy: 0.8760 - val_auc: 0.9416\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3403 - accuracy: 0.8325 - auc: 0.9313 - val_loss: 0.3097 - val_accuracy: 0.8781 - val_auc: 0.9422\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3252 - accuracy: 0.8416 - auc: 0.9369 - val_loss: 0.3119 - val_accuracy: 0.8701 - val_auc: 0.9416\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3067 - accuracy: 0.8418 - auc: 0.9451 - val_loss: 0.3031 - val_accuracy: 0.8841 - val_auc: 0.9437\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3002 - accuracy: 0.8496 - auc: 0.9469 - val_loss: 0.3012 - val_accuracy: 0.8864 - val_auc: 0.9445\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3097 - accuracy: 0.8617 - auc: 0.9428 - val_loss: 0.3056 - val_accuracy: 0.8823 - val_auc: 0.9436\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2908 - accuracy: 0.8636 - auc: 0.9503 - val_loss: 0.3031 - val_accuracy: 0.8846 - val_auc: 0.9442\n",
      "Epoch 12/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.8683 - auc: 0.9473Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2962 - accuracy: 0.8685 - auc: 0.9478 - val_loss: 0.3060 - val_accuracy: 0.8879 - val_auc: 0.9436\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.6721 - accuracy: 0.7979 - auc: 0.7466 - val_loss: 0.4064 - val_accuracy: 0.8530 - val_auc: 0.9128\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4547 - accuracy: 0.8376 - auc: 0.8868 - val_loss: 0.3592 - val_accuracy: 0.8820 - val_auc: 0.9271\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3887 - accuracy: 0.8680 - auc: 0.9167 - val_loss: 0.3347 - val_accuracy: 0.8916 - val_auc: 0.9339\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3757 - accuracy: 0.8770 - auc: 0.9196 - val_loss: 0.3295 - val_accuracy: 0.8922 - val_auc: 0.9320\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3503 - accuracy: 0.8832 - auc: 0.9321 - val_loss: 0.3148 - val_accuracy: 0.8955 - val_auc: 0.9373\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3324 - accuracy: 0.8864 - auc: 0.9378 - val_loss: 0.3164 - val_accuracy: 0.9048 - val_auc: 0.9354\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.3444 - accuracy: 0.8913 - auc: 0.9338 - val_loss: 0.3135 - val_accuracy: 0.8940 - val_auc: 0.9375\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3212 - accuracy: 0.8921 - auc: 0.9413 - val_loss: 0.3108 - val_accuracy: 0.8952 - val_auc: 0.9382\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3131 - accuracy: 0.8946 - auc: 0.9445 - val_loss: 0.3160 - val_accuracy: 0.8961 - val_auc: 0.9361\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3071 - accuracy: 0.8934 - auc: 0.9471 - val_loss: 0.3186 - val_accuracy: 0.8997 - val_auc: 0.9356\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3064 - accuracy: 0.8961 - auc: 0.9471 - val_loss: 0.3238 - val_accuracy: 0.8981 - val_auc: 0.9336\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3037 - accuracy: 0.8958 - auc: 0.9478 - val_loss: 0.3280 - val_accuracy: 0.8965 - val_auc: 0.9322\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2983 - accuracy: 0.8959 - auc: 0.9485 - val_loss: 0.3310 - val_accuracy: 0.9016 - val_auc: 0.9318\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2929 - accuracy: 0.8960 - auc: 0.9509 - val_loss: 0.3319 - val_accuracy: 0.9045 - val_auc: 0.9320\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3031 - accuracy: 0.8963 - auc: 0.9482 - val_loss: 0.3412 - val_accuracy: 0.8994 - val_auc: 0.9311\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2960 - accuracy: 0.8986 - auc: 0.9502 - val_loss: 0.3439 - val_accuracy: 0.8961 - val_auc: 0.9313\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2800 - accuracy: 0.8978 - auc: 0.9554 - val_loss: 0.3469 - val_accuracy: 0.9002 - val_auc: 0.9330\n",
      "Epoch 18/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.2861 - accuracy: 0.8996 - auc: 0.9533Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2858 - accuracy: 0.8996 - auc: 0.9537 - val_loss: 0.3581 - val_accuracy: 0.8977 - val_auc: 0.9300\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6053 - accuracy: 0.7104 - auc: 0.7831 - val_loss: 0.3978 - val_accuracy: 0.8304 - val_auc: 0.9173\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4467 - accuracy: 0.8303 - auc: 0.8851 - val_loss: 0.3536 - val_accuracy: 0.8663 - val_auc: 0.9301\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3872 - accuracy: 0.8665 - auc: 0.9150 - val_loss: 0.3297 - val_accuracy: 0.8769 - val_auc: 0.9418\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3675 - accuracy: 0.8749 - auc: 0.9235 - val_loss: 0.3185 - val_accuracy: 0.8834 - val_auc: 0.9427\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3338 - accuracy: 0.8814 - auc: 0.9371 - val_loss: 0.3144 - val_accuracy: 0.8852 - val_auc: 0.9422\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3308 - accuracy: 0.8819 - auc: 0.9372 - val_loss: 0.3128 - val_accuracy: 0.8886 - val_auc: 0.9427\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3129 - accuracy: 0.8887 - auc: 0.9443 - val_loss: 0.3128 - val_accuracy: 0.8917 - val_auc: 0.9409\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3096 - accuracy: 0.8885 - auc: 0.9452 - val_loss: 0.3121 - val_accuracy: 0.8945 - val_auc: 0.9410\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3019 - accuracy: 0.8934 - auc: 0.9473 - val_loss: 0.3220 - val_accuracy: 0.8853 - val_auc: 0.9374\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2893 - accuracy: 0.8909 - auc: 0.9517 - val_loss: 0.3154 - val_accuracy: 0.9009 - val_auc: 0.9401\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2952 - accuracy: 0.8953 - auc: 0.9494 - val_loss: 0.3285 - val_accuracy: 0.8860 - val_auc: 0.9351\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2860 - accuracy: 0.8914 - auc: 0.9533 - val_loss: 0.3252 - val_accuracy: 0.8933 - val_auc: 0.9372\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2827 - accuracy: 0.8899 - auc: 0.9538 - val_loss: 0.3300 - val_accuracy: 0.9065 - val_auc: 0.9359\n",
      "Epoch 14/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2795 - accuracy: 0.8974 - auc: 0.9545Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2797 - accuracy: 0.8974 - auc: 0.9545 - val_loss: 0.3311 - val_accuracy: 0.9003 - val_auc: 0.9366\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.9802 - accuracy: 0.7138 - auc: 0.6739 - val_loss: 0.5148 - val_accuracy: 0.7675 - val_auc: 0.8680\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5344 - accuracy: 0.7724 - auc: 0.8559 - val_loss: 0.3872 - val_accuracy: 0.8306 - val_auc: 0.9226\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4093 - accuracy: 0.8373 - auc: 0.9060 - val_loss: 0.3388 - val_accuracy: 0.8705 - val_auc: 0.9339\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3723 - accuracy: 0.8655 - auc: 0.9219 - val_loss: 0.3243 - val_accuracy: 0.8804 - val_auc: 0.9376\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3463 - accuracy: 0.8742 - auc: 0.9298 - val_loss: 0.3126 - val_accuracy: 0.8885 - val_auc: 0.9403\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3249 - accuracy: 0.8849 - auc: 0.9393 - val_loss: 0.3084 - val_accuracy: 0.8887 - val_auc: 0.9419\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3098 - accuracy: 0.8857 - auc: 0.9444 - val_loss: 0.3113 - val_accuracy: 0.8929 - val_auc: 0.9404\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3053 - accuracy: 0.8854 - auc: 0.9459 - val_loss: 0.3135 - val_accuracy: 0.8957 - val_auc: 0.9395\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2939 - accuracy: 0.8932 - auc: 0.9496 - val_loss: 0.3184 - val_accuracy: 0.8914 - val_auc: 0.9383\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2930 - accuracy: 0.8901 - auc: 0.9497 - val_loss: 0.3236 - val_accuracy: 0.8913 - val_auc: 0.9372\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2819 - accuracy: 0.8895 - auc: 0.9533 - val_loss: 0.3261 - val_accuracy: 0.9001 - val_auc: 0.9368\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2744 - accuracy: 0.8947 - auc: 0.9555 - val_loss: 0.3314 - val_accuracy: 0.8967 - val_auc: 0.9369\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2765 - accuracy: 0.8928 - auc: 0.9549 - val_loss: 0.3436 - val_accuracy: 0.8975 - val_auc: 0.9353\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2693 - accuracy: 0.8923 - auc: 0.9568 - val_loss: 0.3514 - val_accuracy: 0.8973 - val_auc: 0.9344\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2794 - accuracy: 0.8955 - auc: 0.9561 - val_loss: 0.3606 - val_accuracy: 0.8919 - val_auc: 0.9328\n",
      "Epoch 16/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2626 - accuracy: 0.8903 - auc: 0.9588Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2631 - accuracy: 0.8903 - auc: 0.9587 - val_loss: 0.3564 - val_accuracy: 0.8995 - val_auc: 0.9347\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.8209 - accuracy: 0.7568 - auc: 0.6928 - val_loss: 0.5033 - val_accuracy: 0.8244 - val_auc: 0.8911\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4648 - accuracy: 0.8263 - auc: 0.8770 - val_loss: 0.4244 - val_accuracy: 0.8682 - val_auc: 0.9204\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4196 - accuracy: 0.8550 - auc: 0.9030 - val_loss: 0.4041 - val_accuracy: 0.8869 - val_auc: 0.9253\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3708 - accuracy: 0.8775 - auc: 0.9205 - val_loss: 0.3759 - val_accuracy: 0.8948 - val_auc: 0.9303\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3307 - accuracy: 0.8854 - auc: 0.9384 - val_loss: 0.3722 - val_accuracy: 0.8950 - val_auc: 0.9315\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3284 - accuracy: 0.8889 - auc: 0.9388 - val_loss: 0.3749 - val_accuracy: 0.9019 - val_auc: 0.9298\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3270 - accuracy: 0.8945 - auc: 0.9387 - val_loss: 0.3760 - val_accuracy: 0.8958 - val_auc: 0.9309\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3099 - accuracy: 0.8912 - auc: 0.9455 - val_loss: 0.3725 - val_accuracy: 0.9045 - val_auc: 0.9314\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3087 - accuracy: 0.8970 - auc: 0.9446 - val_loss: 0.3813 - val_accuracy: 0.8940 - val_auc: 0.9311\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3024 - accuracy: 0.8938 - auc: 0.9460 - val_loss: 0.3760 - val_accuracy: 0.9023 - val_auc: 0.9319\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3032 - accuracy: 0.8950 - auc: 0.9470 - val_loss: 0.3743 - val_accuracy: 0.8985 - val_auc: 0.9323\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2981 - accuracy: 0.8948 - auc: 0.9483 - val_loss: 0.3699 - val_accuracy: 0.8980 - val_auc: 0.9329\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2986 - accuracy: 0.8957 - auc: 0.9477 - val_loss: 0.3757 - val_accuracy: 0.8998 - val_auc: 0.9328\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2782 - accuracy: 0.8981 - auc: 0.9548 - val_loss: 0.3840 - val_accuracy: 0.9049 - val_auc: 0.9315\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2752 - accuracy: 0.8983 - auc: 0.9554 - val_loss: 0.3872 - val_accuracy: 0.9024 - val_auc: 0.9311\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2775 - accuracy: 0.8986 - auc: 0.9540 - val_loss: 0.3999 - val_accuracy: 0.9048 - val_auc: 0.9316\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2684 - accuracy: 0.9020 - auc: 0.9566 - val_loss: 0.4065 - val_accuracy: 0.8998 - val_auc: 0.9308\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2707 - accuracy: 0.8999 - auc: 0.9564 - val_loss: 0.4135 - val_accuracy: 0.9023 - val_auc: 0.9302\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2598 - accuracy: 0.8989 - auc: 0.9592 - val_loss: 0.4272 - val_accuracy: 0.9058 - val_auc: 0.9290\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2732 - accuracy: 0.9001 - auc: 0.9553 - val_loss: 0.4341 - val_accuracy: 0.9016 - val_auc: 0.9280\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2644 - accuracy: 0.9008 - auc: 0.9581 - val_loss: 0.4489 - val_accuracy: 0.9080 - val_auc: 0.9266\n",
      "Epoch 22/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2585 - accuracy: 0.8991 - auc: 0.9592Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2580 - accuracy: 0.8991 - auc: 0.9594 - val_loss: 0.4617 - val_accuracy: 0.9056 - val_auc: 0.9269\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.8566 - accuracy: 0.3729 - auc: 0.6801 - val_loss: 0.4402 - val_accuracy: 0.6616 - val_auc: 0.9278\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4656 - accuracy: 0.7161 - auc: 0.8814 - val_loss: 0.3350 - val_accuracy: 0.8453 - val_auc: 0.9404\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3845 - accuracy: 0.8204 - auc: 0.9154 - val_loss: 0.3122 - val_accuracy: 0.8788 - val_auc: 0.9421\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3575 - accuracy: 0.8436 - auc: 0.9248 - val_loss: 0.3072 - val_accuracy: 0.8711 - val_auc: 0.9435\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3517 - accuracy: 0.8490 - auc: 0.9338 - val_loss: 0.3020 - val_accuracy: 0.8788 - val_auc: 0.9452\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3225 - accuracy: 0.8567 - auc: 0.9395 - val_loss: 0.3071 - val_accuracy: 0.8771 - val_auc: 0.9428\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3136 - accuracy: 0.8572 - auc: 0.9438 - val_loss: 0.3038 - val_accuracy: 0.8903 - val_auc: 0.9440\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3032 - accuracy: 0.8661 - auc: 0.9458 - val_loss: 0.3021 - val_accuracy: 0.8841 - val_auc: 0.9447\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2831 - accuracy: 0.8669 - auc: 0.9522 - val_loss: 0.3050 - val_accuracy: 0.8964 - val_auc: 0.9444\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2815 - accuracy: 0.8735 - auc: 0.9521 - val_loss: 0.3068 - val_accuracy: 0.8930 - val_auc: 0.9441\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2890 - accuracy: 0.8754 - auc: 0.9501 - val_loss: 0.3076 - val_accuracy: 0.8916 - val_auc: 0.9435\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2804 - accuracy: 0.8741 - auc: 0.9528 - val_loss: 0.3084 - val_accuracy: 0.8923 - val_auc: 0.9438\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2746 - accuracy: 0.8763 - auc: 0.9545 - val_loss: 0.3127 - val_accuracy: 0.8893 - val_auc: 0.9428\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2749 - accuracy: 0.8771 - auc: 0.9545 - val_loss: 0.3228 - val_accuracy: 0.8878 - val_auc: 0.9393\n",
      "Epoch 15/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.8759 - auc: 0.9576Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2659 - accuracy: 0.8760 - auc: 0.9573 - val_loss: 0.3222 - val_accuracy: 0.8940 - val_auc: 0.9416\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.7042 - accuracy: 0.6514 - auc: 0.7469 - val_loss: 0.4177 - val_accuracy: 0.7862 - val_auc: 0.9219\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4477 - accuracy: 0.8018 - auc: 0.8903 - val_loss: 0.3620 - val_accuracy: 0.8532 - val_auc: 0.9367\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3988 - accuracy: 0.8491 - auc: 0.9098 - val_loss: 0.3418 - val_accuracy: 0.8681 - val_auc: 0.9391\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3747 - accuracy: 0.8639 - auc: 0.9221 - val_loss: 0.3382 - val_accuracy: 0.8809 - val_auc: 0.9383\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3447 - accuracy: 0.8762 - auc: 0.9333 - val_loss: 0.3306 - val_accuracy: 0.8839 - val_auc: 0.9371\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3323 - accuracy: 0.8825 - auc: 0.9367 - val_loss: 0.3356 - val_accuracy: 0.8826 - val_auc: 0.9375\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3117 - accuracy: 0.8854 - auc: 0.9456 - val_loss: 0.3313 - val_accuracy: 0.8899 - val_auc: 0.9366\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3192 - accuracy: 0.8877 - auc: 0.9422 - val_loss: 0.3330 - val_accuracy: 0.8950 - val_auc: 0.9357\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2970 - accuracy: 0.8902 - auc: 0.9498 - val_loss: 0.3330 - val_accuracy: 0.8956 - val_auc: 0.9350\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2889 - accuracy: 0.8925 - auc: 0.9524 - val_loss: 0.3380 - val_accuracy: 0.9016 - val_auc: 0.9351\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2950 - accuracy: 0.8956 - auc: 0.9502 - val_loss: 0.3450 - val_accuracy: 0.8898 - val_auc: 0.9347\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2904 - accuracy: 0.8893 - auc: 0.9519 - val_loss: 0.3463 - val_accuracy: 0.8952 - val_auc: 0.9343\n",
      "Epoch 13/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2797 - accuracy: 0.8950 - auc: 0.9558Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2805 - accuracy: 0.8951 - auc: 0.9552 - val_loss: 0.3553 - val_accuracy: 0.9001 - val_auc: 0.9325\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 18us/sample - loss: 0.5967 - accuracy: 0.7989 - auc: 0.8108 - val_loss: 0.3962 - val_accuracy: 0.8409 - val_auc: 0.9180\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4137 - accuracy: 0.8406 - auc: 0.9055 - val_loss: 0.3787 - val_accuracy: 0.8762 - val_auc: 0.9207\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3736 - accuracy: 0.8723 - auc: 0.9195 - val_loss: 0.3743 - val_accuracy: 0.8851 - val_auc: 0.9210\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3454 - accuracy: 0.8807 - auc: 0.9358 - val_loss: 0.3528 - val_accuracy: 0.8926 - val_auc: 0.9244\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3257 - accuracy: 0.8860 - auc: 0.9395 - val_loss: 0.3440 - val_accuracy: 0.8992 - val_auc: 0.9274\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3173 - accuracy: 0.8902 - auc: 0.9446 - val_loss: 0.3476 - val_accuracy: 0.8956 - val_auc: 0.9272\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3059 - accuracy: 0.8911 - auc: 0.9482 - val_loss: 0.3580 - val_accuracy: 0.8990 - val_auc: 0.9236\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2932 - accuracy: 0.8948 - auc: 0.9519 - val_loss: 0.3541 - val_accuracy: 0.8996 - val_auc: 0.9258\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2968 - accuracy: 0.8943 - auc: 0.9507 - val_loss: 0.3581 - val_accuracy: 0.9018 - val_auc: 0.9242\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2911 - accuracy: 0.8976 - auc: 0.9523 - val_loss: 0.3612 - val_accuracy: 0.8962 - val_auc: 0.9251\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2834 - accuracy: 0.8957 - auc: 0.9541 - val_loss: 0.3552 - val_accuracy: 0.8957 - val_auc: 0.9265\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2753 - accuracy: 0.8962 - auc: 0.9569 - val_loss: 0.3668 - val_accuracy: 0.9010 - val_auc: 0.9265\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2848 - accuracy: 0.8991 - auc: 0.9532 - val_loss: 0.3713 - val_accuracy: 0.8852 - val_auc: 0.9253\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2733 - accuracy: 0.8937 - auc: 0.9574 - val_loss: 0.3711 - val_accuracy: 0.9028 - val_auc: 0.9253\n",
      "Epoch 15/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9001 - auc: 0.9588Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2678 - accuracy: 0.9001 - auc: 0.9587 - val_loss: 0.3813 - val_accuracy: 0.9016 - val_auc: 0.9232\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.8046 - accuracy: 0.3815 - auc: 0.7127 - val_loss: 0.4281 - val_accuracy: 0.7084 - val_auc: 0.9221\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4541 - accuracy: 0.7408 - auc: 0.8873 - val_loss: 0.3541 - val_accuracy: 0.8515 - val_auc: 0.9312\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3833 - accuracy: 0.8212 - auc: 0.9173 - val_loss: 0.3393 - val_accuracy: 0.8676 - val_auc: 0.9343\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3550 - accuracy: 0.8399 - auc: 0.9263 - val_loss: 0.3330 - val_accuracy: 0.8773 - val_auc: 0.9343\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3330 - accuracy: 0.8539 - auc: 0.9353 - val_loss: 0.3421 - val_accuracy: 0.8765 - val_auc: 0.9320\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3235 - accuracy: 0.8539 - auc: 0.9380 - val_loss: 0.3412 - val_accuracy: 0.8748 - val_auc: 0.9334\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3160 - accuracy: 0.8588 - auc: 0.9406 - val_loss: 0.3377 - val_accuracy: 0.8813 - val_auc: 0.9337\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3107 - accuracy: 0.8642 - auc: 0.9423 - val_loss: 0.3513 - val_accuracy: 0.8752 - val_auc: 0.9324\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2910 - accuracy: 0.8669 - auc: 0.9499 - val_loss: 0.3509 - val_accuracy: 0.8863 - val_auc: 0.9320\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2758 - accuracy: 0.8724 - auc: 0.9544 - val_loss: 0.3605 - val_accuracy: 0.8887 - val_auc: 0.9319\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2928 - accuracy: 0.8723 - auc: 0.9485 - val_loss: 0.3595 - val_accuracy: 0.8782 - val_auc: 0.9309\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2796 - accuracy: 0.8688 - auc: 0.9530 - val_loss: 0.3553 - val_accuracy: 0.8928 - val_auc: 0.9322\n",
      "Epoch 13/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.8758 - auc: 0.9576Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2657 - accuracy: 0.8757 - auc: 0.9576 - val_loss: 0.3694 - val_accuracy: 0.8830 - val_auc: 0.9315\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 0.8352 - accuracy: 0.8911 - auc: 0.7220 - val_loss: 0.5188 - val_accuracy: 0.8746 - val_auc: 0.8854\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4763 - accuracy: 0.8522 - auc: 0.8726 - val_loss: 0.4061 - val_accuracy: 0.8793 - val_auc: 0.9202\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3968 - accuracy: 0.8735 - auc: 0.9072 - val_loss: 0.3774 - val_accuracy: 0.8861 - val_auc: 0.9236\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3602 - accuracy: 0.8819 - auc: 0.9229 - val_loss: 0.3610 - val_accuracy: 0.8977 - val_auc: 0.9250\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3556 - accuracy: 0.8870 - auc: 0.9277 - val_loss: 0.3397 - val_accuracy: 0.8959 - val_auc: 0.9296\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3203 - accuracy: 0.8917 - auc: 0.9425 - val_loss: 0.3519 - val_accuracy: 0.9001 - val_auc: 0.9281\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3212 - accuracy: 0.8928 - auc: 0.9405 - val_loss: 0.3564 - val_accuracy: 0.8974 - val_auc: 0.9291\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3176 - accuracy: 0.8925 - auc: 0.9429 - val_loss: 0.3498 - val_accuracy: 0.8976 - val_auc: 0.9296\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3066 - accuracy: 0.8940 - auc: 0.9471 - val_loss: 0.3442 - val_accuracy: 0.9124 - val_auc: 0.9313\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2953 - accuracy: 0.9010 - auc: 0.9501 - val_loss: 0.3485 - val_accuracy: 0.9048 - val_auc: 0.9309\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2961 - accuracy: 0.8983 - auc: 0.9492 - val_loss: 0.3683 - val_accuracy: 0.8986 - val_auc: 0.9295\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2944 - accuracy: 0.8998 - auc: 0.9498 - val_loss: 0.3682 - val_accuracy: 0.8995 - val_auc: 0.9293\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2829 - accuracy: 0.8990 - auc: 0.9530 - val_loss: 0.3791 - val_accuracy: 0.9003 - val_auc: 0.9294\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2825 - accuracy: 0.8986 - auc: 0.9528 - val_loss: 0.3778 - val_accuracy: 0.9044 - val_auc: 0.9295\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2859 - accuracy: 0.8997 - auc: 0.9519 - val_loss: 0.3841 - val_accuracy: 0.8996 - val_auc: 0.9293\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2745 - accuracy: 0.8995 - auc: 0.9556 - val_loss: 0.3926 - val_accuracy: 0.9005 - val_auc: 0.9301\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2679 - accuracy: 0.9002 - auc: 0.9573 - val_loss: 0.4035 - val_accuracy: 0.9055 - val_auc: 0.9298\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2704 - accuracy: 0.9024 - auc: 0.9563 - val_loss: 0.4089 - val_accuracy: 0.9036 - val_auc: 0.9306\n",
      "Epoch 19/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9011 - auc: 0.9586Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2630 - accuracy: 0.9011 - auc: 0.9587 - val_loss: 0.4124 - val_accuracy: 0.9040 - val_auc: 0.9305\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.4988 - accuracy: 0.7541 - auc: 0.8483 - val_loss: 0.3794 - val_accuracy: 0.8649 - val_auc: 0.9310\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3842 - accuracy: 0.8606 - auc: 0.9159 - val_loss: 0.3312 - val_accuracy: 0.8792 - val_auc: 0.9382\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3559 - accuracy: 0.8729 - auc: 0.9269 - val_loss: 0.3115 - val_accuracy: 0.8865 - val_auc: 0.9430\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3317 - accuracy: 0.8821 - auc: 0.9360 - val_loss: 0.3142 - val_accuracy: 0.8905 - val_auc: 0.9400\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3021 - accuracy: 0.8888 - auc: 0.9473 - val_loss: 0.3139 - val_accuracy: 0.8906 - val_auc: 0.9383\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3014 - accuracy: 0.8902 - auc: 0.9468 - val_loss: 0.3158 - val_accuracy: 0.8984 - val_auc: 0.9385\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2892 - accuracy: 0.8940 - auc: 0.9514 - val_loss: 0.3185 - val_accuracy: 0.8932 - val_auc: 0.9374\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2779 - accuracy: 0.8943 - auc: 0.9545 - val_loss: 0.3186 - val_accuracy: 0.9006 - val_auc: 0.9377\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2811 - accuracy: 0.8932 - auc: 0.9531 - val_loss: 0.3099 - val_accuracy: 0.8983 - val_auc: 0.9412\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2733 - accuracy: 0.8965 - auc: 0.9557 - val_loss: 0.3204 - val_accuracy: 0.8950 - val_auc: 0.9382\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2728 - accuracy: 0.8954 - auc: 0.9554 - val_loss: 0.3219 - val_accuracy: 0.8980 - val_auc: 0.9388\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2702 - accuracy: 0.8932 - auc: 0.9560 - val_loss: 0.3314 - val_accuracy: 0.9009 - val_auc: 0.9357\n",
      "Epoch 13/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.8958 - auc: 0.9596Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2603 - accuracy: 0.8958 - auc: 0.9597 - val_loss: 0.3342 - val_accuracy: 0.9054 - val_auc: 0.9360\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.6133 - accuracy: 0.6943 - auc: 0.7915 - val_loss: 0.3757 - val_accuracy: 0.8377 - val_auc: 0.9258\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4496 - accuracy: 0.8219 - auc: 0.8897 - val_loss: 0.3306 - val_accuracy: 0.8782 - val_auc: 0.9422\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3848 - accuracy: 0.8637 - auc: 0.9189 - val_loss: 0.3198 - val_accuracy: 0.8811 - val_auc: 0.9425\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3478 - accuracy: 0.8745 - auc: 0.9319 - val_loss: 0.3197 - val_accuracy: 0.8848 - val_auc: 0.9385\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3247 - accuracy: 0.8784 - auc: 0.9412 - val_loss: 0.3147 - val_accuracy: 0.8910 - val_auc: 0.9393\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3304 - accuracy: 0.8819 - auc: 0.9381 - val_loss: 0.3265 - val_accuracy: 0.8854 - val_auc: 0.9341\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3142 - accuracy: 0.8828 - auc: 0.9436 - val_loss: 0.3282 - val_accuracy: 0.8867 - val_auc: 0.9341\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3027 - accuracy: 0.8852 - auc: 0.9477 - val_loss: 0.3278 - val_accuracy: 0.8915 - val_auc: 0.9351\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2902 - accuracy: 0.8891 - auc: 0.9518 - val_loss: 0.3338 - val_accuracy: 0.8856 - val_auc: 0.9346\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2815 - accuracy: 0.8877 - auc: 0.9546 - val_loss: 0.3278 - val_accuracy: 0.8967 - val_auc: 0.9359\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2860 - accuracy: 0.8904 - auc: 0.9526 - val_loss: 0.3262 - val_accuracy: 0.8964 - val_auc: 0.9368\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2701 - accuracy: 0.8925 - auc: 0.9576 - val_loss: 0.3428 - val_accuracy: 0.8897 - val_auc: 0.9321\n",
      "Epoch 13/100\n",
      "248832/250291 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.8924 - auc: 0.9539Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2802 - accuracy: 0.8923 - auc: 0.9540 - val_loss: 0.3559 - val_accuracy: 0.8917 - val_auc: 0.9311\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.7736 - accuracy: 0.7745 - auc: 0.7797 - val_loss: 0.5333 - val_accuracy: 0.8703 - val_auc: 0.9127\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6576 - accuracy: 0.8469 - auc: 0.8386 - val_loss: 0.5795 - val_accuracy: 0.8677 - val_auc: 0.8742\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6231 - accuracy: 0.8685 - auc: 0.8359 - val_loss: 0.4799 - val_accuracy: 0.9169 - val_auc: 0.9202\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6968 - accuracy: 0.8956 - auc: 0.8191 - val_loss: 0.8233 - val_accuracy: 0.9353 - val_auc: 0.9095\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6148 - accuracy: 0.9092 - auc: 0.8377 - val_loss: 0.6248 - val_accuracy: 0.8547 - val_auc: 0.9125\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6223 - accuracy: 0.8969 - auc: 0.8267 - val_loss: 0.8867 - val_accuracy: 0.8711 - val_auc: 0.9217\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5606 - accuracy: 0.9040 - auc: 0.8307 - val_loss: 0.8972 - val_accuracy: 0.9035 - val_auc: 0.9249\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5203 - accuracy: 0.9251 - auc: 0.8459 - val_loss: 1.0742 - val_accuracy: 0.8650 - val_auc: 0.9206\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8963 - accuracy: 0.8942 - auc: 0.8067 - val_loss: 3.5211 - val_accuracy: 0.9038 - val_auc: 0.9068\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6456 - accuracy: 0.9194 - auc: 0.8145 - val_loss: 3.7439 - val_accuracy: 0.9565 - val_auc: 0.8708\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6558 - accuracy: 0.9317 - auc: 0.7654 - val_loss: 0.6555 - val_accuracy: 0.8941 - val_auc: 0.9093\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5255 - accuracy: 0.9318 - auc: 0.7917 - val_loss: 1.5183 - val_accuracy: 0.9262 - val_auc: 0.9047\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5729 - accuracy: 0.9383 - auc: 0.7577 - val_loss: 1.5467 - val_accuracy: 0.9036 - val_auc: 0.9203\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5380 - accuracy: 0.9401 - auc: 0.7869 - val_loss: 1.0413 - val_accuracy: 0.9292 - val_auc: 0.8948\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5657 - accuracy: 0.8638 - auc: 0.7282 - val_loss: 1.1618 - val_accuracy: 0.9779 - val_auc: 0.8154\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5516 - accuracy: 0.7815 - auc: 0.7564 - val_loss: 1.0810 - val_accuracy: 0.9832 - val_auc: 0.8186\n",
      "Epoch 17/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.6097 - accuracy: 0.6068 - auc: 0.6965Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6094 - accuracy: 0.6001 - auc: 0.6952 - val_loss: 0.6294 - val_accuracy: 0.4482 - val_auc: 0.8152\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.9336 - accuracy: 0.7104 - auc: 0.7585 - val_loss: 0.6201 - val_accuracy: 0.8685 - val_auc: 0.8800\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6646 - accuracy: 0.8615 - auc: 0.8339 - val_loss: 0.5482 - val_accuracy: 0.8903 - val_auc: 0.9258\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6808 - accuracy: 0.8711 - auc: 0.8349 - val_loss: 0.6733 - val_accuracy: 0.9218 - val_auc: 0.9123\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5519 - accuracy: 0.8965 - auc: 0.8640 - val_loss: 0.6130 - val_accuracy: 0.9160 - val_auc: 0.9236\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6846 - accuracy: 0.9040 - auc: 0.8339 - val_loss: 1.3318 - val_accuracy: 0.8614 - val_auc: 0.9160\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9439 - accuracy: 0.9004 - auc: 0.7975 - val_loss: 1.5641 - val_accuracy: 0.8727 - val_auc: 0.9049\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6743 - accuracy: 0.9341 - auc: 0.7895 - val_loss: 2.7459 - val_accuracy: 0.9482 - val_auc: 0.8963\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6469 - accuracy: 0.9133 - auc: 0.7909 - val_loss: 1.4890 - val_accuracy: 0.8836 - val_auc: 0.9155\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6799 - accuracy: 0.9165 - auc: 0.8114 - val_loss: 1.1036 - val_accuracy: 0.9203 - val_auc: 0.9102\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5430 - accuracy: 0.8996 - auc: 0.8032 - val_loss: 1.3733 - val_accuracy: 0.8712 - val_auc: 0.9219\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5327 - accuracy: 0.9422 - auc: 0.7902 - val_loss: 1.3324 - val_accuracy: 0.9052 - val_auc: 0.9189\n",
      "Epoch 12/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.5108 - accuracy: 0.7218 - auc: 0.7860Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5123 - accuracy: 0.7241 - auc: 0.7857 - val_loss: 1.3519 - val_accuracy: 0.9321 - val_auc: 0.9153\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.8033 - accuracy: 0.7702 - auc: 0.7399 - val_loss: 0.5645 - val_accuracy: 0.8992 - val_auc: 0.8882\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6222 - accuracy: 0.8759 - auc: 0.8410 - val_loss: 0.5558 - val_accuracy: 0.8791 - val_auc: 0.9155\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6880 - accuracy: 0.8711 - auc: 0.8229 - val_loss: 0.7252 - val_accuracy: 0.9202 - val_auc: 0.8632\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6613 - accuracy: 0.8858 - auc: 0.8112 - val_loss: 0.5397 - val_accuracy: 0.8217 - val_auc: 0.9128\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5836 - accuracy: 0.9051 - auc: 0.8192 - val_loss: 0.6155 - val_accuracy: 0.9004 - val_auc: 0.9045\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5212 - accuracy: 0.9184 - auc: 0.8363 - val_loss: 0.7491 - val_accuracy: 0.9046 - val_auc: 0.9104\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6230 - accuracy: 0.9283 - auc: 0.8237 - val_loss: 0.7503 - val_accuracy: 0.8852 - val_auc: 0.8978\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5423 - accuracy: 0.8463 - auc: 0.8109 - val_loss: 0.6517 - val_accuracy: 0.9255 - val_auc: 0.8836\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5665 - accuracy: 0.7503 - auc: 0.7983 - val_loss: 0.8333 - val_accuracy: 0.5823 - val_auc: 0.8890\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6676 - accuracy: 0.4074 - auc: 0.7257 - val_loss: 1.9478 - val_accuracy: 0.5508 - val_auc: 0.8011\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6792 - accuracy: 0.4278 - auc: 0.7343 - val_loss: 1.2744 - val_accuracy: 0.9517 - val_auc: 0.8561\n",
      "Epoch 12/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.6552 - accuracy: 0.4715 - auc: 0.7259Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6529 - accuracy: 0.4705 - auc: 0.7258 - val_loss: 2.0886 - val_accuracy: 0.6086 - val_auc: 0.8100\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 19us/sample - loss: 0.9137 - accuracy: 0.7398 - auc: 0.7786 - val_loss: 1.2018 - val_accuracy: 0.5871 - val_auc: 0.8417\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7249 - accuracy: 0.8521 - auc: 0.8359 - val_loss: 0.5810 - val_accuracy: 0.8663 - val_auc: 0.9057\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6540 - accuracy: 0.8514 - auc: 0.8392 - val_loss: 0.9149 - val_accuracy: 0.8734 - val_auc: 0.9088\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0195 - accuracy: 0.7151 - auc: 0.7888 - val_loss: 1.5459 - val_accuracy: 0.5836 - val_auc: 0.7804\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7216 - accuracy: 0.4681 - auc: 0.7368 - val_loss: 1.0048 - val_accuracy: 0.6716 - val_auc: 0.8314\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6187 - accuracy: 0.5185 - auc: 0.7534 - val_loss: 0.8344 - val_accuracy: 0.6989 - val_auc: 0.8547\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5186 - accuracy: 0.5617 - auc: 0.7930 - val_loss: 0.6289 - val_accuracy: 0.6701 - val_auc: 0.8716\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4744 - accuracy: 0.5761 - auc: 0.8214 - val_loss: 0.7766 - val_accuracy: 0.7561 - val_auc: 0.9214\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4620 - accuracy: 0.5988 - auc: 0.8538 - val_loss: 0.7223 - val_accuracy: 0.6768 - val_auc: 0.9173\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4462 - accuracy: 0.5915 - auc: 0.8571 - val_loss: 0.5409 - val_accuracy: 0.7437 - val_auc: 0.9237\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4180 - accuracy: 0.6035 - auc: 0.8635 - val_loss: 0.7151 - val_accuracy: 0.7192 - val_auc: 0.9217\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4604 - accuracy: 0.5940 - auc: 0.8480 - val_loss: 0.9885 - val_accuracy: 0.7257 - val_auc: 0.9140\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4847 - accuracy: 0.5889 - auc: 0.8489 - val_loss: 0.8266 - val_accuracy: 0.7438 - val_auc: 0.9172\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4524 - accuracy: 0.5915 - auc: 0.8517 - val_loss: 0.8346 - val_accuracy: 0.6901 - val_auc: 0.8796\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4806 - accuracy: 0.5737 - auc: 0.8079 - val_loss: 1.1316 - val_accuracy: 0.7181 - val_auc: 0.8697\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4714 - accuracy: 0.5907 - auc: 0.8229 - val_loss: 0.8376 - val_accuracy: 0.6819 - val_auc: 0.8753\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4505 - accuracy: 0.5921 - auc: 0.8315 - val_loss: 1.1199 - val_accuracy: 0.7118 - val_auc: 0.8760\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5087 - accuracy: 0.5840 - auc: 0.8247 - val_loss: 1.4787 - val_accuracy: 0.6974 - val_auc: 0.8606\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4864 - accuracy: 0.5777 - auc: 0.7971 - val_loss: 1.2326 - val_accuracy: 0.6931 - val_auc: 0.8300\n",
      "Epoch 20/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.5240 - accuracy: 0.5748 - auc: 0.8017Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5242 - accuracy: 0.5748 - auc: 0.8015 - val_loss: 1.7671 - val_accuracy: 0.7082 - val_auc: 0.8421\n",
      "Epoch 00020: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.9256 - accuracy: 0.7442 - auc: 0.7378 - val_loss: 0.6968 - val_accuracy: 0.8867 - val_auc: 0.8880\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6036 - accuracy: 0.8628 - auc: 0.8167 - val_loss: 0.5364 - val_accuracy: 0.8655 - val_auc: 0.9258\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9604 - accuracy: 0.8446 - auc: 0.8319 - val_loss: 1.1411 - val_accuracy: 0.9488 - val_auc: 0.9032\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7668 - accuracy: 0.8953 - auc: 0.7622 - val_loss: 0.6466 - val_accuracy: 0.8678 - val_auc: 0.9200\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3468 - accuracy: 0.6908 - auc: 0.7574 - val_loss: 0.4996 - val_accuracy: 0.6111 - val_auc: 0.9293\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6547 - accuracy: 0.7392 - auc: 0.7960 - val_loss: 0.8436 - val_accuracy: 0.9088 - val_auc: 0.8113\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8503 - accuracy: 0.5479 - auc: 0.7740 - val_loss: 1.2687 - val_accuracy: 0.5822 - val_auc: 0.8966\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5755 - accuracy: 0.4387 - auc: 0.7221 - val_loss: 0.9979 - val_accuracy: 0.5791 - val_auc: 0.8136\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7751 - accuracy: 0.4108 - auc: 0.7267 - val_loss: 0.9115 - val_accuracy: 0.9425 - val_auc: 0.9062\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6114 - accuracy: 0.6004 - auc: 0.7870 - val_loss: 0.6901 - val_accuracy: 0.9312 - val_auc: 0.9242\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5143 - accuracy: 0.6809 - auc: 0.8058 - val_loss: 0.5846 - val_accuracy: 0.9049 - val_auc: 0.9141\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5447 - accuracy: 0.7045 - auc: 0.8169 - val_loss: 0.8358 - val_accuracy: 0.9088 - val_auc: 0.9113\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5826 - accuracy: 0.7714 - auc: 0.8262 - val_loss: 0.9716 - val_accuracy: 0.6299 - val_auc: 0.9101\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5581 - accuracy: 0.7251 - auc: 0.8394 - val_loss: 0.6625 - val_accuracy: 0.8948 - val_auc: 0.8986\n",
      "Epoch 15/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.5635 - accuracy: 0.6207 - auc: 0.8042Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5631 - accuracy: 0.6169 - auc: 0.8037 - val_loss: 0.6738 - val_accuracy: 0.5971 - val_auc: 0.8427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.0257 - accuracy: 0.7645 - auc: 0.8063 - val_loss: 0.8277 - val_accuracy: 0.7021 - val_auc: 0.9028\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2951 - accuracy: 0.7910 - auc: 0.8085 - val_loss: 1.0374 - val_accuracy: 0.7538 - val_auc: 0.8426\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9185 - accuracy: 0.8634 - auc: 0.8458 - val_loss: 0.6603 - val_accuracy: 0.7423 - val_auc: 0.8983\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7551 - accuracy: 0.8576 - auc: 0.8577 - val_loss: 1.1080 - val_accuracy: 0.9402 - val_auc: 0.9029\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7887 - accuracy: 0.8837 - auc: 0.8260 - val_loss: 1.3501 - val_accuracy: 0.8879 - val_auc: 0.8862\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.9800 - accuracy: 0.8804 - auc: 0.8327 - val_loss: 1.4489 - val_accuracy: 0.9311 - val_auc: 0.8789\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6519 - accuracy: 0.9062 - auc: 0.8472 - val_loss: 1.3545 - val_accuracy: 0.8783 - val_auc: 0.9121\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5253 - accuracy: 0.9183 - auc: 0.8432 - val_loss: 1.4776 - val_accuracy: 0.8862 - val_auc: 0.8927\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5372 - accuracy: 0.9207 - auc: 0.8498 - val_loss: 1.1097 - val_accuracy: 0.9189 - val_auc: 0.9129\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7935 - accuracy: 0.8970 - auc: 0.8384 - val_loss: 1.2506 - val_accuracy: 0.9033 - val_auc: 0.9190\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2720 - accuracy: 0.9118 - auc: 0.8088 - val_loss: 1.2916 - val_accuracy: 0.8919 - val_auc: 0.9182\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5570 - accuracy: 0.8931 - auc: 0.8109 - val_loss: 1.0331 - val_accuracy: 0.9244 - val_auc: 0.8677\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6246 - accuracy: 0.8969 - auc: 0.7906 - val_loss: 1.1272 - val_accuracy: 0.9301 - val_auc: 0.8872\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5474 - accuracy: 0.9326 - auc: 0.8125 - val_loss: 0.9162 - val_accuracy: 0.9080 - val_auc: 0.9120\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4676 - accuracy: 0.9318 - auc: 0.8552 - val_loss: 0.6816 - val_accuracy: 0.9238 - val_auc: 0.9154\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4943 - accuracy: 0.8691 - auc: 0.8455 - val_loss: 0.9412 - val_accuracy: 0.9232 - val_auc: 0.9116\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5381 - accuracy: 0.7545 - auc: 0.8263 - val_loss: 1.4274 - val_accuracy: 0.5957 - val_auc: 0.9232\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4831 - accuracy: 0.7987 - auc: 0.8344 - val_loss: 1.6730 - val_accuracy: 0.9186 - val_auc: 0.9139\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4689 - accuracy: 0.9380 - auc: 0.8392 - val_loss: 2.0406 - val_accuracy: 0.9006 - val_auc: 0.9131\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5741 - accuracy: 0.6415 - auc: 0.8193 - val_loss: 1.9965 - val_accuracy: 0.6298 - val_auc: 0.8858\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5844 - accuracy: 0.5129 - auc: 0.7927 - val_loss: 1.2363 - val_accuracy: 0.6596 - val_auc: 0.8673\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5732 - accuracy: 0.4739 - auc: 0.7932 - val_loss: 1.6697 - val_accuracy: 0.6524 - val_auc: 0.8833\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5121 - accuracy: 0.4903 - auc: 0.7956 - val_loss: 1.7622 - val_accuracy: 0.6651 - val_auc: 0.8093\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5757 - accuracy: 0.4952 - auc: 0.7464 - val_loss: 0.8823 - val_accuracy: 0.6550 - val_auc: 0.8058\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5005 - accuracy: 0.5146 - auc: 0.7530 - val_loss: 1.2165 - val_accuracy: 0.6800 - val_auc: 0.8155\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4814 - accuracy: 0.5365 - auc: 0.7679 - val_loss: 1.2411 - val_accuracy: 0.6932 - val_auc: 0.8147\n",
      "Epoch 27/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.4812 - accuracy: 0.5495 - auc: 0.7737Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4838 - accuracy: 0.5495 - auc: 0.7720 - val_loss: 1.1580 - val_accuracy: 0.6938 - val_auc: 0.8220\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.2170 - accuracy: 0.6902 - auc: 0.7783 - val_loss: 0.8295 - val_accuracy: 0.7982 - val_auc: 0.8685\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4415 - accuracy: 0.7901 - auc: 0.8103 - val_loss: 1.0923 - val_accuracy: 0.8842 - val_auc: 0.9075\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4695 - accuracy: 0.8301 - auc: 0.8297 - val_loss: 2.9262 - val_accuracy: 0.8618 - val_auc: 0.9131\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3309 - accuracy: 0.8685 - auc: 0.8346 - val_loss: 0.7851 - val_accuracy: 0.7850 - val_auc: 0.8975\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0214 - accuracy: 0.8653 - auc: 0.7631 - val_loss: 2.2317 - val_accuracy: 0.8657 - val_auc: 0.8889\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6017 - accuracy: 0.9315 - auc: 0.8341 - val_loss: 1.2721 - val_accuracy: 0.9061 - val_auc: 0.9135\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5725 - accuracy: 0.8951 - auc: 0.8604 - val_loss: 1.4170 - val_accuracy: 0.9160 - val_auc: 0.9136\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5465 - accuracy: 0.9063 - auc: 0.8748 - val_loss: 1.1782 - val_accuracy: 0.8932 - val_auc: 0.9185\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5120 - accuracy: 0.9115 - auc: 0.8837 - val_loss: 1.4600 - val_accuracy: 0.8739 - val_auc: 0.9117\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5001 - accuracy: 0.8918 - auc: 0.8676 - val_loss: 2.2251 - val_accuracy: 0.8938 - val_auc: 0.9108\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5064 - accuracy: 0.8388 - auc: 0.8704 - val_loss: 1.6163 - val_accuracy: 0.6265 - val_auc: 0.9008\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5084 - accuracy: 0.8050 - auc: 0.8602 - val_loss: 1.8874 - val_accuracy: 0.8855 - val_auc: 0.9105\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4749 - accuracy: 0.8429 - auc: 0.8640 - val_loss: 1.8393 - val_accuracy: 0.9021 - val_auc: 0.9205\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4403 - accuracy: 0.9287 - auc: 0.8922 - val_loss: 1.4833 - val_accuracy: 0.9390 - val_auc: 0.9204\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4304 - accuracy: 0.8804 - auc: 0.8804 - val_loss: 1.5658 - val_accuracy: 0.8909 - val_auc: 0.9246\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4497 - accuracy: 0.8287 - auc: 0.8828 - val_loss: 1.8358 - val_accuracy: 0.9083 - val_auc: 0.9172\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4182 - accuracy: 0.9301 - auc: 0.8797 - val_loss: 1.8135 - val_accuracy: 0.9100 - val_auc: 0.9221\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5063 - accuracy: 0.8307 - auc: 0.8614 - val_loss: 2.0950 - val_accuracy: 0.6272 - val_auc: 0.8358\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4762 - accuracy: 0.5423 - auc: 0.8064 - val_loss: 1.8977 - val_accuracy: 0.6368 - val_auc: 0.9127\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4425 - accuracy: 0.5414 - auc: 0.8372 - val_loss: 1.7011 - val_accuracy: 0.6669 - val_auc: 0.9145\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4406 - accuracy: 0.5862 - auc: 0.8394 - val_loss: 1.9483 - val_accuracy: 0.6572 - val_auc: 0.9172\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4507 - accuracy: 0.5121 - auc: 0.8310 - val_loss: 1.6186 - val_accuracy: 0.6372 - val_auc: 0.9166\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4473 - accuracy: 0.5114 - auc: 0.8261 - val_loss: 2.5618 - val_accuracy: 0.6832 - val_auc: 0.9110\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4491 - accuracy: 0.5208 - auc: 0.8342 - val_loss: 1.9110 - val_accuracy: 0.6654 - val_auc: 0.9189\n",
      "Epoch 25/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.4472 - accuracy: 0.5379 - auc: 0.8417Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4462 - accuracy: 0.5377 - auc: 0.8410 - val_loss: 1.8612 - val_accuracy: 0.6518 - val_auc: 0.9119\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 6s 24us/sample - loss: 1.7686 - accuracy: 0.6882 - auc: 0.7625 - val_loss: 2.3001 - val_accuracy: 0.8581 - val_auc: 0.8786\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7904 - accuracy: 0.7887 - auc: 0.7974 - val_loss: 0.9229 - val_accuracy: 0.8562 - val_auc: 0.9062\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5174 - accuracy: 0.8433 - auc: 0.8248 - val_loss: 1.1003 - val_accuracy: 0.8873 - val_auc: 0.8689\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1660 - accuracy: 0.8623 - auc: 0.7781 - val_loss: 0.8714 - val_accuracy: 0.8743 - val_auc: 0.8919\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7234 - accuracy: 0.8638 - auc: 0.8173 - val_loss: 0.8553 - val_accuracy: 0.9400 - val_auc: 0.9055\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6331 - accuracy: 0.7756 - auc: 0.8497 - val_loss: 1.1695 - val_accuracy: 0.8868 - val_auc: 0.9193\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5611 - accuracy: 0.8827 - auc: 0.8662 - val_loss: 0.8214 - val_accuracy: 0.8476 - val_auc: 0.9149\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4751 - accuracy: 0.8804 - auc: 0.8686 - val_loss: 0.7541 - val_accuracy: 0.6671 - val_auc: 0.9213\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6071 - accuracy: 0.7840 - auc: 0.8676 - val_loss: 1.4177 - val_accuracy: 0.8849 - val_auc: 0.9227\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5187 - accuracy: 0.7121 - auc: 0.8780 - val_loss: 1.5918 - val_accuracy: 0.6827 - val_auc: 0.9185\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5675 - accuracy: 0.5773 - auc: 0.8464 - val_loss: 3.0686 - val_accuracy: 0.6558 - val_auc: 0.8619\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6915 - accuracy: 0.5554 - auc: 0.7967 - val_loss: 2.4558 - val_accuracy: 0.5768 - val_auc: 0.8588\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6050 - accuracy: 0.5129 - auc: 0.7935 - val_loss: 3.5048 - val_accuracy: 0.6265 - val_auc: 0.8500\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7995 - accuracy: 0.4888 - auc: 0.7637 - val_loss: 3.9981 - val_accuracy: 0.5961 - val_auc: 0.7969\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6126 - accuracy: 0.4984 - auc: 0.7640 - val_loss: 2.9250 - val_accuracy: 0.6138 - val_auc: 0.8186\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5202 - accuracy: 0.5243 - auc: 0.7699 - val_loss: 2.6127 - val_accuracy: 0.6205 - val_auc: 0.8210\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6013 - accuracy: 0.5377 - auc: 0.7923 - val_loss: 1.5620 - val_accuracy: 0.6018 - val_auc: 0.8386\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6410 - accuracy: 0.5399 - auc: 0.7847 - val_loss: 4.6833 - val_accuracy: 0.6487 - val_auc: 0.8074\n",
      "Epoch 19/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.4566 - accuracy: 0.5554 - auc: 0.7882Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4539 - accuracy: 0.5552 - auc: 0.7906 - val_loss: 4.1752 - val_accuracy: 0.6701 - val_auc: 0.8117\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 24us/sample - loss: 1.4991 - accuracy: 0.6993 - auc: 0.7669 - val_loss: 1.5187 - val_accuracy: 0.8286 - val_auc: 0.8898\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0347 - accuracy: 0.8290 - auc: 0.8405 - val_loss: 1.0273 - val_accuracy: 0.8831 - val_auc: 0.8445\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9268 - accuracy: 0.8513 - auc: 0.8456 - val_loss: 1.2197 - val_accuracy: 0.8963 - val_auc: 0.9203\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3362 - accuracy: 0.8440 - auc: 0.8506 - val_loss: 1.8441 - val_accuracy: 0.8839 - val_auc: 0.9179\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1661 - accuracy: 0.8691 - auc: 0.8212 - val_loss: 0.8536 - val_accuracy: 0.8829 - val_auc: 0.8834\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8236 - accuracy: 0.8909 - auc: 0.8401 - val_loss: 1.6131 - val_accuracy: 0.8609 - val_auc: 0.9100\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6417 - accuracy: 0.8979 - auc: 0.8413 - val_loss: 1.2988 - val_accuracy: 0.8749 - val_auc: 0.9054\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0449 - accuracy: 0.8779 - auc: 0.8167 - val_loss: 1.0694 - val_accuracy: 0.8604 - val_auc: 0.7214\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7407 - accuracy: 0.7680 - auc: 0.7996 - val_loss: 3.2539 - val_accuracy: 0.5649 - val_auc: 0.8687\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7954 - accuracy: 0.7078 - auc: 0.8120 - val_loss: 2.5484 - val_accuracy: 0.9212 - val_auc: 0.8962\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8444 - accuracy: 0.6407 - auc: 0.8179 - val_loss: 3.8152 - val_accuracy: 0.6681 - val_auc: 0.8952\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8324 - accuracy: 0.5135 - auc: 0.7966 - val_loss: 3.5443 - val_accuracy: 0.6351 - val_auc: 0.8350\n",
      "Epoch 13/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.5669 - accuracy: 0.4919 - auc: 0.7981Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5652 - accuracy: 0.4922 - auc: 0.7993 - val_loss: 3.2516 - val_accuracy: 0.6311 - val_auc: 0.9067\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 19us/sample - loss: 1.4921 - accuracy: 0.6782 - auc: 0.7686 - val_loss: 0.8245 - val_accuracy: 0.8057 - val_auc: 0.9064\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6493 - accuracy: 0.8012 - auc: 0.8000 - val_loss: 1.1854 - val_accuracy: 0.8598 - val_auc: 0.8990\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5084 - accuracy: 0.8356 - auc: 0.8186 - val_loss: 1.3309 - val_accuracy: 0.6315 - val_auc: 0.7986\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4547 - accuracy: 0.8446 - auc: 0.8246 - val_loss: 4.8024 - val_accuracy: 0.8440 - val_auc: 0.9008\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6811 - accuracy: 0.8624 - auc: 0.8225 - val_loss: 2.0568 - val_accuracy: 0.8532 - val_auc: 0.9030\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9960 - accuracy: 0.7811 - auc: 0.8156 - val_loss: 2.4095 - val_accuracy: 0.8576 - val_auc: 0.9040\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7886 - accuracy: 0.7105 - auc: 0.8139 - val_loss: 2.4542 - val_accuracy: 0.9079 - val_auc: 0.7996\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7279 - accuracy: 0.5023 - auc: 0.8046 - val_loss: 2.2015 - val_accuracy: 0.5789 - val_auc: 0.8908\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.0846 - accuracy: 0.5895 - auc: 0.7809 - val_loss: 10.6630 - val_accuracy: 0.5674 - val_auc: 0.9078\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6481 - accuracy: 0.4891 - auc: 0.7617 - val_loss: 7.0071 - val_accuracy: 0.5029 - val_auc: 0.7984\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9159 - accuracy: 0.3771 - auc: 0.7283 - val_loss: 6.7244 - val_accuracy: 0.4983 - val_auc: 0.7925\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7857 - accuracy: 0.3714 - auc: 0.7252 - val_loss: 7.3772 - val_accuracy: 0.5058 - val_auc: 0.7617\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7357 - accuracy: 0.3723 - auc: 0.7082 - val_loss: 5.7910 - val_accuracy: 0.5061 - val_auc: 0.7687\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.7317 - accuracy: 0.4300 - auc: 0.7104 - val_loss: 14.8405 - val_accuracy: 0.9397 - val_auc: 0.8053\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1204 - accuracy: 0.4924 - auc: 0.7443 - val_loss: 13.7323 - val_accuracy: 0.9367 - val_auc: 0.8909\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9708 - accuracy: 0.4477 - auc: 0.7385 - val_loss: 12.8259 - val_accuracy: 0.4822 - val_auc: 0.8294\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8449 - accuracy: 0.6147 - auc: 0.7672 - val_loss: 10.9086 - val_accuracy: 0.4598 - val_auc: 0.8917\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6070 - accuracy: 0.8025 - auc: 0.7914 - val_loss: 10.1102 - val_accuracy: 0.8792 - val_auc: 0.9022\n",
      "Epoch 19/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.6689 - accuracy: 0.6110 - auc: 0.7490Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6708 - accuracy: 0.6080 - auc: 0.7481 - val_loss: 10.3375 - val_accuracy: 0.4646 - val_auc: 0.7379\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.7980 - accuracy: 0.7296 - auc: 0.7920 - val_loss: 1.9447 - val_accuracy: 0.8823 - val_auc: 0.8472\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.2243 - accuracy: 0.7693 - auc: 0.8103 - val_loss: 2.5427 - val_accuracy: 0.8405 - val_auc: 0.8828\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 1.9601 - accuracy: 0.7878 - auc: 0.8189 - val_loss: 1.5678 - val_accuracy: 0.8044 - val_auc: 0.8704\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6007 - accuracy: 0.8346 - auc: 0.8475 - val_loss: 1.5812 - val_accuracy: 0.7077 - val_auc: 0.8546\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6782 - accuracy: 0.8518 - auc: 0.8394 - val_loss: 2.5744 - val_accuracy: 0.5557 - val_auc: 0.7235\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 2.4193 - accuracy: 0.8356 - auc: 0.8189 - val_loss: 3.4099 - val_accuracy: 0.8981 - val_auc: 0.9054.\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 1.2026 - accuracy: 0.8893 - auc: 0.8374 - val_loss: 2.1977 - val_accuracy: 0.8576 - val_auc: 0.8721\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.8883 - accuracy: 0.9086 - auc: 0.8400 - val_loss: 3.7995 - val_accuracy: 0.9271 - val_auc: 0.8954\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.8758 - accuracy: 0.9060 - auc: 0.8392 - val_loss: 3.8494 - val_accuracy: 0.9348 - val_auc: 0.9092\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8444 - accuracy: 0.8820 - auc: 0.8207 - val_loss: 3.0722 - val_accuracy: 0.8813 - val_auc: 0.8907\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.6771 - accuracy: 0.8957 - auc: 0.8495 - val_loss: 3.3093 - val_accuracy: 0.8839 - val_auc: 0.9115\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7917 - accuracy: 0.9140 - auc: 0.8445 - val_loss: 7.3662 - val_accuracy: 0.8659 - val_auc: 0.8982\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6305 - accuracy: 0.9110 - auc: 0.8587 - val_loss: 7.4500 - val_accuracy: 0.9034 - val_auc: 0.9074\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6922 - accuracy: 0.9077 - auc: 0.8589 - val_loss: 5.9945 - val_accuracy: 0.8899 - val_auc: 0.9098\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5170 - accuracy: 0.9011 - auc: 0.8698 - val_loss: 5.9138 - val_accuracy: 0.9607 - val_auc: 0.8540\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5545 - accuracy: 0.6743 - auc: 0.8496 - val_loss: 5.2967 - val_accuracy: 0.6059 - val_auc: 0.9019\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6117 - accuracy: 0.5528 - auc: 0.8203 - val_loss: 5.1393 - val_accuracy: 0.9321 - val_auc: 0.8992\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5614 - accuracy: 0.5000 - auc: 0.8173 - val_loss: 5.1134 - val_accuracy: 0.6058 - val_auc: 0.8939\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6291 - accuracy: 0.4660 - auc: 0.7815 - val_loss: 4.9196 - val_accuracy: 0.5707 - val_auc: 0.8774\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5278 - accuracy: 0.5020 - auc: 0.7985 - val_loss: 4.6252 - val_accuracy: 0.6028 - val_auc: 0.8952\n",
      "Epoch 21/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.5872 - accuracy: 0.4819 - auc: 0.8189Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5848 - accuracy: 0.4817 - auc: 0.8178 - val_loss: 5.4066 - val_accuracy: 0.5908 - val_auc: 0.8895\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 2.1295 - accuracy: 0.6900 - auc: 0.7686 - val_loss: 1.0333 - val_accuracy: 0.7531 - val_auc: 0.8757\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8805 - accuracy: 0.7867 - auc: 0.8207 - val_loss: 3.4174 - val_accuracy: 0.9052 - val_auc: 0.8810\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0760 - accuracy: 0.8118 - auc: 0.8248 - val_loss: 1.5076 - val_accuracy: 0.8447 - val_auc: 0.8712\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.7240 - accuracy: 0.8051 - auc: 0.8034 - val_loss: 4.4858 - val_accuracy: 0.9176 - val_auc: 0.8734\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.3661 - accuracy: 0.8578 - auc: 0.8457 - val_loss: 3.9715 - val_accuracy: 0.8603 - val_auc: 0.8966\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3448 - accuracy: 0.8821 - auc: 0.8363 - val_loss: 5.3588 - val_accuracy: 0.6167 - val_auc: 0.8721\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6289 - accuracy: 0.8002 - auc: 0.8367 - val_loss: 5.2966 - val_accuracy: 0.5945 - val_auc: 0.8396\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.0857 - accuracy: 0.6101 - auc: 0.7670 - val_loss: 13.1919 - val_accuracy: 0.5893 - val_auc: 0.7911\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0158 - accuracy: 0.4742 - auc: 0.7625 - val_loss: 10.6260 - val_accuracy: 0.6007 - val_auc: 0.8172\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7131 - accuracy: 0.6164 - auc: 0.8096 - val_loss: 5.2854 - val_accuracy: 0.9171 - val_auc: 0.8709\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0160 - accuracy: 0.7287 - auc: 0.8090 - val_loss: 9.6668 - val_accuracy: 0.6122 - val_auc: 0.8560\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2113 - accuracy: 0.4949 - auc: 0.7770 - val_loss: 7.5128 - val_accuracy: 0.5648 - val_auc: 0.8065\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9478 - accuracy: 0.4948 - auc: 0.8116 - val_loss: 8.1831 - val_accuracy: 0.5960 - val_auc: 0.8650\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8008 - accuracy: 0.5598 - auc: 0.7923 - val_loss: 15.8098 - val_accuracy: 0.5348 - val_auc: 0.8574\n",
      "Epoch 15/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 1.0065 - accuracy: 0.4713 - auc: 0.8013Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0040 - accuracy: 0.4713 - auc: 0.8022 - val_loss: 12.2642 - val_accuracy: 0.5495 - val_auc: 0.8660\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 2.2902 - accuracy: 0.6809 - auc: 0.7731 - val_loss: 1.6106 - val_accuracy: 0.6613 - val_auc: 0.8039\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0049 - accuracy: 0.7800 - auc: 0.8068 - val_loss: 1.4068 - val_accuracy: 0.8787 - val_auc: 0.8942\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.3115 - accuracy: 0.7939 - auc: 0.8003 - val_loss: 2.4873 - val_accuracy: 0.8786 - val_auc: 0.9006\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5838 - accuracy: 0.8203 - auc: 0.8266 - val_loss: 4.8219 - val_accuracy: 0.9606 - val_auc: 0.8582\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7801 - accuracy: 0.8414 - auc: 0.8120 - val_loss: 3.7345 - val_accuracy: 0.9197 - val_auc: 0.8884\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5789 - accuracy: 0.8733 - auc: 0.8192 - val_loss: 3.9093 - val_accuracy: 0.8639 - val_auc: 0.8476\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5584 - accuracy: 0.8395 - auc: 0.8223 - val_loss: 3.1040 - val_accuracy: 0.9386 - val_auc: 0.8966\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9541 - accuracy: 0.8211 - auc: 0.8444 - val_loss: 3.0695 - val_accuracy: 0.8235 - val_auc: 0.8500\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3845 - accuracy: 0.8777 - auc: 0.8389 - val_loss: 6.0078 - val_accuracy: 0.8726 - val_auc: 0.9103\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8537 - accuracy: 0.8526 - auc: 0.8523 - val_loss: 4.7027 - val_accuracy: 0.9439 - val_auc: 0.8967\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9346 - accuracy: 0.8054 - auc: 0.8579 - val_loss: 5.1406 - val_accuracy: 0.8922 - val_auc: 0.8990\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7019 - accuracy: 0.9231 - auc: 0.8709 - val_loss: 5.1418 - val_accuracy: 0.8713 - val_auc: 0.9040\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7072 - accuracy: 0.8099 - auc: 0.8663 - val_loss: 5.4410 - val_accuracy: 0.9048 - val_auc: 0.9047\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4988 - accuracy: 0.8963 - auc: 0.8810 - val_loss: 6.4325 - val_accuracy: 0.5903 - val_auc: 0.9065\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5187 - accuracy: 0.7832 - auc: 0.8783 - val_loss: 6.6913 - val_accuracy: 0.8975 - val_auc: 0.9032\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5175 - accuracy: 0.7283 - auc: 0.8639 - val_loss: 6.3652 - val_accuracy: 0.9269 - val_auc: 0.9115\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4692 - accuracy: 0.7389 - auc: 0.8707 - val_loss: 5.2163 - val_accuracy: 0.9110 - val_auc: 0.9108\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4778 - accuracy: 0.8675 - auc: 0.8898 - val_loss: 5.3110 - val_accuracy: 0.9273 - val_auc: 0.9201\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4658 - accuracy: 0.9137 - auc: 0.8820 - val_loss: 5.3764 - val_accuracy: 0.9224 - val_auc: 0.9127\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4650 - accuracy: 0.8986 - auc: 0.8873 - val_loss: 3.3652 - val_accuracy: 0.5397 - val_auc: 0.8820\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5008 - accuracy: 0.6696 - auc: 0.8584 - val_loss: 7.5223 - val_accuracy: 0.6223 - val_auc: 0.9003\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5058 - accuracy: 0.5319 - auc: 0.8188 - val_loss: 7.5870 - val_accuracy: 0.6366 - val_auc: 0.8156\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5829 - accuracy: 0.5406 - auc: 0.8022 - val_loss: 4.8895 - val_accuracy: 0.6444 - val_auc: 0.8702\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5145 - accuracy: 0.5478 - auc: 0.8222 - val_loss: 4.4093 - val_accuracy: 0.6416 - val_auc: 0.8901\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4538 - accuracy: 0.5546 - auc: 0.8443 - val_loss: 4.8361 - val_accuracy: 0.6453 - val_auc: 0.8963\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4366 - accuracy: 0.5567 - auc: 0.8356 - val_loss: 4.2984 - val_accuracy: 0.6747 - val_auc: 0.8591\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4772 - accuracy: 0.5594 - auc: 0.7976 - val_loss: 4.8783 - val_accuracy: 0.6556 - val_auc: 0.8152\n",
      "Epoch 28/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.4821 - accuracy: 0.5631 - auc: 0.7863Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4792 - accuracy: 0.5629 - auc: 0.7861 - val_loss: 4.6815 - val_accuracy: 0.6613 - val_auc: 0.8217\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 2.1330 - accuracy: 0.7022 - auc: 0.7635 - val_loss: 1.0093 - val_accuracy: 0.8067 - val_auc: 0.8876\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 2.0238 - accuracy: 0.7833 - auc: 0.8026 - val_loss: 2.5891 - val_accuracy: 0.5427 - val_auc: 0.8135\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 2.0637 - accuracy: 0.8168 - auc: 0.8382 - val_loss: 1.5195 - val_accuracy: 0.9251 - val_auc: 0.8970\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 2.8628 - accuracy: 0.8310 - auc: 0.8298 - val_loss: 2.4147 - val_accuracy: 0.8999 - val_auc: 0.8926\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.3770 - accuracy: 0.8572 - auc: 0.8291 - val_loss: 1.6524 - val_accuracy: 0.7369 - val_auc: 0.8058\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0799 - accuracy: 0.8982 - auc: 0.8261 - val_loss: 1.7906 - val_accuracy: 0.8385 - val_auc: 0.8687\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.8835 - accuracy: 0.8589 - auc: 0.8077 - val_loss: 1.4753 - val_accuracy: 0.5634 - val_auc: 0.8907\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7983 - accuracy: 0.8810 - auc: 0.7887 - val_loss: 3.2325 - val_accuracy: 0.9378 - val_auc: 0.8812\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4919 - accuracy: 0.7938 - auc: 0.7832 - val_loss: 1.4443 - val_accuracy: 0.5182 - val_auc: 0.8763\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7312 - accuracy: 0.5772 - auc: 0.7626 - val_loss: 3.5148 - val_accuracy: 0.9699 - val_auc: 0.8693\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1405 - accuracy: 0.7088 - auc: 0.7976 - val_loss: 3.4791 - val_accuracy: 0.5857 - val_auc: 0.8676\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8406 - accuracy: 0.5746 - auc: 0.8097 - val_loss: 2.6437 - val_accuracy: 0.8977 - val_auc: 0.9025\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5500 - accuracy: 0.6489 - auc: 0.8023 - val_loss: 5.1923 - val_accuracy: 0.8612 - val_auc: 0.9053\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9309 - accuracy: 0.7566 - auc: 0.8369 - val_loss: 5.8625 - val_accuracy: 0.8990 - val_auc: 0.9036\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1161 - accuracy: 0.8908 - auc: 0.8264 - val_loss: 5.5607 - val_accuracy: 0.8998 - val_auc: 0.9037\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2176 - accuracy: 0.8376 - auc: 0.8156 - val_loss: 4.7345 - val_accuracy: 0.9371 - val_auc: 0.8950\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6994 - accuracy: 0.8253 - auc: 0.8362 - val_loss: 4.2154 - val_accuracy: 0.5666 - val_auc: 0.9005\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6876 - accuracy: 0.6677 - auc: 0.8193 - val_loss: 4.4219 - val_accuracy: 0.5382 - val_auc: 0.7319\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1152 - accuracy: 0.5741 - auc: 0.8002 - val_loss: 4.5598 - val_accuracy: 0.5225 - val_auc: 0.9060\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6168 - accuracy: 0.5618 - auc: 0.8197 - val_loss: 4.7959 - val_accuracy: 0.9288 - val_auc: 0.9003\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9856 - accuracy: 0.7516 - auc: 0.8116 - val_loss: 4.1247 - val_accuracy: 0.9142 - val_auc: 0.9090\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5494 - accuracy: 0.8693 - auc: 0.8347 - val_loss: 6.0391 - val_accuracy: 0.9152 - val_auc: 0.9011\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5188 - accuracy: 0.8507 - auc: 0.8244 - val_loss: 6.7957 - val_accuracy: 0.5312 - val_auc: 0.9008\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4753 - accuracy: 0.6333 - auc: 0.8237 - val_loss: 7.2690 - val_accuracy: 0.5445 - val_auc: 0.9013\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5330 - accuracy: 0.6655 - auc: 0.8250 - val_loss: 7.5747 - val_accuracy: 0.9143 - val_auc: 0.8928\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5431 - accuracy: 0.6368 - auc: 0.8172 - val_loss: 6.4293 - val_accuracy: 0.5259 - val_auc: 0.8124\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5049 - accuracy: 0.4574 - auc: 0.7712 - val_loss: 6.3556 - val_accuracy: 0.5866 - val_auc: 0.8484\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5009 - accuracy: 0.4731 - auc: 0.7849 - val_loss: 8.3743 - val_accuracy: 0.5918 - val_auc: 0.8513\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4908 - accuracy: 0.4861 - auc: 0.7826 - val_loss: 8.1730 - val_accuracy: 0.5989 - val_auc: 0.8535\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5765 - accuracy: 0.4730 - auc: 0.7591 - val_loss: 8.4564 - val_accuracy: 0.5921 - val_auc: 0.7697\n",
      "Epoch 31/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.5354 - accuracy: 0.4731 - auc: 0.7352Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5347 - accuracy: 0.4731 - auc: 0.7352 - val_loss: 8.1178 - val_accuracy: 0.5856 - val_auc: 0.7665\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 19us/sample - loss: 1.8189 - accuracy: 0.7143 - auc: 0.7778 - val_loss: 1.8077 - val_accuracy: 0.8802 - val_auc: 0.8616\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.1580 - accuracy: 0.7809 - auc: 0.7998 - val_loss: 1.3469 - val_accuracy: 0.8992 - val_auc: 0.8774\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.4231 - accuracy: 0.7784 - auc: 0.8059 - val_loss: 5.8838 - val_accuracy: 0.8538 - val_auc: 0.8484\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.2027 - accuracy: 0.8119 - auc: 0.7913 - val_loss: 2.4489 - val_accuracy: 0.9096 - val_auc: 0.8796\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.5787 - accuracy: 0.8172 - auc: 0.7917 - val_loss: 3.9301 - val_accuracy: 0.8868 - val_auc: 0.8596\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9116 - accuracy: 0.8462 - auc: 0.8361 - val_loss: 1.6690 - val_accuracy: 0.4981 - val_auc: 0.8849\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.7980 - accuracy: 0.7237 - auc: 0.7596 - val_loss: 9.4135 - val_accuracy: 0.5067 - val_auc: 0.8073\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.1124 - accuracy: 0.7527 - auc: 0.7989 - val_loss: 4.7702 - val_accuracy: 0.8997 - val_auc: 0.9002\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1222 - accuracy: 0.8451 - auc: 0.8258 - val_loss: 5.9464 - val_accuracy: 0.9376 - val_auc: 0.8887\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7699 - accuracy: 0.6442 - auc: 0.7922 - val_loss: 3.5321 - val_accuracy: 0.8970 - val_auc: 0.8564\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0930 - accuracy: 0.7197 - auc: 0.8140 - val_loss: 6.3779 - val_accuracy: 0.5173 - val_auc: 0.7971\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9721 - accuracy: 0.4863 - auc: 0.7479 - val_loss: 5.8751 - val_accuracy: 0.4330 - val_auc: 0.8075\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9680 - accuracy: 0.7941 - auc: 0.8108 - val_loss: 10.0491 - val_accuracy: 0.9252 - val_auc: 0.9003\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2067 - accuracy: 0.8591 - auc: 0.8323 - val_loss: 3.4101 - val_accuracy: 0.4158 - val_auc: 0.8397\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6319 - accuracy: 0.7465 - auc: 0.8201 - val_loss: 11.6760 - val_accuracy: 0.9385 - val_auc: 0.8888\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3858 - accuracy: 0.8031 - auc: 0.8209 - val_loss: 8.1161 - val_accuracy: 0.9198 - val_auc: 0.8982\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7786 - accuracy: 0.6366 - auc: 0.8117 - val_loss: 9.1917 - val_accuracy: 0.5088 - val_auc: 0.8983\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7206 - accuracy: 0.7459 - auc: 0.8215 - val_loss: 5.8147 - val_accuracy: 0.5021 - val_auc: 0.8820\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7388 - accuracy: 0.6513 - auc: 0.8020 - val_loss: 14.0232 - val_accuracy: 0.8921 - val_auc: 0.9155\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8290 - accuracy: 0.6140 - auc: 0.7997 - val_loss: 14.0074 - val_accuracy: 0.9292 - val_auc: 0.8482\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8105 - accuracy: 0.5305 - auc: 0.7875 - val_loss: 10.7590 - val_accuracy: 0.9218 - val_auc: 0.8386\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8429 - accuracy: 0.6141 - auc: 0.7971 - val_loss: 11.8561 - val_accuracy: 0.5074 - val_auc: 0.8042\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8314 - accuracy: 0.4168 - auc: 0.7709 - val_loss: 11.2608 - val_accuracy: 0.5152 - val_auc: 0.8984\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6698 - accuracy: 0.6350 - auc: 0.8171 - val_loss: 11.5304 - val_accuracy: 0.5351 - val_auc: 0.8681\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6421 - accuracy: 0.4466 - auc: 0.7494 - val_loss: 11.5298 - val_accuracy: 0.5316 - val_auc: 0.7799\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6506 - accuracy: 0.4357 - auc: 0.7364 - val_loss: 11.4659 - val_accuracy: 0.5363 - val_auc: 0.7879\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7929 - accuracy: 0.4266 - auc: 0.7252 - val_loss: 8.8263 - val_accuracy: 0.5124 - val_auc: 0.7591\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7321 - accuracy: 0.4238 - auc: 0.7223 - val_loss: 5.2237 - val_accuracy: 0.5126 - val_auc: 0.7436\n",
      "Epoch 29/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.5569 - accuracy: 0.4299 - auc: 0.7357Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5571 - accuracy: 0.4299 - auc: 0.7354 - val_loss: 6.8731 - val_accuracy: 0.5284 - val_auc: 0.7443\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 3.3413 - accuracy: 0.6533 - auc: 0.7594 - val_loss: 3.6680 - val_accuracy: 0.8307 - val_auc: 0.8325\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.4123 - accuracy: 0.7564 - auc: 0.7969 - val_loss: 4.4211 - val_accuracy: 0.7915 - val_auc: 0.8631\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 5.4461 - accuracy: 0.7865 - auc: 0.8084 - val_loss: 3.0946 - val_accuracy: 0.7693 - val_auc: 0.8966\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 4.1839 - accuracy: 0.7990 - auc: 0.8125 - val_loss: 4.1162 - val_accuracy: 0.6288 - val_auc: 0.7950\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9459 - accuracy: 0.8524 - auc: 0.8419 - val_loss: 4.6605 - val_accuracy: 0.8836 - val_auc: 0.8891\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.6331 - accuracy: 0.8197 - auc: 0.8117 - val_loss: 17.0639 - val_accuracy: 0.8938 - val_auc: 0.8589\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.9535 - accuracy: 0.8471 - auc: 0.8081 - val_loss: 11.2181 - val_accuracy: 0.9136 - val_auc: 0.8604\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.9535 - accuracy: 0.8322 - auc: 0.8199 - val_loss: 11.2078 - val_accuracy: 0.9114 - val_auc: 0.8943\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.7864 - accuracy: 0.8500 - auc: 0.8021 - val_loss: 7.3922 - val_accuracy: 0.9202 - val_auc: 0.8660\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6945 - accuracy: 0.8368 - auc: 0.8205 - val_loss: 8.0720 - val_accuracy: 0.8646 - val_auc: 0.8657\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8386 - accuracy: 0.7594 - auc: 0.8192 - val_loss: 5.1242 - val_accuracy: 0.9356 - val_auc: 0.8703\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.2334 - accuracy: 0.8631 - auc: 0.8207 - val_loss: 20.3696 - val_accuracy: 0.8826 - val_auc: 0.8836\n",
      "Epoch 13/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 4.2674 - accuracy: 0.8399 - auc: 0.8230Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.3387 - accuracy: 0.8408 - auc: 0.8241 - val_loss: 25.3542 - val_accuracy: 0.9101 - val_auc: 0.8719\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 3.0562 - accuracy: 0.6677 - auc: 0.7744 - val_loss: 2.4652 - val_accuracy: 0.7040 - val_auc: 0.8381\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.6598 - accuracy: 0.7679 - auc: 0.8072 - val_loss: 2.5067 - val_accuracy: 0.8234 - val_auc: 0.8718\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.2289 - accuracy: 0.7996 - auc: 0.8290 - val_loss: 6.1475 - val_accuracy: 0.9140 - val_auc: 0.8532\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.1957 - accuracy: 0.8074 - auc: 0.8237 - val_loss: 6.2158 - val_accuracy: 0.8667 - val_auc: 0.8400\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.1153 - accuracy: 0.8285 - auc: 0.8252 - val_loss: 8.5111 - val_accuracy: 0.9052 - val_auc: 0.8759\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.5959 - accuracy: 0.8417 - auc: 0.8057 - val_loss: 7.4387 - val_accuracy: 0.9253 - val_auc: 0.8740\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8946 - accuracy: 0.8663 - auc: 0.8211 - val_loss: 5.3349 - val_accuracy: 0.9047 - val_auc: 0.8958\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7489 - accuracy: 0.8968 - auc: 0.8431 - val_loss: 7.1800 - val_accuracy: 0.8901 - val_auc: 0.8714\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8481 - accuracy: 0.8035 - auc: 0.8168 - val_loss: 8.6493 - val_accuracy: 0.9164 - val_auc: 0.8790\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6047 - accuracy: 0.5867 - auc: 0.7841 - val_loss: 7.2761 - val_accuracy: 0.5494 - val_auc: 0.7900\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.1144 - accuracy: 0.6382 - auc: 0.7865 - val_loss: 8.1913 - val_accuracy: 0.5300 - val_auc: 0.8466\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9386 - accuracy: 0.5414 - auc: 0.7948 - val_loss: 11.3255 - val_accuracy: 0.9779 - val_auc: 0.8385\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7172 - accuracy: 0.6965 - auc: 0.8062 - val_loss: 10.8670 - val_accuracy: 0.9330 - val_auc: 0.8767\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8816 - accuracy: 0.6259 - auc: 0.8320 - val_loss: 9.2643 - val_accuracy: 0.9435 - val_auc: 0.8803\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2851 - accuracy: 0.6806 - auc: 0.8301 - val_loss: 11.0457 - val_accuracy: 0.9304 - val_auc: 0.8967\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9030 - accuracy: 0.6594 - auc: 0.8355 - val_loss: 8.6773 - val_accuracy: 0.5247 - val_auc: 0.8957\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8479 - accuracy: 0.6522 - auc: 0.8405 - val_loss: 7.8381 - val_accuracy: 0.9092 - val_auc: 0.8975\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7216 - accuracy: 0.7369 - auc: 0.8405 - val_loss: 8.1943 - val_accuracy: 0.9074 - val_auc: 0.9007\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8854 - accuracy: 0.6254 - auc: 0.8416 - val_loss: 7.7757 - val_accuracy: 0.9239 - val_auc: 0.8962\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5693 - accuracy: 0.6550 - auc: 0.8470 - val_loss: 9.2571 - val_accuracy: 0.5593 - val_auc: 0.8972\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7082 - accuracy: 0.4915 - auc: 0.8227 - val_loss: 11.2334 - val_accuracy: 0.5656 - val_auc: 0.8956\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7148 - accuracy: 0.6228 - auc: 0.8434 - val_loss: 11.4837 - val_accuracy: 0.5817 - val_auc: 0.9026\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0694 - accuracy: 0.5180 - auc: 0.8362 - val_loss: 8.1945 - val_accuracy: 0.5501 - val_auc: 0.8801\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2528 - accuracy: 0.6387 - auc: 0.8337 - val_loss: 22.0947 - val_accuracy: 0.5593 - val_auc: 0.8813\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7725 - accuracy: 0.5735 - auc: 0.8225 - val_loss: 15.1727 - val_accuracy: 0.5453 - val_auc: 0.8960\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7213 - accuracy: 0.4793 - auc: 0.8282 - val_loss: 16.2885 - val_accuracy: 0.5535 - val_auc: 0.8948\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5425 - accuracy: 0.6587 - auc: 0.8300 - val_loss: 20.2655 - val_accuracy: 0.5266 - val_auc: 0.8792\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9372 - accuracy: 0.5585 - auc: 0.8196 - val_loss: 15.5999 - val_accuracy: 0.5078 - val_auc: 0.7228\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0753 - accuracy: 0.4453 - auc: 0.7218 - val_loss: 20.0149 - val_accuracy: 0.5325 - val_auc: 0.7702\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7763 - accuracy: 0.4490 - auc: 0.7572 - val_loss: 18.6027 - val_accuracy: 0.5442 - val_auc: 0.8098\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6819 - accuracy: 0.4550 - auc: 0.7628 - val_loss: 17.8541 - val_accuracy: 0.5364 - val_auc: 0.7978\n",
      "Epoch 32/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.7547 - accuracy: 0.4578 - auc: 0.7600Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7548 - accuracy: 0.4578 - auc: 0.7598 - val_loss: 14.7861 - val_accuracy: 0.5317 - val_auc: 0.7954\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 3.0919 - accuracy: 0.6551 - auc: 0.7587 - val_loss: 2.1076 - val_accuracy: 0.6935 - val_auc: 0.8872\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.7956 - accuracy: 0.7498 - auc: 0.7856 - val_loss: 4.2611 - val_accuracy: 0.9039 - val_auc: 0.8651\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.7008 - accuracy: 0.7694 - auc: 0.7971 - val_loss: 4.9766 - val_accuracy: 0.9313 - val_auc: 0.8693\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5813 - accuracy: 0.8216 - auc: 0.8280 - val_loss: 3.5719 - val_accuracy: 0.8713 - val_auc: 0.8965\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9364 - accuracy: 0.8281 - auc: 0.8266 - val_loss: 3.1482 - val_accuracy: 0.8633 - val_auc: 0.8890\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0259 - accuracy: 0.8590 - auc: 0.8457 - val_loss: 3.2170 - val_accuracy: 0.8604 - val_auc: 0.8751\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.4134 - accuracy: 0.8502 - auc: 0.8304 - val_loss: 7.9660 - val_accuracy: 0.9328 - val_auc: 0.8771\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8378 - accuracy: 0.8690 - auc: 0.8390 - val_loss: 5.2574 - val_accuracy: 0.9090 - val_auc: 0.8601\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7579 - accuracy: 0.8832 - auc: 0.8324 - val_loss: 7.9168 - val_accuracy: 0.8456 - val_auc: 0.8900\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6595 - accuracy: 0.6258 - auc: 0.7890 - val_loss: 4.1466 - val_accuracy: 0.8781 - val_auc: 0.8744\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2205 - accuracy: 0.7363 - auc: 0.8204 - val_loss: 7.9707 - val_accuracy: 0.8650 - val_auc: 0.8598\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9347 - accuracy: 0.5887 - auc: 0.8057 - val_loss: 5.6943 - val_accuracy: 0.5546 - val_auc: 0.8710\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.7796 - accuracy: 0.6018 - auc: 0.8138 - val_loss: 6.4618 - val_accuracy: 0.5805 - val_auc: 0.8760\n",
      "Epoch 14/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 1.1972 - accuracy: 0.5492 - auc: 0.8010Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1909 - accuracy: 0.5486 - auc: 0.8014 - val_loss: 9.4026 - val_accuracy: 0.5630 - val_auc: 0.8820\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 18us/sample - loss: 2.5740 - accuracy: 0.6856 - auc: 0.7710 - val_loss: 2.4476 - val_accuracy: 0.4785 - val_auc: 0.8510\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.7128 - accuracy: 0.7741 - auc: 0.8163 - val_loss: 2.9205 - val_accuracy: 0.8794 - val_auc: 0.8753\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.4034 - accuracy: 0.8118 - auc: 0.8372 - val_loss: 2.4807 - val_accuracy: 0.8071 - val_auc: 0.8788s: 1\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.5622 - accuracy: 0.8261 - auc: 0.8375 - val_loss: 2.9994 - val_accuracy: 0.8422 - val_auc: 0.8708\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.3010 - accuracy: 0.8316 - auc: 0.8363 - val_loss: 6.1000 - val_accuracy: 0.5056 - val_auc: 0.6966\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.1409 - accuracy: 0.8433 - auc: 0.8246 - val_loss: 2.8829 - val_accuracy: 0.7951 - val_auc: 0.8564\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5450 - accuracy: 0.7800 - auc: 0.7989 - val_loss: 5.4772 - val_accuracy: 0.8760 - val_auc: 0.8921\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8439 - accuracy: 0.6584 - auc: 0.8128 - val_loss: 8.1625 - val_accuracy: 0.6752 - val_auc: 0.8829\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.5170 - accuracy: 0.6049 - auc: 0.8063 - val_loss: 5.9996 - val_accuracy: 0.6533 - val_auc: 0.6713\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 5.7067 - accuracy: 0.7643 - auc: 0.7976 - val_loss: 12.3028 - val_accuracy: 0.8892 - val_auc: 0.8667\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.6304 - accuracy: 0.9010 - auc: 0.8130 - val_loss: 10.7755 - val_accuracy: 0.8998 - val_auc: 0.8722\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.3522 - accuracy: 0.7383 - auc: 0.7907 - val_loss: 20.9003 - val_accuracy: 0.8992 - val_auc: 0.8946\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.1229 - accuracy: 0.9181 - auc: 0.8277 - val_loss: 20.6028 - val_accuracy: 0.9285 - val_auc: 0.8834\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7655 - accuracy: 0.5955 - auc: 0.7975 - val_loss: 17.4804 - val_accuracy: 0.5047 - val_auc: 0.8582\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2737 - accuracy: 0.4407 - auc: 0.7902 - val_loss: 9.6388 - val_accuracy: 0.9698 - val_auc: 0.8544\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4024 - accuracy: 0.5779 - auc: 0.7664 - val_loss: 9.7527 - val_accuracy: 0.4746 - val_auc: 0.8477\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4491 - accuracy: 0.4348 - auc: 0.7696 - val_loss: 15.0857 - val_accuracy: 0.9542 - val_auc: 0.8656\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3578 - accuracy: 0.7403 - auc: 0.8110 - val_loss: 15.2104 - val_accuracy: 0.9240 - val_auc: 0.8954\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8330 - accuracy: 0.8713 - auc: 0.8495 - val_loss: 21.5214 - val_accuracy: 0.9176 - val_auc: 0.8982\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7370 - accuracy: 0.9298 - auc: 0.8493 - val_loss: 12.0453 - val_accuracy: 0.5051 - val_auc: 0.8605\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8314 - accuracy: 0.6488 - auc: 0.8210 - val_loss: 11.4077 - val_accuracy: 0.5114 - val_auc: 0.8393\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7789 - accuracy: 0.4647 - auc: 0.7869 - val_loss: 11.7283 - val_accuracy: 0.5114 - val_auc: 0.8564\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7421 - accuracy: 0.5108 - auc: 0.7755 - val_loss: 14.0611 - val_accuracy: 0.5121 - val_auc: 0.8179\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6212 - accuracy: 0.4981 - auc: 0.8054 - val_loss: 9.6025 - val_accuracy: 0.5018 - val_auc: 0.8853\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6261 - accuracy: 0.5763 - auc: 0.8235 - val_loss: 12.0200 - val_accuracy: 0.5113 - val_auc: 0.8837\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6869 - accuracy: 0.6741 - auc: 0.8249 - val_loss: 12.6060 - val_accuracy: 0.5114 - val_auc: 0.8729\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6805 - accuracy: 0.6372 - auc: 0.8210 - val_loss: 12.8331 - val_accuracy: 0.5079 - val_auc: 0.8991\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6079 - accuracy: 0.7052 - auc: 0.8256 - val_loss: 16.2807 - val_accuracy: 0.5135 - val_auc: 0.8950\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6569 - accuracy: 0.4962 - auc: 0.7809 - val_loss: 19.6559 - val_accuracy: 0.5174 - val_auc: 0.7919\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6087 - accuracy: 0.4409 - auc: 0.7462 - val_loss: 19.8792 - val_accuracy: 0.5273 - val_auc: 0.7769\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8676 - accuracy: 0.4408 - auc: 0.7483 - val_loss: 18.8281 - val_accuracy: 0.5255 - val_auc: 0.8738\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6642 - accuracy: 0.4653 - auc: 0.7717 - val_loss: 19.5783 - val_accuracy: 0.5199 - val_auc: 0.7749\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6117 - accuracy: 0.4343 - auc: 0.7420 - val_loss: 18.5468 - val_accuracy: 0.5129 - val_auc: 0.7731\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5536 - accuracy: 0.4362 - auc: 0.7488 - val_loss: 19.8997 - val_accuracy: 0.5204 - val_auc: 0.79660.5742 - accuracy\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5232 - accuracy: 0.4422 - auc: 0.7619 - val_loss: 20.5952 - val_accuracy: 0.5266 - val_auc: 0.8481\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5551 - accuracy: 0.4442 - auc: 0.7895 - val_loss: 20.5163 - val_accuracy: 0.5266 - val_auc: 0.9132\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5699 - accuracy: 0.5242 - auc: 0.7571 - val_loss: 21.5223 - val_accuracy: 0.5330 - val_auc: 0.7597\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6965 - accuracy: 0.4481 - auc: 0.7178 - val_loss: 24.0044 - val_accuracy: 0.5227 - val_auc: 0.7509\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6037 - accuracy: 0.4451 - auc: 0.7181 - val_loss: 23.2753 - val_accuracy: 0.5234 - val_auc: 0.7487\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7373 - accuracy: 0.4426 - auc: 0.7323 - val_loss: 18.4772 - val_accuracy: 0.5470 - val_auc: 0.7682\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9043 - accuracy: 0.4463 - auc: 0.7384 - val_loss: 17.9992 - val_accuracy: 0.5273 - val_auc: 0.7645\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5884 - accuracy: 0.4409 - auc: 0.7396 - val_loss: 20.7266 - val_accuracy: 0.5126 - val_auc: 0.7771\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5420 - accuracy: 0.4393 - auc: 0.7508 - val_loss: 22.8774 - val_accuracy: 0.5171 - val_auc: 0.7730\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6448 - accuracy: 0.4353 - auc: 0.7394 - val_loss: 18.5071 - val_accuracy: 0.5154 - val_auc: 0.8109\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5990 - accuracy: 0.4390 - auc: 0.7788 - val_loss: 19.0925 - val_accuracy: 0.5158 - val_auc: 0.8120\n",
      "Epoch 46/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.6291 - accuracy: 0.4386 - auc: 0.7643Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6265 - accuracy: 0.4387 - auc: 0.7633 - val_loss: 21.8278 - val_accuracy: 0.5183 - val_auc: 0.7626\n",
      "Epoch 00046: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 26us/sample - loss: 2.7027 - accuracy: 0.6917 - auc: 0.7684 - val_loss: 2.2507 - val_accuracy: 0.8969 - val_auc: 0.8707\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.1457 - accuracy: 0.7690 - auc: 0.8010 - val_loss: 4.4661 - val_accuracy: 0.5291 - val_auc: 0.7965\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.6464 - accuracy: 0.7846 - auc: 0.8153 - val_loss: 11.8308 - val_accuracy: 0.9174 - val_auc: 0.8541\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.9843 - accuracy: 0.7906 - auc: 0.8048 - val_loss: 3.9067 - val_accuracy: 0.7916 - val_auc: 0.8769\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.9070 - accuracy: 0.8150 - auc: 0.8091 - val_loss: 3.3192 - val_accuracy: 0.8235 - val_auc: 0.8501\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.2333 - accuracy: 0.8503 - auc: 0.8279 - val_loss: 8.1611 - val_accuracy: 0.8675 - val_auc: 0.8887\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.1827 - accuracy: 0.8555 - auc: 0.8044 - val_loss: 4.1192 - val_accuracy: 0.8420 - val_auc: 0.8733\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.3011 - accuracy: 0.6237 - auc: 0.7146 - val_loss: 7.8358 - val_accuracy: 0.4861 - val_auc: 0.7944\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.1545 - accuracy: 0.5906 - auc: 0.7702 - val_loss: 4.9695 - val_accuracy: 0.5125 - val_auc: 0.8428\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5800 - accuracy: 0.8007 - auc: 0.7825 - val_loss: 5.7184 - val_accuracy: 0.4891 - val_auc: 0.7918\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.1192 - accuracy: 0.4696 - auc: 0.7531 - val_loss: 6.6840 - val_accuracy: 0.5002 - val_auc: 0.7961\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3475 - accuracy: 0.4614 - auc: 0.7409 - val_loss: 8.2124 - val_accuracy: 0.9561 - val_auc: 0.7997\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.3178 - accuracy: 0.4399 - auc: 0.7440 - val_loss: 5.7349 - val_accuracy: 0.4863 - val_auc: 0.8076\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1938 - accuracy: 0.4742 - auc: 0.7739 - val_loss: 3.6159 - val_accuracy: 0.5026 - val_auc: 0.8290\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8447 - accuracy: 0.5942 - auc: 0.7756 - val_loss: 4.7149 - val_accuracy: 0.5172 - val_auc: 0.8341\n",
      "Epoch 16/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.8765 - accuracy: 0.4285 - auc: 0.7810Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8783 - accuracy: 0.4286 - auc: 0.7804 - val_loss: 6.2914 - val_accuracy: 0.5234 - val_auc: 0.7846\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 0.7145 - accuracy: 0.8726 - auc: 0.7871 - val_loss: 0.4033 - val_accuracy: 0.9267 - val_auc: 0.9230\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4272 - accuracy: 0.8986 - auc: 0.8899 - val_loss: 0.3602 - val_accuracy: 0.8989 - val_auc: 0.9343\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4240 - accuracy: 0.9037 - auc: 0.8945 - val_loss: 0.3560 - val_accuracy: 0.8996 - val_auc: 0.9354\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3963 - accuracy: 0.8964 - auc: 0.9129 - val_loss: 0.3442 - val_accuracy: 0.9101 - val_auc: 0.9391\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3852 - accuracy: 0.9018 - auc: 0.9162 - val_loss: 0.3405 - val_accuracy: 0.9093 - val_auc: 0.9391\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3719 - accuracy: 0.8985 - auc: 0.9223 - val_loss: 0.3565 - val_accuracy: 0.8882 - val_auc: 0.9307\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3476 - accuracy: 0.8986 - auc: 0.9324 - val_loss: 0.3575 - val_accuracy: 0.9106 - val_auc: 0.9293\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3570 - accuracy: 0.8996 - auc: 0.9264 - val_loss: 0.3502 - val_accuracy: 0.8825 - val_auc: 0.9327\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3430 - accuracy: 0.8948 - auc: 0.9315 - val_loss: 0.3637 - val_accuracy: 0.8987 - val_auc: 0.9307\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3417 - accuracy: 0.8954 - auc: 0.9320 - val_loss: 0.3593 - val_accuracy: 0.8926 - val_auc: 0.9319\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3223 - accuracy: 0.8937 - auc: 0.9387 - val_loss: 0.3755 - val_accuracy: 0.8914 - val_auc: 0.9309\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3248 - accuracy: 0.8940 - auc: 0.9376 - val_loss: 0.4076 - val_accuracy: 0.8632 - val_auc: 0.9311\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3306 - accuracy: 0.8903 - auc: 0.9373 - val_loss: 0.3869 - val_accuracy: 0.8820 - val_auc: 0.9316\n",
      "Epoch 14/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.8885 - auc: 0.9400Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3183 - accuracy: 0.8883 - auc: 0.9398 - val_loss: 0.3888 - val_accuracy: 0.8816 - val_auc: 0.9298\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5532 - accuracy: 0.8604 - auc: 0.8116 - val_loss: 0.3431 - val_accuracy: 0.8779 - val_auc: 0.9390\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4159 - accuracy: 0.8882 - auc: 0.9055 - val_loss: 0.3291 - val_accuracy: 0.9005 - val_auc: 0.9435\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3793 - accuracy: 0.9014 - auc: 0.9181 - val_loss: 0.3245 - val_accuracy: 0.8720 - val_auc: 0.9420\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3642 - accuracy: 0.9002 - auc: 0.9252 - val_loss: 0.3316 - val_accuracy: 0.9035 - val_auc: 0.9352\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3553 - accuracy: 0.9015 - auc: 0.9297 - val_loss: 0.3214 - val_accuracy: 0.8923 - val_auc: 0.9383\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3378 - accuracy: 0.8974 - auc: 0.9346 - val_loss: 0.3175 - val_accuracy: 0.8867 - val_auc: 0.9395\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3451 - accuracy: 0.8950 - auc: 0.9319 - val_loss: 0.3152 - val_accuracy: 0.9027 - val_auc: 0.9413\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3370 - accuracy: 0.8950 - auc: 0.9347 - val_loss: 0.3225 - val_accuracy: 0.9024 - val_auc: 0.9385\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3244 - accuracy: 0.8993 - auc: 0.9394 - val_loss: 0.3389 - val_accuracy: 0.8894 - val_auc: 0.9356\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3284 - accuracy: 0.8919 - auc: 0.9367 - val_loss: 0.3481 - val_accuracy: 0.8938 - val_auc: 0.9371\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3095 - accuracy: 0.8904 - auc: 0.9427 - val_loss: 0.3540 - val_accuracy: 0.8987 - val_auc: 0.9374\n",
      "Epoch 12/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.8905 - auc: 0.9375Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3266 - accuracy: 0.8906 - auc: 0.9370 - val_loss: 0.3895 - val_accuracy: 0.8906 - val_auc: 0.9307\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6909 - accuracy: 0.8709 - auc: 0.7771 - val_loss: 0.4008 - val_accuracy: 0.8969 - val_auc: 0.9202\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4258 - accuracy: 0.8836 - auc: 0.8925 - val_loss: 0.3688 - val_accuracy: 0.8754 - val_auc: 0.9288\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3914 - accuracy: 0.8873 - auc: 0.9115 - val_loss: 0.3398 - val_accuracy: 0.8682 - val_auc: 0.9356\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3822 - accuracy: 0.8925 - auc: 0.9157 - val_loss: 0.3375 - val_accuracy: 0.8852 - val_auc: 0.9357\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3530 - accuracy: 0.8944 - auc: 0.9276 - val_loss: 0.3430 - val_accuracy: 0.9015 - val_auc: 0.9325\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3636 - accuracy: 0.8953 - auc: 0.9238 - val_loss: 0.3458 - val_accuracy: 0.8754 - val_auc: 0.9330\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3299 - accuracy: 0.8968 - auc: 0.9364 - val_loss: 0.3404 - val_accuracy: 0.8911 - val_auc: 0.9356\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3314 - accuracy: 0.8939 - auc: 0.9357 - val_loss: 0.3538 - val_accuracy: 0.8864 - val_auc: 0.9324\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3261 - accuracy: 0.8873 - auc: 0.9380 - val_loss: 0.3490 - val_accuracy: 0.8865 - val_auc: 0.9332\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3263 - accuracy: 0.8886 - auc: 0.9356 - val_loss: 0.3823 - val_accuracy: 0.8874 - val_auc: 0.9315\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3119 - accuracy: 0.8889 - auc: 0.9392 - val_loss: 0.3883 - val_accuracy: 0.8909 - val_auc: 0.9312\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3135 - accuracy: 0.8861 - auc: 0.9405 - val_loss: 0.4010 - val_accuracy: 0.8855 - val_auc: 0.9319\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3121 - accuracy: 0.8832 - auc: 0.9393 - val_loss: 0.3985 - val_accuracy: 0.8768 - val_auc: 0.9330\n",
      "Epoch 14/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3044 - accuracy: 0.8824 - auc: 0.9428Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3038 - accuracy: 0.8824 - auc: 0.9432 - val_loss: 0.3919 - val_accuracy: 0.8889 - val_auc: 0.9334\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5315 - accuracy: 0.5687 - auc: 0.8550 - val_loss: 0.3427 - val_accuracy: 0.8514 - val_auc: 0.9339\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3740 - accuracy: 0.8471 - auc: 0.9191 - val_loss: 0.3121 - val_accuracy: 0.8622 - val_auc: 0.9415\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3537 - accuracy: 0.8681 - auc: 0.9278 - val_loss: 0.3081 - val_accuracy: 0.8885 - val_auc: 0.9430\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3549 - accuracy: 0.8798 - auc: 0.9281 - val_loss: 0.3084 - val_accuracy: 0.8941 - val_auc: 0.9432\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3256 - accuracy: 0.8866 - auc: 0.9389 - val_loss: 0.3204 - val_accuracy: 0.8810 - val_auc: 0.9400\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3163 - accuracy: 0.8845 - auc: 0.9401 - val_loss: 0.3136 - val_accuracy: 0.8825 - val_auc: 0.9424\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3192 - accuracy: 0.8882 - auc: 0.9400 - val_loss: 0.3217 - val_accuracy: 0.8926 - val_auc: 0.9388\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3191 - accuracy: 0.8865 - auc: 0.9404 - val_loss: 0.3410 - val_accuracy: 0.8971 - val_auc: 0.9363\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3172 - accuracy: 0.8863 - auc: 0.9409 - val_loss: 0.3350 - val_accuracy: 0.8926 - val_auc: 0.9379\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3053 - accuracy: 0.8935 - auc: 0.9449 - val_loss: 0.3505 - val_accuracy: 0.9066 - val_auc: 0.9370\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3024 - accuracy: 0.8894 - auc: 0.9456 - val_loss: 0.3622 - val_accuracy: 0.9102 - val_auc: 0.9371\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3099 - accuracy: 0.8957 - auc: 0.9434 - val_loss: 0.3865 - val_accuracy: 0.8834 - val_auc: 0.9307\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3112 - accuracy: 0.8921 - auc: 0.9446 - val_loss: 0.3399 - val_accuracy: 0.8893 - val_auc: 0.9394\n",
      "Epoch 14/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3038 - accuracy: 0.8925 - auc: 0.9466Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3023 - accuracy: 0.8925 - auc: 0.9469 - val_loss: 0.3631 - val_accuracy: 0.8824 - val_auc: 0.9376\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5155 - accuracy: 0.8310 - auc: 0.8459 - val_loss: 0.3315 - val_accuracy: 0.8944 - val_auc: 0.9414\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3876 - accuracy: 0.8890 - auc: 0.9149 - val_loss: 0.3163 - val_accuracy: 0.8957 - val_auc: 0.9376\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3710 - accuracy: 0.8840 - auc: 0.9211 - val_loss: 0.3014 - val_accuracy: 0.9074 - val_auc: 0.9453\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3482 - accuracy: 0.8949 - auc: 0.9304 - val_loss: 0.3062 - val_accuracy: 0.8766 - val_auc: 0.9421\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3467 - accuracy: 0.8910 - auc: 0.9323 - val_loss: 0.3142 - val_accuracy: 0.8907 - val_auc: 0.9395\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3467 - accuracy: 0.8906 - auc: 0.9322 - val_loss: 0.3291 - val_accuracy: 0.8693 - val_auc: 0.9374\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3417 - accuracy: 0.8885 - auc: 0.9340 - val_loss: 0.3203 - val_accuracy: 0.9031 - val_auc: 0.9382\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3351 - accuracy: 0.8953 - auc: 0.9381 - val_loss: 0.3272 - val_accuracy: 0.8809 - val_auc: 0.9375\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3258 - accuracy: 0.8901 - auc: 0.9398 - val_loss: 0.3380 - val_accuracy: 0.9035 - val_auc: 0.9348\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3263 - accuracy: 0.8899 - auc: 0.9407 - val_loss: 0.3679 - val_accuracy: 0.8989 - val_auc: 0.9311\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3279 - accuracy: 0.8927 - auc: 0.9398 - val_loss: 0.3630 - val_accuracy: 0.8955 - val_auc: 0.9330\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3187 - accuracy: 0.8948 - auc: 0.9413 - val_loss: 0.3715 - val_accuracy: 0.8869 - val_auc: 0.9319\n",
      "Epoch 13/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.8912 - auc: 0.9433Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3165 - accuracy: 0.8912 - auc: 0.9433 - val_loss: 0.3829 - val_accuracy: 0.8894 - val_auc: 0.9298\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6042 - accuracy: 0.6820 - auc: 0.8458 - val_loss: 0.3421 - val_accuracy: 0.8402 - val_auc: 0.9356\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3964 - accuracy: 0.8083 - auc: 0.9126 - val_loss: 0.3173 - val_accuracy: 0.8698 - val_auc: 0.9405\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3540 - accuracy: 0.8440 - auc: 0.9277 - val_loss: 0.3246 - val_accuracy: 0.8545 - val_auc: 0.9386\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3180 - accuracy: 0.8509 - auc: 0.9403 - val_loss: 0.3415 - val_accuracy: 0.8563 - val_auc: 0.9350\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3284 - accuracy: 0.8525 - auc: 0.9375 - val_loss: 0.3308 - val_accuracy: 0.8728 - val_auc: 0.9378\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3077 - accuracy: 0.8585 - auc: 0.9442 - val_loss: 0.3472 - val_accuracy: 0.8775 - val_auc: 0.9352\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3057 - accuracy: 0.8535 - auc: 0.9444 - val_loss: 0.3717 - val_accuracy: 0.8755 - val_auc: 0.9311\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2974 - accuracy: 0.8547 - auc: 0.9481 - val_loss: 0.3820 - val_accuracy: 0.8691 - val_auc: 0.9306\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2920 - accuracy: 0.8536 - auc: 0.9500 - val_loss: 0.4365 - val_accuracy: 0.8662 - val_auc: 0.9246\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2895 - accuracy: 0.8580 - auc: 0.9504 - val_loss: 0.4280 - val_accuracy: 0.8656 - val_auc: 0.9263\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3002 - accuracy: 0.8548 - auc: 0.9479 - val_loss: 0.4126 - val_accuracy: 0.8633 - val_auc: 0.9280\n",
      "Epoch 12/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.8561 - auc: 0.9561Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2777 - accuracy: 0.8563 - auc: 0.9551 - val_loss: 0.5240 - val_accuracy: 0.8819 - val_auc: 0.9247\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 21us/sample - loss: 0.5971 - accuracy: 0.6256 - auc: 0.8481 - val_loss: 0.3594 - val_accuracy: 0.8290 - val_auc: 0.9257\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3948 - accuracy: 0.7918 - auc: 0.9190 - val_loss: 0.3158 - val_accuracy: 0.8444 - val_auc: 0.9412\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3434 - accuracy: 0.8225 - auc: 0.9323 - val_loss: 0.3288 - val_accuracy: 0.8672 - val_auc: 0.9361\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3351 - accuracy: 0.8364 - auc: 0.9354 - val_loss: 0.3276 - val_accuracy: 0.8788 - val_auc: 0.9376\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3154 - accuracy: 0.8587 - auc: 0.9422 - val_loss: 0.3254 - val_accuracy: 0.8786 - val_auc: 0.9393\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3045 - accuracy: 0.8677 - auc: 0.9467 - val_loss: 0.3223 - val_accuracy: 0.8782 - val_auc: 0.9387\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2927 - accuracy: 0.8664 - auc: 0.9492 - val_loss: 0.3495 - val_accuracy: 0.8924 - val_auc: 0.9361\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2994 - accuracy: 0.8676 - auc: 0.9475 - val_loss: 0.3511 - val_accuracy: 0.8756 - val_auc: 0.9331\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2985 - accuracy: 0.8714 - auc: 0.9482 - val_loss: 0.3597 - val_accuracy: 0.8794 - val_auc: 0.9317\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2897 - accuracy: 0.8756 - auc: 0.9509 - val_loss: 0.3720 - val_accuracy: 0.8888 - val_auc: 0.9323\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2847 - accuracy: 0.8775 - auc: 0.9519 - val_loss: 0.4299 - val_accuracy: 0.9029 - val_auc: 0.9292\n",
      "Epoch 12/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2786 - accuracy: 0.8751 - auc: 0.9537Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2820 - accuracy: 0.8750 - auc: 0.9527 - val_loss: 0.4402 - val_accuracy: 0.8792 - val_auc: 0.9296\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5320 - accuracy: 0.7230 - auc: 0.8520 - val_loss: 0.3394 - val_accuracy: 0.8589 - val_auc: 0.9380\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3762 - accuracy: 0.8682 - auc: 0.9173 - val_loss: 0.3128 - val_accuracy: 0.8787 - val_auc: 0.9443\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3507 - accuracy: 0.8832 - auc: 0.9290 - val_loss: 0.3071 - val_accuracy: 0.8939 - val_auc: 0.9423\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3405 - accuracy: 0.8839 - auc: 0.9330 - val_loss: 0.3161 - val_accuracy: 0.8942 - val_auc: 0.9381\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3328 - accuracy: 0.8861 - auc: 0.9351 - val_loss: 0.3085 - val_accuracy: 0.8940 - val_auc: 0.9420\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3086 - accuracy: 0.8907 - auc: 0.9436 - val_loss: 0.3303 - val_accuracy: 0.9002 - val_auc: 0.9359\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3021 - accuracy: 0.8910 - auc: 0.9467 - val_loss: 0.3473 - val_accuracy: 0.8926 - val_auc: 0.9342\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3083 - accuracy: 0.8901 - auc: 0.9444 - val_loss: 0.3805 - val_accuracy: 0.9078 - val_auc: 0.9288\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3071 - accuracy: 0.8924 - auc: 0.9454 - val_loss: 0.3456 - val_accuracy: 0.9012 - val_auc: 0.9341\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2999 - accuracy: 0.8931 - auc: 0.9467 - val_loss: 0.3640 - val_accuracy: 0.8940 - val_auc: 0.9338\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2988 - accuracy: 0.8899 - auc: 0.9477 - val_loss: 0.3568 - val_accuracy: 0.8906 - val_auc: 0.9347\n",
      "Epoch 12/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2960 - accuracy: 0.8918 - auc: 0.9487Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2948 - accuracy: 0.8920 - auc: 0.9487 - val_loss: 0.4055 - val_accuracy: 0.9096 - val_auc: 0.9295\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5745 - accuracy: 0.6938 - auc: 0.8474 - val_loss: 0.3284 - val_accuracy: 0.8528 - val_auc: 0.9359\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3733 - accuracy: 0.8305 - auc: 0.9229 - val_loss: 0.3235 - val_accuracy: 0.8750 - val_auc: 0.9366\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3553 - accuracy: 0.8615 - auc: 0.9271 - val_loss: 0.3150 - val_accuracy: 0.8744 - val_auc: 0.9394\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3205 - accuracy: 0.8744 - auc: 0.9403 - val_loss: 0.3352 - val_accuracy: 0.8928 - val_auc: 0.9374\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3331 - accuracy: 0.8820 - auc: 0.9405 - val_loss: 0.3215 - val_accuracy: 0.8817 - val_auc: 0.9399\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3181 - accuracy: 0.8818 - auc: 0.9408 - val_loss: 0.3119 - val_accuracy: 0.8689 - val_auc: 0.9431\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3033 - accuracy: 0.8847 - auc: 0.9461 - val_loss: 0.3544 - val_accuracy: 0.8841 - val_auc: 0.9324\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3152 - accuracy: 0.8830 - auc: 0.9443 - val_loss: 0.3379 - val_accuracy: 0.8810 - val_auc: 0.9360\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3050 - accuracy: 0.8816 - auc: 0.9460 - val_loss: 0.3523 - val_accuracy: 0.8960 - val_auc: 0.9347\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3068 - accuracy: 0.8807 - auc: 0.9456 - val_loss: 0.3463 - val_accuracy: 0.9009 - val_auc: 0.9367\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2899 - accuracy: 0.8846 - auc: 0.9503 - val_loss: 0.3437 - val_accuracy: 0.8916 - val_auc: 0.9374\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2864 - accuracy: 0.8843 - auc: 0.9514 - val_loss: 0.4077 - val_accuracy: 0.8790 - val_auc: 0.9319\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2881 - accuracy: 0.8776 - auc: 0.9516 - val_loss: 0.3915 - val_accuracy: 0.8839 - val_auc: 0.9305\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2814 - accuracy: 0.8750 - auc: 0.9528 - val_loss: 0.4478 - val_accuracy: 0.8902 - val_auc: 0.9289\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2861 - accuracy: 0.8807 - auc: 0.9517 - val_loss: 0.3981 - val_accuracy: 0.8895 - val_auc: 0.9304\n",
      "Epoch 16/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.8823 - auc: 0.9526Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2882 - accuracy: 0.8822 - auc: 0.9522 - val_loss: 0.4463 - val_accuracy: 0.8819 - val_auc: 0.9306\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5781 - accuracy: 0.8216 - auc: 0.8449 - val_loss: 0.3577 - val_accuracy: 0.8908 - val_auc: 0.9271\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3646 - accuracy: 0.8897 - auc: 0.9282 - val_loss: 0.3380 - val_accuracy: 0.8974 - val_auc: 0.9300\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3458 - accuracy: 0.8968 - auc: 0.9359 - val_loss: 0.3285 - val_accuracy: 0.8945 - val_auc: 0.9365\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3595 - accuracy: 0.8895 - auc: 0.9308 - val_loss: 0.3365 - val_accuracy: 0.8782 - val_auc: 0.9344\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3420 - accuracy: 0.8981 - auc: 0.9362 - val_loss: 0.3224 - val_accuracy: 0.9031 - val_auc: 0.9363\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3311 - accuracy: 0.8986 - auc: 0.9421 - val_loss: 0.3426 - val_accuracy: 0.9116 - val_auc: 0.9280\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3595 - accuracy: 0.8967 - auc: 0.9348 - val_loss: 0.3296 - val_accuracy: 0.9129 - val_auc: 0.9284\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3277 - accuracy: 0.8991 - auc: 0.9418 - val_loss: 0.3293 - val_accuracy: 0.8969 - val_auc: 0.9329\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3122 - accuracy: 0.9009 - auc: 0.9470 - val_loss: 0.3445 - val_accuracy: 0.8948 - val_auc: 0.9301\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3091 - accuracy: 0.8997 - auc: 0.9477 - val_loss: 0.3660 - val_accuracy: 0.9089 - val_auc: 0.9269\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3208 - accuracy: 0.8940 - auc: 0.9446 - val_loss: 0.3593 - val_accuracy: 0.8992 - val_auc: 0.9294\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3134 - accuracy: 0.8973 - auc: 0.9454 - val_loss: 0.3566 - val_accuracy: 0.9186 - val_auc: 0.9278\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.3056 - accuracy: 0.9018 - auc: 0.9485Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3073 - accuracy: 0.9018 - auc: 0.9478 - val_loss: 0.3550 - val_accuracy: 0.9050 - val_auc: 0.9308\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5445 - accuracy: 0.6989 - auc: 0.8606 - val_loss: 0.3514 - val_accuracy: 0.8601 - val_auc: 0.9283\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3649 - accuracy: 0.8289 - auc: 0.9252 - val_loss: 0.3262 - val_accuracy: 0.8656 - val_auc: 0.9372\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3552 - accuracy: 0.8463 - auc: 0.9276 - val_loss: 0.3377 - val_accuracy: 0.8753 - val_auc: 0.9327\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3230 - accuracy: 0.8608 - auc: 0.9393 - val_loss: 0.3656 - val_accuracy: 0.8990 - val_auc: 0.9302\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3167 - accuracy: 0.8688 - auc: 0.9418 - val_loss: 0.3615 - val_accuracy: 0.8748 - val_auc: 0.9313\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3066 - accuracy: 0.8616 - auc: 0.9450 - val_loss: 0.3605 - val_accuracy: 0.8888 - val_auc: 0.9307\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2983 - accuracy: 0.8817 - auc: 0.9482 - val_loss: 0.3669 - val_accuracy: 0.8769 - val_auc: 0.9308\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3033 - accuracy: 0.8690 - auc: 0.9475 - val_loss: 0.3744 - val_accuracy: 0.8736 - val_auc: 0.9315\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2936 - accuracy: 0.8766 - auc: 0.9491 - val_loss: 0.4439 - val_accuracy: 0.8831 - val_auc: 0.9238\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2934 - accuracy: 0.8811 - auc: 0.9501 - val_loss: 0.4298 - val_accuracy: 0.8693 - val_auc: 0.9244\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3041 - accuracy: 0.8709 - auc: 0.9475 - val_loss: 0.4724 - val_accuracy: 0.8893 - val_auc: 0.9233\n",
      "Epoch 12/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2763 - accuracy: 0.8805 - auc: 0.9546Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2796 - accuracy: 0.8803 - auc: 0.9538 - val_loss: 0.5178 - val_accuracy: 0.8855 - val_auc: 0.9198\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5278 - accuracy: 0.7201 - auc: 0.8562 - val_loss: 0.3151 - val_accuracy: 0.8670 - val_auc: 0.9427\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3553 - accuracy: 0.8461 - auc: 0.9259 - val_loss: 0.3193 - val_accuracy: 0.8664 - val_auc: 0.9411\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3361 - accuracy: 0.8685 - auc: 0.9341 - val_loss: 0.3189 - val_accuracy: 0.8526 - val_auc: 0.9426\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3233 - accuracy: 0.8735 - auc: 0.9390 - val_loss: 0.3180 - val_accuracy: 0.8791 - val_auc: 0.9396\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3066 - accuracy: 0.8813 - auc: 0.9451 - val_loss: 0.3296 - val_accuracy: 0.8718 - val_auc: 0.9372\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3093 - accuracy: 0.8836 - auc: 0.9449 - val_loss: 0.3369 - val_accuracy: 0.9095 - val_auc: 0.9371\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3100 - accuracy: 0.8853 - auc: 0.9444 - val_loss: 0.3302 - val_accuracy: 0.8768 - val_auc: 0.9373\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2924 - accuracy: 0.8880 - auc: 0.9504 - val_loss: 0.3484 - val_accuracy: 0.8727 - val_auc: 0.9345\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2929 - accuracy: 0.8874 - auc: 0.9499 - val_loss: 0.3656 - val_accuracy: 0.8898 - val_auc: 0.9322\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2896 - accuracy: 0.8898 - auc: 0.9524 - val_loss: 0.3842 - val_accuracy: 0.8912 - val_auc: 0.9282\n",
      "Epoch 11/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.8941 - auc: 0.9501Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2960 - accuracy: 0.8941 - auc: 0.9502 - val_loss: 0.3757 - val_accuracy: 0.8938 - val_auc: 0.9339\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 6s 25us/sample - loss: 0.5506 - accuracy: 0.8142 - auc: 0.8492 - val_loss: 0.3860 - val_accuracy: 0.8905 - val_auc: 0.9274\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3599 - accuracy: 0.8854 - auc: 0.9263 - val_loss: 0.3443 - val_accuracy: 0.9049 - val_auc: 0.9287\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3479 - accuracy: 0.8884 - auc: 0.9303 - val_loss: 0.3308 - val_accuracy: 0.8865 - val_auc: 0.9358\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3405 - accuracy: 0.8908 - auc: 0.9328 - val_loss: 0.3439 - val_accuracy: 0.9066 - val_auc: 0.9309\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3339 - accuracy: 0.8951 - auc: 0.9361 - val_loss: 0.3399 - val_accuracy: 0.8870 - val_auc: 0.9353\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3173 - accuracy: 0.8938 - auc: 0.9426 - val_loss: 0.3364 - val_accuracy: 0.8951 - val_auc: 0.9335\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3168 - accuracy: 0.8936 - auc: 0.9420 - val_loss: 0.3481 - val_accuracy: 0.9145 - val_auc: 0.9334\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3031 - accuracy: 0.8965 - auc: 0.9468 - val_loss: 0.3811 - val_accuracy: 0.9171 - val_auc: 0.9300\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3065 - accuracy: 0.8940 - auc: 0.9458 - val_loss: 0.3780 - val_accuracy: 0.9004 - val_auc: 0.9297\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2971 - accuracy: 0.9002 - auc: 0.9481 - val_loss: 0.4036 - val_accuracy: 0.9065 - val_auc: 0.9296\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2989 - accuracy: 0.8970 - auc: 0.9487 - val_loss: 0.3836 - val_accuracy: 0.9028 - val_auc: 0.9287\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2986 - accuracy: 0.9025 - auc: 0.9489 - val_loss: 0.3980 - val_accuracy: 0.8920 - val_auc: 0.9266\n",
      "Epoch 13/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2891 - accuracy: 0.8991 - auc: 0.9512Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2889 - accuracy: 0.8990 - auc: 0.9513 - val_loss: 0.4273 - val_accuracy: 0.9046 - val_auc: 0.9267\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 21us/sample - loss: 0.5204 - accuracy: 0.7865 - auc: 0.8680 - val_loss: 0.3430 - val_accuracy: 0.8622 - val_auc: 0.9356\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3770 - accuracy: 0.8742 - auc: 0.9230 - val_loss: 0.3114 - val_accuracy: 0.8890 - val_auc: 0.9420\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3415 - accuracy: 0.8808 - auc: 0.9316 - val_loss: 0.3161 - val_accuracy: 0.8810 - val_auc: 0.9404\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3257 - accuracy: 0.8864 - auc: 0.9399 - val_loss: 0.3132 - val_accuracy: 0.8950 - val_auc: 0.9397\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3066 - accuracy: 0.8920 - auc: 0.9449 - val_loss: 0.3467 - val_accuracy: 0.8972 - val_auc: 0.9337\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3099 - accuracy: 0.8880 - auc: 0.9439 - val_loss: 0.3327 - val_accuracy: 0.8859 - val_auc: 0.9370\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3078 - accuracy: 0.8880 - auc: 0.9447 - val_loss: 0.3643 - val_accuracy: 0.9061 - val_auc: 0.9338\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2931 - accuracy: 0.8912 - auc: 0.9496 - val_loss: 0.3529 - val_accuracy: 0.8900 - val_auc: 0.9352\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2842 - accuracy: 0.8928 - auc: 0.9527 - val_loss: 0.3317 - val_accuracy: 0.9005 - val_auc: 0.9409\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2833 - accuracy: 0.8921 - auc: 0.9522 - val_loss: 0.3682 - val_accuracy: 0.9024 - val_auc: 0.9330\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2866 - accuracy: 0.8948 - auc: 0.9520 - val_loss: 0.3639 - val_accuracy: 0.8890 - val_auc: 0.9374\n",
      "Epoch 12/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2817 - accuracy: 0.8942 - auc: 0.9529Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2808 - accuracy: 0.8942 - auc: 0.9535 - val_loss: 0.4133 - val_accuracy: 0.8963 - val_auc: 0.9326\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.5767 - accuracy: 0.6991 - auc: 0.8565 - val_loss: 0.3559 - val_accuracy: 0.8474 - val_auc: 0.9276\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3777 - accuracy: 0.8194 - auc: 0.9197 - val_loss: 0.3225 - val_accuracy: 0.8674 - val_auc: 0.9372\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3417 - accuracy: 0.8383 - auc: 0.9336 - val_loss: 0.3459 - val_accuracy: 0.8880 - val_auc: 0.9328\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3333 - accuracy: 0.8555 - auc: 0.9357 - val_loss: 0.3344 - val_accuracy: 0.8746 - val_auc: 0.9329\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3229 - accuracy: 0.8620 - auc: 0.9420 - val_loss: 0.3288 - val_accuracy: 0.8844 - val_auc: 0.9359\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3042 - accuracy: 0.8712 - auc: 0.9463 - val_loss: 0.3477 - val_accuracy: 0.8790 - val_auc: 0.9340\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3140 - accuracy: 0.8700 - auc: 0.9441 - val_loss: 0.3265 - val_accuracy: 0.8788 - val_auc: 0.9382\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2879 - accuracy: 0.8777 - auc: 0.9513 - val_loss: 0.3670 - val_accuracy: 0.8911 - val_auc: 0.9323\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2929 - accuracy: 0.8691 - auc: 0.9497 - val_loss: 0.3978 - val_accuracy: 0.9050 - val_auc: 0.9280\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2970 - accuracy: 0.8748 - auc: 0.9494 - val_loss: 0.4063 - val_accuracy: 0.8951 - val_auc: 0.9304\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2831 - accuracy: 0.8828 - auc: 0.9535 - val_loss: 0.4241 - val_accuracy: 0.8811 - val_auc: 0.9302\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2812 - accuracy: 0.8701 - auc: 0.9532 - val_loss: 0.4319 - val_accuracy: 0.8954 - val_auc: 0.9302\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2732 - accuracy: 0.8735 - auc: 0.9553 - val_loss: 0.4493 - val_accuracy: 0.8979 - val_auc: 0.9263\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2873 - accuracy: 0.8707 - auc: 0.9520 - val_loss: 0.4280 - val_accuracy: 0.8802 - val_auc: 0.9314\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2757 - accuracy: 0.8798 - auc: 0.9555 - val_loss: 0.4682 - val_accuracy: 0.8842 - val_auc: 0.9279\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2692 - accuracy: 0.8802 - auc: 0.9574 - val_loss: 0.4717 - val_accuracy: 0.8996 - val_auc: 0.9266\n",
      "Epoch 17/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2612 - accuracy: 0.8802 - auc: 0.9594Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2599 - accuracy: 0.8803 - auc: 0.9596 - val_loss: 0.5126 - val_accuracy: 0.8986 - val_auc: 0.9304\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5132 - accuracy: 0.8262 - auc: 0.8640 - val_loss: 0.3485 - val_accuracy: 0.8787 - val_auc: 0.9374\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3554 - accuracy: 0.8875 - auc: 0.9287 - val_loss: 0.3398 - val_accuracy: 0.9190 - val_auc: 0.9301\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3518 - accuracy: 0.8899 - auc: 0.9337 - val_loss: 0.3519 - val_accuracy: 0.8825 - val_auc: 0.9312\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3350 - accuracy: 0.8918 - auc: 0.9388 - val_loss: 0.3466 - val_accuracy: 0.8993 - val_auc: 0.9306\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3276 - accuracy: 0.8925 - auc: 0.9397 - val_loss: 0.3605 - val_accuracy: 0.9051 - val_auc: 0.9217\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3263 - accuracy: 0.8966 - auc: 0.9405 - val_loss: 0.3662 - val_accuracy: 0.8672 - val_auc: 0.9317\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3337 - accuracy: 0.8940 - auc: 0.9420 - val_loss: 0.3641 - val_accuracy: 0.8635 - val_auc: 0.9354\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3050 - accuracy: 0.8938 - auc: 0.9501 - val_loss: 0.3761 - val_accuracy: 0.9098 - val_auc: 0.9265\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3059 - accuracy: 0.8924 - auc: 0.9491 - val_loss: 0.3653 - val_accuracy: 0.9039 - val_auc: 0.9264\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3007 - accuracy: 0.8964 - auc: 0.9497 - val_loss: 0.4190 - val_accuracy: 0.9007 - val_auc: 0.9185\n",
      "Epoch 11/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3081 - accuracy: 0.8961 - auc: 0.9474Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3079 - accuracy: 0.8961 - auc: 0.9475 - val_loss: 0.3577 - val_accuracy: 0.8798 - val_auc: 0.9288\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.4871 - accuracy: 0.7748 - auc: 0.8805 - val_loss: 0.3255 - val_accuracy: 0.8821 - val_auc: 0.9367\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3620 - accuracy: 0.8624 - auc: 0.9274 - val_loss: 0.3374 - val_accuracy: 0.8724 - val_auc: 0.9325\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3343 - accuracy: 0.8766 - auc: 0.9359 - val_loss: 0.3299 - val_accuracy: 0.8689 - val_auc: 0.9383\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3165 - accuracy: 0.8841 - auc: 0.9440 - val_loss: 0.3248 - val_accuracy: 0.8910 - val_auc: 0.9398\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3469 - accuracy: 0.8805 - auc: 0.9411 - val_loss: 0.3490 - val_accuracy: 0.9131 - val_auc: 0.9342\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3105 - accuracy: 0.8894 - auc: 0.9472 - val_loss: 0.3234 - val_accuracy: 0.9073 - val_auc: 0.9395s: 0.2914 - accuracy: \n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2926 - accuracy: 0.8913 - auc: 0.9508 - val_loss: 0.3391 - val_accuracy: 0.8914 - val_auc: 0.9355\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2984 - accuracy: 0.8894 - auc: 0.9485 - val_loss: 0.3591 - val_accuracy: 0.9008 - val_auc: 0.9339\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2900 - accuracy: 0.8923 - auc: 0.9513 - val_loss: 0.3841 - val_accuracy: 0.8788 - val_auc: 0.9338\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2919 - accuracy: 0.8933 - auc: 0.9514 - val_loss: 0.3723 - val_accuracy: 0.8822 - val_auc: 0.9369\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2797 - accuracy: 0.8931 - auc: 0.9554 - val_loss: 0.3920 - val_accuracy: 0.8882 - val_auc: 0.9302\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2743 - accuracy: 0.8925 - auc: 0.9557 - val_loss: 0.4630 - val_accuracy: 0.9054 - val_auc: 0.9238\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2704 - accuracy: 0.8970 - auc: 0.9581 - val_loss: 0.4361 - val_accuracy: 0.9008 - val_auc: 0.9280\n",
      "Epoch 14/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.8958 - auc: 0.9590Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2633 - accuracy: 0.8955 - auc: 0.9590 - val_loss: 0.4810 - val_accuracy: 0.8826 - val_auc: 0.9265\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5329 - accuracy: 0.7680 - auc: 0.8581 - val_loss: 0.3214 - val_accuracy: 0.8892 - val_auc: 0.9406\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3739 - accuracy: 0.8645 - auc: 0.9199 - val_loss: 0.3378 - val_accuracy: 0.8896 - val_auc: 0.9296\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3332 - accuracy: 0.8814 - auc: 0.9343 - val_loss: 0.3222 - val_accuracy: 0.8808 - val_auc: 0.9378\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3219 - accuracy: 0.8828 - auc: 0.9390 - val_loss: 0.3361 - val_accuracy: 0.9012 - val_auc: 0.9346\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3215 - accuracy: 0.8859 - auc: 0.9384 - val_loss: 0.3478 - val_accuracy: 0.9051 - val_auc: 0.9322\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3059 - accuracy: 0.8886 - auc: 0.9470 - val_loss: 0.3489 - val_accuracy: 0.9019 - val_auc: 0.9354\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3161 - accuracy: 0.8840 - auc: 0.9437 - val_loss: 0.3452 - val_accuracy: 0.8740 - val_auc: 0.9337\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3063 - accuracy: 0.8897 - auc: 0.9453 - val_loss: 0.3483 - val_accuracy: 0.8998 - val_auc: 0.9336\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2946 - accuracy: 0.8924 - auc: 0.9498 - val_loss: 0.4050 - val_accuracy: 0.9089 - val_auc: 0.9290\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3018 - accuracy: 0.8892 - auc: 0.9472 - val_loss: 0.4102 - val_accuracy: 0.8941 - val_auc: 0.9303\n",
      "Epoch 11/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2782 - accuracy: 0.8924 - auc: 0.9540Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2772 - accuracy: 0.8923 - auc: 0.9545 - val_loss: 0.4333 - val_accuracy: 0.8976 - val_auc: 0.9302\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.5585 - accuracy: 0.8246 - auc: 0.8584 - val_loss: 0.3454 - val_accuracy: 0.9210 - val_auc: 0.9378\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3528 - accuracy: 0.8927 - auc: 0.9321 - val_loss: 0.3435 - val_accuracy: 0.9280 - val_auc: 0.9312\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3604 - accuracy: 0.8946 - auc: 0.9318 - val_loss: 0.3217 - val_accuracy: 0.8884 - val_auc: 0.9424\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3379 - accuracy: 0.8964 - auc: 0.9374 - val_loss: 0.3294 - val_accuracy: 0.8929 - val_auc: 0.9344\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3401 - accuracy: 0.8987 - auc: 0.9414 - val_loss: 0.3277 - val_accuracy: 0.8943 - val_auc: 0.9376\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3298 - accuracy: 0.8931 - auc: 0.9404 - val_loss: 0.3486 - val_accuracy: 0.9345 - val_auc: 0.9328\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3093 - accuracy: 0.9015 - auc: 0.9467 - val_loss: 0.3331 - val_accuracy: 0.9081 - val_auc: 0.9334\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3031 - accuracy: 0.8995 - auc: 0.9482 - val_loss: 0.3318 - val_accuracy: 0.9038 - val_auc: 0.9385\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3073 - accuracy: 0.8950 - auc: 0.9474 - val_loss: 0.3916 - val_accuracy: 0.9258 - val_auc: 0.9305\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3105 - accuracy: 0.9004 - auc: 0.9471 - val_loss: 0.3394 - val_accuracy: 0.9057 - val_auc: 0.9331\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2898 - accuracy: 0.8995 - auc: 0.9527 - val_loss: 0.3709 - val_accuracy: 0.9016 - val_auc: 0.9311\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2953 - accuracy: 0.8939 - auc: 0.9513 - val_loss: 0.3640 - val_accuracy: 0.9020 - val_auc: 0.9340\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.2908 - accuracy: 0.8958 - auc: 0.9521Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2888 - accuracy: 0.8959 - auc: 0.9526 - val_loss: 0.3799 - val_accuracy: 0.9090 - val_auc: 0.9338\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 20us/sample - loss: 0.5855 - accuracy: 0.7026 - auc: 0.8645 - val_loss: 0.3864 - val_accuracy: 0.8471 - val_auc: 0.9141\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4208 - accuracy: 0.7981 - auc: 0.9094 - val_loss: 0.3466 - val_accuracy: 0.8032 - val_auc: 0.9392\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3468 - accuracy: 0.8228 - auc: 0.9326 - val_loss: 0.3330 - val_accuracy: 0.8514 - val_auc: 0.9364\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3190 - accuracy: 0.8465 - auc: 0.9409 - val_loss: 0.3364 - val_accuracy: 0.8659 - val_auc: 0.9354\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3237 - accuracy: 0.8518 - auc: 0.9420 - val_loss: 0.3432 - val_accuracy: 0.8816 - val_auc: 0.9339\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2992 - accuracy: 0.8651 - auc: 0.9481 - val_loss: 0.3391 - val_accuracy: 0.8929 - val_auc: 0.9370\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2951 - accuracy: 0.8740 - auc: 0.9496 - val_loss: 0.3424 - val_accuracy: 0.8739 - val_auc: 0.9350\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2896 - accuracy: 0.8751 - auc: 0.9528 - val_loss: 0.3648 - val_accuracy: 0.8901 - val_auc: 0.9303\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2875 - accuracy: 0.8823 - auc: 0.9517 - val_loss: 0.3829 - val_accuracy: 0.8904 - val_auc: 0.9291\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2789 - accuracy: 0.8783 - auc: 0.9547 - val_loss: 0.3904 - val_accuracy: 0.8867 - val_auc: 0.9319\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2828 - accuracy: 0.8814 - auc: 0.9547 - val_loss: 0.3744 - val_accuracy: 0.8716 - val_auc: 0.9333\n",
      "Epoch 12/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2902 - accuracy: 0.8810 - auc: 0.9527Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2892 - accuracy: 0.8810 - auc: 0.9528 - val_loss: 0.3921 - val_accuracy: 0.8989 - val_auc: 0.9287\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.7679 - accuracy: 0.7686 - auc: 0.6770 - val_loss: 0.4548 - val_accuracy: 0.8473 - val_auc: 0.8760\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5617 - accuracy: 0.8245 - auc: 0.8089 - val_loss: 0.3990 - val_accuracy: 0.8692 - val_auc: 0.9133\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4684 - accuracy: 0.8558 - auc: 0.8635 - val_loss: 0.3688 - val_accuracy: 0.8854 - val_auc: 0.9223\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4542 - accuracy: 0.8735 - auc: 0.8759 - val_loss: 0.3597 - val_accuracy: 0.8881 - val_auc: 0.9265\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4027 - accuracy: 0.8799 - auc: 0.9065 - val_loss: 0.3506 - val_accuracy: 0.8871 - val_auc: 0.9284\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3768 - accuracy: 0.8870 - auc: 0.9206 - val_loss: 0.3443 - val_accuracy: 0.8933 - val_auc: 0.9292\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3835 - accuracy: 0.8911 - auc: 0.9160 - val_loss: 0.3393 - val_accuracy: 0.8923 - val_auc: 0.9314\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3732 - accuracy: 0.8932 - auc: 0.9211 - val_loss: 0.3354 - val_accuracy: 0.8957 - val_auc: 0.9331\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3708 - accuracy: 0.8944 - auc: 0.9239 - val_loss: 0.3316 - val_accuracy: 0.8983 - val_auc: 0.9341\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3561 - accuracy: 0.8983 - auc: 0.9290 - val_loss: 0.3300 - val_accuracy: 0.9033 - val_auc: 0.9347\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3504 - accuracy: 0.8997 - auc: 0.9319 - val_loss: 0.3271 - val_accuracy: 0.9015 - val_auc: 0.9359\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3587 - accuracy: 0.8982 - auc: 0.9292 - val_loss: 0.3270 - val_accuracy: 0.9036 - val_auc: 0.9355\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3466 - accuracy: 0.9021 - auc: 0.9330 - val_loss: 0.3266 - val_accuracy: 0.9034 - val_auc: 0.9359\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3468 - accuracy: 0.9027 - auc: 0.9321 - val_loss: 0.3224 - val_accuracy: 0.9072 - val_auc: 0.9375\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3529 - accuracy: 0.9037 - auc: 0.9320 - val_loss: 0.3252 - val_accuracy: 0.8973 - val_auc: 0.9356\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3395 - accuracy: 0.8996 - auc: 0.9372 - val_loss: 0.3240 - val_accuracy: 0.9056 - val_auc: 0.9359\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3340 - accuracy: 0.9029 - auc: 0.9390 - val_loss: 0.3281 - val_accuracy: 0.9017 - val_auc: 0.9339\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3385 - accuracy: 0.9036 - auc: 0.9370 - val_loss: 0.3285 - val_accuracy: 0.9025 - val_auc: 0.9349\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3315 - accuracy: 0.9037 - auc: 0.9403 - val_loss: 0.3286 - val_accuracy: 0.9060 - val_auc: 0.9351\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3376 - accuracy: 0.9047 - auc: 0.9358 - val_loss: 0.3277 - val_accuracy: 0.9057 - val_auc: 0.9349\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3354 - accuracy: 0.9042 - auc: 0.9384 - val_loss: 0.3322 - val_accuracy: 0.9015 - val_auc: 0.9340\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3251 - accuracy: 0.9025 - auc: 0.9426 - val_loss: 0.3321 - val_accuracy: 0.9008 - val_auc: 0.9345\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3296 - accuracy: 0.9023 - auc: 0.9404 - val_loss: 0.3306 - val_accuracy: 0.9025 - val_auc: 0.9350\n",
      "Epoch 24/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.9009 - auc: 0.9430Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3220 - accuracy: 0.9010 - auc: 0.9436 - val_loss: 0.3303 - val_accuracy: 0.9042 - val_auc: 0.9346\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.9044 - accuracy: 0.3346 - auc: 0.6297 - val_loss: 0.6168 - val_accuracy: 0.4028 - val_auc: 0.7981\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.6767 - accuracy: 0.4190 - auc: 0.7657 - val_loss: 0.4828 - val_accuracy: 0.5651 - val_auc: 0.8974\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5637 - accuracy: 0.5237 - auc: 0.8343 - val_loss: 0.4147 - val_accuracy: 0.6760 - val_auc: 0.9222\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5144 - accuracy: 0.5860 - auc: 0.8627 - val_loss: 0.3771 - val_accuracy: 0.7405 - val_auc: 0.9314\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4582 - accuracy: 0.6416 - auc: 0.8940 - val_loss: 0.3505 - val_accuracy: 0.7901 - val_auc: 0.9365\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4283 - accuracy: 0.6766 - auc: 0.8999 - val_loss: 0.3354 - val_accuracy: 0.8150 - val_auc: 0.9387\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3882 - accuracy: 0.7081 - auc: 0.9177 - val_loss: 0.3220 - val_accuracy: 0.8387 - val_auc: 0.9406\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3867 - accuracy: 0.7332 - auc: 0.9143 - val_loss: 0.3195 - val_accuracy: 0.8450 - val_auc: 0.9402\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3758 - accuracy: 0.7426 - auc: 0.9198 - val_loss: 0.3167 - val_accuracy: 0.8509 - val_auc: 0.9404\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3615 - accuracy: 0.7510 - auc: 0.9264 - val_loss: 0.3161 - val_accuracy: 0.8550 - val_auc: 0.9402\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3546 - accuracy: 0.7603 - auc: 0.9276 - val_loss: 0.3155 - val_accuracy: 0.8585 - val_auc: 0.9401\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3493 - accuracy: 0.7706 - auc: 0.9308 - val_loss: 0.3165 - val_accuracy: 0.8597 - val_auc: 0.9400\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3447 - accuracy: 0.7749 - auc: 0.9300 - val_loss: 0.3172 - val_accuracy: 0.8604 - val_auc: 0.9398\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3334 - accuracy: 0.7796 - auc: 0.9364 - val_loss: 0.3181 - val_accuracy: 0.8614 - val_auc: 0.9399\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3314 - accuracy: 0.7861 - auc: 0.9358 - val_loss: 0.3196 - val_accuracy: 0.8638 - val_auc: 0.9395\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3232 - accuracy: 0.7873 - auc: 0.9408 - val_loss: 0.3219 - val_accuracy: 0.8678 - val_auc: 0.9391\n",
      "Epoch 17/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.7921 - auc: 0.9404Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3211 - accuracy: 0.7920 - auc: 0.9401 - val_loss: 0.3233 - val_accuracy: 0.8674 - val_auc: 0.9388\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.7153 - accuracy: 0.3172 - auc: 0.7312 - val_loss: 0.5298 - val_accuracy: 0.4916 - val_auc: 0.8653\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5620 - accuracy: 0.5276 - auc: 0.8227 - val_loss: 0.4199 - val_accuracy: 0.7345 - val_auc: 0.9106\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4791 - accuracy: 0.6486 - auc: 0.8648 - val_loss: 0.3671 - val_accuracy: 0.8168 - val_auc: 0.9258\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4211 - accuracy: 0.7178 - auc: 0.8938 - val_loss: 0.3437 - val_accuracy: 0.8508 - val_auc: 0.9319\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4041 - accuracy: 0.7545 - auc: 0.8996 - val_loss: 0.3342 - val_accuracy: 0.8563 - val_auc: 0.9348\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4033 - accuracy: 0.7645 - auc: 0.9030 - val_loss: 0.3326 - val_accuracy: 0.8527 - val_auc: 0.9353\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3795 - accuracy: 0.7754 - auc: 0.9117 - val_loss: 0.3312 - val_accuracy: 0.8546 - val_auc: 0.9358\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3690 - accuracy: 0.7870 - auc: 0.9181 - val_loss: 0.3303 - val_accuracy: 0.8530 - val_auc: 0.9362\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3502 - accuracy: 0.7900 - auc: 0.9247 - val_loss: 0.3296 - val_accuracy: 0.8605 - val_auc: 0.9370\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3469 - accuracy: 0.8006 - auc: 0.9248 - val_loss: 0.3327 - val_accuracy: 0.8616 - val_auc: 0.9366\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3512 - accuracy: 0.7989 - auc: 0.9256 - val_loss: 0.3366 - val_accuracy: 0.8560 - val_auc: 0.9350\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3359 - accuracy: 0.8011 - auc: 0.9300 - val_loss: 0.3390 - val_accuracy: 0.8588 - val_auc: 0.9357\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3397 - accuracy: 0.8057 - auc: 0.9294 - val_loss: 0.3423 - val_accuracy: 0.8574 - val_auc: 0.9340\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3335 - accuracy: 0.8075 - auc: 0.9316 - val_loss: 0.3478 - val_accuracy: 0.8590 - val_auc: 0.9331\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3196 - accuracy: 0.8101 - auc: 0.9354 - val_loss: 0.3483 - val_accuracy: 0.8639 - val_auc: 0.9338\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3188 - accuracy: 0.8143 - auc: 0.9364 - val_loss: 0.3462 - val_accuracy: 0.8657 - val_auc: 0.9340\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3265 - accuracy: 0.8184 - auc: 0.9344 - val_loss: 0.3473 - val_accuracy: 0.8654 - val_auc: 0.9342\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3248 - accuracy: 0.8178 - auc: 0.9342 - val_loss: 0.3508 - val_accuracy: 0.8641 - val_auc: 0.9335\n",
      "Epoch 19/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8136 - auc: 0.9322Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3318 - accuracy: 0.8137 - auc: 0.9327 - val_loss: 0.3546 - val_accuracy: 0.8615 - val_auc: 0.9329\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.9612 - accuracy: 0.5190 - auc: 0.5816 - val_loss: 0.6953 - val_accuracy: 0.6018 - val_auc: 0.7525\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6921 - accuracy: 0.6038 - auc: 0.7426 - val_loss: 0.4926 - val_accuracy: 0.7199 - val_auc: 0.8710\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5498 - accuracy: 0.7547 - auc: 0.8246 - val_loss: 0.4192 - val_accuracy: 0.8216 - val_auc: 0.9138\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4833 - accuracy: 0.8204 - auc: 0.8624 - val_loss: 0.3760 - val_accuracy: 0.8540 - val_auc: 0.9247\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4403 - accuracy: 0.8477 - auc: 0.8865 - val_loss: 0.3497 - val_accuracy: 0.8750 - val_auc: 0.9329\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4051 - accuracy: 0.8647 - auc: 0.9016 - val_loss: 0.3321 - val_accuracy: 0.8809 - val_auc: 0.9366\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3828 - accuracy: 0.8733 - auc: 0.9121 - val_loss: 0.3219 - val_accuracy: 0.8910 - val_auc: 0.9375\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3947 - accuracy: 0.8764 - auc: 0.9064 - val_loss: 0.3208 - val_accuracy: 0.8865 - val_auc: 0.9365\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3771 - accuracy: 0.8772 - auc: 0.9137 - val_loss: 0.3191 - val_accuracy: 0.8886 - val_auc: 0.9363\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3582 - accuracy: 0.8811 - auc: 0.9252 - val_loss: 0.3146 - val_accuracy: 0.8855 - val_auc: 0.9377\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3557 - accuracy: 0.8787 - auc: 0.9249 - val_loss: 0.3097 - val_accuracy: 0.8919 - val_auc: 0.9397\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3536 - accuracy: 0.8819 - auc: 0.9270 - val_loss: 0.3093 - val_accuracy: 0.8947 - val_auc: 0.9401\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3511 - accuracy: 0.8844 - auc: 0.9274 - val_loss: 0.3067 - val_accuracy: 0.8921 - val_auc: 0.9414\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3345 - accuracy: 0.8850 - auc: 0.9350 - val_loss: 0.3098 - val_accuracy: 0.8917 - val_auc: 0.9397\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3310 - accuracy: 0.8841 - auc: 0.9347 - val_loss: 0.3095 - val_accuracy: 0.8882 - val_auc: 0.9401\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3283 - accuracy: 0.8833 - auc: 0.9356 - val_loss: 0.3111 - val_accuracy: 0.8900 - val_auc: 0.9395\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3235 - accuracy: 0.8846 - auc: 0.9379 - val_loss: 0.3106 - val_accuracy: 0.8915 - val_auc: 0.9401\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3252 - accuracy: 0.8883 - auc: 0.9376 - val_loss: 0.3119 - val_accuracy: 0.8891 - val_auc: 0.9397\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3212 - accuracy: 0.8827 - auc: 0.9392 - val_loss: 0.3176 - val_accuracy: 0.8922 - val_auc: 0.9384\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3235 - accuracy: 0.8856 - auc: 0.9377 - val_loss: 0.3156 - val_accuracy: 0.8885 - val_auc: 0.9393\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3168 - accuracy: 0.8830 - auc: 0.9406 - val_loss: 0.3173 - val_accuracy: 0.8878 - val_auc: 0.9388\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3148 - accuracy: 0.8848 - auc: 0.9419 - val_loss: 0.3180 - val_accuracy: 0.8885 - val_auc: 0.9392\n",
      "Epoch 23/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.3103 - accuracy: 0.8849 - auc: 0.9427Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3099 - accuracy: 0.8849 - auc: 0.9432 - val_loss: 0.3209 - val_accuracy: 0.8881 - val_auc: 0.9382\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 1.0046 - accuracy: 0.4609 - auc: 0.5437 - val_loss: 0.7187 - val_accuracy: 0.5552 - val_auc: 0.7843\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6905 - accuracy: 0.5334 - auc: 0.7578 - val_loss: 0.5553 - val_accuracy: 0.7052 - val_auc: 0.8590\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5436 - accuracy: 0.6725 - auc: 0.8391 - val_loss: 0.4552 - val_accuracy: 0.7908 - val_auc: 0.9069\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4841 - accuracy: 0.7792 - auc: 0.8639 - val_loss: 0.4067 - val_accuracy: 0.8279 - val_auc: 0.9247\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4388 - accuracy: 0.8182 - auc: 0.8966 - val_loss: 0.3785 - val_accuracy: 0.8502 - val_auc: 0.9297\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4172 - accuracy: 0.8381 - auc: 0.9072 - val_loss: 0.3579 - val_accuracy: 0.8602 - val_auc: 0.9328\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4012 - accuracy: 0.8517 - auc: 0.9121 - val_loss: 0.3432 - val_accuracy: 0.8724 - val_auc: 0.9338\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3715 - accuracy: 0.8611 - auc: 0.9224 - val_loss: 0.3307 - val_accuracy: 0.8752 - val_auc: 0.9354\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3711 - accuracy: 0.8660 - auc: 0.9214 - val_loss: 0.3246 - val_accuracy: 0.8789 - val_auc: 0.9360\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3613 - accuracy: 0.8701 - auc: 0.9256 - val_loss: 0.3201 - val_accuracy: 0.8805 - val_auc: 0.9370\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3549 - accuracy: 0.8720 - auc: 0.9273 - val_loss: 0.3197 - val_accuracy: 0.8810 - val_auc: 0.9365\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3401 - accuracy: 0.8778 - auc: 0.9345 - val_loss: 0.3204 - val_accuracy: 0.8828 - val_auc: 0.9364\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3544 - accuracy: 0.8739 - auc: 0.9278 - val_loss: 0.3188 - val_accuracy: 0.8847 - val_auc: 0.9369\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3381 - accuracy: 0.8783 - auc: 0.9350 - val_loss: 0.3165 - val_accuracy: 0.8842 - val_auc: 0.9380\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3381 - accuracy: 0.8781 - auc: 0.9329 - val_loss: 0.3163 - val_accuracy: 0.8844 - val_auc: 0.9379\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3273 - accuracy: 0.8799 - auc: 0.9392 - val_loss: 0.3128 - val_accuracy: 0.8853 - val_auc: 0.9391\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3248 - accuracy: 0.8812 - auc: 0.9393 - val_loss: 0.3131 - val_accuracy: 0.8854 - val_auc: 0.9393\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3272 - accuracy: 0.8812 - auc: 0.9378 - val_loss: 0.3133 - val_accuracy: 0.8889 - val_auc: 0.9393\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3229 - accuracy: 0.8859 - auc: 0.9399 - val_loss: 0.3141 - val_accuracy: 0.8861 - val_auc: 0.9390\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3214 - accuracy: 0.8855 - auc: 0.9400 - val_loss: 0.3155 - val_accuracy: 0.8900 - val_auc: 0.9391\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3213 - accuracy: 0.8849 - auc: 0.9401 - val_loss: 0.3176 - val_accuracy: 0.8880 - val_auc: 0.9384\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3148 - accuracy: 0.8843 - auc: 0.9431 - val_loss: 0.3170 - val_accuracy: 0.8872 - val_auc: 0.9391\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3077 - accuracy: 0.8869 - auc: 0.9456 - val_loss: 0.3178 - val_accuracy: 0.8889 - val_auc: 0.9389\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3170 - accuracy: 0.8845 - auc: 0.9419 - val_loss: 0.3197 - val_accuracy: 0.8898 - val_auc: 0.9390\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3101 - accuracy: 0.8877 - auc: 0.9439 - val_loss: 0.3208 - val_accuracy: 0.8900 - val_auc: 0.9392\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2997 - accuracy: 0.8879 - auc: 0.9487 - val_loss: 0.3211 - val_accuracy: 0.8945 - val_auc: 0.9395\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3013 - accuracy: 0.8916 - auc: 0.9481 - val_loss: 0.3238 - val_accuracy: 0.8939 - val_auc: 0.9392\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3035 - accuracy: 0.8909 - auc: 0.9459 - val_loss: 0.3259 - val_accuracy: 0.8939 - val_auc: 0.9382\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3024 - accuracy: 0.8902 - auc: 0.9459 - val_loss: 0.3286 - val_accuracy: 0.8931 - val_auc: 0.9377\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2986 - accuracy: 0.8894 - auc: 0.9483 - val_loss: 0.3295 - val_accuracy: 0.8937 - val_auc: 0.9377\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3009 - accuracy: 0.8903 - auc: 0.9473 - val_loss: 0.3305 - val_accuracy: 0.8927 - val_auc: 0.9375\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3118 - accuracy: 0.8917 - auc: 0.9436 - val_loss: 0.3329 - val_accuracy: 0.8932 - val_auc: 0.9369\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3038 - accuracy: 0.8917 - auc: 0.9452 - val_loss: 0.3395 - val_accuracy: 0.8928 - val_auc: 0.9344\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3038 - accuracy: 0.8900 - auc: 0.9461 - val_loss: 0.3377 - val_accuracy: 0.8916 - val_auc: 0.9357\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2920 - accuracy: 0.8888 - auc: 0.9505 - val_loss: 0.3465 - val_accuracy: 0.8938 - val_auc: 0.9339\n",
      "Epoch 36/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2869 - accuracy: 0.8900 - auc: 0.9520Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2868 - accuracy: 0.8900 - auc: 0.9520 - val_loss: 0.3423 - val_accuracy: 0.8925 - val_auc: 0.9361\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 1.1119 - accuracy: 0.7534 - auc: 0.6012 - val_loss: 0.6210 - val_accuracy: 0.7695 - val_auc: 0.8025\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6415 - accuracy: 0.7420 - auc: 0.8053 - val_loss: 0.4457 - val_accuracy: 0.8070 - val_auc: 0.8938\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4963 - accuracy: 0.7918 - auc: 0.8674 - val_loss: 0.3979 - val_accuracy: 0.8424 - val_auc: 0.9130\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4288 - accuracy: 0.8291 - auc: 0.9039 - val_loss: 0.3815 - val_accuracy: 0.8619 - val_auc: 0.9168\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3937 - accuracy: 0.8499 - auc: 0.9153 - val_loss: 0.3754 - val_accuracy: 0.8761 - val_auc: 0.9192\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3907 - accuracy: 0.8618 - auc: 0.9146 - val_loss: 0.3723 - val_accuracy: 0.8823 - val_auc: 0.9200\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3664 - accuracy: 0.8682 - auc: 0.9285 - val_loss: 0.3710 - val_accuracy: 0.8861 - val_auc: 0.9203\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3613 - accuracy: 0.8749 - auc: 0.9269 - val_loss: 0.3555 - val_accuracy: 0.8902 - val_auc: 0.9242\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3452 - accuracy: 0.8787 - auc: 0.9325 - val_loss: 0.3656 - val_accuracy: 0.8872 - val_auc: 0.9226\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3294 - accuracy: 0.8805 - auc: 0.9372 - val_loss: 0.3651 - val_accuracy: 0.8870 - val_auc: 0.9234\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3159 - accuracy: 0.8816 - auc: 0.9430 - val_loss: 0.3662 - val_accuracy: 0.8923 - val_auc: 0.9252\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3148 - accuracy: 0.8836 - auc: 0.9425 - val_loss: 0.3679 - val_accuracy: 0.8930 - val_auc: 0.9255\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3152 - accuracy: 0.8873 - auc: 0.9436 - val_loss: 0.3689 - val_accuracy: 0.8917 - val_auc: 0.9275\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3112 - accuracy: 0.8867 - auc: 0.9447 - val_loss: 0.3624 - val_accuracy: 0.8923 - val_auc: 0.9289\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3015 - accuracy: 0.8864 - auc: 0.9474 - val_loss: 0.3641 - val_accuracy: 0.8923 - val_auc: 0.9287\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3044 - accuracy: 0.8887 - auc: 0.9459 - val_loss: 0.3687 - val_accuracy: 0.8938 - val_auc: 0.9288\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2915 - accuracy: 0.8868 - auc: 0.9507 - val_loss: 0.3713 - val_accuracy: 0.8934 - val_auc: 0.9281\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2879 - accuracy: 0.8919 - auc: 0.9522 - val_loss: 0.3778 - val_accuracy: 0.8952 - val_auc: 0.9266\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2935 - accuracy: 0.8889 - auc: 0.9513 - val_loss: 0.3704 - val_accuracy: 0.8938 - val_auc: 0.9294\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2816 - accuracy: 0.8916 - auc: 0.9537 - val_loss: 0.3695 - val_accuracy: 0.8970 - val_auc: 0.9304\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2842 - accuracy: 0.8916 - auc: 0.9529 - val_loss: 0.3763 - val_accuracy: 0.8972 - val_auc: 0.9292\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2840 - accuracy: 0.8916 - auc: 0.9530 - val_loss: 0.3819 - val_accuracy: 0.9004 - val_auc: 0.9287\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2823 - accuracy: 0.8927 - auc: 0.9534 - val_loss: 0.3918 - val_accuracy: 0.8988 - val_auc: 0.9284\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2767 - accuracy: 0.8928 - auc: 0.9555 - val_loss: 0.3910 - val_accuracy: 0.8968 - val_auc: 0.9281\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2789 - accuracy: 0.8913 - auc: 0.9547 - val_loss: 0.4009 - val_accuracy: 0.8960 - val_auc: 0.9261\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2669 - accuracy: 0.8905 - auc: 0.9581 - val_loss: 0.4003 - val_accuracy: 0.9004 - val_auc: 0.9277\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2805 - accuracy: 0.8915 - auc: 0.9538 - val_loss: 0.4000 - val_accuracy: 0.9010 - val_auc: 0.9281\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2726 - accuracy: 0.8945 - auc: 0.9563 - val_loss: 0.4113 - val_accuracy: 0.8971 - val_auc: 0.9271\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2735 - accuracy: 0.8930 - auc: 0.9557 - val_loss: 0.4182 - val_accuracy: 0.8975 - val_auc: 0.9258\n",
      "Epoch 30/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.8919 - auc: 0.9591Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2649 - accuracy: 0.8918 - auc: 0.9588 - val_loss: 0.4150 - val_accuracy: 0.8997 - val_auc: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.7470 - accuracy: 0.6532 - auc: 0.6875 - val_loss: 0.4301 - val_accuracy: 0.7643 - val_auc: 0.9164\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4808 - accuracy: 0.7777 - auc: 0.8703 - val_loss: 0.3617 - val_accuracy: 0.8473 - val_auc: 0.9375\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4265 - accuracy: 0.8361 - auc: 0.8988 - val_loss: 0.3391 - val_accuracy: 0.8764 - val_auc: 0.9412\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3767 - accuracy: 0.8692 - auc: 0.9208 - val_loss: 0.3278 - val_accuracy: 0.8808 - val_auc: 0.9418\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3707 - accuracy: 0.8707 - auc: 0.9231 - val_loss: 0.3270 - val_accuracy: 0.8833 - val_auc: 0.9389\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3614 - accuracy: 0.8769 - auc: 0.9232 - val_loss: 0.3300 - val_accuracy: 0.8932 - val_auc: 0.9381\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3375 - accuracy: 0.8867 - auc: 0.9351 - val_loss: 0.3250 - val_accuracy: 0.8940 - val_auc: 0.9382\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3369 - accuracy: 0.8876 - auc: 0.9338 - val_loss: 0.3223 - val_accuracy: 0.8947 - val_auc: 0.9382\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3319 - accuracy: 0.8918 - auc: 0.9370 - val_loss: 0.3228 - val_accuracy: 0.8908 - val_auc: 0.9387\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3205 - accuracy: 0.8913 - auc: 0.9416 - val_loss: 0.3259 - val_accuracy: 0.8916 - val_auc: 0.9380\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3122 - accuracy: 0.8912 - auc: 0.9449 - val_loss: 0.3263 - val_accuracy: 0.9017 - val_auc: 0.9371\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3137 - accuracy: 0.8986 - auc: 0.9434 - val_loss: 0.3310 - val_accuracy: 0.8977 - val_auc: 0.9352\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3102 - accuracy: 0.8946 - auc: 0.9459 - val_loss: 0.3320 - val_accuracy: 0.9009 - val_auc: 0.9350\n",
      "Epoch 14/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.8976 - auc: 0.9492Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2984 - accuracy: 0.8976 - auc: 0.9493 - val_loss: 0.3322 - val_accuracy: 0.8996 - val_auc: 0.9352\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6729 - accuracy: 0.6434 - auc: 0.7325 - val_loss: 0.4327 - val_accuracy: 0.8211 - val_auc: 0.8993\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5050 - accuracy: 0.8039 - auc: 0.8393 - val_loss: 0.3761 - val_accuracy: 0.8724 - val_auc: 0.9234\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4236 - accuracy: 0.8477 - auc: 0.8945 - val_loss: 0.3466 - val_accuracy: 0.8796 - val_auc: 0.9319\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3869 - accuracy: 0.8608 - auc: 0.9130 - val_loss: 0.3306 - val_accuracy: 0.8883 - val_auc: 0.9360\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3636 - accuracy: 0.8769 - auc: 0.9213 - val_loss: 0.3231 - val_accuracy: 0.8934 - val_auc: 0.9366\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3600 - accuracy: 0.8780 - auc: 0.9235 - val_loss: 0.3182 - val_accuracy: 0.8890 - val_auc: 0.9379\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3386 - accuracy: 0.8797 - auc: 0.9341 - val_loss: 0.3158 - val_accuracy: 0.8987 - val_auc: 0.9377\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3221 - accuracy: 0.8881 - auc: 0.9408 - val_loss: 0.3145 - val_accuracy: 0.8922 - val_auc: 0.9378\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3204 - accuracy: 0.8873 - auc: 0.9394 - val_loss: 0.3143 - val_accuracy: 0.8927 - val_auc: 0.9375\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3165 - accuracy: 0.8890 - auc: 0.9411 - val_loss: 0.3161 - val_accuracy: 0.8920 - val_auc: 0.9373\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3036 - accuracy: 0.8913 - auc: 0.9460 - val_loss: 0.3193 - val_accuracy: 0.8922 - val_auc: 0.9359\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3210 - accuracy: 0.8885 - auc: 0.9406 - val_loss: 0.3210 - val_accuracy: 0.8903 - val_auc: 0.9353\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3018 - accuracy: 0.8894 - auc: 0.9463 - val_loss: 0.3231 - val_accuracy: 0.8921 - val_auc: 0.9347\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3101 - accuracy: 0.8897 - auc: 0.9429 - val_loss: 0.3272 - val_accuracy: 0.8973 - val_auc: 0.9332\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2997 - accuracy: 0.8903 - auc: 0.9467 - val_loss: 0.3278 - val_accuracy: 0.8977 - val_auc: 0.9329\n",
      "Epoch 16/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2926 - accuracy: 0.8932 - auc: 0.9497Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2921 - accuracy: 0.8932 - auc: 0.9498 - val_loss: 0.3300 - val_accuracy: 0.8954 - val_auc: 0.9334\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.8936 - accuracy: 0.1876 - auc: 0.7103 - val_loss: 0.5452 - val_accuracy: 0.3310 - val_auc: 0.9153\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5767 - accuracy: 0.4933 - auc: 0.8515 - val_loss: 0.3946 - val_accuracy: 0.7290 - val_auc: 0.9373\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4622 - accuracy: 0.6694 - auc: 0.8864 - val_loss: 0.3344 - val_accuracy: 0.8246 - val_auc: 0.9445\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4052 - accuracy: 0.7386 - auc: 0.9094 - val_loss: 0.3104 - val_accuracy: 0.8558 - val_auc: 0.9458\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3736 - accuracy: 0.7774 - auc: 0.9206 - val_loss: 0.3010 - val_accuracy: 0.8669 - val_auc: 0.9472\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3477 - accuracy: 0.7956 - auc: 0.9326 - val_loss: 0.2979 - val_accuracy: 0.8810 - val_auc: 0.9470\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3449 - accuracy: 0.8113 - auc: 0.9316 - val_loss: 0.2950 - val_accuracy: 0.8768 - val_auc: 0.9476\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3278 - accuracy: 0.8175 - auc: 0.9380 - val_loss: 0.2975 - val_accuracy: 0.8791 - val_auc: 0.9463\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3314 - accuracy: 0.8225 - auc: 0.9358 - val_loss: 0.2987 - val_accuracy: 0.8807 - val_auc: 0.9459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3129 - accuracy: 0.8260 - auc: 0.9435 - val_loss: 0.3014 - val_accuracy: 0.8824 - val_auc: 0.9451\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3263 - accuracy: 0.8246 - auc: 0.9386 - val_loss: 0.3011 - val_accuracy: 0.8850 - val_auc: 0.9454\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3008 - accuracy: 0.8352 - auc: 0.9471 - val_loss: 0.3068 - val_accuracy: 0.8851 - val_auc: 0.9436\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3043 - accuracy: 0.8368 - auc: 0.9453 - val_loss: 0.3054 - val_accuracy: 0.8836 - val_auc: 0.9442\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3029 - accuracy: 0.8360 - auc: 0.9467 - val_loss: 0.3071 - val_accuracy: 0.8797 - val_auc: 0.9437\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2966 - accuracy: 0.8339 - auc: 0.9481 - val_loss: 0.3089 - val_accuracy: 0.8820 - val_auc: 0.9435\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2976 - accuracy: 0.8414 - auc: 0.9477 - val_loss: 0.3095 - val_accuracy: 0.8816 - val_auc: 0.9431\n",
      "Epoch 17/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.8411 - auc: 0.9511Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2883 - accuracy: 0.8410 - auc: 0.9514 - val_loss: 0.3101 - val_accuracy: 0.8808 - val_auc: 0.9435\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.8830 - accuracy: 0.6510 - auc: 0.6001 - val_loss: 0.5632 - val_accuracy: 0.6993 - val_auc: 0.8596\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5590 - accuracy: 0.7092 - auc: 0.8229 - val_loss: 0.4377 - val_accuracy: 0.7970 - val_auc: 0.9145\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4697 - accuracy: 0.7778 - auc: 0.8780 - val_loss: 0.3877 - val_accuracy: 0.8394 - val_auc: 0.9257\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4214 - accuracy: 0.8241 - auc: 0.9013 - val_loss: 0.3624 - val_accuracy: 0.8646 - val_auc: 0.9322\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3977 - accuracy: 0.8427 - auc: 0.9133 - val_loss: 0.3384 - val_accuracy: 0.8739 - val_auc: 0.9368\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3683 - accuracy: 0.8607 - auc: 0.9231 - val_loss: 0.3322 - val_accuracy: 0.8789 - val_auc: 0.9369\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3565 - accuracy: 0.8671 - auc: 0.9292 - val_loss: 0.3260 - val_accuracy: 0.8819 - val_auc: 0.9377\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3353 - accuracy: 0.8719 - auc: 0.9361 - val_loss: 0.3253 - val_accuracy: 0.8809 - val_auc: 0.9377\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3369 - accuracy: 0.8721 - auc: 0.9355 - val_loss: 0.3284 - val_accuracy: 0.8856 - val_auc: 0.9370\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3261 - accuracy: 0.8743 - auc: 0.9393 - val_loss: 0.3281 - val_accuracy: 0.8850 - val_auc: 0.9372\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3275 - accuracy: 0.8783 - auc: 0.9383 - val_loss: 0.3261 - val_accuracy: 0.8843 - val_auc: 0.9370\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3179 - accuracy: 0.8795 - auc: 0.9420 - val_loss: 0.3247 - val_accuracy: 0.8879 - val_auc: 0.9372\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3003 - accuracy: 0.8826 - auc: 0.9481 - val_loss: 0.3279 - val_accuracy: 0.8882 - val_auc: 0.9363\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2988 - accuracy: 0.8832 - auc: 0.9483 - val_loss: 0.3281 - val_accuracy: 0.8879 - val_auc: 0.9359\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3091 - accuracy: 0.8798 - auc: 0.9444 - val_loss: 0.3304 - val_accuracy: 0.8899 - val_auc: 0.9360\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2975 - accuracy: 0.8829 - auc: 0.9487 - val_loss: 0.3334 - val_accuracy: 0.8920 - val_auc: 0.9359\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3001 - accuracy: 0.8829 - auc: 0.9477 - val_loss: 0.3378 - val_accuracy: 0.8920 - val_auc: 0.9350\n",
      "Epoch 18/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.3008 - accuracy: 0.8822 - auc: 0.9470Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3007 - accuracy: 0.8822 - auc: 0.9471 - val_loss: 0.3377 - val_accuracy: 0.8907 - val_auc: 0.9346\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.8820 - accuracy: 0.1870 - auc: 0.6919 - val_loss: 0.5371 - val_accuracy: 0.4121 - val_auc: 0.8871\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5326 - accuracy: 0.5831 - auc: 0.8591 - val_loss: 0.3664 - val_accuracy: 0.8044 - val_auc: 0.9320\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4394 - accuracy: 0.7385 - auc: 0.8998 - val_loss: 0.3233 - val_accuracy: 0.8468 - val_auc: 0.9403\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3721 - accuracy: 0.7865 - auc: 0.9217 - val_loss: 0.3140 - val_accuracy: 0.8669 - val_auc: 0.9404\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3626 - accuracy: 0.8119 - auc: 0.9250 - val_loss: 0.3092 - val_accuracy: 0.8635 - val_auc: 0.9422\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3475 - accuracy: 0.8170 - auc: 0.9307 - val_loss: 0.3138 - val_accuracy: 0.8710 - val_auc: 0.9402\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3321 - accuracy: 0.8248 - auc: 0.9365 - val_loss: 0.3175 - val_accuracy: 0.8754 - val_auc: 0.9393\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3255 - accuracy: 0.8328 - auc: 0.9386 - val_loss: 0.3201 - val_accuracy: 0.8748 - val_auc: 0.9388\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3258 - accuracy: 0.8368 - auc: 0.9405 - val_loss: 0.3257 - val_accuracy: 0.8726 - val_auc: 0.9380\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3131 - accuracy: 0.8409 - auc: 0.9433 - val_loss: 0.3266 - val_accuracy: 0.8749 - val_auc: 0.9385\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2993 - accuracy: 0.8422 - auc: 0.9476 - val_loss: 0.3391 - val_accuracy: 0.8791 - val_auc: 0.9353\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3055 - accuracy: 0.8436 - auc: 0.9471 - val_loss: 0.3377 - val_accuracy: 0.8794 - val_auc: 0.9367\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2964 - accuracy: 0.8484 - auc: 0.9489 - val_loss: 0.3488 - val_accuracy: 0.8775 - val_auc: 0.9345\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2875 - accuracy: 0.8467 - auc: 0.9511 - val_loss: 0.3530 - val_accuracy: 0.8788 - val_auc: 0.9337\n",
      "Epoch 15/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.8523 - auc: 0.9521Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2874 - accuracy: 0.8523 - auc: 0.9521 - val_loss: 0.3595 - val_accuracy: 0.8840 - val_auc: 0.9328\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 6s 24us/sample - loss: 0.8694 - accuracy: 0.2717 - auc: 0.7151 - val_loss: 0.4822 - val_accuracy: 0.5433 - val_auc: 0.9214\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5277 - accuracy: 0.6424 - auc: 0.8661 - val_loss: 0.3537 - val_accuracy: 0.8106 - val_auc: 0.9388\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4533 - accuracy: 0.7523 - auc: 0.8943 - val_loss: 0.3207 - val_accuracy: 0.8514 - val_auc: 0.9436\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3905 - accuracy: 0.8043 - auc: 0.9144 - val_loss: 0.3095 - val_accuracy: 0.8684 - val_auc: 0.9443\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3707 - accuracy: 0.8172 - auc: 0.9219 - val_loss: 0.3099 - val_accuracy: 0.8669 - val_auc: 0.9430\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3556 - accuracy: 0.8256 - auc: 0.9273 - val_loss: 0.3121 - val_accuracy: 0.8701 - val_auc: 0.9421\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3422 - accuracy: 0.8252 - auc: 0.9333 - val_loss: 0.3123 - val_accuracy: 0.8724 - val_auc: 0.9423\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3242 - accuracy: 0.8397 - auc: 0.9384 - val_loss: 0.3154 - val_accuracy: 0.8731 - val_auc: 0.9411\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3257 - accuracy: 0.8459 - auc: 0.9412 - val_loss: 0.3165 - val_accuracy: 0.8746 - val_auc: 0.9411\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3119 - accuracy: 0.8427 - auc: 0.9433 - val_loss: 0.3172 - val_accuracy: 0.8789 - val_auc: 0.9410\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2977 - accuracy: 0.8500 - auc: 0.9476 - val_loss: 0.3189 - val_accuracy: 0.8824 - val_auc: 0.9410\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2978 - accuracy: 0.8529 - auc: 0.9474 - val_loss: 0.3197 - val_accuracy: 0.8858 - val_auc: 0.9413\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3008 - accuracy: 0.8561 - auc: 0.9466 - val_loss: 0.3270 - val_accuracy: 0.8772 - val_auc: 0.9389\n",
      "Epoch 14/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.8501 - auc: 0.9473Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2988 - accuracy: 0.8501 - auc: 0.9473 - val_loss: 0.3284 - val_accuracy: 0.8766 - val_auc: 0.9388\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.8385 - accuracy: 0.9486 - auc: 0.5103 - val_loss: 0.7758 - val_accuracy: 0.9285 - val_auc: 0.8399\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6824 - accuracy: 0.8633 - auc: 0.7839 - val_loss: 0.5819 - val_accuracy: 0.8800 - val_auc: 0.8891\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5317 - accuracy: 0.8490 - auc: 0.8446 - val_loss: 0.4955 - val_accuracy: 0.8813 - val_auc: 0.9056\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4691 - accuracy: 0.8637 - auc: 0.8763 - val_loss: 0.4432 - val_accuracy: 0.8857 - val_auc: 0.9157\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4260 - accuracy: 0.8714 - auc: 0.8973 - val_loss: 0.4046 - val_accuracy: 0.8878 - val_auc: 0.9219\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3884 - accuracy: 0.8803 - auc: 0.9138 - val_loss: 0.3754 - val_accuracy: 0.8909 - val_auc: 0.9259\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3770 - accuracy: 0.8836 - auc: 0.9206 - val_loss: 0.3601 - val_accuracy: 0.8942 - val_auc: 0.9287\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3538 - accuracy: 0.8867 - auc: 0.9305 - val_loss: 0.3546 - val_accuracy: 0.8994 - val_auc: 0.9299\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3540 - accuracy: 0.8904 - auc: 0.9288 - val_loss: 0.3487 - val_accuracy: 0.8985 - val_auc: 0.9323\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3412 - accuracy: 0.8927 - auc: 0.9334 - val_loss: 0.3400 - val_accuracy: 0.8995 - val_auc: 0.9334\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3347 - accuracy: 0.8940 - auc: 0.9361 - val_loss: 0.3369 - val_accuracy: 0.8990 - val_auc: 0.9315\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3215 - accuracy: 0.8939 - auc: 0.9419 - val_loss: 0.3329 - val_accuracy: 0.8996 - val_auc: 0.9317\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3136 - accuracy: 0.8936 - auc: 0.9441 - val_loss: 0.3361 - val_accuracy: 0.9007 - val_auc: 0.9317\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3160 - accuracy: 0.8981 - auc: 0.9428 - val_loss: 0.3512 - val_accuracy: 0.9005 - val_auc: 0.9324\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3124 - accuracy: 0.8953 - auc: 0.9440 - val_loss: 0.3580 - val_accuracy: 0.9006 - val_auc: 0.9313\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3004 - accuracy: 0.8973 - auc: 0.9478 - val_loss: 0.3535 - val_accuracy: 0.9038 - val_auc: 0.9316\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2984 - accuracy: 0.8983 - auc: 0.9490 - val_loss: 0.3489 - val_accuracy: 0.9043 - val_auc: 0.9325\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2929 - accuracy: 0.8975 - auc: 0.9506 - val_loss: 0.3526 - val_accuracy: 0.9048 - val_auc: 0.9323\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2974 - accuracy: 0.8982 - auc: 0.9486 - val_loss: 0.3569 - val_accuracy: 0.9019 - val_auc: 0.9329\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2849 - accuracy: 0.8973 - auc: 0.9528 - val_loss: 0.3560 - val_accuracy: 0.9061 - val_auc: 0.9335\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2844 - accuracy: 0.9000 - auc: 0.9527 - val_loss: 0.3612 - val_accuracy: 0.9059 - val_auc: 0.9320\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2789 - accuracy: 0.9021 - auc: 0.9543 - val_loss: 0.3603 - val_accuracy: 0.9044 - val_auc: 0.9319\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2683 - accuracy: 0.9000 - auc: 0.9571 - val_loss: 0.3650 - val_accuracy: 0.9072 - val_auc: 0.9312\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2715 - accuracy: 0.9029 - auc: 0.9562 - val_loss: 0.3782 - val_accuracy: 0.9038 - val_auc: 0.9313\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2685 - accuracy: 0.8983 - auc: 0.9572 - val_loss: 0.3758 - val_accuracy: 0.9084 - val_auc: 0.9312\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2717 - accuracy: 0.9048 - auc: 0.9561 - val_loss: 0.3809 - val_accuracy: 0.9033 - val_auc: 0.9313\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2741 - accuracy: 0.8995 - auc: 0.9551 - val_loss: 0.3832 - val_accuracy: 0.9008 - val_auc: 0.9308\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2636 - accuracy: 0.9001 - auc: 0.9582 - val_loss: 0.3859 - val_accuracy: 0.9068 - val_auc: 0.9312\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2631 - accuracy: 0.9016 - auc: 0.9583 - val_loss: 0.3881 - val_accuracy: 0.9046 - val_auc: 0.9307\n",
      "Epoch 30/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2588 - accuracy: 0.9016 - auc: 0.9599Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2567 - accuracy: 0.9016 - auc: 0.9602 - val_loss: 0.3977 - val_accuracy: 0.9041 - val_auc: 0.9303\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.9061 - accuracy: 0.2219 - auc: 0.6173 - val_loss: 0.5580 - val_accuracy: 0.3716 - val_auc: 0.8809\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5699 - accuracy: 0.5361 - auc: 0.8364 - val_loss: 0.3969 - val_accuracy: 0.7357 - val_auc: 0.9301\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4451 - accuracy: 0.7135 - auc: 0.8916 - val_loss: 0.3414 - val_accuracy: 0.8356 - val_auc: 0.9377\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3951 - accuracy: 0.7860 - auc: 0.9088 - val_loss: 0.3220 - val_accuracy: 0.8590 - val_auc: 0.9417\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3904 - accuracy: 0.8044 - auc: 0.9150 - val_loss: 0.3153 - val_accuracy: 0.8699 - val_auc: 0.9431\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3535 - accuracy: 0.8239 - auc: 0.9263 - val_loss: 0.3187 - val_accuracy: 0.8770 - val_auc: 0.9423\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3372 - accuracy: 0.8347 - auc: 0.9324 - val_loss: 0.3134 - val_accuracy: 0.8790 - val_auc: 0.9434\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3314 - accuracy: 0.8395 - auc: 0.9356 - val_loss: 0.3160 - val_accuracy: 0.8776 - val_auc: 0.9435\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3183 - accuracy: 0.8436 - auc: 0.9397 - val_loss: 0.3148 - val_accuracy: 0.8810 - val_auc: 0.9429\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3022 - accuracy: 0.8560 - auc: 0.9454 - val_loss: 0.3200 - val_accuracy: 0.8841 - val_auc: 0.9419\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3034 - accuracy: 0.8550 - auc: 0.9446 - val_loss: 0.3225 - val_accuracy: 0.8807 - val_auc: 0.9411\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2926 - accuracy: 0.8557 - auc: 0.9488 - val_loss: 0.3246 - val_accuracy: 0.8838 - val_auc: 0.9402\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2864 - accuracy: 0.8596 - auc: 0.9507 - val_loss: 0.3265 - val_accuracy: 0.8869 - val_auc: 0.9398\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2850 - accuracy: 0.8632 - auc: 0.9518 - val_loss: 0.3314 - val_accuracy: 0.8886 - val_auc: 0.9393\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2908 - accuracy: 0.8644 - auc: 0.9492 - val_loss: 0.3312 - val_accuracy: 0.8876 - val_auc: 0.9393\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2845 - accuracy: 0.8604 - auc: 0.9511 - val_loss: 0.3343 - val_accuracy: 0.8865 - val_auc: 0.9393\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2757 - accuracy: 0.8644 - auc: 0.9543 - val_loss: 0.3419 - val_accuracy: 0.8877 - val_auc: 0.9377\n",
      "Epoch 18/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.8687 - auc: 0.9566Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2688 - accuracy: 0.8687 - auc: 0.9561 - val_loss: 0.3438 - val_accuracy: 0.8902 - val_auc: 0.9381\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.7572 - accuracy: 0.5122 - auc: 0.7230 - val_loss: 0.4461 - val_accuracy: 0.7180 - val_auc: 0.9053\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4971 - accuracy: 0.7254 - auc: 0.8649 - val_loss: 0.3663 - val_accuracy: 0.8340 - val_auc: 0.9277\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4259 - accuracy: 0.7990 - auc: 0.8972 - val_loss: 0.3354 - val_accuracy: 0.8673 - val_auc: 0.9343\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3945 - accuracy: 0.8355 - auc: 0.9099 - val_loss: 0.3261 - val_accuracy: 0.8719 - val_auc: 0.9352\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3728 - accuracy: 0.8397 - auc: 0.9193 - val_loss: 0.3240 - val_accuracy: 0.8711 - val_auc: 0.9358\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3450 - accuracy: 0.8476 - auc: 0.9305 - val_loss: 0.3214 - val_accuracy: 0.8758 - val_auc: 0.9354\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3439 - accuracy: 0.8556 - auc: 0.9321 - val_loss: 0.3166 - val_accuracy: 0.8813 - val_auc: 0.9365\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3318 - accuracy: 0.8563 - auc: 0.9356 - val_loss: 0.3226 - val_accuracy: 0.8753 - val_auc: 0.9356\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3112 - accuracy: 0.8627 - auc: 0.9433 - val_loss: 0.3239 - val_accuracy: 0.8824 - val_auc: 0.9355\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3202 - accuracy: 0.8623 - auc: 0.9400 - val_loss: 0.3272 - val_accuracy: 0.8818 - val_auc: 0.9350\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2974 - accuracy: 0.8689 - auc: 0.9478 - val_loss: 0.3287 - val_accuracy: 0.8865 - val_auc: 0.9353\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2995 - accuracy: 0.8710 - auc: 0.9467 - val_loss: 0.3289 - val_accuracy: 0.8840 - val_auc: 0.9354\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2901 - accuracy: 0.8747 - auc: 0.9506 - val_loss: 0.3310 - val_accuracy: 0.8857 - val_auc: 0.9353\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2917 - accuracy: 0.8727 - auc: 0.9505 - val_loss: 0.3301 - val_accuracy: 0.8890 - val_auc: 0.9358\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2806 - accuracy: 0.8752 - auc: 0.9533 - val_loss: 0.3342 - val_accuracy: 0.8884 - val_auc: 0.9352\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2799 - accuracy: 0.8762 - auc: 0.9534 - val_loss: 0.3406 - val_accuracy: 0.8881 - val_auc: 0.9348\n",
      "Epoch 17/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.8755 - auc: 0.9530Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2813 - accuracy: 0.8755 - auc: 0.9529 - val_loss: 0.3471 - val_accuracy: 0.8882 - val_auc: 0.9342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.6402 - accuracy: 0.8261 - auc: 0.7786 - val_loss: 0.4161 - val_accuracy: 0.8729 - val_auc: 0.9069\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4708 - accuracy: 0.8377 - auc: 0.8751 - val_loss: 0.3795 - val_accuracy: 0.8730 - val_auc: 0.9213\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4087 - accuracy: 0.8645 - auc: 0.9075 - val_loss: 0.3702 - val_accuracy: 0.8812 - val_auc: 0.9210\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3840 - accuracy: 0.8733 - auc: 0.9156 - val_loss: 0.3688 - val_accuracy: 0.8892 - val_auc: 0.9251\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3482 - accuracy: 0.8820 - auc: 0.9332 - val_loss: 0.3632 - val_accuracy: 0.8912 - val_auc: 0.9261\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3351 - accuracy: 0.8853 - auc: 0.9362 - val_loss: 0.3558 - val_accuracy: 0.8971 - val_auc: 0.9286\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3248 - accuracy: 0.8866 - auc: 0.9395 - val_loss: 0.3614 - val_accuracy: 0.8964 - val_auc: 0.9261\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3127 - accuracy: 0.8918 - auc: 0.9447 - val_loss: 0.3521 - val_accuracy: 0.9011 - val_auc: 0.9281\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3022 - accuracy: 0.8950 - auc: 0.9483 - val_loss: 0.3558 - val_accuracy: 0.9020 - val_auc: 0.9280\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3107 - accuracy: 0.8947 - auc: 0.9447 - val_loss: 0.3641 - val_accuracy: 0.8970 - val_auc: 0.9298\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3063 - accuracy: 0.8949 - auc: 0.9465 - val_loss: 0.3729 - val_accuracy: 0.8963 - val_auc: 0.9289\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2847 - accuracy: 0.8975 - auc: 0.9537 - val_loss: 0.3730 - val_accuracy: 0.9036 - val_auc: 0.9287\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2865 - accuracy: 0.8956 - auc: 0.9525 - val_loss: 0.3785 - val_accuracy: 0.9007 - val_auc: 0.9282\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2854 - accuracy: 0.8990 - auc: 0.9529 - val_loss: 0.3809 - val_accuracy: 0.9005 - val_auc: 0.9270\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2829 - accuracy: 0.8967 - auc: 0.9542 - val_loss: 0.3906 - val_accuracy: 0.9037 - val_auc: 0.9271\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2767 - accuracy: 0.8978 - auc: 0.9559 - val_loss: 0.3917 - val_accuracy: 0.9032 - val_auc: 0.9281\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2742 - accuracy: 0.8989 - auc: 0.9568 - val_loss: 0.3951 - val_accuracy: 0.9033 - val_auc: 0.9277\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2704 - accuracy: 0.9005 - auc: 0.9575 - val_loss: 0.4151 - val_accuracy: 0.8980 - val_auc: 0.9255\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2760 - accuracy: 0.8981 - auc: 0.9561 - val_loss: 0.4157 - val_accuracy: 0.9010 - val_auc: 0.9261\n",
      "Epoch 20/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2623 - accuracy: 0.9012 - auc: 0.9600Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2625 - accuracy: 0.9012 - auc: 0.9599 - val_loss: 0.4468 - val_accuracy: 0.9036 - val_auc: 0.9238\n",
      "Epoch 00020: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.6704 - accuracy: 0.5008 - auc: 0.7637 - val_loss: 0.4162 - val_accuracy: 0.7732 - val_auc: 0.9210\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4559 - accuracy: 0.7615 - auc: 0.8830 - val_loss: 0.3487 - val_accuracy: 0.8594 - val_auc: 0.9369\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3920 - accuracy: 0.8335 - auc: 0.9129 - val_loss: 0.3238 - val_accuracy: 0.8828 - val_auc: 0.9405ss:\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3709 - accuracy: 0.8535 - auc: 0.9201 - val_loss: 0.3170 - val_accuracy: 0.8784 - val_auc: 0.9419\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3307 - accuracy: 0.8640 - auc: 0.9365 - val_loss: 0.3121 - val_accuracy: 0.8824 - val_auc: 0.9427\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3341 - accuracy: 0.8697 - auc: 0.9352 - val_loss: 0.3135 - val_accuracy: 0.8880 - val_auc: 0.9417\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3026 - accuracy: 0.8761 - auc: 0.9474 - val_loss: 0.3128 - val_accuracy: 0.8942 - val_auc: 0.9419\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3050 - accuracy: 0.8787 - auc: 0.9442 - val_loss: 0.3134 - val_accuracy: 0.8920 - val_auc: 0.9417\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2846 - accuracy: 0.8751 - auc: 0.9530 - val_loss: 0.3126 - val_accuracy: 0.8935 - val_auc: 0.9418\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2861 - accuracy: 0.8807 - auc: 0.9513 - val_loss: 0.3156 - val_accuracy: 0.8926 - val_auc: 0.9414\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2862 - accuracy: 0.8808 - auc: 0.9511 - val_loss: 0.3181 - val_accuracy: 0.8912 - val_auc: 0.9413\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2817 - accuracy: 0.8829 - auc: 0.9526 - val_loss: 0.3185 - val_accuracy: 0.8917 - val_auc: 0.9411\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2872 - accuracy: 0.8779 - auc: 0.9508 - val_loss: 0.3170 - val_accuracy: 0.8934 - val_auc: 0.9416\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2776 - accuracy: 0.8823 - auc: 0.9538 - val_loss: 0.3286 - val_accuracy: 0.8944 - val_auc: 0.9383\n",
      "Epoch 15/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.8845 - auc: 0.9558Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2718 - accuracy: 0.8846 - auc: 0.9559 - val_loss: 0.3312 - val_accuracy: 0.8951 - val_auc: 0.9376\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 6s 24us/sample - loss: 0.7559 - accuracy: 0.8081 - auc: 0.7226 - val_loss: 0.4432 - val_accuracy: 0.8313 - val_auc: 0.9049\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4905 - accuracy: 0.8167 - auc: 0.8686 - val_loss: 0.3824 - val_accuracy: 0.8651 - val_auc: 0.9207\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4004 - accuracy: 0.8507 - auc: 0.9117 - val_loss: 0.3652 - val_accuracy: 0.8776 - val_auc: 0.9258\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3828 - accuracy: 0.8660 - auc: 0.9153 - val_loss: 0.3539 - val_accuracy: 0.8887 - val_auc: 0.9282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3582 - accuracy: 0.8767 - auc: 0.9252 - val_loss: 0.3487 - val_accuracy: 0.8913 - val_auc: 0.9306\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3387 - accuracy: 0.8817 - auc: 0.9331 - val_loss: 0.3424 - val_accuracy: 0.8939 - val_auc: 0.9326\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3351 - accuracy: 0.8822 - auc: 0.9346 - val_loss: 0.3411 - val_accuracy: 0.8931 - val_auc: 0.9333\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3188 - accuracy: 0.8818 - auc: 0.9408 - val_loss: 0.3533 - val_accuracy: 0.8980 - val_auc: 0.9314\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3058 - accuracy: 0.8882 - auc: 0.9457 - val_loss: 0.3528 - val_accuracy: 0.8995 - val_auc: 0.9314\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3015 - accuracy: 0.8938 - auc: 0.9463 - val_loss: 0.3615 - val_accuracy: 0.8921 - val_auc: 0.9309\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2948 - accuracy: 0.8898 - auc: 0.9482 - val_loss: 0.3640 - val_accuracy: 0.8977 - val_auc: 0.9305\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2973 - accuracy: 0.8913 - auc: 0.9476 - val_loss: 0.3633 - val_accuracy: 0.8983 - val_auc: 0.9315\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2842 - accuracy: 0.8924 - auc: 0.9523 - val_loss: 0.3628 - val_accuracy: 0.8985 - val_auc: 0.9311\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2779 - accuracy: 0.8944 - auc: 0.9542 - val_loss: 0.3680 - val_accuracy: 0.8987 - val_auc: 0.9304\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2805 - accuracy: 0.8924 - auc: 0.9531 - val_loss: 0.3681 - val_accuracy: 0.8946 - val_auc: 0.9307\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2734 - accuracy: 0.8940 - auc: 0.9556 - val_loss: 0.3727 - val_accuracy: 0.9006 - val_auc: 0.9300\n",
      "Epoch 17/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.8982 - auc: 0.9572Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2685 - accuracy: 0.8982 - auc: 0.9569 - val_loss: 0.3747 - val_accuracy: 0.9021 - val_auc: 0.9304\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 22us/sample - loss: 0.7776 - accuracy: 0.3996 - auc: 0.7186 - val_loss: 0.4363 - val_accuracy: 0.6744 - val_auc: 0.9229\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4899 - accuracy: 0.7043 - auc: 0.8707 - val_loss: 0.3521 - val_accuracy: 0.8240 - val_auc: 0.9351\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4003 - accuracy: 0.7931 - auc: 0.9147 - val_loss: 0.3278 - val_accuracy: 0.8694 - val_auc: 0.9367\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3603 - accuracy: 0.8282 - auc: 0.9249 - val_loss: 0.3206 - val_accuracy: 0.8826 - val_auc: 0.9379\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3506 - accuracy: 0.8454 - auc: 0.9284 - val_loss: 0.3182 - val_accuracy: 0.8873 - val_auc: 0.9397\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3264 - accuracy: 0.8580 - auc: 0.9366 - val_loss: 0.3241 - val_accuracy: 0.8846 - val_auc: 0.9395\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3231 - accuracy: 0.8589 - auc: 0.9381 - val_loss: 0.3250 - val_accuracy: 0.8869 - val_auc: 0.9385\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3107 - accuracy: 0.8630 - auc: 0.9422 - val_loss: 0.3304 - val_accuracy: 0.8824 - val_auc: 0.9374\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2954 - accuracy: 0.8624 - auc: 0.9495 - val_loss: 0.3294 - val_accuracy: 0.8920 - val_auc: 0.9374\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2813 - accuracy: 0.8710 - auc: 0.9527 - val_loss: 0.3361 - val_accuracy: 0.8962 - val_auc: 0.9373\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2869 - accuracy: 0.8755 - auc: 0.9501 - val_loss: 0.3437 - val_accuracy: 0.8914 - val_auc: 0.9366\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2821 - accuracy: 0.8724 - auc: 0.9521 - val_loss: 0.3475 - val_accuracy: 0.8927 - val_auc: 0.9360\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2701 - accuracy: 0.8763 - auc: 0.9560 - val_loss: 0.3494 - val_accuracy: 0.8963 - val_auc: 0.9353\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2648 - accuracy: 0.8795 - auc: 0.9574 - val_loss: 0.3512 - val_accuracy: 0.8957 - val_auc: 0.9358\n",
      "Epoch 15/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2626 - accuracy: 0.8758 - auc: 0.9583Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2618 - accuracy: 0.8758 - auc: 0.9584 - val_loss: 0.3553 - val_accuracy: 0.8947 - val_auc: 0.9362\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.6494 - accuracy: 0.6658 - auc: 0.7743 - val_loss: 0.4069 - val_accuracy: 0.7995 - val_auc: 0.9213\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4616 - accuracy: 0.8018 - auc: 0.8837 - val_loss: 0.3681 - val_accuracy: 0.8578 - val_auc: 0.9317\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3878 - accuracy: 0.8484 - auc: 0.9204 - val_loss: 0.3551 - val_accuracy: 0.8829 - val_auc: 0.9315\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3614 - accuracy: 0.8673 - auc: 0.9268 - val_loss: 0.3528 - val_accuracy: 0.8910 - val_auc: 0.9308\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3412 - accuracy: 0.8793 - auc: 0.9330 - val_loss: 0.3523 - val_accuracy: 0.8896 - val_auc: 0.9291\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3483 - accuracy: 0.8724 - auc: 0.9334 - val_loss: 0.3455 - val_accuracy: 0.8945 - val_auc: 0.9299\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3345 - accuracy: 0.8830 - auc: 0.9365 - val_loss: 0.3481 - val_accuracy: 0.8922 - val_auc: 0.9288\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3051 - accuracy: 0.8843 - auc: 0.9481 - val_loss: 0.3477 - val_accuracy: 0.8984 - val_auc: 0.9290\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2953 - accuracy: 0.8897 - auc: 0.9504 - val_loss: 0.3571 - val_accuracy: 0.8987 - val_auc: 0.9281\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3087 - accuracy: 0.8901 - auc: 0.9450 - val_loss: 0.3553 - val_accuracy: 0.8926 - val_auc: 0.9278\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2900 - accuracy: 0.8882 - auc: 0.9518 - val_loss: 0.3616 - val_accuracy: 0.9038 - val_auc: 0.9273\n",
      "Epoch 12/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2852 - accuracy: 0.8928 - auc: 0.9529Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2854 - accuracy: 0.8928 - auc: 0.9529 - val_loss: 0.3607 - val_accuracy: 0.8987 - val_auc: 0.9275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 6s 22us/sample - loss: 0.6561 - accuracy: 0.7393 - auc: 0.8116 - val_loss: 0.4115 - val_accuracy: 0.8693 - val_auc: 0.9276\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5710 - accuracy: 0.8731 - auc: 0.8557 - val_loss: 0.4462 - val_accuracy: 0.8707 - val_auc: 0.9272\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5931 - accuracy: 0.8617 - auc: 0.8641 - val_loss: 0.3894 - val_accuracy: 0.9229 - val_auc: 0.9338\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5148 - accuracy: 0.8898 - auc: 0.8818 - val_loss: 0.4470 - val_accuracy: 0.8591 - val_auc: 0.9150\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5486 - accuracy: 0.8838 - auc: 0.8576 - val_loss: 0.4245 - val_accuracy: 0.8806 - val_auc: 0.9221\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5080 - accuracy: 0.8917 - auc: 0.8726 - val_loss: 0.4310 - val_accuracy: 0.9271 - val_auc: 0.9200\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4676 - accuracy: 0.9064 - auc: 0.8755 - val_loss: 0.3768 - val_accuracy: 0.9250 - val_auc: 0.9275\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4667 - accuracy: 0.9079 - auc: 0.8769 - val_loss: 0.4468 - val_accuracy: 0.9428 - val_auc: 0.9182\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4534 - accuracy: 0.9157 - auc: 0.8789 - val_loss: 0.4535 - val_accuracy: 0.8654 - val_auc: 0.9221\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4548 - accuracy: 0.9026 - auc: 0.8792 - val_loss: 0.4251 - val_accuracy: 0.9216 - val_auc: 0.9248\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4399 - accuracy: 0.9146 - auc: 0.8903 - val_loss: 0.4011 - val_accuracy: 0.9084 - val_auc: 0.9368\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4343 - accuracy: 0.9184 - auc: 0.8945 - val_loss: 0.5476 - val_accuracy: 0.9136 - val_auc: 0.9143\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4868 - accuracy: 0.7686 - auc: 0.8470 - val_loss: 0.4420 - val_accuracy: 0.6890 - val_auc: 0.9301\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5285 - accuracy: 0.5277 - auc: 0.8168 - val_loss: 0.7661 - val_accuracy: 0.7132 - val_auc: 0.8762\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5187 - accuracy: 0.5323 - auc: 0.8242 - val_loss: 0.5412 - val_accuracy: 0.6940 - val_auc: 0.8868\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4683 - accuracy: 0.5446 - auc: 0.8313 - val_loss: 1.0343 - val_accuracy: 0.7261 - val_auc: 0.8828\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4698 - accuracy: 0.5449 - auc: 0.8554 - val_loss: 0.8308 - val_accuracy: 0.7370 - val_auc: 0.9226\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4403 - accuracy: 0.6195 - auc: 0.8631 - val_loss: 0.8849 - val_accuracy: 0.8741 - val_auc: 0.9229\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4363 - accuracy: 0.7672 - auc: 0.8690 - val_loss: 0.6782 - val_accuracy: 0.7015 - val_auc: 0.9271\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4244 - accuracy: 0.6261 - auc: 0.8709 - val_loss: 0.6827 - val_accuracy: 0.7058 - val_auc: 0.9262\n",
      "Epoch 21/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.4004 - accuracy: 0.6050 - auc: 0.8808Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4000 - accuracy: 0.6158 - auc: 0.8805 - val_loss: 0.6166 - val_accuracy: 0.8943 - val_auc: 0.9263\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6864 - accuracy: 0.7241 - auc: 0.8060 - val_loss: 0.4761 - val_accuracy: 0.8842 - val_auc: 0.9160\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6370 - accuracy: 0.8601 - auc: 0.8595 - val_loss: 0.4927 - val_accuracy: 0.9625 - val_auc: 0.9202\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5859 - accuracy: 0.8591 - auc: 0.8633 - val_loss: 0.5688 - val_accuracy: 0.9109 - val_auc: 0.9197\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5967 - accuracy: 0.8725 - auc: 0.8646 - val_loss: 0.4783 - val_accuracy: 0.8007 - val_auc: 0.9082\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4589 - accuracy: 0.9009 - auc: 0.8944 - val_loss: 0.5472 - val_accuracy: 0.8673 - val_auc: 0.9120\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4920 - accuracy: 0.8909 - auc: 0.8828 - val_loss: 0.5533 - val_accuracy: 0.8773 - val_auc: 0.9277\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5863 - accuracy: 0.8836 - auc: 0.8705 - val_loss: 0.7778 - val_accuracy: 0.8996 - val_auc: 0.9188\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4145 - accuracy: 0.9122 - auc: 0.8927 - val_loss: 0.8622 - val_accuracy: 0.8859 - val_auc: 0.9335\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4608 - accuracy: 0.8221 - auc: 0.8755 - val_loss: 0.8054 - val_accuracy: 0.8458 - val_auc: 0.9214\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5436 - accuracy: 0.8156 - auc: 0.8594 - val_loss: 0.9840 - val_accuracy: 0.6484 - val_auc: 0.9068\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4778 - accuracy: 0.5218 - auc: 0.8353 - val_loss: 0.7131 - val_accuracy: 0.6755 - val_auc: 0.9121\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4594 - accuracy: 0.5602 - auc: 0.8384 - val_loss: 0.7229 - val_accuracy: 0.6998 - val_auc: 0.9245\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4373 - accuracy: 0.5737 - auc: 0.8403 - val_loss: 0.8369 - val_accuracy: 0.7114 - val_auc: 0.9232\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4404 - accuracy: 0.5637 - auc: 0.8484 - val_loss: 0.7735 - val_accuracy: 0.7154 - val_auc: 0.9221\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4372 - accuracy: 0.5765 - auc: 0.8492 - val_loss: 0.7948 - val_accuracy: 0.6930 - val_auc: 0.9245\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4287 - accuracy: 0.5800 - auc: 0.8561 - val_loss: 0.7240 - val_accuracy: 0.7427 - val_auc: 0.9247\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4313 - accuracy: 0.5923 - auc: 0.8555 - val_loss: 0.7781 - val_accuracy: 0.7300 - val_auc: 0.9274\n",
      "Epoch 18/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.4260 - accuracy: 0.6048 - auc: 0.8619Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4286 - accuracy: 0.6049 - auc: 0.8609 - val_loss: 0.6636 - val_accuracy: 0.7402 - val_auc: 0.9277\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6726 - accuracy: 0.7381 - auc: 0.7822 - val_loss: 0.6384 - val_accuracy: 0.8866 - val_auc: 0.8920\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5687 - accuracy: 0.8708 - auc: 0.8323 - val_loss: 0.4540 - val_accuracy: 0.8773 - val_auc: 0.9106\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5385 - accuracy: 0.8671 - auc: 0.8567 - val_loss: 0.5091 - val_accuracy: 0.9440 - val_auc: 0.9193\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4910 - accuracy: 0.8712 - auc: 0.8772 - val_loss: 0.6086 - val_accuracy: 0.8484 - val_auc: 0.9279\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4877 - accuracy: 0.8838 - auc: 0.8818 - val_loss: 0.6087 - val_accuracy: 0.8550 - val_auc: 0.9307\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5292 - accuracy: 0.8899 - auc: 0.8935 - val_loss: 1.0529 - val_accuracy: 0.8572 - val_auc: 0.9154\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5346 - accuracy: 0.7655 - auc: 0.8623 - val_loss: 0.9472 - val_accuracy: 0.5979 - val_auc: 0.8854\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5651 - accuracy: 0.6674 - auc: 0.8502 - val_loss: 0.7442 - val_accuracy: 0.6515 - val_auc: 0.9164\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4602 - accuracy: 0.7996 - auc: 0.8771 - val_loss: 0.9773 - val_accuracy: 0.8726 - val_auc: 0.9210\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4249 - accuracy: 0.8130 - auc: 0.8878 - val_loss: 1.3955 - val_accuracy: 0.8842 - val_auc: 0.9174\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4457 - accuracy: 0.7999 - auc: 0.8927 - val_loss: 0.8937 - val_accuracy: 0.7051 - val_auc: 0.9173\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4147 - accuracy: 0.8191 - auc: 0.8948 - val_loss: 1.2659 - val_accuracy: 0.7123 - val_auc: 0.9250\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3946 - accuracy: 0.6725 - auc: 0.8975 - val_loss: 1.0395 - val_accuracy: 0.8948 - val_auc: 0.9253\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3752 - accuracy: 0.8037 - auc: 0.9078 - val_loss: 0.9859 - val_accuracy: 0.8671 - val_auc: 0.9278\n",
      "Epoch 15/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.8549 - auc: 0.9053Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4398 - accuracy: 0.8558 - auc: 0.9053 - val_loss: 1.1228 - val_accuracy: 0.9148 - val_auc: 0.9145\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.7764 - accuracy: 0.7785 - auc: 0.7858 - val_loss: 0.4856 - val_accuracy: 0.7956 - val_auc: 0.8989\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5256 - accuracy: 0.8840 - auc: 0.8629 - val_loss: 0.5139 - val_accuracy: 0.8885 - val_auc: 0.9206\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5336 - accuracy: 0.8672 - auc: 0.8735 - val_loss: 0.5466 - val_accuracy: 0.8995 - val_auc: 0.9084\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4896 - accuracy: 0.8923 - auc: 0.8879 - val_loss: 0.6274 - val_accuracy: 0.8829 - val_auc: 0.9247\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5457 - accuracy: 0.8807 - auc: 0.8829 - val_loss: 1.0615 - val_accuracy: 0.9059 - val_auc: 0.9152\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5245 - accuracy: 0.8651 - auc: 0.8785 - val_loss: 0.7486 - val_accuracy: 0.9225 - val_auc: 0.9205\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5300 - accuracy: 0.9014 - auc: 0.8747 - val_loss: 0.7379 - val_accuracy: 0.8711 - val_auc: 0.9207\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4455 - accuracy: 0.8911 - auc: 0.8771 - val_loss: 0.7298 - val_accuracy: 0.9042 - val_auc: 0.9289\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4179 - accuracy: 0.9175 - auc: 0.8975 - val_loss: 0.5851 - val_accuracy: 0.9174 - val_auc: 0.9293\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5222 - accuracy: 0.8868 - auc: 0.8886 - val_loss: 1.2902 - val_accuracy: 0.8214 - val_auc: 0.9277\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4687 - accuracy: 0.8597 - auc: 0.8843 - val_loss: 1.5407 - val_accuracy: 0.8759 - val_auc: 0.9159\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4814 - accuracy: 0.8037 - auc: 0.8720 - val_loss: 1.1982 - val_accuracy: 0.9158 - val_auc: 0.9151\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4154 - accuracy: 0.8893 - auc: 0.8874 - val_loss: 0.9514 - val_accuracy: 0.9311 - val_auc: 0.9163\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3875 - accuracy: 0.8511 - auc: 0.8922 - val_loss: 1.0212 - val_accuracy: 0.6710 - val_auc: 0.9231\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3776 - accuracy: 0.8686 - auc: 0.9027 - val_loss: 0.9261 - val_accuracy: 0.9348 - val_auc: 0.9210\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3668 - accuracy: 0.9241 - auc: 0.9141 - val_loss: 0.7801 - val_accuracy: 0.8701 - val_auc: 0.9250\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3974 - accuracy: 0.8635 - auc: 0.8921 - val_loss: 0.7285 - val_accuracy: 0.8755 - val_auc: 0.9226\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3821 - accuracy: 0.7671 - auc: 0.8919 - val_loss: 0.7007 - val_accuracy: 0.9147 - val_auc: 0.9260\n",
      "Epoch 19/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3707 - accuracy: 0.8033 - auc: 0.9032Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3682 - accuracy: 0.7961 - auc: 0.9033 - val_loss: 0.6908 - val_accuracy: 0.7292 - val_auc: 0.9188\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.6637 - accuracy: 0.8084 - auc: 0.8066 - val_loss: 0.4074 - val_accuracy: 0.9360 - val_auc: 0.9215\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5613 - accuracy: 0.8629 - auc: 0.8594 - val_loss: 0.4718 - val_accuracy: 0.9088 - val_auc: 0.9262\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4808 - accuracy: 0.8854 - auc: 0.8895 - val_loss: 0.5011 - val_accuracy: 0.9178 - val_auc: 0.9261\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5072 - accuracy: 0.8763 - auc: 0.8749 - val_loss: 0.5350 - val_accuracy: 0.8687 - val_auc: 0.9297\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4492 - accuracy: 0.8916 - auc: 0.8957 - val_loss: 0.4179 - val_accuracy: 0.9252 - val_auc: 0.9294\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4391 - accuracy: 0.8951 - auc: 0.8913 - val_loss: 0.4518 - val_accuracy: 0.8765 - val_auc: 0.9302\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4745 - accuracy: 0.8972 - auc: 0.8902 - val_loss: 0.4421 - val_accuracy: 0.8710 - val_auc: 0.9283\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4537 - accuracy: 0.8993 - auc: 0.9054 - val_loss: 0.3576 - val_accuracy: 0.9054 - val_auc: 0.9352\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4743 - accuracy: 0.9097 - auc: 0.8858 - val_loss: 0.3670 - val_accuracy: 0.9107 - val_auc: 0.9261\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4399 - accuracy: 0.8902 - auc: 0.8799 - val_loss: 0.5324 - val_accuracy: 0.9236 - val_auc: 0.9263\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4470 - accuracy: 0.9086 - auc: 0.8870 - val_loss: 0.5269 - val_accuracy: 0.9034 - val_auc: 0.9097\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4896 - accuracy: 0.9113 - auc: 0.8609 - val_loss: 0.5422 - val_accuracy: 0.9178 - val_auc: 0.9289\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4450 - accuracy: 0.9106 - auc: 0.8785 - val_loss: 0.6621 - val_accuracy: 0.8824 - val_auc: 0.9264\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4343 - accuracy: 0.9129 - auc: 0.8647 - val_loss: 0.5775 - val_accuracy: 0.9032 - val_auc: 0.9277\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4223 - accuracy: 0.9247 - auc: 0.8752 - val_loss: 0.7681 - val_accuracy: 0.8863 - val_auc: 0.9266\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4404 - accuracy: 0.9194 - auc: 0.8792 - val_loss: 0.5635 - val_accuracy: 0.8885 - val_auc: 0.9248\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4874 - accuracy: 0.9302 - auc: 0.8665 - val_loss: 0.6597 - val_accuracy: 0.6387 - val_auc: 0.8965\n",
      "Epoch 18/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.4569 - accuracy: 0.6924 - auc: 0.8409Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4551 - accuracy: 0.6970 - auc: 0.8419 - val_loss: 0.5259 - val_accuracy: 0.9400 - val_auc: 0.9166\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.8582 - accuracy: 0.6903 - auc: 0.8021 - val_loss: 0.6484 - val_accuracy: 0.9023 - val_auc: 0.8980\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.0326 - accuracy: 0.7779 - auc: 0.8202 - val_loss: 0.9537 - val_accuracy: 0.7729 - val_auc: 0.8825\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.1929 - accuracy: 0.8159 - auc: 0.8353 - val_loss: 0.8028 - val_accuracy: 0.8677 - val_auc: 0.9008\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8666 - accuracy: 0.8346 - auc: 0.8536 - val_loss: 2.4643 - val_accuracy: 0.9407 - val_auc: 0.8929\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8666 - accuracy: 0.8713 - auc: 0.8640 - val_loss: 1.0371 - val_accuracy: 0.8902 - val_auc: 0.8947\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8556 - accuracy: 0.8707 - auc: 0.8433 - val_loss: 3.1685 - val_accuracy: 0.6559 - val_auc: 0.8887\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0876 - accuracy: 0.5878 - auc: 0.8102 - val_loss: 2.1052 - val_accuracy: 0.6093 - val_auc: 0.8940\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2508 - accuracy: 0.6733 - auc: 0.8211 - val_loss: 4.3786 - val_accuracy: 0.9052 - val_auc: 0.8876\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2949 - accuracy: 0.5968 - auc: 0.8010 - val_loss: 6.4657 - val_accuracy: 0.6416 - val_auc: 0.8852\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2855 - accuracy: 0.4987 - auc: 0.7985 - val_loss: 5.9019 - val_accuracy: 0.6054 - val_auc: 0.8861\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2735 - accuracy: 0.6144 - auc: 0.8213 - val_loss: 5.4071 - val_accuracy: 0.5947 - val_auc: 0.9085\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0626 - accuracy: 0.4856 - auc: 0.7952 - val_loss: 5.1773 - val_accuracy: 0.5957 - val_auc: 0.8089\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7170 - accuracy: 0.5172 - auc: 0.7732 - val_loss: 4.9950 - val_accuracy: 0.6106 - val_auc: 0.8237\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6160 - accuracy: 0.5342 - auc: 0.7919 - val_loss: 4.6821 - val_accuracy: 0.6250 - val_auc: 0.8633\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6036 - accuracy: 0.5445 - auc: 0.8283 - val_loss: 3.0113 - val_accuracy: 0.6327 - val_auc: 0.8975\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5450 - accuracy: 0.5579 - auc: 0.8264 - val_loss: 3.5070 - val_accuracy: 0.6649 - val_auc: 0.9130\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6922 - accuracy: 0.5787 - auc: 0.8410 - val_loss: 3.1783 - val_accuracy: 0.6761 - val_auc: 0.9062\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5784 - accuracy: 0.5748 - auc: 0.8334 - val_loss: 4.6399 - val_accuracy: 0.6765 - val_auc: 0.9047\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5202 - accuracy: 0.5761 - auc: 0.8473 - val_loss: 3.8661 - val_accuracy: 0.6803 - val_auc: 0.9175\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5115 - accuracy: 0.5809 - auc: 0.8532 - val_loss: 3.9768 - val_accuracy: 0.6837 - val_auc: 0.9124\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5600 - accuracy: 0.5744 - auc: 0.8540 - val_loss: 3.8616 - val_accuracy: 0.6671 - val_auc: 0.9184\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4569 - accuracy: 0.5769 - auc: 0.8509 - val_loss: 3.7835 - val_accuracy: 0.6867 - val_auc: 0.9163\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4809 - accuracy: 0.5817 - auc: 0.8581 - val_loss: 3.3786 - val_accuracy: 0.6959 - val_auc: 0.9155\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4338 - accuracy: 0.5962 - auc: 0.8613 - val_loss: 3.5453 - val_accuracy: 0.7135 - val_auc: 0.9181\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4808 - accuracy: 0.6034 - auc: 0.8584 - val_loss: 4.0591 - val_accuracy: 0.7108 - val_auc: 0.7364\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4269 - accuracy: 0.6026 - auc: 0.8602 - val_loss: 3.9583 - val_accuracy: 0.7081 - val_auc: 0.9102\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4356 - accuracy: 0.6038 - auc: 0.8685 - val_loss: 3.6707 - val_accuracy: 0.6974 - val_auc: 0.9014\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4029 - accuracy: 0.6108 - auc: 0.8616 - val_loss: 3.2247 - val_accuracy: 0.7231 - val_auc: 0.9164\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3924 - accuracy: 0.6134 - auc: 0.8697 - val_loss: 3.5426 - val_accuracy: 0.7265 - val_auc: 0.9230\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3938 - accuracy: 0.6199 - auc: 0.8678 - val_loss: 3.1693 - val_accuracy: 0.7225 - val_auc: 0.9214\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4081 - accuracy: 0.6134 - auc: 0.8641 - val_loss: 3.0296 - val_accuracy: 0.7305 - val_auc: 0.9211\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3868 - accuracy: 0.6299 - auc: 0.8727 - val_loss: 3.0213 - val_accuracy: 0.7266 - val_auc: 0.9166\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3775 - accuracy: 0.6327 - auc: 0.8798 - val_loss: 2.9051 - val_accuracy: 0.7284 - val_auc: 0.9164\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3767 - accuracy: 0.6308 - auc: 0.8732 - val_loss: 2.8316 - val_accuracy: 0.7301 - val_auc: 0.9201\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4082 - accuracy: 0.6329 - auc: 0.8767 - val_loss: 1.7259 - val_accuracy: 0.7313 - val_auc: 0.9198\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3795 - accuracy: 0.6404 - auc: 0.8860 - val_loss: 2.3060 - val_accuracy: 0.7463 - val_auc: 0.9162\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3807 - accuracy: 0.6473 - auc: 0.8834 - val_loss: 1.7948 - val_accuracy: 0.7500 - val_auc: 0.9133\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3947 - accuracy: 0.6441 - auc: 0.8771 - val_loss: 1.7097 - val_accuracy: 0.7351 - val_auc: 0.9131\n",
      "Epoch 39/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.4142 - accuracy: 0.6387 - auc: 0.8389Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4143 - accuracy: 0.6388 - auc: 0.8390 - val_loss: 1.6975 - val_accuracy: 0.7409 - val_auc: 0.8627\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.9978 - accuracy: 0.7298 - auc: 0.8073 - val_loss: 0.9804 - val_accuracy: 0.8437 - val_auc: 0.8296\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0237 - accuracy: 0.8154 - auc: 0.8361 - val_loss: 1.2272 - val_accuracy: 0.9390 - val_auc: 0.9031\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2763 - accuracy: 0.8332 - auc: 0.8371 - val_loss: 1.1316 - val_accuracy: 0.8353 - val_auc: 0.8958\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2122 - accuracy: 0.8262 - auc: 0.8371 - val_loss: 1.0321 - val_accuracy: 0.8687 - val_auc: 0.8890\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1643 - accuracy: 0.8552 - auc: 0.8483 - val_loss: 1.1210 - val_accuracy: 0.8487 - val_auc: 0.8660\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1984 - accuracy: 0.8328 - auc: 0.8437 - val_loss: 5.1343 - val_accuracy: 0.8938 - val_auc: 0.8996\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1765 - accuracy: 0.8654 - auc: 0.8610 - val_loss: 3.1381 - val_accuracy: 0.8921 - val_auc: 0.9075\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6187 - accuracy: 0.8945 - auc: 0.8773 - val_loss: 3.6229 - val_accuracy: 0.8695 - val_auc: 0.9100\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8398 - accuracy: 0.8755 - auc: 0.8491 - val_loss: 4.6431 - val_accuracy: 0.9679 - val_auc: 0.9102\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7481 - accuracy: 0.8038 - auc: 0.8507 - val_loss: 3.1305 - val_accuracy: 0.5799 - val_auc: 0.8999\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5044 - accuracy: 0.7645 - auc: 0.8689 - val_loss: 2.8150 - val_accuracy: 0.8855 - val_auc: 0.9081\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5298 - accuracy: 0.8159 - auc: 0.8543 - val_loss: 2.9884 - val_accuracy: 0.9218 - val_auc: 0.8930\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4916 - accuracy: 0.6251 - auc: 0.8553 - val_loss: 3.4554 - val_accuracy: 0.6397 - val_auc: 0.9083\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6115 - accuracy: 0.6714 - auc: 0.8563 - val_loss: 3.0283 - val_accuracy: 0.6267 - val_auc: 0.9140\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5991 - accuracy: 0.6459 - auc: 0.8708 - val_loss: 3.0875 - val_accuracy: 0.6279 - val_auc: 0.9191\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4987 - accuracy: 0.6542 - auc: 0.8700 - val_loss: 3.3030 - val_accuracy: 0.6377 - val_auc: 0.9146\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4393 - accuracy: 0.5962 - auc: 0.8814 - val_loss: 3.2153 - val_accuracy: 0.9004 - val_auc: 0.9215\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4078 - accuracy: 0.7391 - auc: 0.8900 - val_loss: 3.1303 - val_accuracy: 0.6626 - val_auc: 0.9200\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4019 - accuracy: 0.5960 - auc: 0.8794 - val_loss: 2.9617 - val_accuracy: 0.6802 - val_auc: 0.9198\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3872 - accuracy: 0.6030 - auc: 0.8828 - val_loss: 2.9345 - val_accuracy: 0.7030 - val_auc: 0.9178\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3698 - accuracy: 0.6197 - auc: 0.8929 - val_loss: 2.8916 - val_accuracy: 0.7101 - val_auc: 0.9232\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3717 - accuracy: 0.6605 - auc: 0.8949 - val_loss: 2.6489 - val_accuracy: 0.7237 - val_auc: 0.9204\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3716 - accuracy: 0.6359 - auc: 0.8981 - val_loss: 2.4444 - val_accuracy: 0.7228 - val_auc: 0.9216\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3643 - accuracy: 0.6432 - auc: 0.8977 - val_loss: 2.2277 - val_accuracy: 0.7402 - val_auc: 0.9198\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3880 - accuracy: 0.6534 - auc: 0.9014 - val_loss: 2.3678 - val_accuracy: 0.7192 - val_auc: 0.9198\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3672 - accuracy: 0.6582 - auc: 0.9001 - val_loss: 2.4185 - val_accuracy: 0.7567 - val_auc: 0.9206\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3492 - accuracy: 0.6707 - auc: 0.9071 - val_loss: 2.3479 - val_accuracy: 0.7572 - val_auc: 0.9187\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3792 - accuracy: 0.6687 - auc: 0.8916 - val_loss: 1.9745 - val_accuracy: 0.7293 - val_auc: 0.9124\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3724 - accuracy: 0.6677 - auc: 0.8977 - val_loss: 2.2715 - val_accuracy: 0.7682 - val_auc: 0.9161\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3555 - accuracy: 0.6729 - auc: 0.8947 - val_loss: 2.1418 - val_accuracy: 0.7661 - val_auc: 0.9151\n",
      "Epoch 31/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3436 - accuracy: 0.6802 - auc: 0.8980Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3433 - accuracy: 0.6802 - auc: 0.8980 - val_loss: 2.1908 - val_accuracy: 0.7685 - val_auc: 0.9193\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7874 - accuracy: 0.7499 - auc: 0.7962 - val_loss: 0.8512 - val_accuracy: 0.7257 - val_auc: 0.9020\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.9593 - accuracy: 0.8106 - auc: 0.8250 - val_loss: 0.7168 - val_accuracy: 0.8654 - val_auc: 0.8974\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8468 - accuracy: 0.8483 - auc: 0.8557 - val_loss: 1.5602 - val_accuracy: 0.8860 - val_auc: 0.9016\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8933 - accuracy: 0.8438 - auc: 0.8570 - val_loss: 1.4386 - val_accuracy: 0.8835 - val_auc: 0.9015\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0737 - accuracy: 0.8370 - auc: 0.8178 - val_loss: 1.1498 - val_accuracy: 0.8472 - val_auc: 0.9008\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7295 - accuracy: 0.8836 - auc: 0.8569 - val_loss: 1.6621 - val_accuracy: 0.8380 - val_auc: 0.9107\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6832 - accuracy: 0.8939 - auc: 0.8774 - val_loss: 0.8015 - val_accuracy: 0.8798 - val_auc: 0.8964\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5660 - accuracy: 0.8893 - auc: 0.8708 - val_loss: 2.1391 - val_accuracy: 0.9018 - val_auc: 0.9179\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6802 - accuracy: 0.8772 - auc: 0.8693 - val_loss: 2.2307 - val_accuracy: 0.9099 - val_auc: 0.9121\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5090 - accuracy: 0.9055 - auc: 0.8903 - val_loss: 1.3519 - val_accuracy: 0.9185 - val_auc: 0.9203\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4433 - accuracy: 0.9097 - auc: 0.8916 - val_loss: 1.2123 - val_accuracy: 0.8595 - val_auc: 0.9176\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4233 - accuracy: 0.9052 - auc: 0.9063 - val_loss: 1.3799 - val_accuracy: 0.6752 - val_auc: 0.9208\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3981 - accuracy: 0.8327 - auc: 0.9032 - val_loss: 1.1310 - val_accuracy: 0.9028 - val_auc: 0.9223\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3877 - accuracy: 0.9078 - auc: 0.9038 - val_loss: 1.3147 - val_accuracy: 0.8971 - val_auc: 0.9245\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4143 - accuracy: 0.8580 - auc: 0.9019 - val_loss: 1.0663 - val_accuracy: 0.8959 - val_auc: 0.9142\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3975 - accuracy: 0.8536 - auc: 0.9097 - val_loss: 1.3416 - val_accuracy: 0.7119 - val_auc: 0.9249\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3882 - accuracy: 0.8808 - auc: 0.9115 - val_loss: 1.3710 - val_accuracy: 0.8896 - val_auc: 0.9234\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4018 - accuracy: 0.7892 - auc: 0.9111 - val_loss: 0.9148 - val_accuracy: 0.6715 - val_auc: 0.9225\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4170 - accuracy: 0.8919 - auc: 0.9132 - val_loss: 1.4447 - val_accuracy: 0.9077 - val_auc: 0.9046\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3684 - accuracy: 0.7854 - auc: 0.9189 - val_loss: 1.0977 - val_accuracy: 0.8854 - val_auc: 0.9206\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4640 - accuracy: 0.8224 - auc: 0.9001 - val_loss: 2.4941 - val_accuracy: 0.8745 - val_auc: 0.9264\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5538 - accuracy: 0.7206 - auc: 0.9059 - val_loss: 3.8272 - val_accuracy: 0.9378 - val_auc: 0.9164\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5611 - accuracy: 0.6336 - auc: 0.8963 - val_loss: 4.6390 - val_accuracy: 0.7110 - val_auc: 0.9169\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5153 - accuracy: 0.7230 - auc: 0.8916 - val_loss: 3.9454 - val_accuracy: 0.7207 - val_auc: 0.9267\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4338 - accuracy: 0.6216 - auc: 0.8909 - val_loss: 2.4794 - val_accuracy: 0.6995 - val_auc: 0.9180\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4253 - accuracy: 0.6285 - auc: 0.8947 - val_loss: 2.6935 - val_accuracy: 0.7494 - val_auc: 0.9270\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4056 - accuracy: 0.6347 - auc: 0.8916 - val_loss: 3.8173 - val_accuracy: 0.7329 - val_auc: 0.9195\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4234 - accuracy: 0.6448 - auc: 0.8903 - val_loss: 4.7283 - val_accuracy: 0.7085 - val_auc: 0.9014\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4383 - accuracy: 0.6333 - auc: 0.8814 - val_loss: 4.7062 - val_accuracy: 0.7280 - val_auc: 0.9182\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4361 - accuracy: 0.6385 - auc: 0.8916 - val_loss: 4.9079 - val_accuracy: 0.7480 - val_auc: 0.9111\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4655 - accuracy: 0.6328 - auc: 0.8640 - val_loss: 4.7531 - val_accuracy: 0.7265 - val_auc: 0.8728\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4105 - accuracy: 0.6316 - auc: 0.8418 - val_loss: 4.2445 - val_accuracy: 0.7343 - val_auc: 0.8806\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4050 - accuracy: 0.6440 - auc: 0.8494 - val_loss: 4.4523 - val_accuracy: 0.7532 - val_auc: 0.8832\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3868 - accuracy: 0.6547 - auc: 0.8615 - val_loss: 4.4608 - val_accuracy: 0.7513 - val_auc: 0.8887\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3883 - accuracy: 0.6628 - auc: 0.8651 - val_loss: 4.1065 - val_accuracy: 0.7621 - val_auc: 0.8874\n",
      "Epoch 36/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.6682 - auc: 0.8706Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3907 - accuracy: 0.6682 - auc: 0.8708 - val_loss: 3.5165 - val_accuracy: 0.7785 - val_auc: 0.8893\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 23us/sample - loss: 0.8613 - accuracy: 0.6937 - auc: 0.8056 - val_loss: 0.8127 - val_accuracy: 0.8819 - val_auc: 0.9089\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1327 - accuracy: 0.8164 - auc: 0.8438 - val_loss: 1.0576 - val_accuracy: 0.8475 - val_auc: 0.9029\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.5252 - accuracy: 0.8127 - auc: 0.8258 - val_loss: 1.2880 - val_accuracy: 0.8714 - val_auc: 0.8917\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1197 - accuracy: 0.8375 - auc: 0.8366 - val_loss: 1.8451 - val_accuracy: 0.8672 - val_auc: 0.9086\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3707 - accuracy: 0.8345 - auc: 0.8262 - val_loss: 1.2669 - val_accuracy: 0.7881 - val_auc: 0.8799\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3368 - accuracy: 0.8786 - auc: 0.8393 - val_loss: 1.2498 - val_accuracy: 0.8833 - val_auc: 0.8892\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0034 - accuracy: 0.6784 - auc: 0.8050 - val_loss: 1.8424 - val_accuracy: 0.8667 - val_auc: 0.8542\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2693 - accuracy: 0.8911 - auc: 0.8443 - val_loss: 2.9938 - val_accuracy: 0.7908 - val_auc: 0.9003\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8401 - accuracy: 0.7857 - auc: 0.8400 - val_loss: 3.5164 - val_accuracy: 0.5907 - val_auc: 0.9100\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5801 - accuracy: 0.5948 - auc: 0.8506 - val_loss: 1.9318 - val_accuracy: 0.5763 - val_auc: 0.8995\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5906 - accuracy: 0.6097 - auc: 0.8488 - val_loss: 2.2858 - val_accuracy: 0.9120 - val_auc: 0.8940\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5159 - accuracy: 0.7194 - auc: 0.8725 - val_loss: 2.1372 - val_accuracy: 0.8691 - val_auc: 0.9166\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5630 - accuracy: 0.7427 - auc: 0.8728 - val_loss: 1.7369 - val_accuracy: 0.9311 - val_auc: 0.8994\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4865 - accuracy: 0.6283 - auc: 0.8639 - val_loss: 2.0425 - val_accuracy: 0.6392 - val_auc: 0.9143\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4888 - accuracy: 0.6652 - auc: 0.8675 - val_loss: 1.5143 - val_accuracy: 0.6267 - val_auc: 0.9119\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4174 - accuracy: 0.6467 - auc: 0.8901 - val_loss: 1.9261 - val_accuracy: 0.6466 - val_auc: 0.9157\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4043 - accuracy: 0.7194 - auc: 0.9011 - val_loss: 2.5994 - val_accuracy: 0.8784 - val_auc: 0.9231\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4091 - accuracy: 0.7595 - auc: 0.8999 - val_loss: 2.1751 - val_accuracy: 0.6725 - val_auc: 0.9197\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3790 - accuracy: 0.7145 - auc: 0.9023 - val_loss: 2.2513 - val_accuracy: 0.6966 - val_auc: 0.9243\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3856 - accuracy: 0.7188 - auc: 0.9010 - val_loss: 1.6780 - val_accuracy: 0.6660 - val_auc: 0.9275\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3846 - accuracy: 0.6146 - auc: 0.8948 - val_loss: 1.7624 - val_accuracy: 0.6999 - val_auc: 0.9259\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3559 - accuracy: 0.7077 - auc: 0.9130 - val_loss: 1.9213 - val_accuracy: 0.7063 - val_auc: 0.9308\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3898 - accuracy: 0.6663 - auc: 0.9003 - val_loss: 1.9165 - val_accuracy: 0.7110 - val_auc: 0.9182\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3992 - accuracy: 0.6332 - auc: 0.8985 - val_loss: 2.1899 - val_accuracy: 0.7174 - val_auc: 0.9185\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3547 - accuracy: 0.6911 - auc: 0.9050 - val_loss: 2.1127 - val_accuracy: 0.7292 - val_auc: 0.9233\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3513 - accuracy: 0.6526 - auc: 0.9142 - val_loss: 1.8861 - val_accuracy: 0.7087 - val_auc: 0.9254\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3460 - accuracy: 0.7318 - auc: 0.9173 - val_loss: 1.9257 - val_accuracy: 0.7253 - val_auc: 0.9221\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3358 - accuracy: 0.6643 - auc: 0.9163 - val_loss: 1.9861 - val_accuracy: 0.7529 - val_auc: 0.9220\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3386 - accuracy: 0.6716 - auc: 0.9144 - val_loss: 1.9076 - val_accuracy: 0.7362 - val_auc: 0.9164\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3644 - accuracy: 0.6650 - auc: 0.9049 - val_loss: 1.5627 - val_accuracy: 0.7437 - val_auc: 0.9235\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3639 - accuracy: 0.6745 - auc: 0.9095 - val_loss: 1.6503 - val_accuracy: 0.7477 - val_auc: 0.9232\n",
      "Epoch 32/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.6731 - auc: 0.9140Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3387 - accuracy: 0.6734 - auc: 0.9146 - val_loss: 1.9077 - val_accuracy: 0.7623 - val_auc: 0.9209\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.8850 - accuracy: 0.7725 - auc: 0.8064 - val_loss: 0.4856 - val_accuracy: 0.8810 - val_auc: 0.9100\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.8851 - accuracy: 0.8087 - auc: 0.8326 - val_loss: 0.5206 - val_accuracy: 0.8321 - val_auc: 0.8977\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6788 - accuracy: 0.8538 - auc: 0.8647 - val_loss: 0.7342 - val_accuracy: 0.8622 - val_auc: 0.8698\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7652 - accuracy: 0.8593 - auc: 0.8787 - val_loss: 0.8523 - val_accuracy: 0.8337 - val_auc: 0.9170\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0076 - accuracy: 0.8350 - auc: 0.8443 - val_loss: 2.0589 - val_accuracy: 0.8925 - val_auc: 0.9060\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9981 - accuracy: 0.8432 - auc: 0.8441 - val_loss: 1.3232 - val_accuracy: 0.8385 - val_auc: 0.9038\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2296 - accuracy: 0.8148 - auc: 0.8375 - val_loss: 3.1717 - val_accuracy: 0.6091 - val_auc: 0.9080\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1204 - accuracy: 0.6772 - auc: 0.8117 - val_loss: 2.4251 - val_accuracy: 0.8632 - val_auc: 0.8785\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7632 - accuracy: 0.5146 - auc: 0.8217 - val_loss: 2.3238 - val_accuracy: 0.6238 - val_auc: 0.9042\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5732 - accuracy: 0.5338 - auc: 0.8422 - val_loss: 2.6990 - val_accuracy: 0.6422 - val_auc: 0.9114\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4677 - accuracy: 0.5598 - auc: 0.8717 - val_loss: 2.1133 - val_accuracy: 0.6736 - val_auc: 0.9181\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4966 - accuracy: 0.6230 - auc: 0.8760 - val_loss: 2.1469 - val_accuracy: 0.8622 - val_auc: 0.9187\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4806 - accuracy: 0.6523 - auc: 0.8719 - val_loss: 2.4932 - val_accuracy: 0.6890 - val_auc: 0.9165\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4330 - accuracy: 0.6009 - auc: 0.8833 - val_loss: 2.4308 - val_accuracy: 0.6743 - val_auc: 0.9174\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4030 - accuracy: 0.6108 - auc: 0.8854 - val_loss: 2.2743 - val_accuracy: 0.7007 - val_auc: 0.9165\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3881 - accuracy: 0.6254 - auc: 0.8957 - val_loss: 1.9352 - val_accuracy: 0.7205 - val_auc: 0.9207\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5112 - accuracy: 0.6211 - auc: 0.8771 - val_loss: 3.5292 - val_accuracy: 0.7309 - val_auc: 0.9192\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4321 - accuracy: 0.6260 - auc: 0.8884 - val_loss: 2.8373 - val_accuracy: 0.7026 - val_auc: 0.9165\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4205 - accuracy: 0.6203 - auc: 0.8842 - val_loss: 2.5002 - val_accuracy: 0.6901 - val_auc: 0.8971\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4347 - accuracy: 0.6254 - auc: 0.8881 - val_loss: 2.3726 - val_accuracy: 0.7112 - val_auc: 0.9176\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3935 - accuracy: 0.6263 - auc: 0.8896 - val_loss: 2.8007 - val_accuracy: 0.7113 - val_auc: 0.9145\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4428 - accuracy: 0.6319 - auc: 0.8931 - val_loss: 3.0402 - val_accuracy: 0.7419 - val_auc: 0.9171\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4258 - accuracy: 0.6387 - auc: 0.8964 - val_loss: 2.6267 - val_accuracy: 0.7237 - val_auc: 0.9203\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4239 - accuracy: 0.6421 - auc: 0.9002 - val_loss: 2.7492 - val_accuracy: 0.7396 - val_auc: 0.9178\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4015 - accuracy: 0.6500 - auc: 0.8972 - val_loss: 2.7685 - val_accuracy: 0.7360 - val_auc: 0.9203\n",
      "Epoch 26/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.6552 - auc: 0.9008Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3766 - accuracy: 0.6553 - auc: 0.9003 - val_loss: 2.8361 - val_accuracy: 0.7481 - val_auc: 0.9150\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 1.2713 - accuracy: 0.6762 - auc: 0.7894 - val_loss: 1.9748 - val_accuracy: 0.8489 - val_auc: 0.8776\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2776 - accuracy: 0.7768 - auc: 0.8333 - val_loss: 1.7436 - val_accuracy: 0.8745 - val_auc: 0.8841\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7017 - accuracy: 0.7925 - auc: 0.8291 - val_loss: 1.2106 - val_accuracy: 0.8208 - val_auc: 0.8787\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4761 - accuracy: 0.8192 - auc: 0.8365 - val_loss: 2.1979 - val_accuracy: 0.8656 - val_auc: 0.9086\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0728 - accuracy: 0.8492 - auc: 0.8610 - val_loss: 1.9126 - val_accuracy: 0.8652 - val_auc: 0.9003\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0851 - accuracy: 0.8605 - auc: 0.8466 - val_loss: 1.3469 - val_accuracy: 0.7816 - val_auc: 0.8862\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.2162 - accuracy: 0.8270 - auc: 0.8302 - val_loss: 4.1004 - val_accuracy: 0.9215 - val_auc: 0.8787\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7747 - accuracy: 0.8574 - auc: 0.8280 - val_loss: 5.8231 - val_accuracy: 0.8742 - val_auc: 0.8814\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3386 - accuracy: 0.8833 - auc: 0.8460 - val_loss: 7.1383 - val_accuracy: 0.9085 - val_auc: 0.8877\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9650 - accuracy: 0.9046 - auc: 0.8528 - val_loss: 8.1725 - val_accuracy: 0.8878 - val_auc: 0.9037\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.6717 - accuracy: 0.8765 - auc: 0.8378 - val_loss: 10.2618 - val_accuracy: 0.9164 - val_auc: 0.9136\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8537 - accuracy: 0.9134 - auc: 0.8820 - val_loss: 9.3348 - val_accuracy: 0.9207 - val_auc: 0.9070\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7325 - accuracy: 0.9270 - auc: 0.8868 - val_loss: 8.6478 - val_accuracy: 0.8892 - val_auc: 0.9088\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1793 - accuracy: 0.8497 - auc: 0.8759 - val_loss: 5.6237 - val_accuracy: 0.8923 - val_auc: 0.8994\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1530 - accuracy: 0.8991 - auc: 0.8667 - val_loss: 16.6185 - val_accuracy: 0.8368 - val_auc: 0.9080\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3266 - accuracy: 0.9087 - auc: 0.8651 - val_loss: 9.5726 - val_accuracy: 0.9030 - val_auc: 0.9020\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8552 - accuracy: 0.9211 - auc: 0.8792 - val_loss: 11.7031 - val_accuracy: 0.9373 - val_auc: 0.9150\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5794 - accuracy: 0.9269 - auc: 0.8929 - val_loss: 13.2890 - val_accuracy: 0.8874 - val_auc: 0.9130\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3807 - accuracy: 0.9184 - auc: 0.8612 - val_loss: 13.0944 - val_accuracy: 0.9355 - val_auc: 0.9084\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9913 - accuracy: 0.9226 - auc: 0.8626 - val_loss: 15.1393 - val_accuracy: 0.5361 - val_auc: 0.9129\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7013 - accuracy: 0.8351 - auc: 0.8734 - val_loss: 15.4318 - val_accuracy: 0.9100 - val_auc: 0.9227\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6396 - accuracy: 0.9076 - auc: 0.8754 - val_loss: 15.4552 - val_accuracy: 0.8703 - val_auc: 0.9040\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6809 - accuracy: 0.9205 - auc: 0.8686 - val_loss: 14.3637 - val_accuracy: 0.9323 - val_auc: 0.9105\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5915 - accuracy: 0.9160 - auc: 0.8707 - val_loss: 14.6453 - val_accuracy: 0.8719 - val_auc: 0.9172\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5812 - accuracy: 0.8954 - auc: 0.8722 - val_loss: 10.8102 - val_accuracy: 0.8470 - val_auc: 0.8976\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7188 - accuracy: 0.9178 - auc: 0.8596 - val_loss: 16.4420 - val_accuracy: 0.9099 - val_auc: 0.9149\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5219 - accuracy: 0.8410 - auc: 0.8714 - val_loss: 16.4448 - val_accuracy: 0.9012 - val_auc: 0.9131\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8130 - accuracy: 0.9231 - auc: 0.8522 - val_loss: 11.8328 - val_accuracy: 0.9330 - val_auc: 0.9056\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6470 - accuracy: 0.6419 - auc: 0.8393 - val_loss: 14.5118 - val_accuracy: 0.5626 - val_auc: 0.9078\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0631 - accuracy: 0.6166 - auc: 0.8221 - val_loss: 7.6129 - val_accuracy: 0.9226 - val_auc: 0.9022\n",
      "Epoch 31/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.7517 - accuracy: 0.6103 - auc: 0.8325Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7512 - accuracy: 0.6102 - auc: 0.8324 - val_loss: 11.6766 - val_accuracy: 0.6175 - val_auc: 0.9044\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 1.2091 - accuracy: 0.7405 - auc: 0.7951 - val_loss: 0.6850 - val_accuracy: 0.8221 - val_auc: 0.9049\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2761 - accuracy: 0.7935 - auc: 0.8331 - val_loss: 0.9652 - val_accuracy: 0.8043 - val_auc: 0.8952\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1703 - accuracy: 0.8311 - auc: 0.8576 - val_loss: 1.0643 - val_accuracy: 0.8079 - val_auc: 0.8727\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 1.4546 - accuracy: 0.8024 - auc: 0.8321 - val_loss: 1.1894 - val_accuracy: 0.9043 - val_auc: 0.8986\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2423 - accuracy: 0.8190 - auc: 0.8477 - val_loss: 1.8125 - val_accuracy: 0.8083 - val_auc: 0.9029\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9276 - accuracy: 0.8624 - auc: 0.8752 - val_loss: 1.8616 - val_accuracy: 0.9153 - val_auc: 0.9115\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7011 - accuracy: 0.8775 - auc: 0.8930 - val_loss: 1.6700 - val_accuracy: 0.9124 - val_auc: 0.9122\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5850 - accuracy: 0.8976 - auc: 0.8938 - val_loss: 1.9458 - val_accuracy: 0.8467 - val_auc: 0.9001\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8974 - accuracy: 0.8705 - auc: 0.8772 - val_loss: 2.2688 - val_accuracy: 0.9077 - val_auc: 0.9041\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5591 - accuracy: 0.9029 - auc: 0.8879 - val_loss: 1.7324 - val_accuracy: 0.9285 - val_auc: 0.9064\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5778 - accuracy: 0.9013 - auc: 0.8887 - val_loss: 1.8506 - val_accuracy: 0.8996 - val_auc: 0.9234\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6384 - accuracy: 0.8937 - auc: 0.8998 - val_loss: 3.1441 - val_accuracy: 0.9061 - val_auc: 0.9156\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6538 - accuracy: 0.8223 - auc: 0.8880 - val_loss: 5.6292 - val_accuracy: 0.8915 - val_auc: 0.9107\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5520 - accuracy: 0.9014 - auc: 0.8761 - val_loss: 3.3035 - val_accuracy: 0.8670 - val_auc: 0.9121\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4353 - accuracy: 0.9188 - auc: 0.8994 - val_loss: 3.0502 - val_accuracy: 0.8921 - val_auc: 0.9135\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4311 - accuracy: 0.8571 - auc: 0.8977 - val_loss: 3.2567 - val_accuracy: 0.8636 - val_auc: 0.9145\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4599 - accuracy: 0.9142 - auc: 0.8947 - val_loss: 3.0794 - val_accuracy: 0.6527 - val_auc: 0.9078\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5497 - accuracy: 0.7899 - auc: 0.8742 - val_loss: 3.6015 - val_accuracy: 0.6361 - val_auc: 0.9120\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6674 - accuracy: 0.6632 - auc: 0.8546 - val_loss: 3.9627 - val_accuracy: 0.6537 - val_auc: 0.9174\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5163 - accuracy: 0.5703 - auc: 0.8721 - val_loss: 4.0120 - val_accuracy: 0.6680 - val_auc: 0.9132\n",
      "Epoch 21/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.4292 - accuracy: 0.6813 - auc: 0.8851Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4288 - accuracy: 0.6811 - auc: 0.8851 - val_loss: 3.1933 - val_accuracy: 0.6634 - val_auc: 0.9179\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 1.2606 - accuracy: 0.7298 - auc: 0.7784 - val_loss: 0.8302 - val_accuracy: 0.8708 - val_auc: 0.9048\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1425 - accuracy: 0.8064 - auc: 0.8457 - val_loss: 1.5564 - val_accuracy: 0.8805 - val_auc: 0.8815\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4680 - accuracy: 0.8176 - auc: 0.8436 - val_loss: 0.9852 - val_accuracy: 0.9227 - val_auc: 0.8752\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3412 - accuracy: 0.8163 - auc: 0.8370 - val_loss: 2.1553 - val_accuracy: 0.9290 - val_auc: 0.9148\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.6914 - accuracy: 0.8289 - auc: 0.8527 - val_loss: 2.4389 - val_accuracy: 0.8479 - val_auc: 0.8839\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.6687 - accuracy: 0.8473 - auc: 0.8509 - val_loss: 6.7577 - val_accuracy: 0.8316 - val_auc: 0.9117\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2011 - accuracy: 0.8603 - auc: 0.8640 - val_loss: 1.5566 - val_accuracy: 0.8479 - val_auc: 0.8936\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7950 - accuracy: 0.8905 - auc: 0.8827 - val_loss: 1.4836 - val_accuracy: 0.8540 - val_auc: 0.9093\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5733 - accuracy: 0.8890 - auc: 0.8921 - val_loss: 3.2530 - val_accuracy: 0.8967 - val_auc: 0.9166\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6407 - accuracy: 0.8902 - auc: 0.8974 - val_loss: 4.3573 - val_accuracy: 0.9447 - val_auc: 0.9147\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7077 - accuracy: 0.8947 - auc: 0.8778 - val_loss: 4.5085 - val_accuracy: 0.8590 - val_auc: 0.9191\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6670 - accuracy: 0.9058 - auc: 0.8879 - val_loss: 4.3394 - val_accuracy: 0.8432 - val_auc: 0.9049\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5883 - accuracy: 0.9001 - auc: 0.8878 - val_loss: 4.2026 - val_accuracy: 0.8393 - val_auc: 0.8992\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5355 - accuracy: 0.8621 - auc: 0.8856 - val_loss: 4.3734 - val_accuracy: 0.6392 - val_auc: 0.9163\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4795 - accuracy: 0.7257 - auc: 0.8825 - val_loss: 3.2099 - val_accuracy: 0.9290 - val_auc: 0.9172\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4211 - accuracy: 0.8128 - auc: 0.8901 - val_loss: 3.0375 - val_accuracy: 0.8986 - val_auc: 0.9225\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3765 - accuracy: 0.9196 - auc: 0.9072 - val_loss: 4.1196 - val_accuracy: 0.8694 - val_auc: 0.9241\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3674 - accuracy: 0.9097 - auc: 0.9148 - val_loss: 4.5513 - val_accuracy: 0.9040 - val_auc: 0.9213\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5187 - accuracy: 0.9020 - auc: 0.8879 - val_loss: 4.8000 - val_accuracy: 0.8968 - val_auc: 0.9110\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5274 - accuracy: 0.5666 - auc: 0.8542 - val_loss: 4.5637 - val_accuracy: 0.6318 - val_auc: 0.8721\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4631 - accuracy: 0.5522 - auc: 0.8625 - val_loss: 3.2520 - val_accuracy: 0.8969 - val_auc: 0.9051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4046 - accuracy: 0.7852 - auc: 0.8816 - val_loss: 3.4881 - val_accuracy: 0.8818 - val_auc: 0.9050\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3674 - accuracy: 0.7622 - auc: 0.8997 - val_loss: 3.5069 - val_accuracy: 0.9030 - val_auc: 0.9219\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3752 - accuracy: 0.7410 - auc: 0.9042 - val_loss: 3.0563 - val_accuracy: 0.9273 - val_auc: 0.9188\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3616 - accuracy: 0.8059 - auc: 0.9100 - val_loss: 3.9981 - val_accuracy: 0.9161 - val_auc: 0.9214\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3884 - accuracy: 0.7911 - auc: 0.8985 - val_loss: 3.3681 - val_accuracy: 0.7103 - val_auc: 0.9205\n",
      "Epoch 27/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.6772 - auc: 0.8984Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3654 - accuracy: 0.6771 - auc: 0.8991 - val_loss: 3.0781 - val_accuracy: 0.7115 - val_auc: 0.9218\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 1.5630 - accuracy: 0.6672 - auc: 0.7828 - val_loss: 1.0668 - val_accuracy: 0.7594 - val_auc: 0.8418\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3742 - accuracy: 0.8155 - auc: 0.8324 - val_loss: 0.9868 - val_accuracy: 0.7359 - val_auc: 0.8717\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.5963 - accuracy: 0.8255 - auc: 0.8575 - val_loss: 0.9621 - val_accuracy: 0.8477 - val_auc: 0.9133\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3179 - accuracy: 0.8261 - auc: 0.8531 - val_loss: 1.7849 - val_accuracy: 0.8841 - val_auc: 0.8903\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1268 - accuracy: 0.8342 - auc: 0.8552 - val_loss: 4.6134 - val_accuracy: 0.8974 - val_auc: 0.8657\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1874 - accuracy: 0.8482 - auc: 0.8646 - val_loss: 2.5054 - val_accuracy: 0.8678 - val_auc: 0.8727\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2237 - accuracy: 0.8510 - auc: 0.8573 - val_loss: 3.1682 - val_accuracy: 0.9113 - val_auc: 0.8793\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3422 - accuracy: 0.7635 - auc: 0.8199 - val_loss: 4.0672 - val_accuracy: 0.6265 - val_auc: 0.8627\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9593 - accuracy: 0.5374 - auc: 0.8149 - val_loss: 3.2312 - val_accuracy: 0.6116 - val_auc: 0.8642\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6986 - accuracy: 0.5413 - auc: 0.8078 - val_loss: 3.6170 - val_accuracy: 0.6558 - val_auc: 0.8615\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7111 - accuracy: 0.5612 - auc: 0.8187 - val_loss: 2.9292 - val_accuracy: 0.6383 - val_auc: 0.8516\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.7985 - accuracy: 0.5957 - auc: 0.8029 - val_loss: 9.9480 - val_accuracy: 0.6215 - val_auc: 0.8817\n",
      "Epoch 13/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.8292 - accuracy: 0.5586 - auc: 0.8481Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8284 - accuracy: 0.5585 - auc: 0.8483 - val_loss: 8.6586 - val_accuracy: 0.6268 - val_auc: 0.8857\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 1.1657 - accuracy: 0.7126 - auc: 0.7914 - val_loss: 0.8271 - val_accuracy: 0.8903 - val_auc: 0.9070\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3253 - accuracy: 0.7861 - auc: 0.8295 - val_loss: 1.3656 - val_accuracy: 0.7728 - val_auc: 0.8718\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.7643 - accuracy: 0.8047 - auc: 0.8461 - val_loss: 2.5316 - val_accuracy: 0.8477 - val_auc: 0.9036\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.6737 - accuracy: 0.7880 - auc: 0.8233 - val_loss: 4.0499 - val_accuracy: 0.8206 - val_auc: 0.8889\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2970 - accuracy: 0.8429 - auc: 0.8514 - val_loss: 1.7964 - val_accuracy: 0.7861 - val_auc: 0.8743\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0916 - accuracy: 0.8603 - auc: 0.8790 - val_loss: 2.5636 - val_accuracy: 0.9275 - val_auc: 0.9085\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7504 - accuracy: 0.8901 - auc: 0.8892 - val_loss: 1.1334 - val_accuracy: 0.8797 - val_auc: 0.9064\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7574 - accuracy: 0.8895 - auc: 0.8910 - val_loss: 2.0845 - val_accuracy: 0.8950 - val_auc: 0.9176\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6700 - accuracy: 0.8828 - auc: 0.8826 - val_loss: 2.0925 - val_accuracy: 0.9067 - val_auc: 0.8934\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8457 - accuracy: 0.8737 - auc: 0.8816 - val_loss: 2.1063 - val_accuracy: 0.8692 - val_auc: 0.8982\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9177 - accuracy: 0.7489 - auc: 0.8464 - val_loss: 3.0968 - val_accuracy: 0.8990 - val_auc: 0.8798\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6685 - accuracy: 0.8280 - auc: 0.8716 - val_loss: 2.6169 - val_accuracy: 0.6209 - val_auc: 0.8862\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5573 - accuracy: 0.8688 - auc: 0.8943 - val_loss: 2.6223 - val_accuracy: 0.8999 - val_auc: 0.9073\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5089 - accuracy: 0.9036 - auc: 0.9008 - val_loss: 2.2740 - val_accuracy: 0.8814 - val_auc: 0.9122\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4667 - accuracy: 0.9051 - auc: 0.9035 - val_loss: 2.3138 - val_accuracy: 0.8634 - val_auc: 0.9242\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4468 - accuracy: 0.8444 - auc: 0.9084 - val_loss: 2.4323 - val_accuracy: 0.8638 - val_auc: 0.9078\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4490 - accuracy: 0.8613 - auc: 0.9020 - val_loss: 2.4158 - val_accuracy: 0.6861 - val_auc: 0.9197\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4053 - accuracy: 0.7860 - auc: 0.9097 - val_loss: 2.0915 - val_accuracy: 0.8949 - val_auc: 0.9173\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4633 - accuracy: 0.6684 - auc: 0.8916 - val_loss: 1.6744 - val_accuracy: 0.7034 - val_auc: 0.9118\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4498 - accuracy: 0.7063 - auc: 0.9023 - val_loss: 2.2378 - val_accuracy: 0.6945 - val_auc: 0.9102\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3833 - accuracy: 0.7018 - auc: 0.9074 - val_loss: 2.2659 - val_accuracy: 0.7071 - val_auc: 0.9160\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3931 - accuracy: 0.6923 - auc: 0.9049 - val_loss: 1.7778 - val_accuracy: 0.7095 - val_auc: 0.9112\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5810 - accuracy: 0.7983 - auc: 0.9107 - val_loss: 4.0566 - val_accuracy: 0.9062 - val_auc: 0.9128\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3781 - accuracy: 0.8061 - auc: 0.9170 - val_loss: 4.0594 - val_accuracy: 0.9071 - val_auc: 0.9081\n",
      "Epoch 25/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.4063 - accuracy: 0.8025 - auc: 0.9009Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4059 - accuracy: 0.8022 - auc: 0.9009 - val_loss: 4.0555 - val_accuracy: 0.7163 - val_auc: 0.8957\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.4730 - accuracy: 0.7230 - auc: 0.8019 - val_loss: 1.1097 - val_accuracy: 0.8915 - val_auc: 0.9047\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7037 - accuracy: 0.8003 - auc: 0.8318 - val_loss: 1.2307 - val_accuracy: 0.7414 - val_auc: 0.8725\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.0090 - accuracy: 0.7840 - auc: 0.8387 - val_loss: 3.1252 - val_accuracy: 0.8570 - val_auc: 0.8819\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.8283 - accuracy: 0.7877 - auc: 0.8231 - val_loss: 3.3517 - val_accuracy: 0.7921 - val_auc: 0.8731\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.7292 - accuracy: 0.7992 - auc: 0.8475 - val_loss: 3.3375 - val_accuracy: 0.7106 - val_auc: 0.8000\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.4039 - accuracy: 0.8458 - auc: 0.8572 - val_loss: 2.3072 - val_accuracy: 0.7687 - val_auc: 0.8936\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.6340 - accuracy: 0.8443 - auc: 0.8542 - val_loss: 5.0980 - val_accuracy: 0.8406 - val_auc: 0.8950\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.6191 - accuracy: 0.8694 - auc: 0.8584 - val_loss: 5.3425 - val_accuracy: 0.8669 - val_auc: 0.8999\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4663 - accuracy: 0.8652 - auc: 0.8707 - val_loss: 6.3498 - val_accuracy: 0.8611 - val_auc: 0.9080\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.0214 - accuracy: 0.8582 - auc: 0.8376 - val_loss: 3.7217 - val_accuracy: 0.8267 - val_auc: 0.8776\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1634 - accuracy: 0.8836 - auc: 0.8548 - val_loss: 7.8979 - val_accuracy: 0.9002 - val_auc: 0.9033\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8992 - accuracy: 0.9046 - auc: 0.8757 - val_loss: 7.8027 - val_accuracy: 0.8955 - val_auc: 0.9136\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8021 - accuracy: 0.9066 - auc: 0.8619 - val_loss: 6.6306 - val_accuracy: 0.8942 - val_auc: 0.9052\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6282 - accuracy: 0.9013 - auc: 0.9001 - val_loss: 5.2336 - val_accuracy: 0.8967 - val_auc: 0.9018\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1503 - accuracy: 0.8910 - auc: 0.8752 - val_loss: 11.1325 - val_accuracy: 0.8915 - val_auc: 0.9063\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3415 - accuracy: 0.9006 - auc: 0.8736 - val_loss: 18.7997 - val_accuracy: 0.8960 - val_auc: 0.8995\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0104 - accuracy: 0.6896 - auc: 0.8610 - val_loss: 18.2584 - val_accuracy: 0.6280 - val_auc: 0.8965\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9793 - accuracy: 0.6473 - auc: 0.8541 - val_loss: 14.1488 - val_accuracy: 0.8727 - val_auc: 0.8892\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7710 - accuracy: 0.8457 - auc: 0.8729 - val_loss: 14.0686 - val_accuracy: 0.8703 - val_auc: 0.9036\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6885 - accuracy: 0.8940 - auc: 0.8806 - val_loss: 12.1495 - val_accuracy: 0.8850 - val_auc: 0.9014\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5661 - accuracy: 0.9230 - auc: 0.8775 - val_loss: 15.1097 - val_accuracy: 0.9240 - val_auc: 0.9073\n",
      "Epoch 22/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 1.2789 - accuracy: 0.8065 - auc: 0.8551Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2774 - accuracy: 0.8067 - auc: 0.8554 - val_loss: 24.0278 - val_accuracy: 0.8857 - val_auc: 0.9033\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.5551 - accuracy: 0.6816 - auc: 0.8052 - val_loss: 0.9737 - val_accuracy: 0.7979 - val_auc: 0.8851\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5652 - accuracy: 0.7853 - auc: 0.8281 - val_loss: 1.3532 - val_accuracy: 0.7943 - val_auc: 0.8971\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7892 - accuracy: 0.7987 - auc: 0.8386 - val_loss: 1.8762 - val_accuracy: 0.9020 - val_auc: 0.8963\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9744 - accuracy: 0.7825 - auc: 0.8255 - val_loss: 2.8151 - val_accuracy: 0.8855 - val_auc: 0.9039\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5126 - accuracy: 0.8095 - auc: 0.8471 - val_loss: 4.8069 - val_accuracy: 0.8712 - val_auc: 0.8797\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.4739 - accuracy: 0.8031 - auc: 0.8317 - val_loss: 3.0571 - val_accuracy: 0.8534 - val_auc: 0.8924\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.9675 - accuracy: 0.8344 - auc: 0.8359 - val_loss: 6.4851 - val_accuracy: 0.9608 - val_auc: 0.8096\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.3463 - accuracy: 0.8741 - auc: 0.8192 - val_loss: 3.5439 - val_accuracy: 0.8109 - val_auc: 0.8382\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.9601 - accuracy: 0.8832 - auc: 0.8448 - val_loss: 8.5432 - val_accuracy: 0.8852 - val_auc: 0.8729\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3191 - accuracy: 0.8153 - auc: 0.8510 - val_loss: 6.4108 - val_accuracy: 0.8800 - val_auc: 0.9043\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0040 - accuracy: 0.8929 - auc: 0.8628 - val_loss: 5.8772 - val_accuracy: 0.9044 - val_auc: 0.9052\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2130 - accuracy: 0.8871 - auc: 0.8661 - val_loss: 11.0914 - val_accuracy: 0.9184 - val_auc: 0.9122\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4170 - accuracy: 0.8481 - auc: 0.8751 - val_loss: 9.7823 - val_accuracy: 0.8755 - val_auc: 0.8923\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.9396 - accuracy: 0.9049 - auc: 0.8455 - val_loss: 12.9546 - val_accuracy: 0.9033 - val_auc: 0.8660\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7522 - accuracy: 0.6609 - auc: 0.8365 - val_loss: 10.9338 - val_accuracy: 0.5823 - val_auc: 0.8807\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1596 - accuracy: 0.7057 - auc: 0.8502 - val_loss: 7.7037 - val_accuracy: 0.5743 - val_auc: 0.8716\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0606 - accuracy: 0.5303 - auc: 0.8404 - val_loss: 6.9645 - val_accuracy: 0.6067 - val_auc: 0.8870\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6514 - accuracy: 0.5362 - auc: 0.8545 - val_loss: 8.1152 - val_accuracy: 0.6120 - val_auc: 0.9065\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5763 - accuracy: 0.5808 - auc: 0.8293 - val_loss: 11.9584 - val_accuracy: 0.9350 - val_auc: 0.9090\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0603 - accuracy: 0.7216 - auc: 0.8547 - val_loss: 13.6535 - val_accuracy: 0.5980 - val_auc: 0.9126\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7650 - accuracy: 0.8375 - auc: 0.8640 - val_loss: 13.7910 - val_accuracy: 0.8765 - val_auc: 0.9109\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5851 - accuracy: 0.7637 - auc: 0.8766 - val_loss: 11.1607 - val_accuracy: 0.5945 - val_auc: 0.9104\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6508 - accuracy: 0.9140 - auc: 0.8789 - val_loss: 12.3834 - val_accuracy: 0.8743 - val_auc: 0.9075\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8729 - accuracy: 0.8249 - auc: 0.8682 - val_loss: 9.7118 - val_accuracy: 0.6142 - val_auc: 0.8684\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7509 - accuracy: 0.5333 - auc: 0.8433 - val_loss: 11.1139 - val_accuracy: 0.6075 - val_auc: 0.8728\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5585 - accuracy: 0.6980 - auc: 0.8738 - val_loss: 11.3705 - val_accuracy: 0.6178 - val_auc: 0.8695\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8292 - accuracy: 0.5441 - auc: 0.8462 - val_loss: 11.2204 - val_accuracy: 0.6214 - val_auc: 0.8634\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7114 - accuracy: 0.5437 - auc: 0.8521 - val_loss: 13.5429 - val_accuracy: 0.6223 - val_auc: 0.8688\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6551 - accuracy: 0.5459 - auc: 0.8385 - val_loss: 12.1845 - val_accuracy: 0.6203 - val_auc: 0.8671\n",
      "Epoch 30/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.5385 - auc: 0.8241Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5922 - accuracy: 0.5386 - auc: 0.8245 - val_loss: 12.1864 - val_accuracy: 0.6215 - val_auc: 0.8862\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.6207 - accuracy: 0.6852 - auc: 0.8021 - val_loss: 2.2458 - val_accuracy: 0.9050 - val_auc: 0.8853\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.9788 - accuracy: 0.7567 - auc: 0.8247 - val_loss: 2.2664 - val_accuracy: 0.9134 - val_auc: 0.8904\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.4547 - accuracy: 0.7748 - auc: 0.8239 - val_loss: 1.9534 - val_accuracy: 0.7826 - val_auc: 0.8771\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.2801 - accuracy: 0.8204 - auc: 0.8397 - val_loss: 2.7304 - val_accuracy: 0.8697 - val_auc: 0.9069\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 3.3173 - accuracy: 0.7856 - auc: 0.8185 - val_loss: 5.1044 - val_accuracy: 0.9007 - val_auc: 0.8808\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7667 - accuracy: 0.8272 - auc: 0.8456 - val_loss: 3.0235 - val_accuracy: 0.8333 - val_auc: 0.8865\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.8515 - accuracy: 0.8683 - auc: 0.8651 - val_loss: 4.4307 - val_accuracy: 0.8841 - val_auc: 0.8867\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2611 - accuracy: 0.8638 - auc: 0.8298 - val_loss: 5.2634 - val_accuracy: 0.6274 - val_auc: 0.8949\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.9227 - accuracy: 0.7133 - auc: 0.8311 - val_loss: 6.6010 - val_accuracy: 0.8622 - val_auc: 0.8753\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7185 - accuracy: 0.8655 - auc: 0.8473 - val_loss: 6.1056 - val_accuracy: 0.8346 - val_auc: 0.8955\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5292 - accuracy: 0.8497 - auc: 0.8316 - val_loss: 11.6094 - val_accuracy: 0.6305 - val_auc: 0.9076\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5512 - accuracy: 0.6317 - auc: 0.8388 - val_loss: 7.3377 - val_accuracy: 0.8426 - val_auc: 0.9009\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1605 - accuracy: 0.5745 - auc: 0.8307 - val_loss: 9.5860 - val_accuracy: 0.5895 - val_auc: 0.8671\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.6036 - accuracy: 0.5268 - auc: 0.8025 - val_loss: 9.9849 - val_accuracy: 0.6207 - val_auc: 0.8068\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0544 - accuracy: 0.5599 - auc: 0.8174 - val_loss: 4.9745 - val_accuracy: 0.6173 - val_auc: 0.8532\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2211 - accuracy: 0.5484 - auc: 0.8229 - val_loss: 8.2164 - val_accuracy: 0.6299 - val_auc: 0.8867\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7456 - accuracy: 0.5572 - auc: 0.8316 - val_loss: 7.9380 - val_accuracy: 0.6248 - val_auc: 0.8756\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7148 - accuracy: 0.5598 - auc: 0.8393 - val_loss: 8.5125 - val_accuracy: 0.6253 - val_auc: 0.8838\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5604 - accuracy: 0.5657 - auc: 0.8576 - val_loss: 10.4797 - val_accuracy: 0.6295 - val_auc: 0.9026\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5656 - accuracy: 0.6180 - auc: 0.8773 - val_loss: 8.8153 - val_accuracy: 0.6794 - val_auc: 0.8389\n",
      "Epoch 21/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.6471 - accuracy: 0.5706 - auc: 0.8389Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6467 - accuracy: 0.5705 - auc: 0.8388 - val_loss: 8.1188 - val_accuracy: 0.6364 - val_auc: 0.8686\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 24us/sample - loss: 1.5404 - accuracy: 0.6978 - auc: 0.8040 - val_loss: 1.7089 - val_accuracy: 0.9465 - val_auc: 0.8670\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.8312 - accuracy: 0.7875 - auc: 0.8291 - val_loss: 3.3920 - val_accuracy: 0.8682 - val_auc: 0.8788\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.4970 - accuracy: 0.7825 - auc: 0.8387 - val_loss: 1.7495 - val_accuracy: 0.8325 - val_auc: 0.8829\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 2.2320 - accuracy: 0.8100 - auc: 0.8467 - val_loss: 2.2160 - val_accuracy: 0.8949 - val_auc: 0.8713\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.9696 - accuracy: 0.8197 - auc: 0.8564 - val_loss: 2.3364 - val_accuracy: 0.8518 - val_auc: 0.9088\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.7593 - accuracy: 0.8093 - auc: 0.8387 - val_loss: 7.2487 - val_accuracy: 0.8510 - val_auc: 0.9022\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.7832 - accuracy: 0.8611 - auc: 0.8698 - val_loss: 2.3119 - val_accuracy: 0.8768 - val_auc: 0.8933\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.8690 - accuracy: 0.8465 - auc: 0.8482 - val_loss: 5.8155 - val_accuracy: 0.9139 - val_auc: 0.8962\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2214 - accuracy: 0.8800 - auc: 0.8876 - val_loss: 4.7649 - val_accuracy: 0.8901 - val_auc: 0.8998\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1260 - accuracy: 0.8939 - auc: 0.8958 - val_loss: 6.8973 - val_accuracy: 0.9052 - val_auc: 0.9148\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.5711 - accuracy: 0.8720 - auc: 0.8689 - val_loss: 18.6186 - val_accuracy: 0.9161 - val_auc: 0.9156\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.1096 - accuracy: 0.8876 - auc: 0.8838 - val_loss: 15.8440 - val_accuracy: 0.9278 - val_auc: 0.9164\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4340 - accuracy: 0.9133 - auc: 0.8849 - val_loss: 8.6425 - val_accuracy: 0.9033 - val_auc: 0.9162\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.3899 - accuracy: 0.8650 - auc: 0.8274 - val_loss: 11.9385 - val_accuracy: 0.8715 - val_auc: 0.9076\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2619 - accuracy: 0.9051 - auc: 0.8591 - val_loss: 18.8290 - val_accuracy: 0.8628 - val_auc: 0.9048\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.6290 - accuracy: 0.8408 - auc: 0.8544 - val_loss: 14.3145 - val_accuracy: 0.5697 - val_auc: 0.9045\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2984 - accuracy: 0.7364 - auc: 0.8597 - val_loss: 11.2860 - val_accuracy: 0.8980 - val_auc: 0.9015\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8265 - accuracy: 0.9215 - auc: 0.8752 - val_loss: 17.9289 - val_accuracy: 0.9027 - val_auc: 0.9087\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0429 - accuracy: 0.8567 - auc: 0.8750 - val_loss: 13.5229 - val_accuracy: 0.9167 - val_auc: 0.9082\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7813 - accuracy: 0.9321 - auc: 0.8778 - val_loss: 13.5048 - val_accuracy: 0.9534 - val_auc: 0.9038\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6087 - accuracy: 0.6487 - auc: 0.8607 - val_loss: 14.9706 - val_accuracy: 0.8856 - val_auc: 0.9173\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9974 - accuracy: 0.8739 - auc: 0.8697 - val_loss: 12.6978 - val_accuracy: 0.9170 - val_auc: 0.9141\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8283 - accuracy: 0.8968 - auc: 0.8824 - val_loss: 19.0544 - val_accuracy: 0.9115 - val_auc: 0.9133\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5849 - accuracy: 0.9350 - auc: 0.8882 - val_loss: 18.7379 - val_accuracy: 0.9262 - val_auc: 0.9171\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5838 - accuracy: 0.7579 - auc: 0.8710 - val_loss: 17.3723 - val_accuracy: 0.9102 - val_auc: 0.9091\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5431 - accuracy: 0.6052 - auc: 0.8622 - val_loss: 17.2671 - val_accuracy: 0.9062 - val_auc: 0.9133\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1932 - accuracy: 0.7916 - auc: 0.8834 - val_loss: 21.9365 - val_accuracy: 0.9519 - val_auc: 0.8579\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8718 - accuracy: 0.9354 - auc: 0.8952 - val_loss: 29.5362 - val_accuracy: 0.8803 - val_auc: 0.9105\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7832 - accuracy: 0.8117 - auc: 0.8814 - val_loss: 31.3891 - val_accuracy: 0.5856 - val_auc: 0.9063\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6256 - accuracy: 0.7654 - auc: 0.8741 - val_loss: 32.6111 - val_accuracy: 0.5856 - val_auc: 0.8982\n",
      "Epoch 31/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.5157 - accuracy: 0.8090 - auc: 0.8821Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5151 - accuracy: 0.8092 - auc: 0.8822 - val_loss: 34.6876 - val_accuracy: 0.9187 - val_auc: 0.9125\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 1.6883 - accuracy: 0.7197 - auc: 0.7894 - val_loss: 1.0829 - val_accuracy: 0.8393 - val_auc: 0.8752\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.7937 - accuracy: 0.7820 - auc: 0.8293 - val_loss: 1.5203 - val_accuracy: 0.9408 - val_auc: 0.8876\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.8530 - accuracy: 0.8051 - auc: 0.8354 - val_loss: 2.2412 - val_accuracy: 0.9142 - val_auc: 0.8867\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.3612 - accuracy: 0.7999 - auc: 0.8319 - val_loss: 3.2224 - val_accuracy: 0.8953 - val_auc: 0.8901\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.7077 - accuracy: 0.8046 - auc: 0.8281 - val_loss: 3.1162 - val_accuracy: 0.9215 - val_auc: 0.8892\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.5865 - accuracy: 0.8624 - auc: 0.8605 - val_loss: 3.2035 - val_accuracy: 0.8864 - val_auc: 0.8756\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4111 - accuracy: 0.8495 - auc: 0.8560 - val_loss: 3.2377 - val_accuracy: 0.8542 - val_auc: 0.8868\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0682 - accuracy: 0.8582 - auc: 0.8762 - val_loss: 2.4599 - val_accuracy: 0.9243 - val_auc: 0.8956\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1836 - accuracy: 0.8779 - auc: 0.8609 - val_loss: 3.2323 - val_accuracy: 0.8769 - val_auc: 0.9043\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.8536 - accuracy: 0.8493 - auc: 0.8463 - val_loss: 3.7064 - val_accuracy: 0.8562 - val_auc: 0.8933\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2741 - accuracy: 0.8769 - auc: 0.8405 - val_loss: 5.0657 - val_accuracy: 0.5711 - val_auc: 0.8954\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7617 - accuracy: 0.7825 - auc: 0.8755 - val_loss: 3.4241 - val_accuracy: 0.9392 - val_auc: 0.9043\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8310 - accuracy: 0.9077 - auc: 0.8778 - val_loss: 4.4673 - val_accuracy: 0.6441 - val_auc: 0.9193\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6085 - accuracy: 0.8636 - auc: 0.8931 - val_loss: 3.4245 - val_accuracy: 0.8866 - val_auc: 0.9144\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7916 - accuracy: 0.7634 - auc: 0.8762 - val_loss: 2.1148 - val_accuracy: 0.7115 - val_auc: 0.8939\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6472 - accuracy: 0.8591 - auc: 0.8816 - val_loss: 4.3847 - val_accuracy: 0.8994 - val_auc: 0.9163\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7629 - accuracy: 0.9009 - auc: 0.8813 - val_loss: 6.6665 - val_accuracy: 0.8832 - val_auc: 0.9172\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8555 - accuracy: 0.8985 - auc: 0.8821 - val_loss: 7.1072 - val_accuracy: 0.6074 - val_auc: 0.9139\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6718 - accuracy: 0.8557 - auc: 0.8852 - val_loss: 7.7015 - val_accuracy: 0.8782 - val_auc: 0.9166\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5633 - accuracy: 0.9101 - auc: 0.8897 - val_loss: 7.0065 - val_accuracy: 0.8919 - val_auc: 0.9165\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5702 - accuracy: 0.9141 - auc: 0.8846 - val_loss: 4.2818 - val_accuracy: 0.8527 - val_auc: 0.9204\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4681 - accuracy: 0.8170 - auc: 0.8889 - val_loss: 4.3251 - val_accuracy: 0.8972 - val_auc: 0.9233\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5260 - accuracy: 0.8875 - auc: 0.8836 - val_loss: 5.1321 - val_accuracy: 0.8649 - val_auc: 0.9146\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5828 - accuracy: 0.8803 - auc: 0.8929 - val_loss: 6.7780 - val_accuracy: 0.8647 - val_auc: 0.9193\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4344 - accuracy: 0.8688 - auc: 0.8987 - val_loss: 7.4943 - val_accuracy: 0.6394 - val_auc: 0.9214\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3809 - accuracy: 0.8200 - auc: 0.9116 - val_loss: 7.5664 - val_accuracy: 0.8878 - val_auc: 0.9218\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3940 - accuracy: 0.9014 - auc: 0.9029 - val_loss: 7.3938 - val_accuracy: 0.9114 - val_auc: 0.9191\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3936 - accuracy: 0.9263 - auc: 0.9073 - val_loss: 7.5425 - val_accuracy: 0.9162 - val_auc: 0.9158\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5445 - accuracy: 0.8582 - auc: 0.8900 - val_loss: 5.5830 - val_accuracy: 0.9233 - val_auc: 0.9097\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4185 - accuracy: 0.7554 - auc: 0.8914 - val_loss: 5.8052 - val_accuracy: 0.8859 - val_auc: 0.9249\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4104 - accuracy: 0.7601 - auc: 0.8974 - val_loss: 5.8797 - val_accuracy: 0.6685 - val_auc: 0.9194\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4078 - accuracy: 0.7491 - auc: 0.8940 - val_loss: 6.1115 - val_accuracy: 0.6680 - val_auc: 0.9112\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4221 - accuracy: 0.6577 - auc: 0.8926 - val_loss: 6.3887 - val_accuracy: 0.9028 - val_auc: 0.9160\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3762 - accuracy: 0.7065 - auc: 0.9012 - val_loss: 6.1683 - val_accuracy: 0.9053 - val_auc: 0.9135\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4816 - accuracy: 0.8745 - auc: 0.9101 - val_loss: 5.5295 - val_accuracy: 0.6839 - val_auc: 0.9032\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4561 - accuracy: 0.5941 - auc: 0.8741 - val_loss: 6.4690 - val_accuracy: 0.6837 - val_auc: 0.9023\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4627 - accuracy: 0.6012 - auc: 0.8731 - val_loss: 6.8212 - val_accuracy: 0.6986 - val_auc: 0.9049\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4482 - accuracy: 0.6019 - auc: 0.8633 - val_loss: 5.9432 - val_accuracy: 0.6887 - val_auc: 0.8957\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6626 - accuracy: 0.5849 - auc: 0.8692 - val_loss: 10.2989 - val_accuracy: 0.6779 - val_auc: 0.9007\n",
      "Epoch 40/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.5812 - auc: 0.8791Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4704 - accuracy: 0.5811 - auc: 0.8793 - val_loss: 10.7524 - val_accuracy: 0.6729 - val_auc: 0.8847\n",
      "Epoch 00040: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.5701 - accuracy: 0.5543 - auc: 0.8476 - val_loss: 0.3559 - val_accuracy: 0.8215 - val_auc: 0.9328\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3919 - accuracy: 0.8290 - auc: 0.9155 - val_loss: 0.3272 - val_accuracy: 0.8603 - val_auc: 0.9368\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3638 - accuracy: 0.8665 - auc: 0.9253 - val_loss: 0.3170 - val_accuracy: 0.8666 - val_auc: 0.9402\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3618 - accuracy: 0.8724 - auc: 0.9246 - val_loss: 0.3353 - val_accuracy: 0.8682 - val_auc: 0.9342\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3360 - accuracy: 0.8817 - auc: 0.9360 - val_loss: 0.3267 - val_accuracy: 0.8892 - val_auc: 0.9365\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3347 - accuracy: 0.8783 - auc: 0.9368 - val_loss: 0.3255 - val_accuracy: 0.8808 - val_auc: 0.9385\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3289 - accuracy: 0.8819 - auc: 0.9372 - val_loss: 0.3341 - val_accuracy: 0.8827 - val_auc: 0.9358\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3269 - accuracy: 0.8845 - auc: 0.9380 - val_loss: 0.3410 - val_accuracy: 0.8860 - val_auc: 0.9359\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3179 - accuracy: 0.8860 - auc: 0.9408 - val_loss: 0.3483 - val_accuracy: 0.8847 - val_auc: 0.9354\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3117 - accuracy: 0.8897 - auc: 0.9429 - val_loss: 0.3621 - val_accuracy: 0.8896 - val_auc: 0.9345\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3198 - accuracy: 0.8890 - auc: 0.9400 - val_loss: 0.3671 - val_accuracy: 0.8895 - val_auc: 0.9336\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3110 - accuracy: 0.8861 - auc: 0.9426 - val_loss: 0.3700 - val_accuracy: 0.8905 - val_auc: 0.9355\n",
      "Epoch 13/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3168 - accuracy: 0.8873 - auc: 0.9410Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3184 - accuracy: 0.8873 - auc: 0.9403 - val_loss: 0.4236 - val_accuracy: 0.8858 - val_auc: 0.9298\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.6274 - accuracy: 0.5976 - auc: 0.7912 - val_loss: 0.3637 - val_accuracy: 0.8501 - val_auc: 0.9282\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4124 - accuracy: 0.8423 - auc: 0.9009 - val_loss: 0.3255 - val_accuracy: 0.8801 - val_auc: 0.9367\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3735 - accuracy: 0.8769 - auc: 0.9160 - val_loss: 0.3126 - val_accuracy: 0.8726 - val_auc: 0.9402\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3680 - accuracy: 0.8695 - auc: 0.9203 - val_loss: 0.3243 - val_accuracy: 0.8732 - val_auc: 0.9381\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3570 - accuracy: 0.8528 - auc: 0.9239 - val_loss: 0.3150 - val_accuracy: 0.8699 - val_auc: 0.9417\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3349 - accuracy: 0.8122 - auc: 0.9316 - val_loss: 0.3379 - val_accuracy: 0.8624 - val_auc: 0.9365\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3361 - accuracy: 0.8077 - auc: 0.9321 - val_loss: 0.3622 - val_accuracy: 0.8511 - val_auc: 0.9313\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3172 - accuracy: 0.8073 - auc: 0.9396 - val_loss: 0.3541 - val_accuracy: 0.8670 - val_auc: 0.9338\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3172 - accuracy: 0.8068 - auc: 0.9381 - val_loss: 0.3517 - val_accuracy: 0.8601 - val_auc: 0.9360\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3196 - accuracy: 0.8076 - auc: 0.9381 - val_loss: 0.3556 - val_accuracy: 0.8696 - val_auc: 0.9358\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3152 - accuracy: 0.8088 - auc: 0.9382 - val_loss: 0.3611 - val_accuracy: 0.8600 - val_auc: 0.9346\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3163 - accuracy: 0.8096 - auc: 0.9377 - val_loss: 0.4065 - val_accuracy: 0.8463 - val_auc: 0.9296\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3151 - accuracy: 0.7976 - auc: 0.9388 - val_loss: 0.3850 - val_accuracy: 0.8620 - val_auc: 0.9317\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3081 - accuracy: 0.8100 - auc: 0.9414 - val_loss: 0.4009 - val_accuracy: 0.8584 - val_auc: 0.9299\n",
      "Epoch 15/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.8013 - auc: 0.9451Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3017 - accuracy: 0.8014 - auc: 0.9438 - val_loss: 0.4110 - val_accuracy: 0.8589 - val_auc: 0.9274\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.5781 - accuracy: 0.5230 - auc: 0.8163 - val_loss: 0.3578 - val_accuracy: 0.8255 - val_auc: 0.9327\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4089 - accuracy: 0.8130 - auc: 0.9068 - val_loss: 0.3142 - val_accuracy: 0.8713 - val_auc: 0.9441\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3666 - accuracy: 0.8727 - auc: 0.9218 - val_loss: 0.3093 - val_accuracy: 0.8899 - val_auc: 0.9411\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3528 - accuracy: 0.8842 - auc: 0.9281 - val_loss: 0.3154 - val_accuracy: 0.8893 - val_auc: 0.9387\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3250 - accuracy: 0.8888 - auc: 0.9378 - val_loss: 0.3210 - val_accuracy: 0.8928 - val_auc: 0.9383\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3283 - accuracy: 0.8859 - auc: 0.9371 - val_loss: 0.3308 - val_accuracy: 0.9008 - val_auc: 0.9359\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3180 - accuracy: 0.8960 - auc: 0.9407 - val_loss: 0.3266 - val_accuracy: 0.8919 - val_auc: 0.9377\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3200 - accuracy: 0.8915 - auc: 0.9386 - val_loss: 0.3539 - val_accuracy: 0.8896 - val_auc: 0.9318\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3185 - accuracy: 0.8883 - auc: 0.9390 - val_loss: 0.3594 - val_accuracy: 0.8901 - val_auc: 0.9302\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3058 - accuracy: 0.8915 - auc: 0.9434 - val_loss: 0.3640 - val_accuracy: 0.8959 - val_auc: 0.9310\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3092 - accuracy: 0.8869 - auc: 0.9425 - val_loss: 0.3806 - val_accuracy: 0.8953 - val_auc: 0.9296\n",
      "Epoch 12/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3070 - accuracy: 0.8934 - auc: 0.9451Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3101 - accuracy: 0.8933 - auc: 0.9439 - val_loss: 0.3706 - val_accuracy: 0.8965 - val_auc: 0.9302\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.5415 - accuracy: 0.8399 - auc: 0.8161 - val_loss: 0.3666 - val_accuracy: 0.8909 - val_auc: 0.9253\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3845 - accuracy: 0.8944 - auc: 0.9187 - val_loss: 0.3270 - val_accuracy: 0.8995 - val_auc: 0.9353\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3663 - accuracy: 0.8964 - auc: 0.9233 - val_loss: 0.3109 - val_accuracy: 0.8948 - val_auc: 0.9429\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3450 - accuracy: 0.9005 - auc: 0.9310 - val_loss: 0.3020 - val_accuracy: 0.8929 - val_auc: 0.9447\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3401 - accuracy: 0.9062 - auc: 0.9341 - val_loss: 0.3066 - val_accuracy: 0.9028 - val_auc: 0.9420\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3404 - accuracy: 0.9018 - auc: 0.9338 - val_loss: 0.3105 - val_accuracy: 0.9050 - val_auc: 0.9406\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3287 - accuracy: 0.9012 - auc: 0.9378 - val_loss: 0.3178 - val_accuracy: 0.8902 - val_auc: 0.9397\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3238 - accuracy: 0.9043 - auc: 0.9407 - val_loss: 0.3265 - val_accuracy: 0.8883 - val_auc: 0.9400\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3180 - accuracy: 0.8996 - auc: 0.9410 - val_loss: 0.3235 - val_accuracy: 0.9083 - val_auc: 0.9398\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3251 - accuracy: 0.9014 - auc: 0.9401 - val_loss: 0.3449 - val_accuracy: 0.8794 - val_auc: 0.9381\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3133 - accuracy: 0.8964 - auc: 0.9439 - val_loss: 0.3423 - val_accuracy: 0.8924 - val_auc: 0.9371\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3158 - accuracy: 0.8993 - auc: 0.9420 - val_loss: 0.3626 - val_accuracy: 0.8952 - val_auc: 0.9330\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3083 - accuracy: 0.8968 - auc: 0.9438 - val_loss: 0.3548 - val_accuracy: 0.9052 - val_auc: 0.9355\n",
      "Epoch 14/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.8964 - auc: 0.9453Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3043 - accuracy: 0.8964 - auc: 0.9456 - val_loss: 0.3715 - val_accuracy: 0.9051 - val_auc: 0.9360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.7030 - accuracy: 0.4517 - auc: 0.7648 - val_loss: 0.3436 - val_accuracy: 0.8263 - val_auc: 0.9296\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4244 - accuracy: 0.7542 - auc: 0.9017 - val_loss: 0.3284 - val_accuracy: 0.8510 - val_auc: 0.9362\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3765 - accuracy: 0.7836 - auc: 0.9161 - val_loss: 0.3298 - val_accuracy: 0.8306 - val_auc: 0.9362\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3522 - accuracy: 0.7895 - auc: 0.9280 - val_loss: 0.3346 - val_accuracy: 0.8442 - val_auc: 0.9344\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3458 - accuracy: 0.7966 - auc: 0.9293 - val_loss: 0.3388 - val_accuracy: 0.8480 - val_auc: 0.9347\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3351 - accuracy: 0.8069 - auc: 0.9321 - val_loss: 0.3440 - val_accuracy: 0.8383 - val_auc: 0.9338\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3266 - accuracy: 0.8062 - auc: 0.9366 - val_loss: 0.3522 - val_accuracy: 0.8483 - val_auc: 0.9326\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3181 - accuracy: 0.8031 - auc: 0.9388 - val_loss: 0.3676 - val_accuracy: 0.8478 - val_auc: 0.9296\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3299 - accuracy: 0.8119 - auc: 0.9348 - val_loss: 0.3454 - val_accuracy: 0.8574 - val_auc: 0.9352\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3270 - accuracy: 0.8121 - auc: 0.9364 - val_loss: 0.3633 - val_accuracy: 0.8492 - val_auc: 0.9318\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3239 - accuracy: 0.8083 - auc: 0.9374 - val_loss: 0.3965 - val_accuracy: 0.8553 - val_auc: 0.9282\n",
      "Epoch 12/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3101 - accuracy: 0.8126 - auc: 0.9402Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3123 - accuracy: 0.8124 - auc: 0.9397 - val_loss: 0.3931 - val_accuracy: 0.8625 - val_auc: 0.9291\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5549 - accuracy: 0.7420 - auc: 0.8534 - val_loss: 0.3578 - val_accuracy: 0.8442 - val_auc: 0.9313\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3694 - accuracy: 0.8565 - auc: 0.9243 - val_loss: 0.3088 - val_accuracy: 0.8781 - val_auc: 0.9440\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3350 - accuracy: 0.8767 - auc: 0.9344 - val_loss: 0.3196 - val_accuracy: 0.8786 - val_auc: 0.9401\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3272 - accuracy: 0.8814 - auc: 0.9403 - val_loss: 0.3184 - val_accuracy: 0.8892 - val_auc: 0.9390\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3180 - accuracy: 0.8777 - auc: 0.9418 - val_loss: 0.3119 - val_accuracy: 0.9000 - val_auc: 0.9422\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3115 - accuracy: 0.8888 - auc: 0.9438 - val_loss: 0.3296 - val_accuracy: 0.8678 - val_auc: 0.9377\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2924 - accuracy: 0.8788 - auc: 0.9500 - val_loss: 0.3358 - val_accuracy: 0.8939 - val_auc: 0.9385\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2920 - accuracy: 0.8860 - auc: 0.9501 - val_loss: 0.3561 - val_accuracy: 0.8984 - val_auc: 0.9346\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2933 - accuracy: 0.8853 - auc: 0.9498 - val_loss: 0.3747 - val_accuracy: 0.8862 - val_auc: 0.9318\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2892 - accuracy: 0.8833 - auc: 0.9508 - val_loss: 0.3825 - val_accuracy: 0.8878 - val_auc: 0.9316\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2901 - accuracy: 0.8856 - auc: 0.9518 - val_loss: 0.3907 - val_accuracy: 0.8846 - val_auc: 0.9305\n",
      "Epoch 12/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2861 - accuracy: 0.8819 - auc: 0.9524Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2876 - accuracy: 0.8812 - auc: 0.9521 - val_loss: 0.4207 - val_accuracy: 0.8767 - val_auc: 0.9208\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 21us/sample - loss: 0.5780 - accuracy: 0.5975 - auc: 0.8525 - val_loss: 0.3370 - val_accuracy: 0.8386 - val_auc: 0.9312\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3916 - accuracy: 0.7798 - auc: 0.9187 - val_loss: 0.3253 - val_accuracy: 0.8593 - val_auc: 0.9368\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3555 - accuracy: 0.8145 - auc: 0.9285 - val_loss: 0.3393 - val_accuracy: 0.8494 - val_auc: 0.9330\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3169 - accuracy: 0.8346 - auc: 0.9417 - val_loss: 0.3355 - val_accuracy: 0.8644 - val_auc: 0.9363\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3189 - accuracy: 0.8232 - auc: 0.9414 - val_loss: 0.3255 - val_accuracy: 0.8682 - val_auc: 0.9393\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3070 - accuracy: 0.8405 - auc: 0.9454 - val_loss: 0.3364 - val_accuracy: 0.8647 - val_auc: 0.9365\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3063 - accuracy: 0.8359 - auc: 0.9451 - val_loss: 0.3442 - val_accuracy: 0.8735 - val_auc: 0.9357\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2915 - accuracy: 0.8502 - auc: 0.9492 - val_loss: 0.3432 - val_accuracy: 0.8653 - val_auc: 0.9367\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2832 - accuracy: 0.8479 - auc: 0.9524 - val_loss: 0.3641 - val_accuracy: 0.8822 - val_auc: 0.9347\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2814 - accuracy: 0.8595 - auc: 0.9529 - val_loss: 0.3946 - val_accuracy: 0.8767 - val_auc: 0.9307\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2681 - accuracy: 0.8597 - auc: 0.9567 - val_loss: 0.4192 - val_accuracy: 0.8865 - val_auc: 0.9298\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2763 - accuracy: 0.8627 - auc: 0.9545 - val_loss: 0.4170 - val_accuracy: 0.8770 - val_auc: 0.9292\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2754 - accuracy: 0.8536 - auc: 0.9546 - val_loss: 0.4306 - val_accuracy: 0.8835 - val_auc: 0.9297\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2719 - accuracy: 0.8614 - auc: 0.9561 - val_loss: 0.4425 - val_accuracy: 0.8779 - val_auc: 0.9301\n",
      "Epoch 15/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.8535 - auc: 0.9565Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2686 - accuracy: 0.8535 - auc: 0.9567 - val_loss: 0.4773 - val_accuracy: 0.8784 - val_auc: 0.9270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6787 - accuracy: 0.5689 - auc: 0.7932 - val_loss: 0.3448 - val_accuracy: 0.8648 - val_auc: 0.9326\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3801 - accuracy: 0.8337 - auc: 0.9159 - val_loss: 0.3361 - val_accuracy: 0.8549 - val_auc: 0.9382\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3510 - accuracy: 0.8401 - auc: 0.9269 - val_loss: 0.3184 - val_accuracy: 0.8675 - val_auc: 0.9389\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3154 - accuracy: 0.8563 - auc: 0.9396 - val_loss: 0.3282 - val_accuracy: 0.8885 - val_auc: 0.9372\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3033 - accuracy: 0.8570 - auc: 0.9445 - val_loss: 0.3475 - val_accuracy: 0.8918 - val_auc: 0.9350\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2954 - accuracy: 0.8632 - auc: 0.9468 - val_loss: 0.3538 - val_accuracy: 0.8912 - val_auc: 0.9347\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3031 - accuracy: 0.8593 - auc: 0.9447 - val_loss: 0.3521 - val_accuracy: 0.8797 - val_auc: 0.9325\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2885 - accuracy: 0.8626 - auc: 0.9489 - val_loss: 0.3762 - val_accuracy: 0.8834 - val_auc: 0.9312\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2834 - accuracy: 0.8635 - auc: 0.9510 - val_loss: 0.3999 - val_accuracy: 0.8825 - val_auc: 0.9281\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2733 - accuracy: 0.8691 - auc: 0.9537 - val_loss: 0.4174 - val_accuracy: 0.8926 - val_auc: 0.9278\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2763 - accuracy: 0.8672 - auc: 0.9526 - val_loss: 0.4253 - val_accuracy: 0.8841 - val_auc: 0.9286\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2865 - accuracy: 0.8554 - auc: 0.9509 - val_loss: 0.4402 - val_accuracy: 0.8832 - val_auc: 0.9269\n",
      "Epoch 13/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2764 - accuracy: 0.8684 - auc: 0.9530Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2853 - accuracy: 0.8680 - auc: 0.9507 - val_loss: 0.4595 - val_accuracy: 0.8821 - val_auc: 0.9284\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.5094 - accuracy: 0.7738 - auc: 0.8560 - val_loss: 0.3214 - val_accuracy: 0.8790 - val_auc: 0.9452\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3526 - accuracy: 0.8784 - auc: 0.9269 - val_loss: 0.3028 - val_accuracy: 0.8947 - val_auc: 0.9453\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3377 - accuracy: 0.8881 - auc: 0.9351 - val_loss: 0.2977 - val_accuracy: 0.8979 - val_auc: 0.9472\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3136 - accuracy: 0.8916 - auc: 0.9425 - val_loss: 0.2970 - val_accuracy: 0.8908 - val_auc: 0.9464\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3106 - accuracy: 0.8937 - auc: 0.9432 - val_loss: 0.3012 - val_accuracy: 0.8821 - val_auc: 0.9461\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2861 - accuracy: 0.8951 - auc: 0.9521 - val_loss: 0.3098 - val_accuracy: 0.8989 - val_auc: 0.9429\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2942 - accuracy: 0.8912 - auc: 0.9484 - val_loss: 0.3105 - val_accuracy: 0.8958 - val_auc: 0.9421\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2878 - accuracy: 0.8928 - auc: 0.9512 - val_loss: 0.3143 - val_accuracy: 0.8980 - val_auc: 0.9436\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2947 - accuracy: 0.8941 - auc: 0.9490 - val_loss: 0.3202 - val_accuracy: 0.9030 - val_auc: 0.9415\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2880 - accuracy: 0.8901 - auc: 0.9510 - val_loss: 0.3236 - val_accuracy: 0.9051 - val_auc: 0.9427\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2736 - accuracy: 0.8916 - auc: 0.9558 - val_loss: 0.3376 - val_accuracy: 0.8809 - val_auc: 0.9403\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2757 - accuracy: 0.8855 - auc: 0.9546 - val_loss: 0.3415 - val_accuracy: 0.8906 - val_auc: 0.9387\n",
      "Epoch 13/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.8906 - auc: 0.9564Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2728 - accuracy: 0.8905 - auc: 0.9563 - val_loss: 0.3552 - val_accuracy: 0.8843 - val_auc: 0.9365\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.5515 - accuracy: 0.7008 - auc: 0.8463 - val_loss: 0.3384 - val_accuracy: 0.8701 - val_auc: 0.9347\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3709 - accuracy: 0.8577 - auc: 0.9215 - val_loss: 0.3298 - val_accuracy: 0.8833 - val_auc: 0.9386\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3503 - accuracy: 0.8741 - auc: 0.9328 - val_loss: 0.3312 - val_accuracy: 0.8980 - val_auc: 0.9383\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3315 - accuracy: 0.8833 - auc: 0.9368 - val_loss: 0.3281 - val_accuracy: 0.8933 - val_auc: 0.9381\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3266 - accuracy: 0.8796 - auc: 0.9389 - val_loss: 0.3270 - val_accuracy: 0.8876 - val_auc: 0.9359\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3192 - accuracy: 0.8831 - auc: 0.9412 - val_loss: 0.3318 - val_accuracy: 0.8812 - val_auc: 0.9353\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3075 - accuracy: 0.8847 - auc: 0.9460 - val_loss: 0.3411 - val_accuracy: 0.8860 - val_auc: 0.9334\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3095 - accuracy: 0.8896 - auc: 0.9446 - val_loss: 0.3454 - val_accuracy: 0.8744 - val_auc: 0.9339\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2896 - accuracy: 0.8896 - auc: 0.9519 - val_loss: 0.3660 - val_accuracy: 0.8920 - val_auc: 0.9319\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2875 - accuracy: 0.8869 - auc: 0.9518 - val_loss: 0.3831 - val_accuracy: 0.9003 - val_auc: 0.9327\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2806 - accuracy: 0.8902 - auc: 0.9540 - val_loss: 0.3879 - val_accuracy: 0.8936 - val_auc: 0.9301\n",
      "Epoch 12/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2830 - accuracy: 0.8842 - auc: 0.9535Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2841 - accuracy: 0.8845 - auc: 0.9531 - val_loss: 0.4006 - val_accuracy: 0.8984 - val_auc: 0.9286\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5910 - accuracy: 0.6618 - auc: 0.8517 - val_loss: 0.3676 - val_accuracy: 0.8341 - val_auc: 0.9253\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3826 - accuracy: 0.8206 - auc: 0.9209 - val_loss: 0.3264 - val_accuracy: 0.8503 - val_auc: 0.9398\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3561 - accuracy: 0.8262 - auc: 0.9290 - val_loss: 0.3105 - val_accuracy: 0.8601 - val_auc: 0.9437\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3140 - accuracy: 0.8459 - auc: 0.9423 - val_loss: 0.3272 - val_accuracy: 0.8684 - val_auc: 0.9384\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3123 - accuracy: 0.8538 - auc: 0.9434 - val_loss: 0.3446 - val_accuracy: 0.8724 - val_auc: 0.9347\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3030 - accuracy: 0.8515 - auc: 0.9473 - val_loss: 0.3238 - val_accuracy: 0.8661 - val_auc: 0.9407\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3021 - accuracy: 0.8536 - auc: 0.9469 - val_loss: 0.3738 - val_accuracy: 0.8787 - val_auc: 0.9311\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2851 - accuracy: 0.8694 - auc: 0.9520 - val_loss: 0.3906 - val_accuracy: 0.8730 - val_auc: 0.9223\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2744 - accuracy: 0.8647 - auc: 0.9550 - val_loss: 0.3939 - val_accuracy: 0.8849 - val_auc: 0.9293\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2762 - accuracy: 0.8685 - auc: 0.9556 - val_loss: 0.4344 - val_accuracy: 0.8807 - val_auc: 0.9229\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2670 - accuracy: 0.8736 - auc: 0.9574 - val_loss: 0.4724 - val_accuracy: 0.8851 - val_auc: 0.9217\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2746 - accuracy: 0.8659 - auc: 0.9555 - val_loss: 0.5206 - val_accuracy: 0.8980 - val_auc: 0.9161\n",
      "Epoch 13/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2614 - accuracy: 0.8700 - auc: 0.9585Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2611 - accuracy: 0.8700 - auc: 0.9585 - val_loss: 0.5032 - val_accuracy: 0.8927 - val_auc: 0.9202\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6679 - accuracy: 0.8055 - auc: 0.8288 - val_loss: 0.3885 - val_accuracy: 0.8789 - val_auc: 0.9248\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3800 - accuracy: 0.8866 - auc: 0.9237 - val_loss: 0.3436 - val_accuracy: 0.8825 - val_auc: 0.9331\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3390 - accuracy: 0.8940 - auc: 0.9358 - val_loss: 0.3766 - val_accuracy: 0.8948 - val_auc: 0.9229\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3422 - accuracy: 0.8922 - auc: 0.9352 - val_loss: 0.3394 - val_accuracy: 0.9055 - val_auc: 0.9309\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3270 - accuracy: 0.8996 - auc: 0.9407 - val_loss: 0.3388 - val_accuracy: 0.9008 - val_auc: 0.9311\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3346 - accuracy: 0.8957 - auc: 0.9403 - val_loss: 0.3377 - val_accuracy: 0.8966 - val_auc: 0.9331\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3098 - accuracy: 0.8992 - auc: 0.9460 - val_loss: 0.3343 - val_accuracy: 0.9080 - val_auc: 0.9314\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3060 - accuracy: 0.8983 - auc: 0.9475 - val_loss: 0.3545 - val_accuracy: 0.8953 - val_auc: 0.9307\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3078 - accuracy: 0.8959 - auc: 0.9460 - val_loss: 0.3591 - val_accuracy: 0.8900 - val_auc: 0.9322\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3016 - accuracy: 0.8942 - auc: 0.9497 - val_loss: 0.4045 - val_accuracy: 0.9001 - val_auc: 0.9277\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2892 - accuracy: 0.8958 - auc: 0.9519 - val_loss: 0.4098 - val_accuracy: 0.9047 - val_auc: 0.9276\n",
      "Epoch 12/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2871 - accuracy: 0.8993 - auc: 0.9526Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2865 - accuracy: 0.8986 - auc: 0.9531 - val_loss: 0.4003 - val_accuracy: 0.8861 - val_auc: 0.9287\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5499 - accuracy: 0.6963 - auc: 0.8550 - val_loss: 0.3411 - val_accuracy: 0.8451 - val_auc: 0.9333\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3699 - accuracy: 0.8186 - auc: 0.9223 - val_loss: 0.3199 - val_accuracy: 0.8773 - val_auc: 0.9373\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3372 - accuracy: 0.8508 - auc: 0.9322 - val_loss: 0.3350 - val_accuracy: 0.8519 - val_auc: 0.9329\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3232 - accuracy: 0.8460 - auc: 0.9368 - val_loss: 0.3449 - val_accuracy: 0.8735 - val_auc: 0.9284\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3179 - accuracy: 0.8614 - auc: 0.9405 - val_loss: 0.3358 - val_accuracy: 0.8787 - val_auc: 0.9337\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2904 - accuracy: 0.8654 - auc: 0.9481 - val_loss: 0.3513 - val_accuracy: 0.8641 - val_auc: 0.9318\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2876 - accuracy: 0.8672 - auc: 0.9497 - val_loss: 0.3420 - val_accuracy: 0.8738 - val_auc: 0.9345\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2873 - accuracy: 0.8728 - auc: 0.9497 - val_loss: 0.3565 - val_accuracy: 0.8584 - val_auc: 0.9322\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2933 - accuracy: 0.8650 - auc: 0.9487 - val_loss: 0.3482 - val_accuracy: 0.8867 - val_auc: 0.9347\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2787 - accuracy: 0.8783 - auc: 0.9525 - val_loss: 0.3931 - val_accuracy: 0.8938 - val_auc: 0.9245\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2732 - accuracy: 0.8784 - auc: 0.9541 - val_loss: 0.3901 - val_accuracy: 0.8772 - val_auc: 0.9260\n",
      "Epoch 12/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2747 - accuracy: 0.8774 - auc: 0.9537Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2744 - accuracy: 0.8774 - auc: 0.9537 - val_loss: 0.4075 - val_accuracy: 0.8901 - val_auc: 0.9224\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 5s 19us/sample - loss: 0.5441 - accuracy: 0.7966 - auc: 0.8445 - val_loss: 0.3516 - val_accuracy: 0.8434 - val_auc: 0.9365\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3629 - accuracy: 0.8677 - auc: 0.9262 - val_loss: 0.3087 - val_accuracy: 0.8844 - val_auc: 0.9427\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3433 - accuracy: 0.8859 - auc: 0.9331 - val_loss: 0.3132 - val_accuracy: 0.8961 - val_auc: 0.9391\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3083 - accuracy: 0.8952 - auc: 0.9441 - val_loss: 0.3351 - val_accuracy: 0.8994 - val_auc: 0.9324\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3064 - accuracy: 0.8925 - auc: 0.9450 - val_loss: 0.3129 - val_accuracy: 0.8832 - val_auc: 0.9427\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3064 - accuracy: 0.8892 - auc: 0.9465 - val_loss: 0.3154 - val_accuracy: 0.9125 - val_auc: 0.9411\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2910 - accuracy: 0.8929 - auc: 0.9509 - val_loss: 0.3181 - val_accuracy: 0.8718 - val_auc: 0.9419\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2828 - accuracy: 0.8872 - auc: 0.9531 - val_loss: 0.3430 - val_accuracy: 0.8944 - val_auc: 0.9346\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2782 - accuracy: 0.8950 - auc: 0.9545 - val_loss: 0.3452 - val_accuracy: 0.9015 - val_auc: 0.9363\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2734 - accuracy: 0.8916 - auc: 0.9551 - val_loss: 0.3568 - val_accuracy: 0.8778 - val_auc: 0.9367\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2826 - accuracy: 0.8906 - auc: 0.9532 - val_loss: 0.3434 - val_accuracy: 0.8928 - val_auc: 0.9385\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2769 - accuracy: 0.8883 - auc: 0.9557 - val_loss: 0.3866 - val_accuracy: 0.9105 - val_auc: 0.9338\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2687 - accuracy: 0.8964 - auc: 0.9573 - val_loss: 0.3842 - val_accuracy: 0.8938 - val_auc: 0.9345\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2633 - accuracy: 0.8950 - auc: 0.9584 - val_loss: 0.4057 - val_accuracy: 0.8962 - val_auc: 0.9346\n",
      "Epoch 15/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.8946 - auc: 0.9582Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2626 - accuracy: 0.8944 - auc: 0.9584 - val_loss: 0.4006 - val_accuracy: 0.8963 - val_auc: 0.9352\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.5945 - accuracy: 0.6059 - auc: 0.8484 - val_loss: 0.3602 - val_accuracy: 0.8279 - val_auc: 0.9282\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4114 - accuracy: 0.7924 - auc: 0.9112 - val_loss: 0.3277 - val_accuracy: 0.8253 - val_auc: 0.9381\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3651 - accuracy: 0.8051 - auc: 0.9287 - val_loss: 0.3208 - val_accuracy: 0.8676 - val_auc: 0.9388\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3290 - accuracy: 0.8279 - auc: 0.9393 - val_loss: 0.3168 - val_accuracy: 0.8762 - val_auc: 0.9421\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3182 - accuracy: 0.8397 - auc: 0.9418 - val_loss: 0.3223 - val_accuracy: 0.8725 - val_auc: 0.9395\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3119 - accuracy: 0.8470 - auc: 0.9440 - val_loss: 0.3182 - val_accuracy: 0.8737 - val_auc: 0.9406\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2957 - accuracy: 0.8552 - auc: 0.9478 - val_loss: 0.3221 - val_accuracy: 0.8653 - val_auc: 0.9401\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2813 - accuracy: 0.8514 - auc: 0.9531 - val_loss: 0.3430 - val_accuracy: 0.8834 - val_auc: 0.9397\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2906 - accuracy: 0.8593 - auc: 0.9504 - val_loss: 0.3496 - val_accuracy: 0.8754 - val_auc: 0.9364\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2726 - accuracy: 0.8654 - auc: 0.9555 - val_loss: 0.3561 - val_accuracy: 0.8791 - val_auc: 0.9350\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2706 - accuracy: 0.8628 - auc: 0.9568 - val_loss: 0.3734 - val_accuracy: 0.8876 - val_auc: 0.9348\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2723 - accuracy: 0.8646 - auc: 0.9560 - val_loss: 0.3969 - val_accuracy: 0.8763 - val_auc: 0.9269\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2729 - accuracy: 0.8648 - auc: 0.9563 - val_loss: 0.3894 - val_accuracy: 0.8773 - val_auc: 0.9305\n",
      "Epoch 14/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.8708 - auc: 0.9587Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2637 - accuracy: 0.8708 - auc: 0.9587 - val_loss: 0.4141 - val_accuracy: 0.8906 - val_auc: 0.9299\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5334 - accuracy: 0.8203 - auc: 0.8589 - val_loss: 0.3567 - val_accuracy: 0.8961 - val_auc: 0.9225\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3647 - accuracy: 0.8791 - auc: 0.9261 - val_loss: 0.3165 - val_accuracy: 0.9012 - val_auc: 0.9452\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3415 - accuracy: 0.8955 - auc: 0.9373 - val_loss: 0.3300 - val_accuracy: 0.9039 - val_auc: 0.9357\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3220 - accuracy: 0.8969 - auc: 0.9437 - val_loss: 0.3362 - val_accuracy: 0.9084 - val_auc: 0.9313\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3268 - accuracy: 0.8946 - auc: 0.9413 - val_loss: 0.3569 - val_accuracy: 0.8851 - val_auc: 0.9286\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3177 - accuracy: 0.8929 - auc: 0.9437 - val_loss: 0.3324 - val_accuracy: 0.9131 - val_auc: 0.9365\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3081 - accuracy: 0.8984 - auc: 0.9478 - val_loss: 0.3582 - val_accuracy: 0.8936 - val_auc: 0.9337\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2936 - accuracy: 0.8966 - auc: 0.9508 - val_loss: 0.3382 - val_accuracy: 0.8967 - val_auc: 0.9373\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2928 - accuracy: 0.8965 - auc: 0.9505 - val_loss: 0.3568 - val_accuracy: 0.9232 - val_auc: 0.9353\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2838 - accuracy: 0.8961 - auc: 0.9541 - val_loss: 0.3851 - val_accuracy: 0.9001 - val_auc: 0.9327\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2855 - accuracy: 0.8960 - auc: 0.9537 - val_loss: 0.3922 - val_accuracy: 0.8998 - val_auc: 0.9319\n",
      "Epoch 12/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.8953 - auc: 0.9562Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2754 - accuracy: 0.8952 - auc: 0.9566 - val_loss: 0.4001 - val_accuracy: 0.8959 - val_auc: 0.9333\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5127 - accuracy: 0.7647 - auc: 0.8734 - val_loss: 0.3694 - val_accuracy: 0.8737 - val_auc: 0.9245\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3755 - accuracy: 0.8566 - auc: 0.9212 - val_loss: 0.3196 - val_accuracy: 0.8917 - val_auc: 0.9407\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3380 - accuracy: 0.8775 - auc: 0.9361 - val_loss: 0.3119 - val_accuracy: 0.8923 - val_auc: 0.9427\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3073 - accuracy: 0.8864 - auc: 0.9451 - val_loss: 0.3235 - val_accuracy: 0.8812 - val_auc: 0.9387\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3093 - accuracy: 0.8860 - auc: 0.9452 - val_loss: 0.3154 - val_accuracy: 0.8920 - val_auc: 0.9405\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2951 - accuracy: 0.8861 - auc: 0.9491 - val_loss: 0.3348 - val_accuracy: 0.8995 - val_auc: 0.9352\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2858 - accuracy: 0.8931 - auc: 0.9517 - val_loss: 0.3369 - val_accuracy: 0.9093 - val_auc: 0.9359\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2806 - accuracy: 0.8941 - auc: 0.9545 - val_loss: 0.3442 - val_accuracy: 0.9064 - val_auc: 0.9370\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2801 - accuracy: 0.8878 - auc: 0.9540 - val_loss: 0.3511 - val_accuracy: 0.8992 - val_auc: 0.9339\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2790 - accuracy: 0.8955 - auc: 0.9544 - val_loss: 0.3603 - val_accuracy: 0.9052 - val_auc: 0.9329\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2875 - accuracy: 0.8927 - auc: 0.9540 - val_loss: 0.3449 - val_accuracy: 0.8987 - val_auc: 0.9380\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2758 - accuracy: 0.8961 - auc: 0.9555 - val_loss: 0.3539 - val_accuracy: 0.9091 - val_auc: 0.9374\n",
      "Epoch 13/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.8950 - auc: 0.9595Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2614 - accuracy: 0.8950 - auc: 0.9595 - val_loss: 0.3924 - val_accuracy: 0.9036 - val_auc: 0.9303\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6552 - accuracy: 0.7287 - auc: 0.8331 - val_loss: 0.3464 - val_accuracy: 0.8502 - val_auc: 0.9390\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3670 - accuracy: 0.8394 - auc: 0.9238 - val_loss: 0.3506 - val_accuracy: 0.8499 - val_auc: 0.9341\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3418 - accuracy: 0.8614 - auc: 0.9320 - val_loss: 0.3407 - val_accuracy: 0.8569 - val_auc: 0.9344\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3229 - accuracy: 0.8738 - auc: 0.9391 - val_loss: 0.3303 - val_accuracy: 0.8791 - val_auc: 0.9382\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3007 - accuracy: 0.8733 - auc: 0.9452 - val_loss: 0.3452 - val_accuracy: 0.8835 - val_auc: 0.9315\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2951 - accuracy: 0.8762 - auc: 0.9474 - val_loss: 0.3401 - val_accuracy: 0.8863 - val_auc: 0.9355\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3023 - accuracy: 0.8775 - auc: 0.9455 - val_loss: 0.3598 - val_accuracy: 0.8858 - val_auc: 0.9318\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2842 - accuracy: 0.8849 - auc: 0.9516 - val_loss: 0.3716 - val_accuracy: 0.8939 - val_auc: 0.9326\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2768 - accuracy: 0.8872 - auc: 0.9546 - val_loss: 0.3996 - val_accuracy: 0.8998 - val_auc: 0.9311\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2809 - accuracy: 0.8860 - auc: 0.9524 - val_loss: 0.3821 - val_accuracy: 0.8920 - val_auc: 0.9318\n",
      "Epoch 11/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.8854 - auc: 0.9576Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2610 - accuracy: 0.8856 - auc: 0.9580 - val_loss: 0.3973 - val_accuracy: 0.9009 - val_auc: 0.9312\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.4678 - accuracy: 0.8506 - auc: 0.8808 - val_loss: 0.3364 - val_accuracy: 0.8878 - val_auc: 0.9353\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3567 - accuracy: 0.8884 - auc: 0.9275 - val_loss: 0.3120 - val_accuracy: 0.8856 - val_auc: 0.9451\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3267 - accuracy: 0.8953 - auc: 0.9397 - val_loss: 0.3061 - val_accuracy: 0.8822 - val_auc: 0.9475\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3132 - accuracy: 0.8997 - auc: 0.9458 - val_loss: 0.3129 - val_accuracy: 0.8756 - val_auc: 0.9426\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3034 - accuracy: 0.8951 - auc: 0.9476 - val_loss: 0.3162 - val_accuracy: 0.9231 - val_auc: 0.9392\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3010 - accuracy: 0.8988 - auc: 0.9484 - val_loss: 0.3003 - val_accuracy: 0.9105 - val_auc: 0.9454\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2960 - accuracy: 0.9025 - auc: 0.9524 - val_loss: 0.3439 - val_accuracy: 0.9023 - val_auc: 0.9329\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2801 - accuracy: 0.9009 - auc: 0.9554 - val_loss: 0.3362 - val_accuracy: 0.8901 - val_auc: 0.9350\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2787 - accuracy: 0.9021 - auc: 0.9550 - val_loss: 0.3410 - val_accuracy: 0.8936 - val_auc: 0.9369\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2903 - accuracy: 0.9017 - auc: 0.9542 - val_loss: 0.3878 - val_accuracy: 0.8972 - val_auc: 0.9300\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2740 - accuracy: 0.8973 - auc: 0.9568 - val_loss: 0.3721 - val_accuracy: 0.9102 - val_auc: 0.9338\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2759 - accuracy: 0.8988 - auc: 0.9559 - val_loss: 0.3829 - val_accuracy: 0.9121 - val_auc: 0.9310\n",
      "Epoch 13/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.9019 - auc: 0.9566Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2773 - accuracy: 0.9020 - auc: 0.9566 - val_loss: 0.4462 - val_accuracy: 0.9364 - val_auc: 0.9296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.4936 - accuracy: 0.7448 - auc: 0.8744 - val_loss: 0.3593 - val_accuracy: 0.8265 - val_auc: 0.9345\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3554 - accuracy: 0.8407 - auc: 0.9315 - val_loss: 0.3155 - val_accuracy: 0.8788 - val_auc: 0.9383\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3320 - accuracy: 0.8584 - auc: 0.9383 - val_loss: 0.3124 - val_accuracy: 0.8771 - val_auc: 0.9403\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3108 - accuracy: 0.8650 - auc: 0.9440 - val_loss: 0.3113 - val_accuracy: 0.8832 - val_auc: 0.9423\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3186 - accuracy: 0.8641 - auc: 0.9422 - val_loss: 0.3157 - val_accuracy: 0.8808 - val_auc: 0.9386\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3005 - accuracy: 0.8712 - auc: 0.9474 - val_loss: 0.3202 - val_accuracy: 0.8935 - val_auc: 0.9406\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2879 - accuracy: 0.8744 - auc: 0.9514 - val_loss: 0.3552 - val_accuracy: 0.8885 - val_auc: 0.9310\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2846 - accuracy: 0.8752 - auc: 0.9532 - val_loss: 0.3559 - val_accuracy: 0.8820 - val_auc: 0.9332\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2865 - accuracy: 0.8782 - auc: 0.9518 - val_loss: 0.3662 - val_accuracy: 0.8958 - val_auc: 0.9296\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2903 - accuracy: 0.8823 - auc: 0.9520 - val_loss: 0.3565 - val_accuracy: 0.8913 - val_auc: 0.9319\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2805 - accuracy: 0.8813 - auc: 0.9541 - val_loss: 0.3512 - val_accuracy: 0.8884 - val_auc: 0.9330\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2767 - accuracy: 0.8875 - auc: 0.9554 - val_loss: 0.3925 - val_accuracy: 0.9016 - val_auc: 0.9284\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2655 - accuracy: 0.8913 - auc: 0.9585 - val_loss: 0.4175 - val_accuracy: 0.8926 - val_auc: 0.9273\n",
      "Epoch 14/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2594 - accuracy: 0.8897 - auc: 0.9599Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2592 - accuracy: 0.8894 - auc: 0.9599 - val_loss: 0.4244 - val_accuracy: 0.8857 - val_auc: 0.9299\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.8845 - accuracy: 0.3707 - auc: 0.6760 - val_loss: 0.5496 - val_accuracy: 0.4683 - val_auc: 0.8733\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6757 - accuracy: 0.4929 - auc: 0.7886 - val_loss: 0.4668 - val_accuracy: 0.6524 - val_auc: 0.9119\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5612 - accuracy: 0.6101 - auc: 0.8326 - val_loss: 0.4256 - val_accuracy: 0.7567 - val_auc: 0.9244\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5151 - accuracy: 0.7425 - auc: 0.8729 - val_loss: 0.4023 - val_accuracy: 0.8083 - val_auc: 0.9278\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4640 - accuracy: 0.7872 - auc: 0.8847 - val_loss: 0.3852 - val_accuracy: 0.8366 - val_auc: 0.9278\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4249 - accuracy: 0.8108 - auc: 0.8987 - val_loss: 0.3751 - val_accuracy: 0.8488 - val_auc: 0.9297\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4223 - accuracy: 0.8271 - auc: 0.9045 - val_loss: 0.3660 - val_accuracy: 0.8564 - val_auc: 0.9302\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4135 - accuracy: 0.8370 - auc: 0.9077 - val_loss: 0.3604 - val_accuracy: 0.8646 - val_auc: 0.9306\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3984 - accuracy: 0.8477 - auc: 0.9112 - val_loss: 0.3565 - val_accuracy: 0.8701 - val_auc: 0.9306\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3831 - accuracy: 0.8547 - auc: 0.9142 - val_loss: 0.3529 - val_accuracy: 0.8742 - val_auc: 0.9307\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3717 - accuracy: 0.8606 - auc: 0.9217 - val_loss: 0.3471 - val_accuracy: 0.8779 - val_auc: 0.9329\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3784 - accuracy: 0.8652 - auc: 0.9197 - val_loss: 0.3432 - val_accuracy: 0.8799 - val_auc: 0.9342\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3667 - accuracy: 0.8669 - auc: 0.9250 - val_loss: 0.3439 - val_accuracy: 0.8808 - val_auc: 0.9340\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3543 - accuracy: 0.8706 - auc: 0.9299 - val_loss: 0.3425 - val_accuracy: 0.8843 - val_auc: 0.9337\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3481 - accuracy: 0.8749 - auc: 0.9339 - val_loss: 0.3417 - val_accuracy: 0.8873 - val_auc: 0.9340\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3427 - accuracy: 0.8768 - auc: 0.9317 - val_loss: 0.3436 - val_accuracy: 0.8877 - val_auc: 0.9326\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3456 - accuracy: 0.8781 - auc: 0.9319 - val_loss: 0.3412 - val_accuracy: 0.8875 - val_auc: 0.9333\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3550 - accuracy: 0.8792 - auc: 0.9286 - val_loss: 0.3413 - val_accuracy: 0.8889 - val_auc: 0.9341\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3424 - accuracy: 0.8775 - auc: 0.9339 - val_loss: 0.3406 - val_accuracy: 0.8848 - val_auc: 0.9346\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3308 - accuracy: 0.8809 - auc: 0.9374 - val_loss: 0.3406 - val_accuracy: 0.8911 - val_auc: 0.9347\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3382 - accuracy: 0.8822 - auc: 0.9349 - val_loss: 0.3407 - val_accuracy: 0.8902 - val_auc: 0.9348\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3398 - accuracy: 0.8790 - auc: 0.9333 - val_loss: 0.3395 - val_accuracy: 0.8865 - val_auc: 0.9350\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3198 - accuracy: 0.8811 - auc: 0.9412 - val_loss: 0.3388 - val_accuracy: 0.8902 - val_auc: 0.9352\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3331 - accuracy: 0.8807 - auc: 0.9348 - val_loss: 0.3414 - val_accuracy: 0.8891 - val_auc: 0.9344\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3132 - accuracy: 0.8841 - auc: 0.9442 - val_loss: 0.3427 - val_accuracy: 0.8897 - val_auc: 0.9346\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3169 - accuracy: 0.8826 - auc: 0.9425 - val_loss: 0.3445 - val_accuracy: 0.8902 - val_auc: 0.9343\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3178 - accuracy: 0.8840 - auc: 0.9414 - val_loss: 0.3462 - val_accuracy: 0.8889 - val_auc: 0.9340\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3305 - accuracy: 0.8818 - auc: 0.9364 - val_loss: 0.3478 - val_accuracy: 0.8893 - val_auc: 0.9342\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3209 - accuracy: 0.8840 - auc: 0.9404 - val_loss: 0.3459 - val_accuracy: 0.8912 - val_auc: 0.9345\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3102 - accuracy: 0.8854 - auc: 0.9447 - val_loss: 0.3461 - val_accuracy: 0.8922 - val_auc: 0.9348\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3223 - accuracy: 0.8858 - auc: 0.9402 - val_loss: 0.3449 - val_accuracy: 0.8916 - val_auc: 0.9356\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3259 - accuracy: 0.8857 - auc: 0.9392 - val_loss: 0.3462 - val_accuracy: 0.8914 - val_auc: 0.9351\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3142 - accuracy: 0.8874 - auc: 0.9429 - val_loss: 0.3484 - val_accuracy: 0.8905 - val_auc: 0.9347\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3146 - accuracy: 0.8852 - auc: 0.9426 - val_loss: 0.3488 - val_accuracy: 0.8915 - val_auc: 0.9350\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3157 - accuracy: 0.8883 - auc: 0.9424 - val_loss: 0.3515 - val_accuracy: 0.8928 - val_auc: 0.9343\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3039 - accuracy: 0.8840 - auc: 0.9469 - val_loss: 0.3571 - val_accuracy: 0.8898 - val_auc: 0.9321\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3069 - accuracy: 0.8878 - auc: 0.9460 - val_loss: 0.3578 - val_accuracy: 0.8918 - val_auc: 0.9330\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3088 - accuracy: 0.8873 - auc: 0.9451 - val_loss: 0.3581 - val_accuracy: 0.8913 - val_auc: 0.9332\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3051 - accuracy: 0.8879 - auc: 0.9458 - val_loss: 0.3573 - val_accuracy: 0.8948 - val_auc: 0.9340\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3076 - accuracy: 0.8885 - auc: 0.9442 - val_loss: 0.3593 - val_accuracy: 0.8914 - val_auc: 0.9334\n",
      "Epoch 41/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.8877 - auc: 0.9495Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2972 - accuracy: 0.8877 - auc: 0.9495 - val_loss: 0.3628 - val_accuracy: 0.8906 - val_auc: 0.9324\n",
      "Epoch 00041: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6703 - accuracy: 0.8134 - auc: 0.7017 - val_loss: 0.4939 - val_accuracy: 0.8716 - val_auc: 0.8452\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5319 - accuracy: 0.8354 - auc: 0.8052 - val_loss: 0.4279 - val_accuracy: 0.8897 - val_auc: 0.9003\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4747 - accuracy: 0.8529 - auc: 0.8604 - val_loss: 0.3945 - val_accuracy: 0.8920 - val_auc: 0.9196\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4492 - accuracy: 0.8660 - auc: 0.8773 - val_loss: 0.3769 - val_accuracy: 0.8929 - val_auc: 0.9235\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4168 - accuracy: 0.8737 - auc: 0.9005 - val_loss: 0.3631 - val_accuracy: 0.8917 - val_auc: 0.9283\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4166 - accuracy: 0.8804 - auc: 0.8988 - val_loss: 0.3548 - val_accuracy: 0.8940 - val_auc: 0.9304\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4029 - accuracy: 0.8844 - auc: 0.9073 - val_loss: 0.3471 - val_accuracy: 0.8943 - val_auc: 0.9325\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3815 - accuracy: 0.8876 - auc: 0.9198 - val_loss: 0.3407 - val_accuracy: 0.8953 - val_auc: 0.9339\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3672 - accuracy: 0.8915 - auc: 0.9278 - val_loss: 0.3333 - val_accuracy: 0.8983 - val_auc: 0.9360\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3680 - accuracy: 0.8929 - auc: 0.9277 - val_loss: 0.3305 - val_accuracy: 0.8975 - val_auc: 0.9362\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3671 - accuracy: 0.8945 - auc: 0.9251 - val_loss: 0.3263 - val_accuracy: 0.8971 - val_auc: 0.9377\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3525 - accuracy: 0.8955 - auc: 0.9316 - val_loss: 0.3244 - val_accuracy: 0.8991 - val_auc: 0.9376\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3501 - accuracy: 0.8968 - auc: 0.9328 - val_loss: 0.3234 - val_accuracy: 0.8998 - val_auc: 0.9384\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3423 - accuracy: 0.8993 - auc: 0.9358 - val_loss: 0.3207 - val_accuracy: 0.9017 - val_auc: 0.9390\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3524 - accuracy: 0.8988 - auc: 0.9312 - val_loss: 0.3203 - val_accuracy: 0.8985 - val_auc: 0.9395\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3460 - accuracy: 0.9002 - auc: 0.9326 - val_loss: 0.3191 - val_accuracy: 0.9012 - val_auc: 0.9396\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3442 - accuracy: 0.8990 - auc: 0.9356 - val_loss: 0.3172 - val_accuracy: 0.9014 - val_auc: 0.9395\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3377 - accuracy: 0.9019 - auc: 0.9362 - val_loss: 0.3162 - val_accuracy: 0.9008 - val_auc: 0.9393\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3231 - accuracy: 0.9004 - auc: 0.9434 - val_loss: 0.3165 - val_accuracy: 0.9010 - val_auc: 0.9391\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3350 - accuracy: 0.9021 - auc: 0.9398 - val_loss: 0.3187 - val_accuracy: 0.8998 - val_auc: 0.9389\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3197 - accuracy: 0.9008 - auc: 0.9448 - val_loss: 0.3182 - val_accuracy: 0.9021 - val_auc: 0.9384\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3228 - accuracy: 0.9017 - auc: 0.9414 - val_loss: 0.3189 - val_accuracy: 0.9015 - val_auc: 0.9385\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3265 - accuracy: 0.9039 - auc: 0.9398 - val_loss: 0.3208 - val_accuracy: 0.9038 - val_auc: 0.9387\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3212 - accuracy: 0.9029 - auc: 0.9427 - val_loss: 0.3220 - val_accuracy: 0.9034 - val_auc: 0.9377\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3260 - accuracy: 0.9026 - auc: 0.9406 - val_loss: 0.3201 - val_accuracy: 0.9030 - val_auc: 0.9385\n",
      "Epoch 26/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.9048 - auc: 0.9445Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3176 - accuracy: 0.9048 - auc: 0.9446 - val_loss: 0.3219 - val_accuracy: 0.9041 - val_auc: 0.9377\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8738 - accuracy: 0.7039 - auc: 0.5874 - val_loss: 0.5665 - val_accuracy: 0.7830 - val_auc: 0.7707\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6160 - accuracy: 0.7421 - auc: 0.7469 - val_loss: 0.4692 - val_accuracy: 0.8306 - val_auc: 0.8685\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5424 - accuracy: 0.7935 - auc: 0.8089 - val_loss: 0.4275 - val_accuracy: 0.8646 - val_auc: 0.8971\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4939 - accuracy: 0.8329 - auc: 0.8458 - val_loss: 0.4059 - val_accuracy: 0.8812 - val_auc: 0.9061\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4579 - accuracy: 0.8521 - auc: 0.8724 - val_loss: 0.3908 - val_accuracy: 0.8847 - val_auc: 0.9150\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4430 - accuracy: 0.8660 - auc: 0.8812 - val_loss: 0.3755 - val_accuracy: 0.8908 - val_auc: 0.9197\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4190 - accuracy: 0.8745 - auc: 0.8928 - val_loss: 0.3660 - val_accuracy: 0.8939 - val_auc: 0.9240\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4142 - accuracy: 0.8753 - auc: 0.8984 - val_loss: 0.3577 - val_accuracy: 0.8913 - val_auc: 0.9278\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3979 - accuracy: 0.8820 - auc: 0.9093 - val_loss: 0.3489 - val_accuracy: 0.8936 - val_auc: 0.9301\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3945 - accuracy: 0.8867 - auc: 0.9041 - val_loss: 0.3441 - val_accuracy: 0.8975 - val_auc: 0.9314\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3745 - accuracy: 0.8905 - auc: 0.9184 - val_loss: 0.3378 - val_accuracy: 0.8965 - val_auc: 0.9330\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3551 - accuracy: 0.8909 - auc: 0.9271 - val_loss: 0.3315 - val_accuracy: 0.8988 - val_auc: 0.9341\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3660 - accuracy: 0.8931 - auc: 0.9218 - val_loss: 0.3321 - val_accuracy: 0.8971 - val_auc: 0.9343\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3505 - accuracy: 0.8907 - auc: 0.9291 - val_loss: 0.3287 - val_accuracy: 0.8951 - val_auc: 0.9346\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3527 - accuracy: 0.8922 - auc: 0.9256 - val_loss: 0.3273 - val_accuracy: 0.8987 - val_auc: 0.9354\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3496 - accuracy: 0.8952 - auc: 0.9293 - val_loss: 0.3255 - val_accuracy: 0.8993 - val_auc: 0.9354\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3454 - accuracy: 0.8960 - auc: 0.9297 - val_loss: 0.3239 - val_accuracy: 0.8997 - val_auc: 0.9357\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3358 - accuracy: 0.8965 - auc: 0.9317 - val_loss: 0.3231 - val_accuracy: 0.8985 - val_auc: 0.9358\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3398 - accuracy: 0.8948 - auc: 0.9337 - val_loss: 0.3226 - val_accuracy: 0.9004 - val_auc: 0.9357\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3403 - accuracy: 0.8980 - auc: 0.9322 - val_loss: 0.3194 - val_accuracy: 0.9009 - val_auc: 0.9362\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3336 - accuracy: 0.8985 - auc: 0.9345 - val_loss: 0.3229 - val_accuracy: 0.8993 - val_auc: 0.9359\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3356 - accuracy: 0.8953 - auc: 0.9329 - val_loss: 0.3247 - val_accuracy: 0.8989 - val_auc: 0.9357\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3324 - accuracy: 0.8972 - auc: 0.9351 - val_loss: 0.3243 - val_accuracy: 0.8984 - val_auc: 0.9364\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3319 - accuracy: 0.8973 - auc: 0.9367 - val_loss: 0.3233 - val_accuracy: 0.8993 - val_auc: 0.9369\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3197 - accuracy: 0.8969 - auc: 0.9408 - val_loss: 0.3240 - val_accuracy: 0.8996 - val_auc: 0.9365\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3263 - accuracy: 0.8971 - auc: 0.9376 - val_loss: 0.3236 - val_accuracy: 0.8990 - val_auc: 0.9363\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3213 - accuracy: 0.8966 - auc: 0.9398 - val_loss: 0.3231 - val_accuracy: 0.9010 - val_auc: 0.9365\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3234 - accuracy: 0.9000 - auc: 0.9393 - val_loss: 0.3208 - val_accuracy: 0.9006 - val_auc: 0.9374\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3213 - accuracy: 0.8984 - auc: 0.9395 - val_loss: 0.3234 - val_accuracy: 0.8985 - val_auc: 0.9372\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3224 - accuracy: 0.8961 - auc: 0.9385 - val_loss: 0.3273 - val_accuracy: 0.8986 - val_auc: 0.9364\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3056 - accuracy: 0.8987 - auc: 0.9453 - val_loss: 0.3268 - val_accuracy: 0.9018 - val_auc: 0.9371\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3070 - accuracy: 0.8979 - auc: 0.9451 - val_loss: 0.3269 - val_accuracy: 0.9003 - val_auc: 0.9368\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3149 - accuracy: 0.8970 - auc: 0.9423 - val_loss: 0.3293 - val_accuracy: 0.8983 - val_auc: 0.9364\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3066 - accuracy: 0.8981 - auc: 0.9441 - val_loss: 0.3297 - val_accuracy: 0.9007 - val_auc: 0.9365\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3060 - accuracy: 0.8984 - auc: 0.9443 - val_loss: 0.3296 - val_accuracy: 0.9031 - val_auc: 0.9368\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3032 - accuracy: 0.9006 - auc: 0.9469 - val_loss: 0.3318 - val_accuracy: 0.9012 - val_auc: 0.9367\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3051 - accuracy: 0.8983 - auc: 0.9445 - val_loss: 0.3308 - val_accuracy: 0.9024 - val_auc: 0.9370\n",
      "Epoch 38/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3027 - accuracy: 0.9004 - auc: 0.9446Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3016 - accuracy: 0.9004 - auc: 0.9451 - val_loss: 0.3290 - val_accuracy: 0.9023 - val_auc: 0.9371\n",
      "Epoch 00038: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.7652 - accuracy: 0.5536 - auc: 0.6952 - val_loss: 0.5206 - val_accuracy: 0.6302 - val_auc: 0.8456\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5961 - accuracy: 0.6549 - auc: 0.7881 - val_loss: 0.4412 - val_accuracy: 0.7488 - val_auc: 0.8999\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5303 - accuracy: 0.7383 - auc: 0.8337 - val_loss: 0.4007 - val_accuracy: 0.8174 - val_auc: 0.9204\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4703 - accuracy: 0.7895 - auc: 0.8656 - val_loss: 0.3770 - val_accuracy: 0.8463 - val_auc: 0.9295\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4456 - accuracy: 0.8152 - auc: 0.8800 - val_loss: 0.3594 - val_accuracy: 0.8569 - val_auc: 0.9365\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4167 - accuracy: 0.8379 - auc: 0.8999 - val_loss: 0.3453 - val_accuracy: 0.8704 - val_auc: 0.9420\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4104 - accuracy: 0.8471 - auc: 0.9004 - val_loss: 0.3331 - val_accuracy: 0.8744 - val_auc: 0.9443\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3969 - accuracy: 0.8599 - auc: 0.9079 - val_loss: 0.3227 - val_accuracy: 0.8819 - val_auc: 0.9464\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3887 - accuracy: 0.8651 - auc: 0.9110 - val_loss: 0.3161 - val_accuracy: 0.8844 - val_auc: 0.9472\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3717 - accuracy: 0.8742 - auc: 0.9212 - val_loss: 0.3105 - val_accuracy: 0.8895 - val_auc: 0.9476\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3574 - accuracy: 0.8777 - auc: 0.9280 - val_loss: 0.3059 - val_accuracy: 0.8923 - val_auc: 0.9478\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3528 - accuracy: 0.8811 - auc: 0.9289 - val_loss: 0.3016 - val_accuracy: 0.8917 - val_auc: 0.9484\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3530 - accuracy: 0.8814 - auc: 0.9295 - val_loss: 0.3004 - val_accuracy: 0.8907 - val_auc: 0.9480\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3431 - accuracy: 0.8835 - auc: 0.9335 - val_loss: 0.2965 - val_accuracy: 0.8945 - val_auc: 0.9486\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3497 - accuracy: 0.8885 - auc: 0.9286 - val_loss: 0.2958 - val_accuracy: 0.8960 - val_auc: 0.9486\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3383 - accuracy: 0.8903 - auc: 0.9349 - val_loss: 0.2940 - val_accuracy: 0.8969 - val_auc: 0.9485\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3341 - accuracy: 0.8912 - auc: 0.9358 - val_loss: 0.2970 - val_accuracy: 0.8955 - val_auc: 0.9471\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3268 - accuracy: 0.8914 - auc: 0.9390 - val_loss: 0.2963 - val_accuracy: 0.8982 - val_auc: 0.9469\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3229 - accuracy: 0.8918 - auc: 0.9401 - val_loss: 0.2948 - val_accuracy: 0.8967 - val_auc: 0.9474\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3176 - accuracy: 0.8932 - auc: 0.9431 - val_loss: 0.2939 - val_accuracy: 0.8968 - val_auc: 0.9474\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3255 - accuracy: 0.8930 - auc: 0.9389 - val_loss: 0.2943 - val_accuracy: 0.8966 - val_auc: 0.9472\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3201 - accuracy: 0.8924 - auc: 0.9407 - val_loss: 0.2939 - val_accuracy: 0.8975 - val_auc: 0.9473\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3240 - accuracy: 0.8953 - auc: 0.9394 - val_loss: 0.2954 - val_accuracy: 0.8976 - val_auc: 0.9467\n",
      "Epoch 24/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3149 - accuracy: 0.8952 - auc: 0.9422Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3159 - accuracy: 0.8951 - auc: 0.9426 - val_loss: 0.2959 - val_accuracy: 0.9001 - val_auc: 0.9464\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 1.0679 - accuracy: 0.4707 - auc: 0.5132 - val_loss: 0.7309 - val_accuracy: 0.5184 - val_auc: 0.7102\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7827 - accuracy: 0.5040 - auc: 0.6439 - val_loss: 0.5712 - val_accuracy: 0.6017 - val_auc: 0.8234\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6026 - accuracy: 0.5708 - auc: 0.7938 - val_loss: 0.4887 - val_accuracy: 0.6884 - val_auc: 0.9007\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5582 - accuracy: 0.6422 - auc: 0.8407 - val_loss: 0.4398 - val_accuracy: 0.7515 - val_auc: 0.9195\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5020 - accuracy: 0.6920 - auc: 0.8622 - val_loss: 0.4024 - val_accuracy: 0.7942 - val_auc: 0.9314\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4797 - accuracy: 0.7634 - auc: 0.8744 - val_loss: 0.3812 - val_accuracy: 0.8310 - val_auc: 0.9342\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4392 - accuracy: 0.8192 - auc: 0.8948 - val_loss: 0.3634 - val_accuracy: 0.8526 - val_auc: 0.9357\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4339 - accuracy: 0.8381 - auc: 0.8948 - val_loss: 0.3516 - val_accuracy: 0.8618 - val_auc: 0.9376\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4125 - accuracy: 0.8433 - auc: 0.9037 - val_loss: 0.3415 - val_accuracy: 0.8644 - val_auc: 0.9396\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3991 - accuracy: 0.8501 - auc: 0.9125 - val_loss: 0.3332 - val_accuracy: 0.8697 - val_auc: 0.9403\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4027 - accuracy: 0.8558 - auc: 0.9082 - val_loss: 0.3253 - val_accuracy: 0.8759 - val_auc: 0.9417\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3841 - accuracy: 0.8640 - auc: 0.9183 - val_loss: 0.3201 - val_accuracy: 0.8778 - val_auc: 0.9416\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3713 - accuracy: 0.8687 - auc: 0.9218 - val_loss: 0.3169 - val_accuracy: 0.8810 - val_auc: 0.9409\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3620 - accuracy: 0.8697 - auc: 0.9254 - val_loss: 0.3140 - val_accuracy: 0.8819 - val_auc: 0.9411\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3661 - accuracy: 0.8726 - auc: 0.9231 - val_loss: 0.3109 - val_accuracy: 0.8852 - val_auc: 0.9422\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3607 - accuracy: 0.8779 - auc: 0.9255 - val_loss: 0.3098 - val_accuracy: 0.8856 - val_auc: 0.9418\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3523 - accuracy: 0.8744 - auc: 0.9287 - val_loss: 0.3094 - val_accuracy: 0.8831 - val_auc: 0.9414\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3622 - accuracy: 0.8731 - auc: 0.9244 - val_loss: 0.3111 - val_accuracy: 0.8817 - val_auc: 0.9409\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3498 - accuracy: 0.8745 - auc: 0.9290 - val_loss: 0.3107 - val_accuracy: 0.8843 - val_auc: 0.9410\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3453 - accuracy: 0.8807 - auc: 0.9307 - val_loss: 0.3094 - val_accuracy: 0.8868 - val_auc: 0.9411\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3403 - accuracy: 0.8771 - auc: 0.9330 - val_loss: 0.3089 - val_accuracy: 0.8860 - val_auc: 0.9416\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3413 - accuracy: 0.8809 - auc: 0.9332 - val_loss: 0.3097 - val_accuracy: 0.8873 - val_auc: 0.9411\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3299 - accuracy: 0.8814 - auc: 0.9376 - val_loss: 0.3098 - val_accuracy: 0.8881 - val_auc: 0.9409\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3416 - accuracy: 0.8815 - auc: 0.9349 - val_loss: 0.3108 - val_accuracy: 0.8874 - val_auc: 0.9405\n",
      "Epoch 25/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.3289 - accuracy: 0.8802 - auc: 0.9375Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3291 - accuracy: 0.8801 - auc: 0.9374 - val_loss: 0.3131 - val_accuracy: 0.8875 - val_auc: 0.9397\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.8900 - accuracy: 0.3127 - auc: 0.6680 - val_loss: 0.5789 - val_accuracy: 0.3781 - val_auc: 0.8614\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6483 - accuracy: 0.4951 - auc: 0.8155 - val_loss: 0.4505 - val_accuracy: 0.6792 - val_auc: 0.9117\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5215 - accuracy: 0.6510 - auc: 0.8618 - val_loss: 0.3876 - val_accuracy: 0.7975 - val_auc: 0.9262\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4569 - accuracy: 0.7352 - auc: 0.8875 - val_loss: 0.3576 - val_accuracy: 0.8369 - val_auc: 0.9301\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4330 - accuracy: 0.7708 - auc: 0.8975 - val_loss: 0.3427 - val_accuracy: 0.8517 - val_auc: 0.9342\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4049 - accuracy: 0.7952 - auc: 0.9094 - val_loss: 0.3370 - val_accuracy: 0.8570 - val_auc: 0.9338\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3990 - accuracy: 0.8034 - auc: 0.9118 - val_loss: 0.3357 - val_accuracy: 0.8592 - val_auc: 0.9341\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3751 - accuracy: 0.8153 - auc: 0.9198 - val_loss: 0.3323 - val_accuracy: 0.8683 - val_auc: 0.9339\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3730 - accuracy: 0.8241 - auc: 0.9227 - val_loss: 0.3256 - val_accuracy: 0.8689 - val_auc: 0.9363\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3568 - accuracy: 0.8268 - auc: 0.9269 - val_loss: 0.3255 - val_accuracy: 0.8731 - val_auc: 0.9360\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3291 - accuracy: 0.8390 - auc: 0.9376 - val_loss: 0.3305 - val_accuracy: 0.8791 - val_auc: 0.9337\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3358 - accuracy: 0.8445 - auc: 0.9335 - val_loss: 0.3306 - val_accuracy: 0.8784 - val_auc: 0.9342\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3209 - accuracy: 0.8457 - auc: 0.9391 - val_loss: 0.3298 - val_accuracy: 0.8790 - val_auc: 0.9343\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3230 - accuracy: 0.8469 - auc: 0.9389 - val_loss: 0.3319 - val_accuracy: 0.8786 - val_auc: 0.9339\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3172 - accuracy: 0.8492 - auc: 0.9407 - val_loss: 0.3349 - val_accuracy: 0.8804 - val_auc: 0.9340\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3082 - accuracy: 0.8504 - auc: 0.9442 - val_loss: 0.3365 - val_accuracy: 0.8797 - val_auc: 0.9332\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3116 - accuracy: 0.8529 - auc: 0.9429 - val_loss: 0.3400 - val_accuracy: 0.8814 - val_auc: 0.9320\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3122 - accuracy: 0.8528 - auc: 0.9426 - val_loss: 0.3384 - val_accuracy: 0.8817 - val_auc: 0.9333\n",
      "Epoch 19/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3037 - accuracy: 0.8551 - auc: 0.9455Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3024 - accuracy: 0.8551 - auc: 0.9458 - val_loss: 0.3423 - val_accuracy: 0.8819 - val_auc: 0.9326\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 6s 23us/sample - loss: 0.7707 - accuracy: 0.8495 - auc: 0.6806 - val_loss: 0.4452 - val_accuracy: 0.8987 - val_auc: 0.8835\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5224 - accuracy: 0.8282 - auc: 0.8342 - val_loss: 0.3866 - val_accuracy: 0.8842 - val_auc: 0.9193\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4547 - accuracy: 0.8414 - auc: 0.8795 - val_loss: 0.3644 - val_accuracy: 0.8865 - val_auc: 0.9264\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4061 - accuracy: 0.8577 - auc: 0.9063 - val_loss: 0.3529 - val_accuracy: 0.8935 - val_auc: 0.9303\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3975 - accuracy: 0.8722 - auc: 0.9077 - val_loss: 0.3419 - val_accuracy: 0.8972 - val_auc: 0.9344\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3836 - accuracy: 0.8764 - auc: 0.9148 - val_loss: 0.3331 - val_accuracy: 0.8959 - val_auc: 0.9359\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3673 - accuracy: 0.8824 - auc: 0.9254 - val_loss: 0.3238 - val_accuracy: 0.8996 - val_auc: 0.9369\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3660 - accuracy: 0.8851 - auc: 0.9249 - val_loss: 0.3221 - val_accuracy: 0.8940 - val_auc: 0.9373\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3581 - accuracy: 0.8866 - auc: 0.9287 - val_loss: 0.3172 - val_accuracy: 0.8983 - val_auc: 0.9378\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3438 - accuracy: 0.8894 - auc: 0.9333 - val_loss: 0.3176 - val_accuracy: 0.9003 - val_auc: 0.9383\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3345 - accuracy: 0.8917 - auc: 0.9383 - val_loss: 0.3129 - val_accuracy: 0.9000 - val_auc: 0.9397\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3228 - accuracy: 0.8963 - auc: 0.9412 - val_loss: 0.3114 - val_accuracy: 0.9032 - val_auc: 0.9402\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3338 - accuracy: 0.8913 - auc: 0.9374 - val_loss: 0.3092 - val_accuracy: 0.8996 - val_auc: 0.9412\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3159 - accuracy: 0.8968 - auc: 0.9445 - val_loss: 0.3115 - val_accuracy: 0.9032 - val_auc: 0.9403\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3250 - accuracy: 0.8957 - auc: 0.9403 - val_loss: 0.3108 - val_accuracy: 0.9014 - val_auc: 0.9405\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3110 - accuracy: 0.8955 - auc: 0.9464 - val_loss: 0.3094 - val_accuracy: 0.9026 - val_auc: 0.9402\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3180 - accuracy: 0.8958 - auc: 0.9432 - val_loss: 0.3128 - val_accuracy: 0.9008 - val_auc: 0.9395\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3147 - accuracy: 0.8957 - auc: 0.9442 - val_loss: 0.3178 - val_accuracy: 0.8975 - val_auc: 0.9376\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3187 - accuracy: 0.8968 - auc: 0.9437 - val_loss: 0.3186 - val_accuracy: 0.8977 - val_auc: 0.9375\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3070 - accuracy: 0.8975 - auc: 0.9471 - val_loss: 0.3184 - val_accuracy: 0.9033 - val_auc: 0.9369\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3121 - accuracy: 0.9004 - auc: 0.9456 - val_loss: 0.3178 - val_accuracy: 0.9026 - val_auc: 0.9370\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3106 - accuracy: 0.8974 - auc: 0.9462 - val_loss: 0.3214 - val_accuracy: 0.9023 - val_auc: 0.9349\n",
      "Epoch 23/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3056 - accuracy: 0.8999 - auc: 0.9475Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3067 - accuracy: 0.8998 - auc: 0.9476 - val_loss: 0.3209 - val_accuracy: 0.9031 - val_auc: 0.9348\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 7s 28us/sample - loss: 0.7097 - accuracy: 0.6726 - auc: 0.7039 - val_loss: 0.4567 - val_accuracy: 0.7644 - val_auc: 0.8943\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5201 - accuracy: 0.7715 - auc: 0.8384 - val_loss: 0.3879 - val_accuracy: 0.8448 - val_auc: 0.9268\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4527 - accuracy: 0.8306 - auc: 0.8780 - val_loss: 0.3599 - val_accuracy: 0.8693 - val_auc: 0.9336\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4243 - accuracy: 0.8553 - auc: 0.8949 - val_loss: 0.3449 - val_accuracy: 0.8794 - val_auc: 0.9369\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4012 - accuracy: 0.8683 - auc: 0.9062 - val_loss: 0.3360 - val_accuracy: 0.8871 - val_auc: 0.9377\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3840 - accuracy: 0.8791 - auc: 0.9151 - val_loss: 0.3297 - val_accuracy: 0.8871 - val_auc: 0.9388\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3750 - accuracy: 0.8814 - auc: 0.9204 - val_loss: 0.3260 - val_accuracy: 0.8893 - val_auc: 0.9383\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3530 - accuracy: 0.8833 - auc: 0.9302 - val_loss: 0.3227 - val_accuracy: 0.8938 - val_auc: 0.9378\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3540 - accuracy: 0.8879 - auc: 0.9294 - val_loss: 0.3206 - val_accuracy: 0.8938 - val_auc: 0.9377\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3358 - accuracy: 0.8900 - auc: 0.9347 - val_loss: 0.3179 - val_accuracy: 0.8969 - val_auc: 0.9375\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3308 - accuracy: 0.8916 - auc: 0.9384 - val_loss: 0.3157 - val_accuracy: 0.8963 - val_auc: 0.9374\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3251 - accuracy: 0.8961 - auc: 0.9395 - val_loss: 0.3146 - val_accuracy: 0.8986 - val_auc: 0.9371\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3260 - accuracy: 0.8924 - auc: 0.9394 - val_loss: 0.3144 - val_accuracy: 0.8952 - val_auc: 0.9371\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3226 - accuracy: 0.8938 - auc: 0.9402 - val_loss: 0.3152 - val_accuracy: 0.8962 - val_auc: 0.9368\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3172 - accuracy: 0.8921 - auc: 0.9429 - val_loss: 0.3169 - val_accuracy: 0.8966 - val_auc: 0.9361\n",
      "Epoch 16/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3156 - accuracy: 0.8939 - auc: 0.9419Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3147 - accuracy: 0.8942 - auc: 0.9428 - val_loss: 0.3163 - val_accuracy: 0.8996 - val_auc: 0.9359\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 1.0951 - accuracy: 0.8286 - auc: 0.5488 - val_loss: 0.6912 - val_accuracy: 0.8945 - val_auc: 0.6934\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6964 - accuracy: 0.8081 - auc: 0.7397 - val_loss: 0.5039 - val_accuracy: 0.8703 - val_auc: 0.8649\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5624 - accuracy: 0.8166 - auc: 0.8192 - val_loss: 0.4338 - val_accuracy: 0.8718 - val_auc: 0.9053\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4919 - accuracy: 0.8371 - auc: 0.8631 - val_loss: 0.3963 - val_accuracy: 0.8826 - val_auc: 0.9193\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4463 - accuracy: 0.8546 - auc: 0.8852 - val_loss: 0.3771 - val_accuracy: 0.8904 - val_auc: 0.9255\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4181 - accuracy: 0.8667 - auc: 0.9028 - val_loss: 0.3550 - val_accuracy: 0.8973 - val_auc: 0.9323\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4259 - accuracy: 0.8735 - auc: 0.9032 - val_loss: 0.3402 - val_accuracy: 0.8930 - val_auc: 0.9351\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4084 - accuracy: 0.8766 - auc: 0.9105 - val_loss: 0.3320 - val_accuracy: 0.8914 - val_auc: 0.9362\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3739 - accuracy: 0.8809 - auc: 0.9190 - val_loss: 0.3284 - val_accuracy: 0.8948 - val_auc: 0.9360\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3759 - accuracy: 0.8843 - auc: 0.9225 - val_loss: 0.3215 - val_accuracy: 0.8951 - val_auc: 0.9375\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3571 - accuracy: 0.8861 - auc: 0.9269 - val_loss: 0.3145 - val_accuracy: 0.8960 - val_auc: 0.9398\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3400 - accuracy: 0.8855 - auc: 0.9334 - val_loss: 0.3188 - val_accuracy: 0.8949 - val_auc: 0.9374\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3469 - accuracy: 0.8849 - auc: 0.9331 - val_loss: 0.3141 - val_accuracy: 0.8928 - val_auc: 0.9385\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3270 - accuracy: 0.8866 - auc: 0.9389 - val_loss: 0.3121 - val_accuracy: 0.8942 - val_auc: 0.9389\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3163 - accuracy: 0.8898 - auc: 0.9426 - val_loss: 0.3116 - val_accuracy: 0.8973 - val_auc: 0.9390\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3091 - accuracy: 0.8915 - auc: 0.9452 - val_loss: 0.3066 - val_accuracy: 0.9003 - val_auc: 0.9410\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2985 - accuracy: 0.8933 - auc: 0.9492 - val_loss: 0.3108 - val_accuracy: 0.8989 - val_auc: 0.9395\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3071 - accuracy: 0.8946 - auc: 0.9459 - val_loss: 0.3134 - val_accuracy: 0.8983 - val_auc: 0.9392\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3050 - accuracy: 0.8944 - auc: 0.9464 - val_loss: 0.3164 - val_accuracy: 0.8982 - val_auc: 0.9388\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2938 - accuracy: 0.8922 - auc: 0.9499 - val_loss: 0.3188 - val_accuracy: 0.9005 - val_auc: 0.9391\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2886 - accuracy: 0.8960 - auc: 0.9519 - val_loss: 0.3213 - val_accuracy: 0.9009 - val_auc: 0.9388\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2866 - accuracy: 0.8976 - auc: 0.9526 - val_loss: 0.3228 - val_accuracy: 0.9012 - val_auc: 0.9380\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2905 - accuracy: 0.8940 - auc: 0.9505 - val_loss: 0.3287 - val_accuracy: 0.9015 - val_auc: 0.9369\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2924 - accuracy: 0.8988 - auc: 0.9506 - val_loss: 0.3316 - val_accuracy: 0.9012 - val_auc: 0.9362\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2983 - accuracy: 0.8956 - auc: 0.9480 - val_loss: 0.3338 - val_accuracy: 0.8998 - val_auc: 0.9357\n",
      "Epoch 26/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2803 - accuracy: 0.8966 - auc: 0.9540Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2817 - accuracy: 0.8967 - auc: 0.9539 - val_loss: 0.3377 - val_accuracy: 0.9011 - val_auc: 0.9354\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.8802 - accuracy: 0.2251 - auc: 0.6466 - val_loss: 0.5922 - val_accuracy: 0.2531 - val_auc: 0.8754\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6337 - accuracy: 0.4084 - auc: 0.8056 - val_loss: 0.4736 - val_accuracy: 0.5692 - val_auc: 0.9156\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5241 - accuracy: 0.5641 - auc: 0.8638 - val_loss: 0.4101 - val_accuracy: 0.7281 - val_auc: 0.9312\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4791 - accuracy: 0.6642 - auc: 0.8851 - val_loss: 0.3731 - val_accuracy: 0.7950 - val_auc: 0.9365\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4332 - accuracy: 0.7162 - auc: 0.9003 - val_loss: 0.3487 - val_accuracy: 0.8244 - val_auc: 0.9396\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4117 - accuracy: 0.7475 - auc: 0.9089 - val_loss: 0.3314 - val_accuracy: 0.8426 - val_auc: 0.9416\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3952 - accuracy: 0.7734 - auc: 0.9133 - val_loss: 0.3220 - val_accuracy: 0.8495 - val_auc: 0.9424\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3775 - accuracy: 0.7842 - auc: 0.9241 - val_loss: 0.3157 - val_accuracy: 0.8580 - val_auc: 0.9422\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3558 - accuracy: 0.8033 - auc: 0.9294 - val_loss: 0.3092 - val_accuracy: 0.8683 - val_auc: 0.9429\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3562 - accuracy: 0.8107 - auc: 0.9283 - val_loss: 0.3109 - val_accuracy: 0.8682 - val_auc: 0.9412\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3454 - accuracy: 0.8213 - auc: 0.9319 - val_loss: 0.3084 - val_accuracy: 0.8713 - val_auc: 0.9417\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3508 - accuracy: 0.8234 - auc: 0.9292 - val_loss: 0.3080 - val_accuracy: 0.8723 - val_auc: 0.9415\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3336 - accuracy: 0.8241 - auc: 0.9372 - val_loss: 0.3098 - val_accuracy: 0.8713 - val_auc: 0.9407\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3223 - accuracy: 0.8280 - auc: 0.9405 - val_loss: 0.3102 - val_accuracy: 0.8733 - val_auc: 0.9404\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3194 - accuracy: 0.8298 - auc: 0.9413 - val_loss: 0.3102 - val_accuracy: 0.8697 - val_auc: 0.9407\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3106 - accuracy: 0.8322 - auc: 0.9444 - val_loss: 0.3113 - val_accuracy: 0.8741 - val_auc: 0.9405\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3104 - accuracy: 0.8377 - auc: 0.9443 - val_loss: 0.3108 - val_accuracy: 0.8769 - val_auc: 0.9409\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3081 - accuracy: 0.8389 - auc: 0.9443 - val_loss: 0.3125 - val_accuracy: 0.8778 - val_auc: 0.9406\n",
      "Epoch 19/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.3036 - accuracy: 0.8413 - auc: 0.9468Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3037 - accuracy: 0.8413 - auc: 0.9466 - val_loss: 0.3145 - val_accuracy: 0.8772 - val_auc: 0.9398\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8746 - accuracy: 0.2374 - auc: 0.6870 - val_loss: 0.5635 - val_accuracy: 0.3572 - val_auc: 0.9031\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5916 - accuracy: 0.4793 - auc: 0.8401 - val_loss: 0.4274 - val_accuracy: 0.6634 - val_auc: 0.9270\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4925 - accuracy: 0.6490 - auc: 0.8753 - val_loss: 0.3713 - val_accuracy: 0.7750 - val_auc: 0.9366oss: 0.503\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4243 - accuracy: 0.7412 - auc: 0.9037 - val_loss: 0.3357 - val_accuracy: 0.8397 - val_auc: 0.9408\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4036 - accuracy: 0.7916 - auc: 0.9095 - val_loss: 0.3199 - val_accuracy: 0.8537 - val_auc: 0.9437\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3695 - accuracy: 0.8170 - auc: 0.9228 - val_loss: 0.3115 - val_accuracy: 0.8709 - val_auc: 0.9439\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3469 - accuracy: 0.8402 - auc: 0.9307 - val_loss: 0.3118 - val_accuracy: 0.8792 - val_auc: 0.9419\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3372 - accuracy: 0.8481 - auc: 0.9332 - val_loss: 0.3155 - val_accuracy: 0.8791 - val_auc: 0.9394\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3246 - accuracy: 0.8523 - auc: 0.9384 - val_loss: 0.3177 - val_accuracy: 0.8823 - val_auc: 0.9385\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3208 - accuracy: 0.8550 - auc: 0.9409 - val_loss: 0.3185 - val_accuracy: 0.8839 - val_auc: 0.9383\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3162 - accuracy: 0.8600 - auc: 0.9410 - val_loss: 0.3214 - val_accuracy: 0.8861 - val_auc: 0.9377\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3156 - accuracy: 0.8642 - auc: 0.9420 - val_loss: 0.3223 - val_accuracy: 0.8844 - val_auc: 0.9375\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2962 - accuracy: 0.8591 - auc: 0.9484 - val_loss: 0.3287 - val_accuracy: 0.8855 - val_auc: 0.9356\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3068 - accuracy: 0.8653 - auc: 0.9441 - val_loss: 0.3292 - val_accuracy: 0.8838 - val_auc: 0.9360\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2855 - accuracy: 0.8649 - auc: 0.9518 - val_loss: 0.3313 - val_accuracy: 0.8869 - val_auc: 0.9357\n",
      "Epoch 16/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2886 - accuracy: 0.8682 - auc: 0.9513Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2893 - accuracy: 0.8679 - auc: 0.9505 - val_loss: 0.3331 - val_accuracy: 0.8865 - val_auc: 0.9358\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8894 - accuracy: 0.6497 - auc: 0.5678 - val_loss: 0.5103 - val_accuracy: 0.7020 - val_auc: 0.8594\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5410 - accuracy: 0.6908 - auc: 0.8203 - val_loss: 0.4196 - val_accuracy: 0.8000 - val_auc: 0.9143\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4654 - accuracy: 0.7675 - auc: 0.8714 - val_loss: 0.3781 - val_accuracy: 0.8427 - val_auc: 0.9241\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4279 - accuracy: 0.8065 - auc: 0.8984 - val_loss: 0.3586 - val_accuracy: 0.8573 - val_auc: 0.9286\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4096 - accuracy: 0.8354 - auc: 0.9086 - val_loss: 0.3465 - val_accuracy: 0.8678 - val_auc: 0.9332\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3683 - accuracy: 0.8522 - auc: 0.9236 - val_loss: 0.3387 - val_accuracy: 0.8800 - val_auc: 0.9351\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3458 - accuracy: 0.8646 - auc: 0.9313 - val_loss: 0.3351 - val_accuracy: 0.8853 - val_auc: 0.9364\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3435 - accuracy: 0.8699 - auc: 0.9309 - val_loss: 0.3309 - val_accuracy: 0.8900 - val_auc: 0.9370\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3523 - accuracy: 0.8713 - auc: 0.9293 - val_loss: 0.3315 - val_accuracy: 0.8860 - val_auc: 0.9367\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3340 - accuracy: 0.8748 - auc: 0.9347 - val_loss: 0.3326 - val_accuracy: 0.8867 - val_auc: 0.9372\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3218 - accuracy: 0.8774 - auc: 0.9399 - val_loss: 0.3313 - val_accuracy: 0.8897 - val_auc: 0.9373\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3175 - accuracy: 0.8810 - auc: 0.9412 - val_loss: 0.3319 - val_accuracy: 0.8921 - val_auc: 0.9373\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3002 - accuracy: 0.8825 - auc: 0.9479 - val_loss: 0.3337 - val_accuracy: 0.8946 - val_auc: 0.9373\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3013 - accuracy: 0.8868 - auc: 0.9469 - val_loss: 0.3321 - val_accuracy: 0.8941 - val_auc: 0.9377\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3032 - accuracy: 0.8864 - auc: 0.9464 - val_loss: 0.3354 - val_accuracy: 0.8950 - val_auc: 0.9373\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2916 - accuracy: 0.8831 - auc: 0.9509 - val_loss: 0.3394 - val_accuracy: 0.8907 - val_auc: 0.9363\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2976 - accuracy: 0.8840 - auc: 0.9478 - val_loss: 0.3411 - val_accuracy: 0.8920 - val_auc: 0.9361\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2930 - accuracy: 0.8861 - auc: 0.9508 - val_loss: 0.3427 - val_accuracy: 0.8948 - val_auc: 0.9365\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2895 - accuracy: 0.8885 - auc: 0.9508 - val_loss: 0.3385 - val_accuracy: 0.8962 - val_auc: 0.9371\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2904 - accuracy: 0.8867 - auc: 0.9509 - val_loss: 0.3468 - val_accuracy: 0.8933 - val_auc: 0.9364\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2813 - accuracy: 0.8900 - auc: 0.9537 - val_loss: 0.3491 - val_accuracy: 0.8986 - val_auc: 0.9362\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2727 - accuracy: 0.8913 - auc: 0.9562 - val_loss: 0.3522 - val_accuracy: 0.8993 - val_auc: 0.9357\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2744 - accuracy: 0.8919 - auc: 0.9553 - val_loss: 0.3568 - val_accuracy: 0.8961 - val_auc: 0.9356\n",
      "Epoch 24/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2719 - accuracy: 0.8905 - auc: 0.9561Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2723 - accuracy: 0.8905 - auc: 0.9562 - val_loss: 0.3569 - val_accuracy: 0.8973 - val_auc: 0.9355\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 1.0297 - accuracy: 0.1195 - auc: 0.6957 - val_loss: 0.6546 - val_accuracy: 0.1617 - val_auc: 0.8887\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6600 - accuracy: 0.3921 - auc: 0.8265 - val_loss: 0.4565 - val_accuracy: 0.6034 - val_auc: 0.9265\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5172 - accuracy: 0.6106 - auc: 0.8664 - val_loss: 0.3861 - val_accuracy: 0.7601 - val_auc: 0.9329\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4474 - accuracy: 0.7048 - auc: 0.8947 - val_loss: 0.3481 - val_accuracy: 0.8137 - val_auc: 0.9376\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4186 - accuracy: 0.7435 - auc: 0.9034 - val_loss: 0.3321 - val_accuracy: 0.8366 - val_auc: 0.9394\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3876 - accuracy: 0.7779 - auc: 0.9146 - val_loss: 0.3217 - val_accuracy: 0.8492 - val_auc: 0.9402\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3809 - accuracy: 0.7927 - auc: 0.9159 - val_loss: 0.3171 - val_accuracy: 0.8567 - val_auc: 0.9409\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3597 - accuracy: 0.8026 - auc: 0.9245 - val_loss: 0.3143 - val_accuracy: 0.8611 - val_auc: 0.9409\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3511 - accuracy: 0.8133 - auc: 0.9279 - val_loss: 0.3137 - val_accuracy: 0.8680 - val_auc: 0.9406\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3373 - accuracy: 0.8202 - auc: 0.9331 - val_loss: 0.3153 - val_accuracy: 0.8704 - val_auc: 0.9397\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3317 - accuracy: 0.8231 - auc: 0.9350 - val_loss: 0.3134 - val_accuracy: 0.8743 - val_auc: 0.9398\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3341 - accuracy: 0.8297 - auc: 0.9348 - val_loss: 0.3143 - val_accuracy: 0.8733 - val_auc: 0.9402\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3182 - accuracy: 0.8329 - auc: 0.9401 - val_loss: 0.3161 - val_accuracy: 0.8751 - val_auc: 0.9393\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3078 - accuracy: 0.8367 - auc: 0.9432 - val_loss: 0.3157 - val_accuracy: 0.8749 - val_auc: 0.9398\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3217 - accuracy: 0.8353 - auc: 0.9382 - val_loss: 0.3168 - val_accuracy: 0.8763 - val_auc: 0.9397\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3148 - accuracy: 0.8408 - auc: 0.9408 - val_loss: 0.3178 - val_accuracy: 0.8770 - val_auc: 0.9396\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2987 - accuracy: 0.8397 - auc: 0.9461 - val_loss: 0.3188 - val_accuracy: 0.8754 - val_auc: 0.9393\n",
      "Epoch 18/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3034 - accuracy: 0.8369 - auc: 0.9450Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3030 - accuracy: 0.8370 - auc: 0.9451 - val_loss: 0.3220 - val_accuracy: 0.8754 - val_auc: 0.9387\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.7007 - accuracy: 0.3890 - auc: 0.7632 - val_loss: 0.4720 - val_accuracy: 0.6189 - val_auc: 0.9045\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5216 - accuracy: 0.6537 - auc: 0.8519 - val_loss: 0.3854 - val_accuracy: 0.8054 - val_auc: 0.9316\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4524 - accuracy: 0.7578 - auc: 0.8852 - val_loss: 0.3490 - val_accuracy: 0.8462 - val_auc: 0.9388\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4176 - accuracy: 0.8049 - auc: 0.9007 - val_loss: 0.3265 - val_accuracy: 0.8649 - val_auc: 0.9423\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3690 - accuracy: 0.8252 - auc: 0.9224 - val_loss: 0.3122 - val_accuracy: 0.8765 - val_auc: 0.9451\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3600 - accuracy: 0.8404 - auc: 0.9260 - val_loss: 0.3055 - val_accuracy: 0.8768 - val_auc: 0.9460\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3461 - accuracy: 0.8472 - auc: 0.9321 - val_loss: 0.2996 - val_accuracy: 0.8848 - val_auc: 0.9462\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3321 - accuracy: 0.8573 - auc: 0.9349 - val_loss: 0.2982 - val_accuracy: 0.8849 - val_auc: 0.9459\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3229 - accuracy: 0.8648 - auc: 0.9421 - val_loss: 0.2979 - val_accuracy: 0.8899 - val_auc: 0.9451\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3192 - accuracy: 0.8652 - auc: 0.9399 - val_loss: 0.2971 - val_accuracy: 0.8858 - val_auc: 0.9455\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3012 - accuracy: 0.8681 - auc: 0.9468 - val_loss: 0.2946 - val_accuracy: 0.8926 - val_auc: 0.9465\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3031 - accuracy: 0.8752 - auc: 0.9447 - val_loss: 0.2966 - val_accuracy: 0.8903 - val_auc: 0.9457\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2957 - accuracy: 0.8710 - auc: 0.9472 - val_loss: 0.2988 - val_accuracy: 0.8926 - val_auc: 0.9450\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2878 - accuracy: 0.8730 - auc: 0.9513 - val_loss: 0.3002 - val_accuracy: 0.8932 - val_auc: 0.9444\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2916 - accuracy: 0.8746 - auc: 0.9492 - val_loss: 0.3004 - val_accuracy: 0.8935 - val_auc: 0.9446\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2873 - accuracy: 0.8793 - auc: 0.9508 - val_loss: 0.3008 - val_accuracy: 0.8923 - val_auc: 0.9451\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2819 - accuracy: 0.8747 - auc: 0.9522 - val_loss: 0.3039 - val_accuracy: 0.8906 - val_auc: 0.9437\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2830 - accuracy: 0.8762 - auc: 0.9521 - val_loss: 0.3063 - val_accuracy: 0.8921 - val_auc: 0.9431\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2743 - accuracy: 0.8776 - auc: 0.9547 - val_loss: 0.3073 - val_accuracy: 0.8961 - val_auc: 0.9432\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2714 - accuracy: 0.8812 - auc: 0.9555 - val_loss: 0.3102 - val_accuracy: 0.8957 - val_auc: 0.9432\n",
      "Epoch 21/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.8791 - auc: 0.9565Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2711 - accuracy: 0.8791 - auc: 0.9556 - val_loss: 0.3110 - val_accuracy: 0.8960 - val_auc: 0.9431\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 23us/sample - loss: 1.1680 - accuracy: 0.2721 - auc: 0.5347 - val_loss: 0.6868 - val_accuracy: 0.2904 - val_auc: 0.8376\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6805 - accuracy: 0.4321 - auc: 0.8066 - val_loss: 0.4910 - val_accuracy: 0.6014 - val_auc: 0.9027\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5563 - accuracy: 0.6208 - auc: 0.8387 - val_loss: 0.4039 - val_accuracy: 0.7570 - val_auc: 0.9223\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4872 - accuracy: 0.7200 - auc: 0.8814 - val_loss: 0.3655 - val_accuracy: 0.8175 - val_auc: 0.9288\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4410 - accuracy: 0.7631 - auc: 0.8940 - val_loss: 0.3459 - val_accuracy: 0.8393 - val_auc: 0.9332\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4148 - accuracy: 0.7953 - auc: 0.9083 - val_loss: 0.3428 - val_accuracy: 0.8569 - val_auc: 0.9309\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3762 - accuracy: 0.8143 - auc: 0.9217 - val_loss: 0.3355 - val_accuracy: 0.8699 - val_auc: 0.9325\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3623 - accuracy: 0.8233 - auc: 0.9261 - val_loss: 0.3382 - val_accuracy: 0.8681 - val_auc: 0.9323\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3577 - accuracy: 0.8290 - auc: 0.9275 - val_loss: 0.3389 - val_accuracy: 0.8689 - val_auc: 0.9328\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3399 - accuracy: 0.8331 - auc: 0.9337 - val_loss: 0.3427 - val_accuracy: 0.8750 - val_auc: 0.9324\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3356 - accuracy: 0.8439 - auc: 0.9361 - val_loss: 0.3409 - val_accuracy: 0.8771 - val_auc: 0.9323\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3190 - accuracy: 0.8395 - auc: 0.9420 - val_loss: 0.3469 - val_accuracy: 0.8770 - val_auc: 0.9322\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3179 - accuracy: 0.8466 - auc: 0.9412 - val_loss: 0.3459 - val_accuracy: 0.8786 - val_auc: 0.9326\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3138 - accuracy: 0.8477 - auc: 0.9432 - val_loss: 0.3422 - val_accuracy: 0.8793 - val_auc: 0.9340\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3060 - accuracy: 0.8489 - auc: 0.9456 - val_loss: 0.3473 - val_accuracy: 0.8795 - val_auc: 0.9340\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2984 - accuracy: 0.8528 - auc: 0.9476 - val_loss: 0.3485 - val_accuracy: 0.8820 - val_auc: 0.9340\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2939 - accuracy: 0.8560 - auc: 0.9491 - val_loss: 0.3514 - val_accuracy: 0.8828 - val_auc: 0.9342\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3001 - accuracy: 0.8543 - auc: 0.9474 - val_loss: 0.3507 - val_accuracy: 0.8832 - val_auc: 0.9353\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3000 - accuracy: 0.8562 - auc: 0.9465 - val_loss: 0.3493 - val_accuracy: 0.8810 - val_auc: 0.9355\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2923 - accuracy: 0.8551 - auc: 0.9500 - val_loss: 0.3554 - val_accuracy: 0.8833 - val_auc: 0.9347\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2790 - accuracy: 0.8591 - auc: 0.9542 - val_loss: 0.3581 - val_accuracy: 0.8851 - val_auc: 0.9342\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2825 - accuracy: 0.8593 - auc: 0.9530 - val_loss: 0.3609 - val_accuracy: 0.8842 - val_auc: 0.9338\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2810 - accuracy: 0.8606 - auc: 0.9535 - val_loss: 0.3638 - val_accuracy: 0.8863 - val_auc: 0.9340\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2801 - accuracy: 0.8624 - auc: 0.9533 - val_loss: 0.3683 - val_accuracy: 0.8849 - val_auc: 0.9340\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2670 - accuracy: 0.8606 - auc: 0.9574 - val_loss: 0.3735 - val_accuracy: 0.8854 - val_auc: 0.9339\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2677 - accuracy: 0.8637 - auc: 0.9570 - val_loss: 0.3757 - val_accuracy: 0.8855 - val_auc: 0.9344\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2750 - accuracy: 0.8613 - auc: 0.9547 - val_loss: 0.3797 - val_accuracy: 0.8830 - val_auc: 0.9338\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2664 - accuracy: 0.8636 - auc: 0.9576 - val_loss: 0.3805 - val_accuracy: 0.8849 - val_auc: 0.9339\n",
      "Epoch 29/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2748 - accuracy: 0.8638 - auc: 0.9551Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2741 - accuracy: 0.8637 - auc: 0.9553 - val_loss: 0.3841 - val_accuracy: 0.8854 - val_auc: 0.9341\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 21us/sample - loss: 0.9791 - accuracy: 0.5180 - auc: 0.5802 - val_loss: 0.5657 - val_accuracy: 0.6037 - val_auc: 0.8677\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5673 - accuracy: 0.6478 - auc: 0.8222 - val_loss: 0.4316 - val_accuracy: 0.7855 - val_auc: 0.9142\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4660 - accuracy: 0.7676 - auc: 0.8808 - val_loss: 0.3876 - val_accuracy: 0.8488 - val_auc: 0.9257\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4240 - accuracy: 0.8166 - auc: 0.8988 - val_loss: 0.3680 - val_accuracy: 0.8638 - val_auc: 0.9286\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3904 - accuracy: 0.8346 - auc: 0.9169 - val_loss: 0.3539 - val_accuracy: 0.8779 - val_auc: 0.9315\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3553 - accuracy: 0.8587 - auc: 0.9296 - val_loss: 0.3454 - val_accuracy: 0.8853 - val_auc: 0.9319\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3447 - accuracy: 0.8592 - auc: 0.9309 - val_loss: 0.3474 - val_accuracy: 0.8855 - val_auc: 0.9322\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3297 - accuracy: 0.8654 - auc: 0.9369 - val_loss: 0.3443 - val_accuracy: 0.8881 - val_auc: 0.9323\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3169 - accuracy: 0.8683 - auc: 0.9424 - val_loss: 0.3483 - val_accuracy: 0.8908 - val_auc: 0.9317\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3323 - accuracy: 0.8702 - auc: 0.9358 - val_loss: 0.3463 - val_accuracy: 0.8880 - val_auc: 0.9336\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3030 - accuracy: 0.8733 - auc: 0.9468 - val_loss: 0.3480 - val_accuracy: 0.8920 - val_auc: 0.9332\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3029 - accuracy: 0.8785 - auc: 0.9463 - val_loss: 0.3539 - val_accuracy: 0.8952 - val_auc: 0.9322\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2962 - accuracy: 0.8752 - auc: 0.9489 - val_loss: 0.3585 - val_accuracy: 0.8945 - val_auc: 0.9309\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2890 - accuracy: 0.8799 - auc: 0.9510 - val_loss: 0.3639 - val_accuracy: 0.8937 - val_auc: 0.9294\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2894 - accuracy: 0.8772 - auc: 0.9508 - val_loss: 0.3674 - val_accuracy: 0.8938 - val_auc: 0.9291\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2837 - accuracy: 0.8763 - auc: 0.9526 - val_loss: 0.3680 - val_accuracy: 0.8930 - val_auc: 0.9298\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2852 - accuracy: 0.8785 - auc: 0.9519 - val_loss: 0.3765 - val_accuracy: 0.8954 - val_auc: 0.9286\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2795 - accuracy: 0.8834 - auc: 0.9538 - val_loss: 0.3802 - val_accuracy: 0.8953 - val_auc: 0.9276\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2708 - accuracy: 0.8842 - auc: 0.9566 - val_loss: 0.3865 - val_accuracy: 0.8959 - val_auc: 0.9271\n",
      "Epoch 20/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.8801 - auc: 0.9554Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2737 - accuracy: 0.8801 - auc: 0.9555 - val_loss: 0.3905 - val_accuracy: 0.8939 - val_auc: 0.9265\n",
      "Epoch 00020: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.8130 - accuracy: 0.4470 - auc: 0.6863 - val_loss: 0.4695 - val_accuracy: 0.6298 - val_auc: 0.9111\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5036 - accuracy: 0.6748 - auc: 0.8726 - val_loss: 0.3791 - val_accuracy: 0.8119 - val_auc: 0.9287\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.4317 - accuracy: 0.7764 - auc: 0.8996 - val_loss: 0.3506 - val_accuracy: 0.8528 - val_auc: 0.9336\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.4117 - accuracy: 0.8152 - auc: 0.9064 - val_loss: 0.3364 - val_accuracy: 0.8641 - val_auc: 0.9369\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3795 - accuracy: 0.8405 - auc: 0.9209 - val_loss: 0.3215 - val_accuracy: 0.8742 - val_auc: 0.9409\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.3738 - accuracy: 0.8512 - auc: 0.9229 - val_loss: 0.3226 - val_accuracy: 0.8745 - val_auc: 0.9393\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3387 - accuracy: 0.8572 - auc: 0.9340 - val_loss: 0.3250 - val_accuracy: 0.8817 - val_auc: 0.9361\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3280 - accuracy: 0.8636 - auc: 0.9376 - val_loss: 0.3247 - val_accuracy: 0.8880 - val_auc: 0.9363\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3188 - accuracy: 0.8740 - auc: 0.9411 - val_loss: 0.3264 - val_accuracy: 0.8897 - val_auc: 0.9357\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3107 - accuracy: 0.8739 - auc: 0.9441 - val_loss: 0.3301 - val_accuracy: 0.8919 - val_auc: 0.9352racy: 0.87\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3049 - accuracy: 0.8770 - auc: 0.9452 - val_loss: 0.3350 - val_accuracy: 0.8940 - val_auc: 0.9352\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3073 - accuracy: 0.8725 - auc: 0.9462 - val_loss: 0.3383 - val_accuracy: 0.8906 - val_auc: 0.9343\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2961 - accuracy: 0.8800 - auc: 0.9482 - val_loss: 0.3369 - val_accuracy: 0.8922 - val_auc: 0.9351\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2836 - accuracy: 0.8818 - auc: 0.9531 - val_loss: 0.3439 - val_accuracy: 0.8973 - val_auc: 0.9349\n",
      "Epoch 15/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8828 - auc: 0.9505 ETARestoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2895 - accuracy: 0.8829 - auc: 0.9506 - val_loss: 0.3470 - val_accuracy: 0.8934 - val_auc: 0.9355\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.9431 - accuracy: 0.2289 - auc: 0.7179 - val_loss: 0.5687 - val_accuracy: 0.3739 - val_auc: 0.8976\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5962 - accuracy: 0.5302 - auc: 0.8368 - val_loss: 0.4114 - val_accuracy: 0.7331 - val_auc: 0.9289\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4915 - accuracy: 0.6885 - auc: 0.8722 - val_loss: 0.3585 - val_accuracy: 0.8198 - val_auc: 0.9343\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4314 - accuracy: 0.7651 - auc: 0.8991 - val_loss: 0.3413 - val_accuracy: 0.8519 - val_auc: 0.9332\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4040 - accuracy: 0.7993 - auc: 0.9065 - val_loss: 0.3378 - val_accuracy: 0.8559 - val_auc: 0.9332\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3646 - accuracy: 0.8081 - auc: 0.9250 - val_loss: 0.3377 - val_accuracy: 0.8725 - val_auc: 0.9311\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3606 - accuracy: 0.8262 - auc: 0.9227 - val_loss: 0.3383 - val_accuracy: 0.8735 - val_auc: 0.9321\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3384 - accuracy: 0.8331 - auc: 0.9323 - val_loss: 0.3403 - val_accuracy: 0.8801 - val_auc: 0.9321\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3378 - accuracy: 0.8386 - auc: 0.9322 - val_loss: 0.3397 - val_accuracy: 0.8823 - val_auc: 0.9319\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3348 - accuracy: 0.8452 - auc: 0.9327 - val_loss: 0.3438 - val_accuracy: 0.8807 - val_auc: 0.9316\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3144 - accuracy: 0.8466 - auc: 0.9409 - val_loss: 0.3449 - val_accuracy: 0.8833 - val_auc: 0.9312\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3059 - accuracy: 0.8502 - auc: 0.9436 - val_loss: 0.3515 - val_accuracy: 0.8876 - val_auc: 0.9308\n",
      "Epoch 13/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3060 - accuracy: 0.8541 - auc: 0.9432Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3057 - accuracy: 0.8541 - auc: 0.9433 - val_loss: 0.3543 - val_accuracy: 0.8870 - val_auc: 0.9305\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.7134 - accuracy: 0.7361 - auc: 0.7185 - val_loss: 0.4310 - val_accuracy: 0.8015 - val_auc: 0.8942\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5003 - accuracy: 0.7925 - auc: 0.8549 - val_loss: 0.3765 - val_accuracy: 0.8570 - val_auc: 0.9207\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4443 - accuracy: 0.8202 - auc: 0.8914 - val_loss: 0.3542 - val_accuracy: 0.8712 - val_auc: 0.9308\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3884 - accuracy: 0.8618 - auc: 0.9155 - val_loss: 0.3370 - val_accuracy: 0.8879 - val_auc: 0.9343\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3751 - accuracy: 0.8690 - auc: 0.9201 - val_loss: 0.3277 - val_accuracy: 0.8926 - val_auc: 0.9364\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3514 - accuracy: 0.8811 - auc: 0.9288 - val_loss: 0.3233 - val_accuracy: 0.8948 - val_auc: 0.9359\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3452 - accuracy: 0.8842 - auc: 0.9316 - val_loss: 0.3249 - val_accuracy: 0.8968 - val_auc: 0.9350\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3286 - accuracy: 0.8854 - auc: 0.9388 - val_loss: 0.3294 - val_accuracy: 0.9000 - val_auc: 0.9333\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3161 - accuracy: 0.8917 - auc: 0.9425 - val_loss: 0.3245 - val_accuracy: 0.9015 - val_auc: 0.9348\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3116 - accuracy: 0.8941 - auc: 0.9445 - val_loss: 0.3289 - val_accuracy: 0.8983 - val_auc: 0.9338\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3092 - accuracy: 0.8889 - auc: 0.9444 - val_loss: 0.3313 - val_accuracy: 0.9001 - val_auc: 0.9341\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2991 - accuracy: 0.8964 - auc: 0.9479 - val_loss: 0.3299 - val_accuracy: 0.9023 - val_auc: 0.9336\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2978 - accuracy: 0.8953 - auc: 0.9487 - val_loss: 0.3297 - val_accuracy: 0.9022 - val_auc: 0.9335\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2974 - accuracy: 0.8960 - auc: 0.9485 - val_loss: 0.3299 - val_accuracy: 0.9002 - val_auc: 0.9340\n",
      "Epoch 15/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.8931 - auc: 0.9525Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2869 - accuracy: 0.8931 - auc: 0.9525 - val_loss: 0.3290 - val_accuracy: 0.9029 - val_auc: 0.9349\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.6638 - accuracy: 0.6004 - auc: 0.7558 - val_loss: 0.4205 - val_accuracy: 0.7464 - val_auc: 0.9182ss: 0.7091 - accura\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4911 - accuracy: 0.7455 - auc: 0.8743 - val_loss: 0.3614 - val_accuracy: 0.8476 - val_auc: 0.9307\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4399 - accuracy: 0.8029 - auc: 0.8929 - val_loss: 0.3429 - val_accuracy: 0.8604 - val_auc: 0.9362\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4097 - accuracy: 0.8326 - auc: 0.9062 - val_loss: 0.3365 - val_accuracy: 0.8678 - val_auc: 0.9353\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3725 - accuracy: 0.8472 - auc: 0.9221 - val_loss: 0.3309 - val_accuracy: 0.8747 - val_auc: 0.9352\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3574 - accuracy: 0.8550 - auc: 0.9274 - val_loss: 0.3275 - val_accuracy: 0.8793 - val_auc: 0.9364\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3530 - accuracy: 0.8630 - auc: 0.9307 - val_loss: 0.3255 - val_accuracy: 0.8848 - val_auc: 0.9362\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3367 - accuracy: 0.8658 - auc: 0.9342 - val_loss: 0.3267 - val_accuracy: 0.8863 - val_auc: 0.9352\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3181 - accuracy: 0.8692 - auc: 0.9425 - val_loss: 0.3288 - val_accuracy: 0.8890 - val_auc: 0.9348\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3135 - accuracy: 0.8738 - auc: 0.9431 - val_loss: 0.3237 - val_accuracy: 0.8907 - val_auc: 0.9355\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3196 - accuracy: 0.8778 - auc: 0.9410 - val_loss: 0.3267 - val_accuracy: 0.8926 - val_auc: 0.9348\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3084 - accuracy: 0.8792 - auc: 0.9452 - val_loss: 0.3250 - val_accuracy: 0.8898 - val_auc: 0.9355\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2947 - accuracy: 0.8772 - auc: 0.9500 - val_loss: 0.3273 - val_accuracy: 0.8937 - val_auc: 0.9347\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2934 - accuracy: 0.8838 - auc: 0.9499 - val_loss: 0.3332 - val_accuracy: 0.8922 - val_auc: 0.9338\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2970 - accuracy: 0.8800 - auc: 0.9496 - val_loss: 0.3367 - val_accuracy: 0.8929 - val_auc: 0.9335\n",
      "Epoch 16/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2872 - accuracy: 0.8834 - auc: 0.9518Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2870 - accuracy: 0.8834 - auc: 0.9518 - val_loss: 0.3358 - val_accuracy: 0.8926 - val_auc: 0.9341\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 312863 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "312863/312863 [==============================] - 5s 15us/sample - loss: 0.4915 - accuracy: 0.7261 - auc: 0.8803 - val_loss: 0.3442 - val_accuracy: 0.8616 - val_auc: 0.9301\n",
      "Epoch 2/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.3871 - accuracy: 0.8134 - auc: 0.9180 - val_loss: 0.3376 - val_accuracy: 0.8685 - val_auc: 0.9308\n",
      "Epoch 3/100\n",
      "312863/312863 [==============================] - 3s 9us/sample - loss: 0.3402 - accuracy: 0.8558 - auc: 0.9334 - val_loss: 0.3235 - val_accuracy: 0.8642 - val_auc: 0.9402\n",
      "Epoch 4/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.3361 - accuracy: 0.8607 - auc: 0.9349 - val_loss: 0.3366 - val_accuracy: 0.8776 - val_auc: 0.9383\n",
      "Epoch 5/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.3280 - accuracy: 0.8751 - auc: 0.9398 - val_loss: 0.3553 - val_accuracy: 0.8838 - val_auc: 0.9340\n",
      "Epoch 6/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.3273 - accuracy: 0.8761 - auc: 0.9400 - val_loss: 0.3492 - val_accuracy: 0.8742 - val_auc: 0.9354\n",
      "Epoch 7/100\n",
      "312863/312863 [==============================] - 3s 9us/sample - loss: 0.3268 - accuracy: 0.8751 - auc: 0.9396 - val_loss: 0.3880 - val_accuracy: 0.8878 - val_auc: 0.9289\n",
      "Epoch 8/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.3250 - accuracy: 0.8782 - auc: 0.9421 - val_loss: 0.3663 - val_accuracy: 0.8906 - val_auc: 0.9334\n",
      "Epoch 9/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.3260 - accuracy: 0.8848 - auc: 0.9414 - val_loss: 0.4059 - val_accuracy: 0.9124 - val_auc: 0.9294\n",
      "Epoch 10/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.3168 - accuracy: 0.8879 - auc: 0.9423 - val_loss: 0.3845 - val_accuracy: 0.8991 - val_auc: 0.9319\n",
      "Epoch 11/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.2930 - accuracy: 0.8866 - auc: 0.9505 - val_loss: 0.4174 - val_accuracy: 0.8832 - val_auc: 0.9301\n",
      "Epoch 12/100\n",
      "312863/312863 [==============================] - 3s 10us/sample - loss: 0.3170 - accuracy: 0.8803 - auc: 0.9451 - val_loss: 0.4627 - val_accuracy: 0.9140 - val_auc: 0.9263\n",
      "Epoch 13/100\n",
      "310272/312863 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.8844 - auc: 0.9478Restoring model weights from the end of the best epoch.\n",
      "312863/312863 [==============================] - 3s 9us/sample - loss: 0.3006 - accuracy: 0.8843 - auc: 0.9478 - val_loss: 0.4899 - val_accuracy: 0.8895 - val_auc: 0.9273\n",
      "Epoch 00013: early stopping\n",
      "127.6017475326856\n"
     ]
    }
   ],
   "source": [
    "model= KerasClassifier(build_fn = create_model)\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_options,\n",
    "                    scoring=scores,\n",
    "                    refit='AUC')\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train,\n",
    "                       callbacks=[es],\n",
    "                       epochs=100,\n",
    "                       class_weight=class_weight,\n",
    "                       validation_data = (X_val,y_val),verbose = 1)\n",
    "end_time=time.time()\n",
    "\n",
    "print((end_time-start_time)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T01:12:26.033639Z",
     "start_time": "2020-05-12T01:12:25.666632Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "J_IMch4MjhLO"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(grid_result.cv_results_).to_excel('GS_weights_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "VCA-ID-Tuning for weight.ipynb",
   "provenance": [
    {
     "file_id": "1feXHQjiqioLl47_p65uRpdSv6vX9EnAr",
     "timestamp": 1589212555597
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
