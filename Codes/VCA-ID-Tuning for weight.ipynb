{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:44:40.812597Z",
     "start_time": "2020-05-21T20:44:39.241218Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1QxOQkOlJ1S_"
   },
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cq34ehtsJ1Th"
   },
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:44:50.234934Z",
     "start_time": "2020-05-21T20:44:40.816085Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10148,
     "status": "ok",
     "timestamp": 1589212832817,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "_v04MZq4J1To",
    "outputId": "0dd4542d-a365-47ce-8669-1d559fef6985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488849, 151)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prsn_Injry_Sev_ID</th>\n",
       "      <th>Unit_Nbr</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Toll_Road_Fl</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Constr_Zone_Fl</th>\n",
       "      <th>Road_Constr_Zone_Wrkr_Fl</th>\n",
       "      <th>At_Intrsct_Fl</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_Cntl_ID_SIGNAL LIGHT WITH RED LIGHT RUNNING CAMERA</th>\n",
       "      <th>Traffic_Cntl_ID_STOP SIGN</th>\n",
       "      <th>Traffic_Cntl_ID_WARNING SIGN</th>\n",
       "      <th>Unit_Desc_ID_MOTOR VEHICLE</th>\n",
       "      <th>Unit_Desc_ID_MOTORIZED CONVEYANCE</th>\n",
       "      <th>Unit_Desc_ID_NON-CONTACT</th>\n",
       "      <th>Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)</th>\n",
       "      <th>Unit_Desc_ID_PEDALCYCLIST</th>\n",
       "      <th>Unit_Desc_ID_PEDESTRIAN</th>\n",
       "      <th>Unit_Desc_ID_TOWED/PUSHED/TRAILER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.660685</td>\n",
       "      <td>-93.893906</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.660685</td>\n",
       "      <td>-93.893906</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.203920</td>\n",
       "      <td>-96.596654</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.203920</td>\n",
       "      <td>-96.596654</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.792394</td>\n",
       "      <td>-95.746539</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prsn_Injry_Sev_ID  Unit_Nbr  Prsn_Age  Toll_Road_Fl  Crash_Speed_Limit  \\\n",
       "0                  0         1      48.0             0                 35   \n",
       "1                  2         2      58.0             0                 35   \n",
       "2                  0         1      68.0             0                 45   \n",
       "3                  0         3      67.0             0                 45   \n",
       "4                  0         1      36.0             0                 35   \n",
       "\n",
       "   Road_Constr_Zone_Fl  Road_Constr_Zone_Wrkr_Fl  At_Intrsct_Fl   Latitude  \\\n",
       "0                    0                         0              0  30.660685   \n",
       "1                    0                         0              0  30.660685   \n",
       "2                    0                         0              1  33.203920   \n",
       "3                    0                         0              1  33.203920   \n",
       "4                    0                         0              1  29.792394   \n",
       "\n",
       "   Longitude  ...  Traffic_Cntl_ID_SIGNAL LIGHT WITH RED LIGHT RUNNING CAMERA  \\\n",
       "0 -93.893906  ...                                                  0            \n",
       "1 -93.893906  ...                                                  0            \n",
       "2 -96.596654  ...                                                  0            \n",
       "3 -96.596654  ...                                                  0            \n",
       "4 -95.746539  ...                                                  0            \n",
       "\n",
       "   Traffic_Cntl_ID_STOP SIGN  Traffic_Cntl_ID_WARNING SIGN  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             1   \n",
       "\n",
       "   Unit_Desc_ID_MOTOR VEHICLE  Unit_Desc_ID_MOTORIZED CONVEYANCE  \\\n",
       "0                           1                                  0   \n",
       "1                           1                                  0   \n",
       "2                           1                                  0   \n",
       "3                           1                                  0   \n",
       "4                           1                                  0   \n",
       "\n",
       "   Unit_Desc_ID_NON-CONTACT  Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)  \\\n",
       "0                         0                                          0   \n",
       "1                         0                                          0   \n",
       "2                         0                                          0   \n",
       "3                         0                                          0   \n",
       "4                         0                                          0   \n",
       "\n",
       "   Unit_Desc_ID_PEDALCYCLIST  Unit_Desc_ID_PEDESTRIAN  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   Unit_Desc_ID_TOWED/PUSHED/TRAILER  \n",
       "0                                  0  \n",
       "1                                  0  \n",
       "2                                  0  \n",
       "3                                  0  \n",
       "4                                  0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link='https://github.com/duonghung86/Fatality-crashes/raw/master/Codes/final%20data.zip'\n",
    "url = urllib.request.urlopen(link)\n",
    "with ZipFile(BytesIO(url.read())) as my_zip_file:\n",
    "    for contained_file in my_zip_file.namelist():\n",
    "        fzip=my_zip_file.open(contained_file)\n",
    "        data=fzip.read()\n",
    "\n",
    "s=str(data,'utf-8')\n",
    "data = StringIO(s)\n",
    "df=pd.read_csv(data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:45:08.945606Z",
     "start_time": "2020-05-21T20:45:08.935127Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10132,
     "status": "ok",
     "timestamp": 1589212832818,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "0yIHRk4sJ1Tx",
    "outputId": "d91e40bd-c01e-4fd0-86d0-bdbcd3ed9f69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.where(df['Prsn_Injry_Sev_ID']==4,1,0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:45:12.593932Z",
     "start_time": "2020-05-21T20:45:12.582954Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10117,
     "status": "ok",
     "timestamp": 1589212832820,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "0Ba_lXcHJ1UI",
    "outputId": "b43fce0d-8bd8-477b-aa39-501a76edc1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 488849\n",
      "    Positive: 1494 (0.31% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(y)\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:45:19.140222Z",
     "start_time": "2020-05-21T20:45:17.017669Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11433,
     "status": "ok",
     "timestamp": 1589212834154,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "Cl4mz5NYJ1UV",
    "outputId": "65dad35a-0845-4226-f71e-61010fc5228e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit_Nbr</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Toll_Road_Fl</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Constr_Zone_Fl</th>\n",
       "      <th>Road_Constr_Zone_Wrkr_Fl</th>\n",
       "      <th>At_Intrsct_Fl</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Crash_month</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_Cntl_ID_SIGNAL LIGHT WITH RED LIGHT RUNNING CAMERA</th>\n",
       "      <th>Traffic_Cntl_ID_STOP SIGN</th>\n",
       "      <th>Traffic_Cntl_ID_WARNING SIGN</th>\n",
       "      <th>Unit_Desc_ID_MOTOR VEHICLE</th>\n",
       "      <th>Unit_Desc_ID_MOTORIZED CONVEYANCE</th>\n",
       "      <th>Unit_Desc_ID_NON-CONTACT</th>\n",
       "      <th>Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)</th>\n",
       "      <th>Unit_Desc_ID_PEDALCYCLIST</th>\n",
       "      <th>Unit_Desc_ID_PEDESTRIAN</th>\n",
       "      <th>Unit_Desc_ID_TOWED/PUSHED/TRAILER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.660685</td>\n",
       "      <td>-93.893906</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.660685</td>\n",
       "      <td>-93.893906</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.203920</td>\n",
       "      <td>-96.596654</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.203920</td>\n",
       "      <td>-96.596654</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.792394</td>\n",
       "      <td>-95.746539</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488844</th>\n",
       "      <td>1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.954878</td>\n",
       "      <td>-97.987513</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488845</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.756880</td>\n",
       "      <td>-94.354907</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488846</th>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.756880</td>\n",
       "      <td>-94.354907</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488847</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.279209</td>\n",
       "      <td>-94.579816</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488848</th>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.279209</td>\n",
       "      <td>-94.579816</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488849 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unit_Nbr  Prsn_Age  Toll_Road_Fl  Crash_Speed_Limit  \\\n",
       "0              1      48.0             0                 35   \n",
       "1              2      58.0             0                 35   \n",
       "2              1      68.0             0                 45   \n",
       "3              3      67.0             0                 45   \n",
       "4              1      36.0             0                 35   \n",
       "...          ...       ...           ...                ...   \n",
       "488844         1      68.0             0                 70   \n",
       "488845         1      44.0             0                 55   \n",
       "488846         2      57.0             0                 55   \n",
       "488847         1      16.0             0                 40   \n",
       "488848         2      16.0             0                 40   \n",
       "\n",
       "        Road_Constr_Zone_Fl  Road_Constr_Zone_Wrkr_Fl  At_Intrsct_Fl  \\\n",
       "0                         0                         0              0   \n",
       "1                         0                         0              0   \n",
       "2                         0                         0              1   \n",
       "3                         0                         0              1   \n",
       "4                         0                         0              1   \n",
       "...                     ...                       ...            ...   \n",
       "488844                    0                         0              1   \n",
       "488845                    0                         0              1   \n",
       "488846                    0                         0              1   \n",
       "488847                    0                         0              0   \n",
       "488848                    0                         0              0   \n",
       "\n",
       "         Latitude  Longitude  Crash_month  ...  \\\n",
       "0       30.660685 -93.893906            6  ...   \n",
       "1       30.660685 -93.893906            6  ...   \n",
       "2       33.203920 -96.596654            6  ...   \n",
       "3       33.203920 -96.596654            6  ...   \n",
       "4       29.792394 -95.746539            6  ...   \n",
       "...           ...        ...          ...  ...   \n",
       "488844  28.954878 -97.987513           11  ...   \n",
       "488845  32.756880 -94.354907           11  ...   \n",
       "488846  32.756880 -94.354907           11  ...   \n",
       "488847  31.279209 -94.579816            9  ...   \n",
       "488848  31.279209 -94.579816            9  ...   \n",
       "\n",
       "        Traffic_Cntl_ID_SIGNAL LIGHT WITH RED LIGHT RUNNING CAMERA  \\\n",
       "0                                                       0            \n",
       "1                                                       0            \n",
       "2                                                       0            \n",
       "3                                                       0            \n",
       "4                                                       0            \n",
       "...                                                   ...            \n",
       "488844                                                  0            \n",
       "488845                                                  0            \n",
       "488846                                                  0            \n",
       "488847                                                  0            \n",
       "488848                                                  0            \n",
       "\n",
       "        Traffic_Cntl_ID_STOP SIGN  Traffic_Cntl_ID_WARNING SIGN  \\\n",
       "0                               0                             0   \n",
       "1                               0                             0   \n",
       "2                               0                             0   \n",
       "3                               0                             0   \n",
       "4                               0                             1   \n",
       "...                           ...                           ...   \n",
       "488844                          0                             0   \n",
       "488845                          1                             0   \n",
       "488846                          1                             0   \n",
       "488847                          1                             0   \n",
       "488848                          1                             0   \n",
       "\n",
       "        Unit_Desc_ID_MOTOR VEHICLE  Unit_Desc_ID_MOTORIZED CONVEYANCE  \\\n",
       "0                                1                                  0   \n",
       "1                                1                                  0   \n",
       "2                                1                                  0   \n",
       "3                                1                                  0   \n",
       "4                                1                                  0   \n",
       "...                            ...                                ...   \n",
       "488844                           1                                  0   \n",
       "488845                           1                                  0   \n",
       "488846                           1                                  0   \n",
       "488847                           1                                  0   \n",
       "488848                           1                                  0   \n",
       "\n",
       "        Unit_Desc_ID_NON-CONTACT  Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)  \\\n",
       "0                              0                                          0   \n",
       "1                              0                                          0   \n",
       "2                              0                                          0   \n",
       "3                              0                                          0   \n",
       "4                              0                                          0   \n",
       "...                          ...                                        ...   \n",
       "488844                         0                                          0   \n",
       "488845                         0                                          0   \n",
       "488846                         0                                          0   \n",
       "488847                         0                                          0   \n",
       "488848                         0                                          0   \n",
       "\n",
       "        Unit_Desc_ID_PEDALCYCLIST  Unit_Desc_ID_PEDESTRIAN  \\\n",
       "0                               0                        0   \n",
       "1                               0                        0   \n",
       "2                               0                        0   \n",
       "3                               0                        0   \n",
       "4                               0                        0   \n",
       "...                           ...                      ...   \n",
       "488844                          0                        0   \n",
       "488845                          0                        0   \n",
       "488846                          0                        0   \n",
       "488847                          0                        0   \n",
       "488848                          0                        0   \n",
       "\n",
       "        Unit_Desc_ID_TOWED/PUSHED/TRAILER  \n",
       "0                                       0  \n",
       "1                                       0  \n",
       "2                                       0  \n",
       "3                                       0  \n",
       "4                                       0  \n",
       "...                                   ...  \n",
       "488844                                  0  \n",
       "488845                                  0  \n",
       "488846                                  0  \n",
       "488847                                  0  \n",
       "488848                                  0  \n",
       "\n",
       "[488849 rows x 150 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,1:].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "548Mc3Y4J1Ui"
   },
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:33.818149Z",
     "start_time": "2020-05-21T20:49:32.580161Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5ERPlNBhJ1Ul"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:54.992352Z",
     "start_time": "2020-05-21T20:49:49.885793Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13534,
     "status": "ok",
     "timestamp": 1589212836277,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "6dDdGqNSJ1Uo",
    "outputId": "2750b62b-92b8-453e-98ba-cc5a1d23821f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (312863, 150)\n",
      "Validation features shape: (78216, 150)\n",
      "Test features shape: (97770, 150)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2,stratify=y_train, random_state=48)\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "X_val=np.array(X_val)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:55.014311Z",
     "start_time": "2020-05-21T20:49:54.996344Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13523,
     "status": "ok",
     "timestamp": 1589212836278,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "Ut-NVd4nJ1Uv",
    "outputId": "d5511c3a-2bc8-4caa-f7e8-fdb612ad8ac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (312863, 1)\n",
      "Validation features shape: (78216, 1)\n",
      "Test features shape: (97770, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train=np.array(y_train).reshape(len(y_train),1)\n",
    "y_test=np.array(y_test).reshape(len(y_test),1)\n",
    "y_val=np.array(y_val).reshape(len(y_val),1)\n",
    "\n",
    "print('Training features shape:', y_train.shape)\n",
    "print('Validation features shape:', y_val.shape)\n",
    "print('Test features shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:55.026787Z",
     "start_time": "2020-05-21T20:49:55.019800Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Lj2Ka9kMJ1U2"
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:57.786654Z",
     "start_time": "2020-05-21T20:49:55.030780Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BiA2g-qsJ1U6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcaKVTGuJ1Vm"
   },
   "source": [
    "# MLP simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HquajIY-J1Vn"
   },
   "source": [
    "## Mini functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Z54FMlfJ1Vp"
   },
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.647931Z",
     "start_time": "2020-05-21T20:49:57.789151Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15926,
     "status": "ok",
     "timestamp": 1589212838693,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "dBEUbS6cYuve",
    "outputId": "511d15ce-1237-4747-9635-9a334cac1bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.733470Z",
     "start_time": "2020-05-21T20:50:07.654421Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "          keras.metrics.Precision(name='precision'),\n",
    "          keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.762718Z",
     "start_time": "2020-05-21T20:50:07.738763Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.BinaryAccuracy(name='accuracy'),keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.785180Z",
     "start_time": "2020-05-21T20:50:07.771203Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yIup1KAaJ1Vr"
   },
   "outputs": [],
   "source": [
    "def create_model(nodes=20,actih='relu',actio='sigmoid',lr=1e-3,output_bias=None,logits=False):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(nodes, activation=actih,input_dim=X_train.shape[1]))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation=actio,bias_initializer=output_bias))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=logits),\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXXqeCA-J1Vu"
   },
   "source": [
    "### Show confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.799649Z",
     "start_time": "2020-05-21T20:50:07.790666Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BCMLDgLcYo6T"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.824106Z",
     "start_time": "2020-05-21T20:50:07.804143Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZhneEw4cRND_"
   },
   "outputs": [],
   "source": [
    "def CI(arr):\n",
    "    op=[arr[0,0],arr[1,1]]/arr.sum(axis=0)\n",
    "    op=np.append(op,(arr[0,0]+arr[1,1])/arr.sum())\n",
    "    op=pd.DataFrame(op,columns=['Precision'],index=['0','1','Global'])\n",
    "    op['n_p']=np.append(arr.sum(axis=0),arr.sum())\n",
    "    op['CI_p']=196*np.sqrt(op.Precision*(1-op.Precision)/op.n_p)\n",
    "    op['Precision']=op.Precision*100\n",
    "\n",
    "    op['Recall']=np.append([arr[0,0],arr[1,1]]/arr.sum(axis=1),(arr[0,0]+arr[1,1])/arr.sum())\n",
    "    op['n_r']=np.append(arr.sum(axis=1),arr.sum())\n",
    "    op['CI_r']=196*np.sqrt(op.Recall*(1-op.Recall)/op.n_r)\n",
    "    op['Recall']=op.Recall*100\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.838078Z",
     "start_time": "2020-05-21T20:50:07.828596Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uFfBF83bJ1V0"
   },
   "outputs": [],
   "source": [
    "def show_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    print(cm)\n",
    "    pcm=classification_report(labels, predictions > p, target_names=['Class 0','Class 1']) \n",
    "    print(pcm)\n",
    "    return CI(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7vWECLdJ1V_"
   },
   "source": [
    "### Plot ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.856545Z",
     "start_time": "2020-05-21T20:50:07.841073Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "C3yM0beyZCHc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.877006Z",
     "start_time": "2020-05-21T20:50:07.863531Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tuV1U8jcJ1WG"
   },
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name + ' (area = %0.2f)' % auc(fp, tp), linewidth=1.5, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([0,100.5])\n",
    "  plt.ylim([0,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.399036Z",
     "start_time": "2020-05-21T20:50:07.880499Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1508,
     "status": "ok",
     "timestamp": 1589212863809,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "gS6h-0G3J1WN",
    "outputId": "b164d038-a489-4aaa-8869-9fd59a9d66f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((150,), (1,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.518317Z",
     "start_time": "2020-05-21T20:50:08.404026Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1497,
     "status": "ok",
     "timestamp": 1589212863810,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "ruuam0vyJ1WT",
    "outputId": "78563a28-99b6-48f3-f572-a6ab749a9e9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((150,), (1,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.533286Z",
     "start_time": "2020-05-21T20:50:08.522306Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1589212863811,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "XkkyFt4uJ1WZ",
    "outputId": "0b58a826-057b-4f6a-fad5-5977d5d47db2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.78753572])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:22:45.429511Z",
     "start_time": "2020-05-21T21:22:45.422024Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3VS51FQTJ1Wk"
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=20,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.571713Z",
     "start_time": "2020-05-21T20:50:08.558738Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CA3Zf0VHJ1Wo"
   },
   "outputs": [],
   "source": [
    "batch_size=2048\n",
    "data_train = data_train.shuffle(len(X_train)).batch(batch_size)\n",
    "data_val = data_val.shuffle(len(X_val)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.583193Z",
     "start_time": "2020-05-21T20:50:08.576206Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wOnyvd3jK739"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:09.313344Z",
     "start_time": "2020-05-21T20:50:08.590678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00471044],\n",
       "       [0.0028761 ],\n",
       "       [0.00174774],\n",
       "       [0.00389626],\n",
       "       [0.00263414],\n",
       "       [0.00190601],\n",
       "       [0.0043803 ],\n",
       "       [0.00223479],\n",
       "       [0.00286854],\n",
       "       [0.00290411]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(output_bias = initial_bias)\n",
    "model.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:12.091676Z",
     "start_time": "2020-05-21T20:50:09.316341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0221\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_train, y_train, batch_size=2048, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:12.107148Z",
     "start_time": "2020-05-21T20:50:12.095670Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:12.259865Z",
     "start_time": "2020-05-21T20:50:12.112637Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:12.282323Z",
     "start_time": "2020-05-21T20:50:12.264357Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model2(nodes=20,actih='relu',actio='sigmoid',lr=1e-3,logits=False):\n",
    "    \n",
    "    #output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(nodes, activation=actih,input_dim=X_train.shape[1]))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation=actio,bias_initializer=None))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=logits),\n",
    "                  metrics=metrics)\n",
    "    model.load_weights(initial_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:47:44.768449Z",
     "start_time": "2020-05-08T22:47:44.455029Z"
    },
    "colab_type": "text",
    "id": "loWcs-MKJ1XR"
   },
   "source": [
    "## Class weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDLuSQMabKFn"
   },
   "source": [
    "### Class weight estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:40.197519Z",
     "start_time": "2020-05-21T20:50:40.191031Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1589212863815,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "y1tT_8gBbIl_",
    "outputId": "28410c3a-2595-4278-ed44-eca0b117068c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.50\n",
      "Weight for class 1: 163.60\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-G092TzzbPWJ"
   },
   "source": [
    "### Run model with class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:15.219205Z",
     "start_time": "2020-05-21T20:51:05.062612Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79639,
     "status": "ok",
     "timestamp": 1589212942074,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "s1fC3msPblwo",
    "outputId": "a782bb12-0d03-44b5-f7e4-31e3e555cd3d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 153 steps, validate for 39 steps\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 13s 85ms/step - loss: 1.6360 - accuracy: 0.9838 - auc: 0.7620 - val_loss: 0.7229 - val_accuracy: 0.9777 - val_auc: 0.9116\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 5s 33ms/step - loss: 0.7431 - accuracy: 0.9410 - auc: 0.8778 - val_loss: 0.5798 - val_accuracy: 0.9361 - val_auc: 0.9296\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 6s 36ms/step - loss: 0.5662 - accuracy: 0.9074 - auc: 0.9025 - val_loss: 0.3973 - val_accuracy: 0.9258 - val_auc: 0.9381\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.5496 - accuracy: 0.9011 - auc: 0.9038 - val_loss: 0.3690 - val_accuracy: 0.9189 - val_auc: 0.9441\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 5s 36ms/step - loss: 0.4881 - accuracy: 0.9020 - auc: 0.9176 - val_loss: 0.3435 - val_accuracy: 0.9160 - val_auc: 0.9465\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.4659 - accuracy: 0.9003 - auc: 0.9223 - val_loss: 0.3308 - val_accuracy: 0.9214 - val_auc: 0.9494\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 6s 40ms/step - loss: 0.4509 - accuracy: 0.9048 - auc: 0.9233 - val_loss: 0.3248 - val_accuracy: 0.9199 - val_auc: 0.9517curacy: \n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.4248 - accuracy: 0.9083 - auc: 0.9308 - val_loss: 0.3132 - val_accuracy: 0.9188 - val_auc: 0.9529\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.4263 - accuracy: 0.9073 - auc: 0.9265 - val_loss: 0.3117 - val_accuracy: 0.9270 - val_auc: 0.9533\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.4077 - accuracy: 0.9073 - auc: 0.9335 - val_loss: 0.3077 - val_accuracy: 0.9272 - val_auc: 0.9534\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 6s 39ms/step - loss: 0.3982 - accuracy: 0.9113 - auc: 0.9366 - val_loss: 0.3050 - val_accuracy: 0.9231 - val_auc: 0.9538\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 6s 40ms/step - loss: 0.4059 - accuracy: 0.9067 - auc: 0.9333 - val_loss: 0.3023 - val_accuracy: 0.9186 - val_auc: 0.9543\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 5s 36ms/step - loss: 0.3857 - accuracy: 0.9074 - auc: 0.9381 - val_loss: 0.3020 - val_accuracy: 0.9229 - val_auc: 0.9551\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3814 - accuracy: 0.9068 - auc: 0.9386 - val_loss: 0.2956 - val_accuracy: 0.9256 - val_auc: 0.9564\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.3737 - accuracy: 0.9120 - auc: 0.9414 - val_loss: 0.2932 - val_accuracy: 0.9265 - val_auc: 0.9571\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 5s 36ms/step - loss: 0.3648 - accuracy: 0.9106 - auc: 0.9423 - val_loss: 0.2897 - val_accuracy: 0.9253 - val_auc: 0.9574\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 5s 36ms/step - loss: 0.3670 - accuracy: 0.9116 - auc: 0.9414 - val_loss: 0.2866 - val_accuracy: 0.9216 - val_auc: 0.9571\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 5s 36ms/step - loss: 0.3552 - accuracy: 0.9130 - auc: 0.9440 - val_loss: 0.2880 - val_accuracy: 0.9232 - val_auc: 0.9571\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 6s 36ms/step - loss: 0.3469 - accuracy: 0.9078 - auc: 0.9466 - val_loss: 0.2915 - val_accuracy: 0.9277 - val_auc: 0.9571\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3527 - accuracy: 0.9145 - auc: 0.9455 - val_loss: 0.2945 - val_accuracy: 0.9256 - val_auc: 0.9568\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3297 - accuracy: 0.9122 - auc: 0.9492 - val_loss: 0.2857 - val_accuracy: 0.9231 - val_auc: 0.9570\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.3276 - accuracy: 0.9132 - auc: 0.9496 - val_loss: 0.2847 - val_accuracy: 0.9261 - val_auc: 0.9570\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.3400 - accuracy: 0.9120 - auc: 0.9471 - val_loss: 0.2924 - val_accuracy: 0.9183 - val_auc: 0.9576\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 5s 34ms/step - loss: 0.3414 - accuracy: 0.9123 - auc: 0.9470 - val_loss: 0.2852 - val_accuracy: 0.9217 - val_auc: 0.9572\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3173 - accuracy: 0.9139 - auc: 0.9528 - val_loss: 0.2848 - val_accuracy: 0.9238 - val_auc: 0.9566\n",
      "Epoch 26/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3283 - accuracy: 0.9140 - auc: 0.9500 - val_loss: 0.2868 - val_accuracy: 0.9229 - val_auc: 0.9558\n",
      "Epoch 27/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3088 - accuracy: 0.9141 - auc: 0.9540 - val_loss: 0.2861 - val_accuracy: 0.9224 - val_auc: 0.9556\n",
      "Epoch 28/100\n",
      "153/153 [==============================] - 7s 45ms/step - loss: 0.3229 - accuracy: 0.9113 - auc: 0.9513 - val_loss: 0.2873 - val_accuracy: 0.9258 - val_auc: 0.9543\n",
      "Epoch 29/100\n",
      "153/153 [==============================] - 6s 37ms/step - loss: 0.3191 - accuracy: 0.9145 - auc: 0.9510 - val_loss: 0.2932 - val_accuracy: 0.9208 - val_auc: 0.9538\n",
      "Epoch 30/100\n",
      "153/153 [==============================] - 6s 36ms/step - loss: 0.3072 - accuracy: 0.9166 - auc: 0.9538 - val_loss: 0.2908 - val_accuracy: 0.9228 - val_auc: 0.9543\n",
      "Epoch 31/100\n",
      "153/153 [==============================] - 6s 42ms/step - loss: 0.3176 - accuracy: 0.9102 - auc: 0.9510 - val_loss: 0.2915 - val_accuracy: 0.9241 - val_auc: 0.9531\n",
      "Epoch 32/100\n",
      "153/153 [==============================] - 5s 35ms/step - loss: 0.3024 - accuracy: 0.9156 - auc: 0.9550 - val_loss: 0.3635 - val_accuracy: 0.9239 - val_auc: 0.9534\n",
      "Epoch 33/100\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.9169 - auc: 0.9582 ETA: Restoring model weights from the end of the best epoch.\n",
      "153/153 [==============================] - 5s 36ms/step - loss: 0.2899 - accuracy: 0.9170 - auc: 0.9583 - val_loss: 0.2930 - val_accuracy: 0.9241 - val_auc: 0.9534\n",
      "Epoch 00033: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "190.1456024646759"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "wei_model=create_model2()\n",
    "Monitor = wei_model.fit(data_train, epochs=100,callbacks=[es],validation_data = data_val,class_weight=class_weight, verbose = 1)\n",
    "end_time=time.time()\n",
    "end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:16.092237Z",
     "start_time": "2020-05-21T20:54:15.222699Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80136,
     "status": "ok",
     "timestamp": 1589212942584,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "gbJOrd5cb8dr",
    "outputId": "31c9319c-6bb8-4250-b977-0f828684e420"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.DataFrame(Monitor.history)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,4),dpi=150)\n",
    "hist[['loss','val_loss']].plot(ax=axes[0])\n",
    "hist[['auc','val_auc']].plot(ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGzf8FEoedp4"
   },
   "source": [
    "### Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:26.326017Z",
     "start_time": "2020-05-21T20:54:16.095973Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tNkmcPN9b8aA"
   },
   "outputs": [],
   "source": [
    "y_pred_train_b = wei_model.predict(X_train)\n",
    "y_pred_test_b = wei_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:27.681796Z",
     "start_time": "2020-05-21T20:54:26.329968Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87565,
     "status": "ok",
     "timestamp": 1589212950043,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "g1AwenWlcgTC",
    "outputId": "a4a70811-abfe-43b4-c30e-1418753a6ff5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(len(y_test)),y_pred_test_b,s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:28.274005Z",
     "start_time": "2020-05-21T20:54:27.684793Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87816,
     "status": "ok",
     "timestamp": 1589212950314,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "5kiSMFi8b8Xp",
    "outputId": "d107db44-9db4-4e01-ddaf-54159c8a4beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89278  8193]\n",
      " [   48   251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.92      0.96     97471\n",
      "     Class 1       0.03      0.84      0.06       299\n",
      "\n",
      "    accuracy                           0.92     97770\n",
      "   macro avg       0.51      0.88      0.51     97770\n",
      "weighted avg       1.00      0.92      0.95     97770\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>n_p</th>\n",
       "      <th>CI_p</th>\n",
       "      <th>Recall</th>\n",
       "      <th>n_r</th>\n",
       "      <th>CI_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.946264</td>\n",
       "      <td>89326</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>91.594423</td>\n",
       "      <td>97471</td>\n",
       "      <td>0.174195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.972525</td>\n",
       "      <td>8444</td>\n",
       "      <td>0.362236</td>\n",
       "      <td>83.946488</td>\n",
       "      <td>299</td>\n",
       "      <td>4.161087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global</th>\n",
       "      <td>91.571034</td>\n",
       "      <td>97770</td>\n",
       "      <td>0.174148</td>\n",
       "      <td>91.571034</td>\n",
       "      <td>97770</td>\n",
       "      <td>0.174148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Precision    n_p      CI_p     Recall    n_r      CI_r\n",
       "0       99.946264  89326  0.015198  91.594423  97471  0.174195\n",
       "1        2.972525   8444  0.362236  83.946488    299  4.161087\n",
       "Global  91.571034  97770  0.174148  91.571034  97770  0.174148"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_cm(y_test,y_pred_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:28.678629Z",
     "start_time": "2020-05-21T20:54:28.277976Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1589213180188,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "l3yBCZz7b8So",
    "outputId": "c6a139fd-2956-47d0-e10b-f8ee4d54f91e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_roc('Base model - train',y_train,y_pred_train_b)\n",
    "plot_roc('Base model - test',y_test,y_pred_test_b)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iaw83EYPd20X"
   },
   "source": [
    "# Tuning parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:28.745489Z",
     "start_time": "2020-05-21T20:54:28.682123Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1589213605661,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "91RuQ-tob8Lt",
    "outputId": "8c7ccd57-0239-48ec-ec01-f64d6f119f52"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:03:25.789999Z",
     "start_time": "2020-05-21T21:03:25.784509Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ijqe1QW9clTc"
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.1,0.01,0.001]\n",
    "nodes = [5,10,20,30]\n",
    "batches=[1024,2048,4096]\n",
    "param_options = {'lr': learning_rates,'nodes': nodes,'batch_size':batches}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:03:28.088963Z",
     "start_time": "2020-05-21T21:03:28.084967Z"
    }
   },
   "outputs": [],
   "source": [
    "scores={'BA':'balanced_accuracy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T00:46:56.664071Z",
     "start_time": "2020-05-21T21:22:54.401397Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uetpo3uQfuSu",
    "outputId": "d2c9d310-5b2f-4ab7-8730-03f602afd365",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.9036 - accuracy: 0.7307 - auc: 0.6955 - val_loss: 0.4930 - val_accuracy: 0.8637 - val_auc: 0.8927\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6570 - accuracy: 0.5516 - auc: 0.7469 - val_loss: 0.4700 - val_accuracy: 0.6957 - val_auc: 0.8709\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6491 - accuracy: 0.5039 - auc: 0.7600 - val_loss: 0.4736 - val_accuracy: 0.6658 - val_auc: 0.8684\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5666 - accuracy: 0.5478 - auc: 0.8059 - val_loss: 0.5012 - val_accuracy: 0.7384 - val_auc: 0.8804\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5265 - accuracy: 0.5577 - auc: 0.7741 - val_loss: 0.4805 - val_accuracy: 0.6683 - val_auc: 0.8606\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5247 - accuracy: 0.5611 - auc: 0.7939 - val_loss: 0.4879 - val_accuracy: 0.7273 - val_auc: 0.8856\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6276 - accuracy: 0.5657 - auc: 0.8045 - val_loss: 0.6151 - val_accuracy: 0.6929 - val_auc: 0.8939\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5649 - accuracy: 0.5318 - auc: 0.7989 - val_loss: 0.8652 - val_accuracy: 0.6818 - val_auc: 0.8228\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6231 - accuracy: 0.5186 - auc: 0.7456 - val_loss: 0.8590 - val_accuracy: 0.6782 - val_auc: 0.8283\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6313 - accuracy: 0.5078 - auc: 0.7524 - val_loss: 1.1236 - val_accuracy: 0.6615 - val_auc: 0.8128\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5651 - accuracy: 0.5285 - auc: 0.7598 - val_loss: 0.7605 - val_accuracy: 0.6417 - val_auc: 0.8240\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5635 - accuracy: 0.5328 - auc: 0.7685 - val_loss: 1.3331 - val_accuracy: 0.6827 - val_auc: 0.8142\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7052 - accuracy: 0.5144 - auc: 0.7461 - val_loss: 1.0978 - val_accuracy: 0.6656 - val_auc: 0.8191\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6631 - accuracy: 0.4920 - auc: 0.7424 - val_loss: 1.2148 - val_accuracy: 0.6560 - val_auc: 0.8181\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5233 - accuracy: 0.4987 - auc: 0.7478 - val_loss: 1.0448 - val_accuracy: 0.6532 - val_auc: 0.8087\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5571 - accuracy: 0.5061 - auc: 0.7392 - val_loss: 1.4139 - val_accuracy: 0.6489 - val_auc: 0.8079\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5298 - accuracy: 0.5230 - auc: 0.7651 - val_loss: 1.1519 - val_accuracy: 0.6970 - val_auc: 0.8289\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5920 - accuracy: 0.5456 - auc: 0.7690 - val_loss: 1.4040 - val_accuracy: 0.7076 - val_auc: 0.8366\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5269 - accuracy: 0.5370 - auc: 0.7572 - val_loss: 1.2477 - val_accuracy: 0.6888 - val_auc: 0.8276\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5203 - accuracy: 0.5361 - auc: 0.7527 - val_loss: 1.1996 - val_accuracy: 0.6749 - val_auc: 0.8248\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6825 - accuracy: 0.5360 - auc: 0.7543 - val_loss: 2.2682 - val_accuracy: 0.6683 - val_auc: 0.8110\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6097 - accuracy: 0.5189 - auc: 0.7489 - val_loss: 3.2515 - val_accuracy: 0.6634 - val_auc: 0.8096\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6340 - accuracy: 0.4977 - auc: 0.7457 - val_loss: 2.1226 - val_accuracy: 0.6364 - val_auc: 0.7942\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7527 - accuracy: 0.4881 - auc: 0.7271 - val_loss: 2.8695 - val_accuracy: 0.6273 - val_auc: 0.7965\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5052 - accuracy: 0.5004 - auc: 0.7525 - val_loss: 2.4651 - val_accuracy: 0.6401 - val_auc: 0.8020\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6704 - accuracy: 0.5009 - auc: 0.7401 - val_loss: 2.0518 - val_accuracy: 0.6308 - val_auc: 0.8015\n",
      "Epoch 27/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.5905 - accuracy: 0.4923 - auc: 0.7402Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.5885 - accuracy: 0.4926 - auc: 0.7406 - val_loss: 3.3689 - val_accuracy: 0.6226 - val_auc: 0.7885\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 18us/sample - loss: 0.8835 - accuracy: 0.7673 - auc: 0.7383 - val_loss: 0.5648 - val_accuracy: 0.7484 - val_auc: 0.8507\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5813 - accuracy: 0.8381 - auc: 0.7996 - val_loss: 0.4882 - val_accuracy: 0.9688 - val_auc: 0.9155\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6675 - accuracy: 0.8886 - auc: 0.7825 - val_loss: 0.5525 - val_accuracy: 0.5816 - val_auc: 0.8414\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.6709 - accuracy: 0.4551 - auc: 0.7397 - val_loss: 0.5578 - val_accuracy: 0.6486 - val_auc: 0.8993\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5752 - accuracy: 0.5143 - auc: 0.7811 - val_loss: 0.6837 - val_accuracy: 0.7061 - val_auc: 0.8526\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5970 - accuracy: 0.4524 - auc: 0.7248 - val_loss: 0.5419 - val_accuracy: 0.6241 - val_auc: 0.8723\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5391 - accuracy: 0.4684 - auc: 0.7444 - val_loss: 0.5764 - val_accuracy: 0.7052 - val_auc: 0.8615\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5391 - accuracy: 0.4673 - auc: 0.7556 - val_loss: 0.5632 - val_accuracy: 0.6559 - val_auc: 0.8587\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5215 - accuracy: 0.5449 - auc: 0.8065 - val_loss: 0.7029 - val_accuracy: 0.7091 - val_auc: 0.8973\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5595 - accuracy: 0.4679 - auc: 0.7565 - val_loss: 0.6962 - val_accuracy: 0.6681 - val_auc: 0.8643\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5004 - accuracy: 0.4912 - auc: 0.7920 - val_loss: 0.8456 - val_accuracy: 0.6912 - val_auc: 0.9058\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.6540 - accuracy: 0.4514 - auc: 0.7586 - val_loss: 1.2677 - val_accuracy: 0.6276 - val_auc: 0.7984\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.5651 - accuracy: 0.4259 - auc: 0.7167 - val_loss: 0.7829 - val_accuracy: 0.6411 - val_auc: 0.8079\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.5472 - accuracy: 0.4441 - auc: 0.7148 - val_loss: 0.7884 - val_accuracy: 0.6628 - val_auc: 0.8184\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5303 - accuracy: 0.4672 - auc: 0.7324 - val_loss: 0.8518 - val_accuracy: 0.6629 - val_auc: 0.8164\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5682 - accuracy: 0.4568 - auc: 0.7195 - val_loss: 1.0415 - val_accuracy: 0.6508 - val_auc: 0.8110\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6963 - accuracy: 0.4300 - auc: 0.7007 - val_loss: 1.5168 - val_accuracy: 0.5724 - val_auc: 0.7427\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8126 - accuracy: 0.4220 - auc: 0.6963 - val_loss: 1.1405 - val_accuracy: 0.6226 - val_auc: 0.7990\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5279 - accuracy: 0.4291 - auc: 0.7138 - val_loss: 1.4233 - val_accuracy: 0.6436 - val_auc: 0.7981\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5306 - accuracy: 0.4382 - auc: 0.7161 - val_loss: 1.2583 - val_accuracy: 0.6271 - val_auc: 0.7949\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5386 - accuracy: 0.4419 - auc: 0.7221 - val_loss: 1.1716 - val_accuracy: 0.6286 - val_auc: 0.8016\n",
      "Epoch 22/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.4468 - auc: 0.7178Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5399 - accuracy: 0.4465 - auc: 0.7199 - val_loss: 1.4271 - val_accuracy: 0.6207 - val_auc: 0.7889\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.2369 - accuracy: 0.7018 - auc: 0.6679 - val_loss: 0.8612 - val_accuracy: 0.2888 - val_auc: 0.5678\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7364 - accuracy: 0.4236 - auc: 0.6690 - val_loss: 0.6182 - val_accuracy: 0.4920 - val_auc: 0.7788\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6812 - accuracy: 0.4936 - auc: 0.7498 - val_loss: 0.7004 - val_accuracy: 0.9243 - val_auc: 0.8644\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6521 - accuracy: 0.4684 - auc: 0.7483 - val_loss: 0.4273 - val_accuracy: 0.5877 - val_auc: 0.9051\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5816 - accuracy: 0.4996 - auc: 0.7548 - val_loss: 0.5246 - val_accuracy: 0.6493 - val_auc: 0.8575\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5864 - accuracy: 0.4403 - auc: 0.7411 - val_loss: 0.4086 - val_accuracy: 0.6666 - val_auc: 0.8762\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5001 - accuracy: 0.5062 - auc: 0.7834 - val_loss: 0.3670 - val_accuracy: 0.6978 - val_auc: 0.9171\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4737 - accuracy: 0.5581 - auc: 0.8080 - val_loss: 0.3710 - val_accuracy: 0.6537 - val_auc: 0.9205\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4214 - accuracy: 0.5948 - auc: 0.8558 - val_loss: 0.4432 - val_accuracy: 0.7675 - val_auc: 0.9423\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5634 - accuracy: 0.5855 - auc: 0.8017 - val_loss: 0.4718 - val_accuracy: 0.6885 - val_auc: 0.8924\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4965 - accuracy: 0.5812 - auc: 0.8162 - val_loss: 0.5318 - val_accuracy: 0.6800 - val_auc: 0.8802\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5536 - accuracy: 0.5790 - auc: 0.8157 - val_loss: 0.7878 - val_accuracy: 0.7271 - val_auc: 0.8950\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4662 - accuracy: 0.5716 - auc: 0.8164 - val_loss: 0.6988 - val_accuracy: 0.7166 - val_auc: 0.8916\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5592 - accuracy: 0.5581 - auc: 0.8262 - val_loss: 1.5418 - val_accuracy: 0.7006 - val_auc: 0.9273\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 1.0090 - accuracy: 0.5174 - auc: 0.7542 - val_loss: 3.5282 - val_accuracy: 0.6628 - val_auc: 0.8136\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.7603 - accuracy: 0.5073 - auc: 0.7469 - val_loss: 1.2517 - val_accuracy: 0.6511 - val_auc: 0.8113\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6601 - accuracy: 0.5152 - auc: 0.7589 - val_loss: 0.9587 - val_accuracy: 0.6285 - val_auc: 0.7881\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 1.1049 - accuracy: 0.5089 - auc: 0.7487 - val_loss: 2.6350 - val_accuracy: 0.6606 - val_auc: 0.8143\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.6220 - accuracy: 0.5041 - auc: 0.7457 - val_loss: 3.6484 - val_accuracy: 0.6105 - val_auc: 0.7823\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.5195 - accuracy: 0.5012 - auc: 0.7493 - val_loss: 3.8057 - val_accuracy: 0.6344 - val_auc: 0.7928\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.4829 - accuracy: 0.5177 - auc: 0.7642 - val_loss: 3.4747 - val_accuracy: 0.6500 - val_auc: 0.8015\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.5149 - accuracy: 0.5175 - auc: 0.7554 - val_loss: 3.0358 - val_accuracy: 0.6554 - val_auc: 0.8015\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.5165 - accuracy: 0.5165 - auc: 0.7582 - val_loss: 1.7410 - val_accuracy: 0.6487 - val_auc: 0.8003\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5599 - accuracy: 0.5190 - auc: 0.7531 - val_loss: 1.9905 - val_accuracy: 0.6521 - val_auc: 0.8081\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4719 - accuracy: 0.5328 - auc: 0.7657 - val_loss: 1.8145 - val_accuracy: 0.6769 - val_auc: 0.8209\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.4710 - accuracy: 0.5459 - auc: 0.7788 - val_loss: 1.6283 - val_accuracy: 0.6870 - val_auc: 0.8277\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.6172 - accuracy: 0.5535 - auc: 0.7722 - val_loss: 3.1098 - val_accuracy: 0.6933 - val_auc: 0.8260\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.4874 - accuracy: 0.5490 - auc: 0.7699 - val_loss: 3.0801 - val_accuracy: 0.6685 - val_auc: 0.8098\n",
      "Epoch 29/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.6400 - accuracy: 0.5240 - auc: 0.7513Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6359 - accuracy: 0.5243 - auc: 0.7516 - val_loss: 2.0473 - val_accuracy: 0.6578 - val_auc: 0.8103\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.7669 - accuracy: 0.8522 - auc: 0.7591 - val_loss: 0.4109 - val_accuracy: 0.9191 - val_auc: 0.9253\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6868 - accuracy: 0.9273 - auc: 0.7635 - val_loss: 0.5825 - val_accuracy: 0.9805 - val_auc: 0.9225\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6664 - accuracy: 0.9342 - auc: 0.7268 - val_loss: 0.7863 - val_accuracy: 0.7692 - val_auc: 0.7353\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6087 - accuracy: 0.9443 - auc: 0.7316 - val_loss: 0.4209 - val_accuracy: 0.9273 - val_auc: 0.9214\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6056 - accuracy: 0.9412 - auc: 0.7499 - val_loss: 0.4195 - val_accuracy: 0.9217 - val_auc: 0.9104\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5734 - accuracy: 0.9472 - auc: 0.7348 - val_loss: 0.4423 - val_accuracy: 0.8841 - val_auc: 0.9078\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7486 - accuracy: 0.9383 - auc: 0.6471 - val_loss: 0.7576 - val_accuracy: 0.0031 - val_auc: 0.5037\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7410 - accuracy: 0.5129 - auc: 0.5120 - val_loss: 0.7239 - val_accuracy: 0.9961 - val_auc: 0.5381\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.8332 - accuracy: 0.4686 - auc: 0.5077 - val_loss: 0.7093 - val_accuracy: 0.0438 - val_auc: 0.5451\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7770 - accuracy: 0.5456 - auc: 0.5025 - val_loss: 0.7570 - val_accuracy: 0.9968 - val_auc: 0.4999\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6960 - accuracy: 0.4829 - auc: 0.5031 - val_loss: 0.7613 - val_accuracy: 0.0031 - val_auc: 0.4999\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7327 - accuracy: 0.4724 - auc: 0.4933 - val_loss: 0.7318 - val_accuracy: 0.9969 - val_auc: 0.4999\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7535 - accuracy: 0.4992 - auc: 0.4959 - val_loss: 0.7230 - val_accuracy: 0.0031 - val_auc: 0.4999\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7376 - accuracy: 0.4909 - auc: 0.4919 - val_loss: 0.7103 - val_accuracy: 0.0031 - val_auc: 0.4999\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7080 - accuracy: 0.5274 - auc: 0.5005 - val_loss: 0.7127 - val_accuracy: 0.0031 - val_auc: 0.4999\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6969 - accuracy: 0.4764 - auc: 0.4887 - val_loss: 0.6977 - val_accuracy: 0.9969 - val_auc: 0.5000\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6941 - accuracy: 0.4358 - auc: 0.5028 - val_loss: 0.6932 - val_accuracy: 0.9969 - val_auc: 0.5000\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6943 - accuracy: 0.5292 - auc: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.9969 - val_auc: 0.5000\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6938 - accuracy: 0.5275 - auc: 0.4940 - val_loss: 0.6956 - val_accuracy: 0.0031 - val_auc: 0.5000\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6938 - accuracy: 0.5293 - auc: 0.4917 - val_loss: 0.6937 - val_accuracy: 0.0031 - val_auc: 0.5000\n",
      "Epoch 21/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.5104 - auc: 0.4988Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6937 - accuracy: 0.5172 - auc: 0.5005 - val_loss: 0.6960 - val_accuracy: 0.9969 - val_auc: 0.5000\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.7990 - accuracy: 0.8447 - auc: 0.7251 - val_loss: 0.5697 - val_accuracy: 0.7087 - val_auc: 0.8651\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6249 - accuracy: 0.9014 - auc: 0.7865 - val_loss: 0.3964 - val_accuracy: 0.8683 - val_auc: 0.9198\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5660 - accuracy: 0.9237 - auc: 0.7881 - val_loss: 0.3917 - val_accuracy: 0.8641 - val_auc: 0.9127\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8403 - accuracy: 0.6217 - auc: 0.7342 - val_loss: 0.7922 - val_accuracy: 0.5415 - val_auc: 0.7527\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7508 - accuracy: 0.3377 - auc: 0.6643 - val_loss: 0.7583 - val_accuracy: 0.5901 - val_auc: 0.7695\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6677 - accuracy: 0.3904 - auc: 0.6870 - val_loss: 0.7395 - val_accuracy: 0.6092 - val_auc: 0.7812\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0542 - accuracy: 0.4155 - auc: 0.6821 - val_loss: 0.8812 - val_accuracy: 0.5856 - val_auc: 0.7887\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5891 - accuracy: 0.3678 - auc: 0.6730 - val_loss: 1.1212 - val_accuracy: 0.5421 - val_auc: 0.7618\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6002 - accuracy: 0.3618 - auc: 0.6853 - val_loss: 0.6385 - val_accuracy: 0.5642 - val_auc: 0.7754\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6379 - accuracy: 0.3692 - auc: 0.6939 - val_loss: 1.2359 - val_accuracy: 0.5651 - val_auc: 0.7753\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5910 - accuracy: 0.3713 - auc: 0.6934 - val_loss: 1.2220 - val_accuracy: 0.5406 - val_auc: 0.7561\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6039 - accuracy: 0.3718 - auc: 0.6838 - val_loss: 1.0196 - val_accuracy: 0.5747 - val_auc: 0.7732\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7685 - accuracy: 0.4156 - auc: 0.6955 - val_loss: 1.2357 - val_accuracy: 0.6099 - val_auc: 0.7866\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7109 - accuracy: 0.4069 - auc: 0.6906 - val_loss: 1.9775 - val_accuracy: 0.5935 - val_auc: 0.7785\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6999 - accuracy: 0.4115 - auc: 0.6977 - val_loss: 1.3246 - val_accuracy: 0.5952 - val_auc: 0.7884\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5263 - accuracy: 0.4332 - auc: 0.7206 - val_loss: 1.0691 - val_accuracy: 0.6216 - val_auc: 0.8036\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5210 - accuracy: 0.4453 - auc: 0.7292 - val_loss: 0.9760 - val_accuracy: 0.6245 - val_auc: 0.8039\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5374 - accuracy: 0.4603 - auc: 0.7353 - val_loss: 1.2082 - val_accuracy: 0.6399 - val_auc: 0.8060\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5007 - accuracy: 0.4768 - auc: 0.7336 - val_loss: 1.0804 - val_accuracy: 0.6766 - val_auc: 0.8225\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5647 - accuracy: 0.4843 - auc: 0.7435 - val_loss: 1.0287 - val_accuracy: 0.6193 - val_auc: 0.7795\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5835 - accuracy: 0.4539 - auc: 0.7258 - val_loss: 1.1979 - val_accuracy: 0.6312 - val_auc: 0.7961\n",
      "Epoch 22/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.4608 - auc: 0.7268Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5750 - accuracy: 0.4608 - auc: 0.7267 - val_loss: 1.2740 - val_accuracy: 0.6343 - val_auc: 0.7974\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.0382 - accuracy: 0.7681 - auc: 0.7541 - val_loss: 0.6345 - val_accuracy: 0.8908 - val_auc: 0.9084\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1925 - accuracy: 0.8070 - auc: 0.7890 - val_loss: 0.5995 - val_accuracy: 0.4669 - val_auc: 0.8514\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0140 - accuracy: 0.7426 - auc: 0.7746 - val_loss: 0.3720 - val_accuracy: 0.9434 - val_auc: 0.9407\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7682 - accuracy: 0.9013 - auc: 0.8448 - val_loss: 0.4290 - val_accuracy: 0.8806 - val_auc: 0.9401\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0384 - accuracy: 0.6263 - auc: 0.7742 - val_loss: 0.6029 - val_accuracy: 0.5990 - val_auc: 0.8425\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8454 - accuracy: 0.4465 - auc: 0.7100 - val_loss: 0.6928 - val_accuracy: 0.5913 - val_auc: 0.7685\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5753 - accuracy: 0.4388 - auc: 0.7201 - val_loss: 0.7303 - val_accuracy: 0.6137 - val_auc: 0.7977\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6052 - accuracy: 0.4524 - auc: 0.7252 - val_loss: 0.6734 - val_accuracy: 0.6308 - val_auc: 0.8043\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5340 - accuracy: 0.4747 - auc: 0.7362 - val_loss: 0.7577 - val_accuracy: 0.6516 - val_auc: 0.8306\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6274 - accuracy: 0.4954 - auc: 0.7472 - val_loss: 1.1552 - val_accuracy: 0.7956 - val_auc: 0.8754\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3292 - accuracy: 0.4465 - auc: 0.7031 - val_loss: 1.4348 - val_accuracy: 0.4523 - val_auc: 0.6624\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6109 - accuracy: 0.4527 - auc: 0.7107 - val_loss: 1.6656 - val_accuracy: 0.5971 - val_auc: 0.7820\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6605 - accuracy: 0.4388 - auc: 0.7181 - val_loss: 0.9710 - val_accuracy: 0.5921 - val_auc: 0.7985\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7374 - accuracy: 0.4348 - auc: 0.7221 - val_loss: 1.4613 - val_accuracy: 0.5846 - val_auc: 0.7762\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5894 - accuracy: 0.4407 - auc: 0.7121 - val_loss: 1.8512 - val_accuracy: 0.5975 - val_auc: 0.7810\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7309 - accuracy: 0.4379 - auc: 0.7094 - val_loss: 1.7598 - val_accuracy: 0.5630 - val_auc: 0.7660\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6106 - accuracy: 0.4266 - auc: 0.7018 - val_loss: 2.0109 - val_accuracy: 0.5870 - val_auc: 0.7766\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6003 - accuracy: 0.4449 - auc: 0.7156 - val_loss: 1.5110 - val_accuracy: 0.5813 - val_auc: 0.7784\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5378 - accuracy: 0.4556 - auc: 0.7255 - val_loss: 1.2657 - val_accuracy: 0.5953 - val_auc: 0.7835\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5132 - accuracy: 0.4619 - auc: 0.7384 - val_loss: 1.0017 - val_accuracy: 0.6170 - val_auc: 0.7923\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6244 - accuracy: 0.4793 - auc: 0.7280 - val_loss: 2.0789 - val_accuracy: 0.6427 - val_auc: 0.7993\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8135 - accuracy: 0.4584 - auc: 0.7181 - val_loss: 2.9826 - val_accuracy: 0.6116 - val_auc: 0.7885\n",
      "Epoch 23/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.5990 - accuracy: 0.4516 - auc: 0.7071Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5969 - accuracy: 0.4509 - auc: 0.7076 - val_loss: 2.0380 - val_accuracy: 0.5773 - val_auc: 0.7698\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.5031 - accuracy: 0.7732 - auc: 0.7671 - val_loss: 1.4207 - val_accuracy: 0.8081 - val_auc: 0.8022\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4090 - accuracy: 0.8421 - auc: 0.7887 - val_loss: 1.7325 - val_accuracy: 0.9170 - val_auc: 0.8438\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.6974 - accuracy: 0.5814 - auc: 0.7298 - val_loss: 3.9232 - val_accuracy: 0.5226 - val_auc: 0.8162\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.3253 - accuracy: 0.5924 - auc: 0.7093 - val_loss: 2.8270 - val_accuracy: 0.4671 - val_auc: 0.7869\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9242 - accuracy: 0.4614 - auc: 0.6498 - val_loss: 3.5404 - val_accuracy: 0.4908 - val_auc: 0.7521\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3019 - accuracy: 0.3498 - auc: 0.6347 - val_loss: 1.7150 - val_accuracy: 0.4863 - val_auc: 0.7547\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9465 - accuracy: 0.4001 - auc: 0.6951 - val_loss: 2.4921 - val_accuracy: 0.4708 - val_auc: 0.8049\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 3.4787 - accuracy: 0.5494 - auc: 0.6800 - val_loss: 1.5393 - val_accuracy: 0.4013 - val_auc: 0.7801\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3459 - accuracy: 0.5291 - auc: 0.6686 - val_loss: 2.5823 - val_accuracy: 0.4314 - val_auc: 0.8081\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9924 - accuracy: 0.4479 - auc: 0.6675 - val_loss: 2.7793 - val_accuracy: 0.5133 - val_auc: 0.7264\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2436 - accuracy: 0.3503 - auc: 0.6535 - val_loss: 2.5224 - val_accuracy: 0.5287 - val_auc: 0.7496\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7306 - accuracy: 0.3276 - auc: 0.6527 - val_loss: 4.4237 - val_accuracy: 0.5335 - val_auc: 0.7544\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3081 - accuracy: 0.3199 - auc: 0.6460 - val_loss: 3.4503 - val_accuracy: 0.5377 - val_auc: 0.7563\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3919 - accuracy: 0.3074 - auc: 0.6537 - val_loss: 4.1506 - val_accuracy: 0.5197 - val_auc: 0.7453\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2448 - accuracy: 0.2837 - auc: 0.6372 - val_loss: 3.7255 - val_accuracy: 0.4755 - val_auc: 0.7274\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7701 - accuracy: 0.2826 - auc: 0.6461 - val_loss: 3.4611 - val_accuracy: 0.4929 - val_auc: 0.7451\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7510 - accuracy: 0.2938 - auc: 0.6551 - val_loss: 3.3553 - val_accuracy: 0.5068 - val_auc: 0.7470\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7214 - accuracy: 0.3363 - auc: 0.6720 - val_loss: 4.4862 - val_accuracy: 0.4767 - val_auc: 0.7413\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8864 - accuracy: 0.2780 - auc: 0.6376 - val_loss: 3.8485 - val_accuracy: 0.4451 - val_auc: 0.7140\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8715 - accuracy: 0.2878 - auc: 0.6379 - val_loss: 2.3721 - val_accuracy: 0.9957 - val_auc: 0.7173\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7161 - accuracy: 0.3127 - auc: 0.6372 - val_loss: 4.2979 - val_accuracy: 0.4713 - val_auc: 0.7194\n",
      "Epoch 22/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.6403 - accuracy: 0.3004 - auc: 0.6510Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6401 - accuracy: 0.3005 - auc: 0.6496 - val_loss: 3.4788 - val_accuracy: 0.4746 - val_auc: 0.7234\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.4815 - accuracy: 0.7150 - auc: 0.7186 - val_loss: 0.6241 - val_accuracy: 0.7552 - val_auc: 0.8944\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9954 - accuracy: 0.8606 - auc: 0.7917 - val_loss: 0.6643 - val_accuracy: 0.8949 - val_auc: 0.9260\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0566 - accuracy: 0.8049 - auc: 0.8080 - val_loss: 0.5523 - val_accuracy: 0.8844 - val_auc: 0.8905\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7316 - accuracy: 0.7594 - auc: 0.8100 - val_loss: 0.5380 - val_accuracy: 0.9053 - val_auc: 0.9348\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5377 - accuracy: 0.4509 - auc: 0.7053 - val_loss: 0.7146 - val_accuracy: 0.4871 - val_auc: 0.8428\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8636 - accuracy: 0.5441 - auc: 0.7308 - val_loss: 1.1837 - val_accuracy: 0.5467 - val_auc: 0.8644\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6808 - accuracy: 0.4005 - auc: 0.7094 - val_loss: 1.3263 - val_accuracy: 0.6477 - val_auc: 0.7985\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6165 - accuracy: 0.4419 - auc: 0.7108 - val_loss: 1.2734 - val_accuracy: 0.6198 - val_auc: 0.8058\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5834 - accuracy: 0.4768 - auc: 0.7371 - val_loss: 0.9962 - val_accuracy: 0.6134 - val_auc: 0.8240\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6741 - accuracy: 0.4925 - auc: 0.7363 - val_loss: 0.8116 - val_accuracy: 0.5857 - val_auc: 0.7662\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7764 - accuracy: 0.4879 - auc: 0.7302 - val_loss: 1.7293 - val_accuracy: 0.6439 - val_auc: 0.8117\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6311 - accuracy: 0.4960 - auc: 0.7414 - val_loss: 0.9124 - val_accuracy: 0.6249 - val_auc: 0.7998\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5573 - accuracy: 0.4821 - auc: 0.7279 - val_loss: 1.3550 - val_accuracy: 0.6413 - val_auc: 0.8063\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0161 - accuracy: 0.5187 - auc: 0.7539 - val_loss: 1.6526 - val_accuracy: 0.6431 - val_auc: 0.8126\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5655 - accuracy: 0.5322 - auc: 0.7636 - val_loss: 1.3815 - val_accuracy: 0.6841 - val_auc: 0.8304\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5940 - accuracy: 0.5343 - auc: 0.7576 - val_loss: 1.4836 - val_accuracy: 0.6864 - val_auc: 0.8286\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5545 - accuracy: 0.5496 - auc: 0.7703 - val_loss: 1.2998 - val_accuracy: 0.6839 - val_auc: 0.8290\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5196 - accuracy: 0.5553 - auc: 0.7741 - val_loss: 2.0399 - val_accuracy: 0.6803 - val_auc: 0.8171\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5999 - accuracy: 0.5397 - auc: 0.7645 - val_loss: 1.4092 - val_accuracy: 0.6719 - val_auc: 0.8156\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5276 - accuracy: 0.5276 - auc: 0.7596 - val_loss: 1.6461 - val_accuracy: 0.6658 - val_auc: 0.8134\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5434 - accuracy: 0.5419 - auc: 0.7639 - val_loss: 1.4308 - val_accuracy: 0.6745 - val_auc: 0.8194\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4764 - accuracy: 0.5461 - auc: 0.7638 - val_loss: 1.3204 - val_accuracy: 0.6752 - val_auc: 0.8265\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5852 - accuracy: 0.5478 - auc: 0.7688 - val_loss: 2.0387 - val_accuracy: 0.6739 - val_auc: 0.8164\n",
      "Epoch 24/100\n",
      "246784/250290 [============================>.] - ETA: 0s - loss: 0.7650 - accuracy: 0.5285 - auc: 0.7571Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7622 - accuracy: 0.5286 - auc: 0.7569 - val_loss: 3.9327 - val_accuracy: 0.6498 - val_auc: 0.8053\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 1.1588 - accuracy: 0.7775 - auc: 0.7630 - val_loss: 0.6764 - val_accuracy: 0.9275 - val_auc: 0.8971\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3229 - accuracy: 0.8320 - auc: 0.8049 - val_loss: 0.7206 - val_accuracy: 0.8914 - val_auc: 0.9201\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0435 - accuracy: 0.7679 - auc: 0.7861 - val_loss: 0.8183 - val_accuracy: 0.8851 - val_auc: 0.9166\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1628 - accuracy: 0.5839 - auc: 0.7654 - val_loss: 0.5978 - val_accuracy: 0.6452 - val_auc: 0.9083\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8112 - accuracy: 0.7323 - auc: 0.8434 - val_loss: 0.6880 - val_accuracy: 0.9365 - val_auc: 0.9206\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0569 - accuracy: 0.8456 - auc: 0.8196 - val_loss: 1.1331 - val_accuracy: 0.5613 - val_auc: 0.9203\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8007 - accuracy: 0.8877 - auc: 0.8360 - val_loss: 0.5428 - val_accuracy: 0.9282 - val_auc: 0.9202\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8387 - accuracy: 0.7759 - auc: 0.8191 - val_loss: 0.9126 - val_accuracy: 0.5308 - val_auc: 0.7899\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5863 - accuracy: 0.4121 - auc: 0.7359 - val_loss: 0.9386 - val_accuracy: 0.5638 - val_auc: 0.8295\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5401 - accuracy: 0.4517 - auc: 0.7479 - val_loss: 0.8965 - val_accuracy: 0.6144 - val_auc: 0.8888\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4993 - accuracy: 0.5252 - auc: 0.8214 - val_loss: 0.8746 - val_accuracy: 0.6187 - val_auc: 0.8451\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5531 - accuracy: 0.6094 - auc: 0.8295 - val_loss: 0.9297 - val_accuracy: 0.6554 - val_auc: 0.8649\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5946 - accuracy: 0.4889 - auc: 0.7466 - val_loss: 0.8627 - val_accuracy: 0.6168 - val_auc: 0.7992\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6171 - accuracy: 0.4995 - auc: 0.7472 - val_loss: 0.7632 - val_accuracy: 0.6608 - val_auc: 0.8195\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5418 - accuracy: 0.5308 - auc: 0.7527 - val_loss: 0.8328 - val_accuracy: 0.6801 - val_auc: 0.8295\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4701 - accuracy: 0.5499 - auc: 0.7719 - val_loss: 0.7091 - val_accuracy: 0.6953 - val_auc: 0.8364\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5164 - accuracy: 0.5525 - auc: 0.7603 - val_loss: 0.8633 - val_accuracy: 0.6748 - val_auc: 0.8283\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5010 - accuracy: 0.5501 - auc: 0.7721 - val_loss: 1.2660 - val_accuracy: 0.6872 - val_auc: 0.8252\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7514 - accuracy: 0.5166 - auc: 0.7536 - val_loss: 1.6937 - val_accuracy: 0.6519 - val_auc: 0.8076\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4772 - accuracy: 0.5342 - auc: 0.7678 - val_loss: 1.5458 - val_accuracy: 0.6831 - val_auc: 0.8271\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5467 - accuracy: 0.5371 - auc: 0.7627 - val_loss: 1.3920 - val_accuracy: 0.6552 - val_auc: 0.8065\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4635 - accuracy: 0.5456 - auc: 0.7670 - val_loss: 1.4840 - val_accuracy: 0.6859 - val_auc: 0.8255\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5527 - accuracy: 0.5400 - auc: 0.7691 - val_loss: 1.6866 - val_accuracy: 0.6715 - val_auc: 0.8100\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5069 - accuracy: 0.5408 - auc: 0.7648 - val_loss: 1.1696 - val_accuracy: 0.6691 - val_auc: 0.8117\n",
      "Epoch 25/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.5970 - accuracy: 0.5491 - auc: 0.7715Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5946 - accuracy: 0.5492 - auc: 0.7722 - val_loss: 1.6974 - val_accuracy: 0.6987 - val_auc: 0.8239\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 1.5995 - accuracy: 0.7427 - auc: 0.7500 - val_loss: 0.6146 - val_accuracy: 0.7841 - val_auc: 0.9339\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8700 - accuracy: 0.8923 - auc: 0.8328 - val_loss: 0.5410 - val_accuracy: 0.8495 - val_auc: 0.9358\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6234 - accuracy: 0.9139 - auc: 0.8625 - val_loss: 0.4319 - val_accuracy: 0.9041 - val_auc: 0.9314\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6779 - accuracy: 0.9078 - auc: 0.8430 - val_loss: 0.5271 - val_accuracy: 0.9139 - val_auc: 0.9338\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9360 - accuracy: 0.9091 - auc: 0.7709 - val_loss: 0.4329 - val_accuracy: 0.9257 - val_auc: 0.9299\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5832 - accuracy: 0.9308 - auc: 0.8156 - val_loss: 0.3640 - val_accuracy: 0.9218 - val_auc: 0.9363\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6583 - accuracy: 0.7787 - auc: 0.7589 - val_loss: 0.5634 - val_accuracy: 0.9268 - val_auc: 0.8067\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8075 - accuracy: 0.7311 - auc: 0.6742 - val_loss: 1.0257 - val_accuracy: 0.9221 - val_auc: 0.7947\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7725 - accuracy: 0.9085 - auc: 0.7207 - val_loss: 0.7160 - val_accuracy: 0.5355 - val_auc: 0.8389\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7085 - accuracy: 0.9252 - auc: 0.7682 - val_loss: 0.9555 - val_accuracy: 0.6891 - val_auc: 0.8635\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9847 - accuracy: 0.4329 - auc: 0.6701 - val_loss: 1.3016 - val_accuracy: 0.0077 - val_auc: 0.2983\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8027 - accuracy: 0.3005 - auc: 0.6450 - val_loss: 0.8595 - val_accuracy: 0.5229 - val_auc: 0.7522\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6982 - accuracy: 0.3369 - auc: 0.6662 - val_loss: 0.7299 - val_accuracy: 0.5688 - val_auc: 0.7991\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5942 - accuracy: 0.3301 - auc: 0.6823 - val_loss: 0.7235 - val_accuracy: 0.5666 - val_auc: 0.8192\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5500 - accuracy: 0.4020 - auc: 0.7325 - val_loss: 0.8782 - val_accuracy: 0.9738 - val_auc: 0.8466\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5767 - accuracy: 0.4010 - auc: 0.7338 - val_loss: 0.6259 - val_accuracy: 0.5595 - val_auc: 0.8450\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5906 - accuracy: 0.3986 - auc: 0.7099 - val_loss: 0.8520 - val_accuracy: 0.6209 - val_auc: 0.7929\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5764 - accuracy: 0.3892 - auc: 0.7042 - val_loss: 0.7367 - val_accuracy: 0.5794 - val_auc: 0.7856\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5487 - accuracy: 0.3872 - auc: 0.6888 - val_loss: 0.7987 - val_accuracy: 0.6140 - val_auc: 0.7925\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5527 - accuracy: 0.3989 - auc: 0.6907 - val_loss: 0.8920 - val_accuracy: 0.6183 - val_auc: 0.7914\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6722 - accuracy: 0.3965 - auc: 0.6896 - val_loss: 1.9268 - val_accuracy: 0.6163 - val_auc: 0.7831\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6458 - accuracy: 0.3833 - auc: 0.6930 - val_loss: 1.0188 - val_accuracy: 0.5938 - val_auc: 0.7832\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5706 - accuracy: 0.3672 - auc: 0.6831 - val_loss: 0.8085 - val_accuracy: 0.5962 - val_auc: 0.7978\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5702 - accuracy: 0.4238 - auc: 0.7293 - val_loss: 1.2243 - val_accuracy: 0.6080 - val_auc: 0.7903\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5445 - accuracy: 0.3965 - auc: 0.6977 - val_loss: 1.1154 - val_accuracy: 0.5975 - val_auc: 0.7888\n",
      "Epoch 26/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.5438 - accuracy: 0.3987 - auc: 0.6982Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5430 - accuracy: 0.3986 - auc: 0.6977 - val_loss: 1.1015 - val_accuracy: 0.6196 - val_auc: 0.7940\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 2.3045 - accuracy: 0.7270 - auc: 0.7692 - val_loss: 3.7410 - val_accuracy: 0.3848 - val_auc: 0.7803\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.6630 - accuracy: 0.7900 - auc: 0.7713 - val_loss: 2.5617 - val_accuracy: 0.9232 - val_auc: 0.8961\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.5637 - accuracy: 0.8405 - auc: 0.7986 - val_loss: 2.6196 - val_accuracy: 0.8635 - val_auc: 0.9093\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8686 - accuracy: 0.7121 - auc: 0.8083 - val_loss: 2.8420 - val_accuracy: 0.9159 - val_auc: 0.8341\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.7987 - accuracy: 0.6925 - auc: 0.7946 - val_loss: 3.0715 - val_accuracy: 0.3686 - val_auc: 0.8005\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5545 - accuracy: 0.5307 - auc: 0.7523 - val_loss: 3.9655 - val_accuracy: 0.9350 - val_auc: 0.8844\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.3912 - accuracy: 0.6910 - auc: 0.7827 - val_loss: 2.5631 - val_accuracy: 0.5223 - val_auc: 0.8465\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 7.6157 - accuracy: 0.5611 - auc: 0.7449 - val_loss: 5.0326 - val_accuracy: 0.9768 - val_auc: 0.8147\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 10.3535 - accuracy: 0.5057 - auc: 0.6702 - val_loss: 6.5161 - val_accuracy: 0.5261 - val_auc: 0.8022\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.9180 - accuracy: 0.4306 - auc: 0.7069 - val_loss: 3.4629 - val_accuracy: 0.4902 - val_auc: 0.7995\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.2477 - accuracy: 0.4237 - auc: 0.7395 - val_loss: 3.9680 - val_accuracy: 0.5095 - val_auc: 0.7931\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0039 - accuracy: 0.3970 - auc: 0.6967 - val_loss: 11.9657 - val_accuracy: 0.4951 - val_auc: 0.7344\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6835 - accuracy: 0.4053 - auc: 0.7075 - val_loss: 7.1541 - val_accuracy: 0.4887 - val_auc: 0.7507\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.5475 - accuracy: 0.4418 - auc: 0.6909 - val_loss: 7.0728 - val_accuracy: 0.4637 - val_auc: 0.7292\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.8275 - accuracy: 0.4316 - auc: 0.7035 - val_loss: 7.4513 - val_accuracy: 0.9861 - val_auc: 0.7923\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.3731 - accuracy: 0.4150 - auc: 0.7043 - val_loss: 6.1726 - val_accuracy: 0.4556 - val_auc: 0.7816\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 4.9434 - accuracy: 0.3964 - auc: 0.6900 - val_loss: 22.9191 - val_accuracy: 0.0581 - val_auc: 0.3637\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 3.2704 - accuracy: 0.4344 - auc: 0.6861 - val_loss: 5.1819 - val_accuracy: 0.5080 - val_auc: 0.7587\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 3.8922 - accuracy: 0.4312 - auc: 0.7024 - val_loss: 5.8747 - val_accuracy: 0.5240 - val_auc: 0.7537\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 3.8130 - accuracy: 0.3906 - auc: 0.6796 - val_loss: 6.2276 - val_accuracy: 0.4851 - val_auc: 0.7279\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5313 - accuracy: 0.3672 - auc: 0.6782 - val_loss: 6.7885 - val_accuracy: 0.4847 - val_auc: 0.7300\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3084 - accuracy: 0.3691 - auc: 0.6926 - val_loss: 5.1482 - val_accuracy: 0.4883 - val_auc: 0.7422\n",
      "Epoch 23/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 6.4130 - accuracy: 0.3534 - auc: 0.6524Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 6.2858 - accuracy: 0.3536 - auc: 0.6539 - val_loss: 5.1032 - val_accuracy: 0.4783 - val_auc: 0.7312\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 18us/sample - loss: 3.0155 - accuracy: 0.7299 - auc: 0.7792 - val_loss: 1.1317 - val_accuracy: 0.8933 - val_auc: 0.9118\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4554 - accuracy: 0.8435 - auc: 0.8350 - val_loss: 1.3997 - val_accuracy: 0.8961 - val_auc: 0.8226\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6763 - accuracy: 0.8441 - auc: 0.8085 - val_loss: 1.7350 - val_accuracy: 0.6053 - val_auc: 0.8332\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9375 - accuracy: 0.7176 - auc: 0.7567 - val_loss: 2.2445 - val_accuracy: 0.4929 - val_auc: 0.8127\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8893 - accuracy: 0.6718 - auc: 0.7446 - val_loss: 1.6373 - val_accuracy: 0.9541 - val_auc: 0.8384\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1543 - accuracy: 0.5982 - auc: 0.7549 - val_loss: 1.4571 - val_accuracy: 0.5473 - val_auc: 0.8755\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0200 - accuracy: 0.5919 - auc: 0.7858 - val_loss: 5.4859 - val_accuracy: 0.5810 - val_auc: 0.8491\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.8999 - accuracy: 0.5373 - auc: 0.7030 - val_loss: 3.1263 - val_accuracy: 0.4005 - val_auc: 0.7647\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1883 - accuracy: 0.6989 - auc: 0.7456 - val_loss: 2.8014 - val_accuracy: 0.9464 - val_auc: 0.8197\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2898 - accuracy: 0.5649 - auc: 0.7271 - val_loss: 2.7676 - val_accuracy: 0.9484 - val_auc: 0.8925\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8149 - accuracy: 0.5111 - auc: 0.7277 - val_loss: 2.5306 - val_accuracy: 0.4975 - val_auc: 0.7567\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5021 - accuracy: 0.3856 - auc: 0.6687 - val_loss: 3.4977 - val_accuracy: 0.4726 - val_auc: 0.7700\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9512 - accuracy: 0.3386 - auc: 0.6952 - val_loss: 2.8988 - val_accuracy: 0.5093 - val_auc: 0.7964\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1398 - accuracy: 0.3923 - auc: 0.7099 - val_loss: 3.5123 - val_accuracy: 0.5224 - val_auc: 0.8197\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0926 - accuracy: 0.4516 - auc: 0.7456 - val_loss: 2.6338 - val_accuracy: 0.9786 - val_auc: 0.8626\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9208 - accuracy: 0.5273 - auc: 0.7517 - val_loss: 3.1343 - val_accuracy: 0.5292 - val_auc: 0.8587\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6774 - accuracy: 0.4777 - auc: 0.7710 - val_loss: 2.4642 - val_accuracy: 0.5343 - val_auc: 0.8835\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5508 - accuracy: 0.5832 - auc: 0.7866 - val_loss: 3.1809 - val_accuracy: 0.5545 - val_auc: 0.8976\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7276 - accuracy: 0.4256 - auc: 0.7344 - val_loss: 3.2395 - val_accuracy: 0.5765 - val_auc: 0.8065\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9449 - accuracy: 0.4210 - auc: 0.7256 - val_loss: 4.3343 - val_accuracy: 0.5744 - val_auc: 0.8080\n",
      "Epoch 21/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.8934 - accuracy: 0.3967 - auc: 0.7322Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8924 - accuracy: 0.3967 - auc: 0.7321 - val_loss: 3.7096 - val_accuracy: 0.5363 - val_auc: 0.8292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 2.5810 - accuracy: 0.7253 - auc: 0.7581 - val_loss: 0.8039 - val_accuracy: 0.9251 - val_auc: 0.8950\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.2997 - accuracy: 0.8091 - auc: 0.7867 - val_loss: 1.8169 - val_accuracy: 0.9606 - val_auc: 0.8787\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.4032 - accuracy: 0.8380 - auc: 0.7842 - val_loss: 1.9348 - val_accuracy: 0.8492 - val_auc: 0.9163\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.4398 - accuracy: 0.7448 - auc: 0.7437 - val_loss: 1.6993 - val_accuracy: 0.9564 - val_auc: 0.8643\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5505 - accuracy: 0.5605 - auc: 0.7300 - val_loss: 2.7311 - val_accuracy: 0.5896 - val_auc: 0.8543\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.1147 - accuracy: 0.6591 - auc: 0.7605 - val_loss: 2.0433 - val_accuracy: 0.4742 - val_auc: 0.8360\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2417 - accuracy: 0.4882 - auc: 0.7349 - val_loss: 1.9943 - val_accuracy: 0.4697 - val_auc: 0.7394\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 5.9142 - accuracy: 0.4935 - auc: 0.6634 - val_loss: 5.3496 - val_accuracy: 0.9055 - val_auc: 0.7163\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.3788 - accuracy: 0.4790 - auc: 0.6575 - val_loss: 4.5952 - val_accuracy: 0.3917 - val_auc: 0.7378\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5724 - accuracy: 0.5450 - auc: 0.7023 - val_loss: 3.3984 - val_accuracy: 0.4181 - val_auc: 0.7344\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.8884 - accuracy: 0.4093 - auc: 0.6485 - val_loss: 5.2734 - val_accuracy: 0.9106 - val_auc: 0.7289\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8607 - accuracy: 0.3494 - auc: 0.6213 - val_loss: 6.2329 - val_accuracy: 0.4371 - val_auc: 0.7097\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1573 - accuracy: 0.3086 - auc: 0.6403 - val_loss: 6.3157 - val_accuracy: 0.9839 - val_auc: 0.7585\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6048 - accuracy: 0.3917 - auc: 0.6458 - val_loss: 1.6799 - val_accuracy: 0.4477 - val_auc: 0.7887\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1139 - accuracy: 0.3833 - auc: 0.6799 - val_loss: 2.7002 - val_accuracy: 0.4893 - val_auc: 0.8212\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3440 - accuracy: 0.4957 - auc: 0.7030 - val_loss: 3.6309 - val_accuracy: 0.4915 - val_auc: 0.7949\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0225 - accuracy: 0.3791 - auc: 0.6968 - val_loss: 4.1810 - val_accuracy: 0.4602 - val_auc: 0.7399\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0998 - accuracy: 0.3330 - auc: 0.6419 - val_loss: 2.1080 - val_accuracy: 0.4707 - val_auc: 0.7277\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 5.9852 - accuracy: 0.2999 - auc: 0.6278 - val_loss: 4.2184 - val_accuracy: 0.4324 - val_auc: 0.7043\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3334 - accuracy: 0.2895 - auc: 0.6261 - val_loss: 6.0789 - val_accuracy: 0.4458 - val_auc: 0.7098\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0990 - accuracy: 0.3039 - auc: 0.6205 - val_loss: 6.9615 - val_accuracy: 0.4547 - val_auc: 0.7141\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7964 - accuracy: 0.2770 - auc: 0.6266 - val_loss: 8.4512 - val_accuracy: 0.4687 - val_auc: 0.7213\n",
      "Epoch 23/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 1.7159 - accuracy: 0.2791 - auc: 0.6189Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7138 - accuracy: 0.2790 - auc: 0.6188 - val_loss: 8.8776 - val_accuracy: 0.4680 - val_auc: 0.7167\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 2.6509 - accuracy: 0.7433 - auc: 0.7787 - val_loss: 0.9183 - val_accuracy: 0.9367 - val_auc: 0.9038\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.6135 - accuracy: 0.7960 - auc: 0.7746 - val_loss: 1.0751 - val_accuracy: 0.8271 - val_auc: 0.9003\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.3731 - accuracy: 0.8207 - auc: 0.8047 - val_loss: 1.1922 - val_accuracy: 0.9513 - val_auc: 0.8754\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8043 - accuracy: 0.8899 - auc: 0.7766 - val_loss: 1.5948 - val_accuracy: 0.8921 - val_auc: 0.8948\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6882 - accuracy: 0.8745 - auc: 0.7557 - val_loss: 2.3498 - val_accuracy: 0.9070 - val_auc: 0.7998\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4236 - accuracy: 0.6498 - auc: 0.7269 - val_loss: 2.5479 - val_accuracy: 0.9272 - val_auc: 0.8498\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.5851 - accuracy: 0.6700 - auc: 0.7049 - val_loss: 3.7430 - val_accuracy: 0.8921 - val_auc: 0.8392\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3943 - accuracy: 0.6088 - auc: 0.7502 - val_loss: 3.5017 - val_accuracy: 0.5433 - val_auc: 0.8960\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5639 - accuracy: 0.5342 - auc: 0.7233 - val_loss: 4.9835 - val_accuracy: 0.5892 - val_auc: 0.5403\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3435 - accuracy: 0.5025 - auc: 0.7181 - val_loss: 2.1288 - val_accuracy: 0.6392 - val_auc: 0.5558\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2733 - accuracy: 0.4128 - auc: 0.6756 - val_loss: 1.2570 - val_accuracy: 0.9837 - val_auc: 0.8080\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6669 - accuracy: 0.4025 - auc: 0.7248 - val_loss: 1.5063 - val_accuracy: 0.5126 - val_auc: 0.8762\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.7016 - accuracy: 0.5736 - auc: 0.7558 - val_loss: 0.9094 - val_accuracy: 0.5579 - val_auc: 0.7833\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9060 - accuracy: 0.3962 - auc: 0.7149 - val_loss: 1.5974 - val_accuracy: 0.5883 - val_auc: 0.7925\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8271 - accuracy: 0.4408 - auc: 0.7387 - val_loss: 1.8276 - val_accuracy: 0.5963 - val_auc: 0.7975\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5770 - accuracy: 0.4602 - auc: 0.7551 - val_loss: 1.8981 - val_accuracy: 0.6234 - val_auc: 0.8410\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6693 - accuracy: 0.4719 - auc: 0.7605 - val_loss: 1.6745 - val_accuracy: 0.6358 - val_auc: 0.8140\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5096 - accuracy: 0.4662 - auc: 0.7305 - val_loss: 1.5275 - val_accuracy: 0.6289 - val_auc: 0.8091\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5990 - accuracy: 0.4317 - auc: 0.7281 - val_loss: 2.1356 - val_accuracy: 0.5903 - val_auc: 0.7841\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6380 - accuracy: 0.4316 - auc: 0.7386 - val_loss: 2.3987 - val_accuracy: 0.5834 - val_auc: 0.7903\n",
      "Epoch 21/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.7468 - accuracy: 0.4301 - auc: 0.7354Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7595 - accuracy: 0.4300 - auc: 0.7336 - val_loss: 2.2291 - val_accuracy: 0.5756 - val_auc: 0.7921\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 2.0729 - accuracy: 0.7580 - auc: 0.7932 - val_loss: 1.6338 - val_accuracy: 0.7335 - val_auc: 0.9006\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.9890 - accuracy: 0.7947 - auc: 0.7959 - val_loss: 6.1850 - val_accuracy: 0.5799 - val_auc: 0.7963\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.6027 - accuracy: 0.8362 - auc: 0.7980 - val_loss: 1.8278 - val_accuracy: 0.8628 - val_auc: 0.9073\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.1629 - accuracy: 0.7950 - auc: 0.7740 - val_loss: 1.6122 - val_accuracy: 0.5531 - val_auc: 0.8471\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.7210 - accuracy: 0.7869 - auc: 0.7357 - val_loss: 3.3843 - val_accuracy: 0.4598 - val_auc: 0.8465\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.0115 - accuracy: 0.6843 - auc: 0.7351 - val_loss: 2.3878 - val_accuracy: 0.9209 - val_auc: 0.9292\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 6.7666 - accuracy: 0.7784 - auc: 0.7656 - val_loss: 4.4769 - val_accuracy: 0.8865 - val_auc: 0.9114\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.5937 - accuracy: 0.6250 - auc: 0.7175 - val_loss: 5.5032 - val_accuracy: 0.4681 - val_auc: 0.7467\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.0495 - accuracy: 0.3655 - auc: 0.6742 - val_loss: 3.0222 - val_accuracy: 0.4499 - val_auc: 0.8043\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9576 - accuracy: 0.3589 - auc: 0.6870 - val_loss: 4.2804 - val_accuracy: 0.4913 - val_auc: 0.8104\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.1100 - accuracy: 0.3469 - auc: 0.6400 - val_loss: 3.7694 - val_accuracy: 0.9874 - val_auc: 0.6959\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1636 - accuracy: 0.2459 - auc: 0.6079 - val_loss: 4.0312 - val_accuracy: 0.4272 - val_auc: 0.7029\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9007 - accuracy: 0.3385 - auc: 0.6077 - val_loss: 4.1790 - val_accuracy: 0.4179 - val_auc: 0.6936\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8902 - accuracy: 0.3194 - auc: 0.6326 - val_loss: 5.5308 - val_accuracy: 0.9960 - val_auc: 0.6940\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6890 - accuracy: 0.2947 - auc: 0.6166 - val_loss: 5.6286 - val_accuracy: 0.4269 - val_auc: 0.6989\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2539 - accuracy: 0.2715 - auc: 0.6129 - val_loss: 5.2776 - val_accuracy: 0.4396 - val_auc: 0.7039\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0154 - accuracy: 0.2271 - auc: 0.6124 - val_loss: 5.1640 - val_accuracy: 0.4537 - val_auc: 0.7096\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8862 - accuracy: 0.3035 - auc: 0.6177 - val_loss: 4.7702 - val_accuracy: 0.4687 - val_auc: 0.7189\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9998 - accuracy: 0.3034 - auc: 0.6198 - val_loss: 2.9148 - val_accuracy: 0.4323 - val_auc: 0.7004\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7295 - accuracy: 0.2287 - auc: 0.6189 - val_loss: 3.2761 - val_accuracy: 0.4336 - val_auc: 0.7013\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8014 - accuracy: 0.3158 - auc: 0.6126 - val_loss: 1.6265 - val_accuracy: 0.4370 - val_auc: 0.7033\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4517 - accuracy: 0.2516 - auc: 0.6142 - val_loss: 4.3003 - val_accuracy: 0.4439 - val_auc: 0.7052\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7911 - accuracy: 0.2880 - auc: 0.6269 - val_loss: 4.6171 - val_accuracy: 0.4530 - val_auc: 0.7089\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7538 - accuracy: 0.2862 - auc: 0.6165 - val_loss: 4.8361 - val_accuracy: 0.4637 - val_auc: 0.7144\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7027 - accuracy: 0.2346 - auc: 0.5943 - val_loss: 4.7162 - val_accuracy: 0.4760 - val_auc: 0.7196\n",
      "Epoch 26/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.6387 - accuracy: 0.2401 - auc: 0.6058Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6400 - accuracy: 0.2399 - auc: 0.6073 - val_loss: 4.8244 - val_accuracy: 0.4602 - val_auc: 0.7108\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 4.7906 - accuracy: 0.6948 - auc: 0.7709 - val_loss: 6.3575 - val_accuracy: 0.4552 - val_auc: 0.7681\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 5.7924 - accuracy: 0.7778 - auc: 0.7971 - val_loss: 1.9945 - val_accuracy: 0.8151 - val_auc: 0.8753\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.6794 - accuracy: 0.8165 - auc: 0.8062 - val_loss: 1.7030 - val_accuracy: 0.8341 - val_auc: 0.8801\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9306 - accuracy: 0.8719 - auc: 0.8091 - val_loss: 1.9568 - val_accuracy: 0.9101 - val_auc: 0.8692\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 5.1378 - accuracy: 0.6950 - auc: 0.7660 - val_loss: 3.9869 - val_accuracy: 0.8853 - val_auc: 0.8417\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 7.8948 - accuracy: 0.6487 - auc: 0.7626 - val_loss: 2.7074 - val_accuracy: 0.4936 - val_auc: 0.8546\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.7868 - accuracy: 0.6290 - auc: 0.7761 - val_loss: 4.1796 - val_accuracy: 0.9138 - val_auc: 0.9055\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.0440 - accuracy: 0.5842 - auc: 0.7723 - val_loss: 4.0649 - val_accuracy: 0.5565 - val_auc: 0.8517\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5814 - accuracy: 0.5475 - auc: 0.7763 - val_loss: 3.9698 - val_accuracy: 0.5563 - val_auc: 0.9131\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1656 - accuracy: 0.5267 - auc: 0.8028 - val_loss: 3.4881 - val_accuracy: 0.5485 - val_auc: 0.9086\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4356 - accuracy: 0.5497 - auc: 0.8024 - val_loss: 3.5828 - val_accuracy: 0.5444 - val_auc: 0.8949\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.4900 - accuracy: 0.5127 - auc: 0.7741 - val_loss: 4.6614 - val_accuracy: 0.5551 - val_auc: 0.8957\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8607 - accuracy: 0.4831 - auc: 0.8048 - val_loss: 4.4400 - val_accuracy: 0.5485 - val_auc: 0.7713\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6150 - accuracy: 0.4658 - auc: 0.7355 - val_loss: 5.1358 - val_accuracy: 0.5270 - val_auc: 0.7855\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.3218 - accuracy: 0.4446 - auc: 0.7228 - val_loss: 3.3184 - val_accuracy: 0.4689 - val_auc: 0.7556\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9574 - accuracy: 0.4480 - auc: 0.7701 - val_loss: 5.4693 - val_accuracy: 0.5576 - val_auc: 0.8911\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5984 - accuracy: 0.4428 - auc: 0.7544 - val_loss: 4.4891 - val_accuracy: 0.5401 - val_auc: 0.7598\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5288 - accuracy: 0.4288 - auc: 0.7199 - val_loss: 3.7756 - val_accuracy: 0.4979 - val_auc: 0.7385\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7191 - accuracy: 0.4525 - auc: 0.7507 - val_loss: 5.8860 - val_accuracy: 0.5407 - val_auc: 0.8153\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6859 - accuracy: 0.4422 - auc: 0.7497 - val_loss: 5.1296 - val_accuracy: 0.5381 - val_auc: 0.8197\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6129 - accuracy: 0.4406 - auc: 0.7456 - val_loss: 5.6923 - val_accuracy: 0.5464 - val_auc: 0.8159\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6873 - accuracy: 0.4394 - auc: 0.7335 - val_loss: 5.7503 - val_accuracy: 0.5353 - val_auc: 0.7549\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5351 - accuracy: 0.4332 - auc: 0.7190 - val_loss: 5.8831 - val_accuracy: 0.5475 - val_auc: 0.7564\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5859 - accuracy: 0.4438 - auc: 0.7280 - val_loss: 4.5629 - val_accuracy: 0.5397 - val_auc: 0.7571\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5344 - accuracy: 0.4428 - auc: 0.7286 - val_loss: 4.4180 - val_accuracy: 0.5457 - val_auc: 0.7619\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5404 - accuracy: 0.4495 - auc: 0.7295 - val_loss: 3.4592 - val_accuracy: 0.5522 - val_auc: 0.7645\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6615 - accuracy: 0.4485 - auc: 0.7311 - val_loss: 4.8506 - val_accuracy: 0.5474 - val_auc: 0.7572\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6302 - accuracy: 0.4496 - auc: 0.7312 - val_loss: 4.1047 - val_accuracy: 0.5537 - val_auc: 0.7647\n",
      "Epoch 29/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.5462 - accuracy: 0.4580 - auc: 0.7183Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5592 - accuracy: 0.4582 - auc: 0.7175 - val_loss: 4.9936 - val_accuracy: 0.5662 - val_auc: 0.7711\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 6.3836 - accuracy: 0.6892 - auc: 0.7677 - val_loss: 5.1788 - val_accuracy: 0.7868 - val_auc: 0.8574\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.5421 - accuracy: 0.7922 - auc: 0.8238 - val_loss: 2.6292 - val_accuracy: 0.8691 - val_auc: 0.8959\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.8827 - accuracy: 0.8155 - auc: 0.8222 - val_loss: 3.4428 - val_accuracy: 0.7001 - val_auc: 0.8614\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.0468 - accuracy: 0.8369 - auc: 0.8165 - val_loss: 2.7640 - val_accuracy: 0.8408 - val_auc: 0.8837\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0586 - accuracy: 0.8640 - auc: 0.8370 - val_loss: 1.8824 - val_accuracy: 0.8731 - val_auc: 0.9006\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.2243 - accuracy: 0.8733 - auc: 0.8211 - val_loss: 2.4220 - val_accuracy: 0.8758 - val_auc: 0.8892\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.3615 - accuracy: 0.8898 - auc: 0.8243 - val_loss: 2.1489 - val_accuracy: 0.9607 - val_auc: 0.9172\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4463 - accuracy: 0.9133 - auc: 0.8481 - val_loss: 1.8597 - val_accuracy: 0.9221 - val_auc: 0.9322\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5217 - accuracy: 0.9068 - auc: 0.8239 - val_loss: 2.0116 - val_accuracy: 0.9032 - val_auc: 0.9046\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2591 - accuracy: 0.9208 - auc: 0.7998 - val_loss: 2.1489 - val_accuracy: 0.9132 - val_auc: 0.9070\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1021 - accuracy: 0.9386 - auc: 0.8150 - val_loss: 3.2394 - val_accuracy: 0.9338 - val_auc: 0.9052\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3006 - accuracy: 0.8724 - auc: 0.8035 - val_loss: 2.2935 - val_accuracy: 0.4877 - val_auc: 0.9019\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6378 - accuracy: 0.9329 - auc: 0.8106 - val_loss: 2.1892 - val_accuracy: 0.8933 - val_auc: 0.8945\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5719 - accuracy: 0.7616 - auc: 0.7859 - val_loss: 2.1684 - val_accuracy: 0.9437 - val_auc: 0.8886\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6957 - accuracy: 0.6363 - auc: 0.7761 - val_loss: 2.6017 - val_accuracy: 0.5432 - val_auc: 0.8304\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6265 - accuracy: 0.5664 - auc: 0.7602 - val_loss: 2.5738 - val_accuracy: 0.5438 - val_auc: 0.7934\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6322 - accuracy: 0.3869 - auc: 0.7254 - val_loss: 2.7598 - val_accuracy: 0.5796 - val_auc: 0.8176\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5876 - accuracy: 0.4411 - auc: 0.7343 - val_loss: 2.9572 - val_accuracy: 0.5688 - val_auc: 0.8315\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5488 - accuracy: 0.4263 - auc: 0.7468 - val_loss: 2.8532 - val_accuracy: 0.5964 - val_auc: 0.8449\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5960 - accuracy: 0.4280 - auc: 0.7552 - val_loss: 3.1941 - val_accuracy: 0.5935 - val_auc: 0.8397\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5823 - accuracy: 0.4994 - auc: 0.7717 - val_loss: 3.3593 - val_accuracy: 0.5815 - val_auc: 0.8325\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5235 - accuracy: 0.4674 - auc: 0.7635 - val_loss: 3.4155 - val_accuracy: 0.5916 - val_auc: 0.8234\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5751 - accuracy: 0.4219 - auc: 0.7421 - val_loss: 3.5131 - val_accuracy: 0.5953 - val_auc: 0.8110\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5628 - accuracy: 0.4514 - auc: 0.7348 - val_loss: 3.8339 - val_accuracy: 0.6341 - val_auc: 0.8266\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7224 - accuracy: 0.4866 - auc: 0.7557 - val_loss: 3.9524 - val_accuracy: 0.6497 - val_auc: 0.8258\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6236 - accuracy: 0.4410 - auc: 0.7385 - val_loss: 4.0424 - val_accuracy: 0.6346 - val_auc: 0.8328\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5309 - accuracy: 0.4423 - auc: 0.7520 - val_loss: 3.4953 - val_accuracy: 0.5863 - val_auc: 0.8442\n",
      "Epoch 28/100\n",
      "246784/250290 [============================>.] - ETA: 0s - loss: 0.5977 - accuracy: 0.4081 - auc: 0.7263Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.5959 - accuracy: 0.4081 - auc: 0.7259 - val_loss: 4.2274 - val_accuracy: 0.5924 - val_auc: 0.8069\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 4.7338 - accuracy: 0.6909 - auc: 0.7597 - val_loss: 5.3360 - val_accuracy: 0.7425 - val_auc: 0.8580\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.5822 - accuracy: 0.7671 - auc: 0.7918 - val_loss: 3.6578 - val_accuracy: 0.9141 - val_auc: 0.8796\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 6.8030 - accuracy: 0.7967 - auc: 0.7965 - val_loss: 2.6104 - val_accuracy: 0.8817 - val_auc: 0.8890\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.2919 - accuracy: 0.8552 - auc: 0.8132 - val_loss: 2.3220 - val_accuracy: 0.8828 - val_auc: 0.8306\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.8956 - accuracy: 0.7551 - auc: 0.7880 - val_loss: 2.4844 - val_accuracy: 0.9192 - val_auc: 0.8651\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8385 - accuracy: 0.6856 - auc: 0.8129 - val_loss: 1.7794 - val_accuracy: 0.5993 - val_auc: 0.8792\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.4861 - accuracy: 0.6612 - auc: 0.7912 - val_loss: 6.9269 - val_accuracy: 0.9710 - val_auc: 0.8189\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.0143 - accuracy: 0.6252 - auc: 0.7997 - val_loss: 6.2735 - val_accuracy: 0.6072 - val_auc: 0.8648\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 7.5205 - accuracy: 0.5740 - auc: 0.7481 - val_loss: 4.2690 - val_accuracy: 0.9379 - val_auc: 0.8635\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9384 - accuracy: 0.6371 - auc: 0.7795 - val_loss: 5.3124 - val_accuracy: 0.5164 - val_auc: 0.8859\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 4.2845 - accuracy: 0.6759 - auc: 0.7766 - val_loss: 5.6888 - val_accuracy: 0.9305 - val_auc: 0.8409\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.1122 - accuracy: 0.5983 - auc: 0.7532 - val_loss: 5.9745 - val_accuracy: 0.5148 - val_auc: 0.8140\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.2330 - accuracy: 0.4005 - auc: 0.7222 - val_loss: 3.1360 - val_accuracy: 0.4738 - val_auc: 0.7732\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7293 - accuracy: 0.3877 - auc: 0.7148 - val_loss: 5.5931 - val_accuracy: 0.4696 - val_auc: 0.7598\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3631 - accuracy: 0.4113 - auc: 0.7302 - val_loss: 5.3654 - val_accuracy: 0.5319 - val_auc: 0.8005\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3591 - accuracy: 0.4116 - auc: 0.7082 - val_loss: 5.2193 - val_accuracy: 0.4782 - val_auc: 0.7940\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5288 - accuracy: 0.4457 - auc: 0.7132 - val_loss: 6.3776 - val_accuracy: 0.9671 - val_auc: 0.8162\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3696 - accuracy: 0.4954 - auc: 0.7487 - val_loss: 4.6311 - val_accuracy: 0.4753 - val_auc: 0.7784\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3000 - accuracy: 0.4185 - auc: 0.7246 - val_loss: 4.6513 - val_accuracy: 0.4661 - val_auc: 0.7848\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9855 - accuracy: 0.5231 - auc: 0.7271 - val_loss: 3.9413 - val_accuracy: 0.5060 - val_auc: 0.8142\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7506 - accuracy: 0.4457 - auc: 0.7219 - val_loss: 1.8879 - val_accuracy: 0.5104 - val_auc: 0.7568\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8388 - accuracy: 0.3684 - auc: 0.6836 - val_loss: 6.3130 - val_accuracy: 0.4933 - val_auc: 0.7661\n",
      "Epoch 23/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.9117 - accuracy: 0.3887 - auc: 0.6967Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9121 - accuracy: 0.3888 - auc: 0.6968 - val_loss: 5.4465 - val_accuracy: 0.4997 - val_auc: 0.7561\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 5.4699 - accuracy: 0.6857 - auc: 0.7586 - val_loss: 3.3094 - val_accuracy: 0.6296 - val_auc: 0.8467\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.9756 - accuracy: 0.7941 - auc: 0.8224 - val_loss: 2.9648 - val_accuracy: 0.9221 - val_auc: 0.8703\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 5.7053 - accuracy: 0.8032 - auc: 0.8196 - val_loss: 3.2149 - val_accuracy: 0.8412 - val_auc: 0.8725\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.0630 - accuracy: 0.8281 - auc: 0.8170 - val_loss: 7.7956 - val_accuracy: 0.5553 - val_auc: 0.6775\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 7.0805 - accuracy: 0.8317 - auc: 0.7824 - val_loss: 5.7255 - val_accuracy: 0.9287 - val_auc: 0.8704\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 8.4911 - accuracy: 0.8316 - auc: 0.7697 - val_loss: 9.6824 - val_accuracy: 0.5788 - val_auc: 0.8413\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.8158 - accuracy: 0.6717 - auc: 0.7634 - val_loss: 4.7197 - val_accuracy: 0.9192 - val_auc: 0.8668\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 6.4585 - accuracy: 0.5329 - auc: 0.7441 - val_loss: 31.8149 - val_accuracy: 0.4660 - val_auc: 0.5475\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 7.1969 - accuracy: 0.5481 - auc: 0.7032 - val_loss: 7.9362 - val_accuracy: 0.4959 - val_auc: 0.7659\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.0371 - accuracy: 0.4433 - auc: 0.7259 - val_loss: 5.7193 - val_accuracy: 0.9658 - val_auc: 0.7748\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.9404 - accuracy: 0.4845 - auc: 0.7159 - val_loss: 6.5172 - val_accuracy: 0.4933 - val_auc: 0.7918\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.0355 - accuracy: 0.4684 - auc: 0.7403 - val_loss: 4.8131 - val_accuracy: 0.5026 - val_auc: 0.8544\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.5148 - accuracy: 0.5830 - auc: 0.7530 - val_loss: 10.0125 - val_accuracy: 0.9533 - val_auc: 0.8845\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.5334 - accuracy: 0.5038 - auc: 0.7499 - val_loss: 6.1299 - val_accuracy: 0.4977 - val_auc: 0.7696\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4315 - accuracy: 0.4178 - auc: 0.7197 - val_loss: 6.8662 - val_accuracy: 0.5127 - val_auc: 0.7351\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4322 - accuracy: 0.3903 - auc: 0.6843 - val_loss: 5.5225 - val_accuracy: 0.5112 - val_auc: 0.7359\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.7764 - accuracy: 0.3638 - auc: 0.6527 - val_loss: 8.2807 - val_accuracy: 0.4810 - val_auc: 0.7269\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1988 - accuracy: 0.3405 - auc: 0.6753 - val_loss: 8.5422 - val_accuracy: 0.4850 - val_auc: 0.7605\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1106 - accuracy: 0.3445 - auc: 0.6730 - val_loss: 9.3188 - val_accuracy: 0.4763 - val_auc: 0.7292\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.4327 - accuracy: 0.3622 - auc: 0.6750 - val_loss: 8.7743 - val_accuracy: 0.4980 - val_auc: 0.7396\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0680 - accuracy: 0.4024 - auc: 0.7065 - val_loss: 8.8983 - val_accuracy: 0.5127 - val_auc: 0.7853\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0573 - accuracy: 0.4616 - auc: 0.7438 - val_loss: 9.2258 - val_accuracy: 0.4937 - val_auc: 0.8056\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.0460 - accuracy: 0.3933 - auc: 0.7255 - val_loss: 11.1524 - val_accuracy: 0.4926 - val_auc: 0.7842\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.0863 - accuracy: 0.3785 - auc: 0.7114 - val_loss: 8.7613 - val_accuracy: 0.5038 - val_auc: 0.8909\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2168 - accuracy: 0.4218 - auc: 0.7140 - val_loss: 10.3587 - val_accuracy: 0.4942 - val_auc: 0.7991\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0790 - accuracy: 0.3710 - auc: 0.6865 - val_loss: 10.7606 - val_accuracy: 0.4913 - val_auc: 0.7280\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2631 - accuracy: 0.3659 - auc: 0.6704 - val_loss: 12.1435 - val_accuracy: 0.4801 - val_auc: 0.7474\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8491 - accuracy: 0.3552 - auc: 0.6655 - val_loss: 12.7678 - val_accuracy: 0.4908 - val_auc: 0.7277\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8591 - accuracy: 0.3259 - auc: 0.6778 - val_loss: 8.0696 - val_accuracy: 0.4903 - val_auc: 0.7289\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6755 - accuracy: 0.3389 - auc: 0.6681 - val_loss: 9.2349 - val_accuracy: 0.4995 - val_auc: 0.7320\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4849 - accuracy: 0.3258 - auc: 0.6606 - val_loss: 7.8385 - val_accuracy: 0.4816 - val_auc: 0.7294\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0209 - accuracy: 0.3271 - auc: 0.6703 - val_loss: 4.9986 - val_accuracy: 0.4894 - val_auc: 0.7357\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6935 - accuracy: 0.3447 - auc: 0.6684 - val_loss: 4.5015 - val_accuracy: 0.4979 - val_auc: 0.7385\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5986 - accuracy: 0.3850 - auc: 0.6899 - val_loss: 6.7287 - val_accuracy: 0.5257 - val_auc: 0.7504\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6640 - accuracy: 0.3510 - auc: 0.6779 - val_loss: 9.4240 - val_accuracy: 0.5175 - val_auc: 0.7429\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6936 - accuracy: 0.3680 - auc: 0.6866 - val_loss: 10.3852 - val_accuracy: 0.5285 - val_auc: 0.7382\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7059 - accuracy: 0.3710 - auc: 0.6820 - val_loss: 10.5387 - val_accuracy: 0.5285 - val_auc: 0.7451\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9028 - accuracy: 0.3727 - auc: 0.6831 - val_loss: 12.6941 - val_accuracy: 0.5178 - val_auc: 0.7419\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.9083 - accuracy: 0.3734 - auc: 0.6683 - val_loss: 10.9501 - val_accuracy: 0.4974 - val_auc: 0.7278\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 2.0430 - accuracy: 0.3790 - auc: 0.6636 - val_loss: 13.3959 - val_accuracy: 0.4936 - val_auc: 0.7392\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.4699 - accuracy: 0.3486 - auc: 0.6632 - val_loss: 9.8866 - val_accuracy: 0.4211 - val_auc: 0.6761\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0005 - accuracy: 0.3815 - auc: 0.6736 - val_loss: 8.3512 - val_accuracy: 0.4888 - val_auc: 0.7361\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8558 - accuracy: 0.3461 - auc: 0.6793 - val_loss: 10.7417 - val_accuracy: 0.4851 - val_auc: 0.7323\n",
      "Epoch 44/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 1.2834 - accuracy: 0.3432 - auc: 0.6573Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2722 - accuracy: 0.3432 - auc: 0.6588 - val_loss: 6.0979 - val_accuracy: 0.4827 - val_auc: 0.7272\n",
      "Epoch 00044: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 4.3593 - accuracy: 0.6908 - auc: 0.7791 - val_loss: 11.7422 - val_accuracy: 0.8604 - val_auc: 0.6375\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 6.4024 - accuracy: 0.7801 - auc: 0.7885 - val_loss: 2.2921 - val_accuracy: 0.8281 - val_auc: 0.8775\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.4582 - accuracy: 0.8325 - auc: 0.8140 - val_loss: 5.5607 - val_accuracy: 0.9086 - val_auc: 0.9009\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 5.0906 - accuracy: 0.8113 - auc: 0.7958 - val_loss: 3.8052 - val_accuracy: 0.8575 - val_auc: 0.8853\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.0210 - accuracy: 0.7511 - auc: 0.7770 - val_loss: 6.5360 - val_accuracy: 0.9428 - val_auc: 0.8745\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 8.6735 - accuracy: 0.7038 - auc: 0.7311 - val_loss: 6.4650 - val_accuracy: 0.4667 - val_auc: 0.7298\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 12.6279 - accuracy: 0.4666 - auc: 0.6729 - val_loss: 12.7865 - val_accuracy: 0.5736 - val_auc: 0.7754\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 7.1970 - accuracy: 0.4795 - auc: 0.7317 - val_loss: 9.2023 - val_accuracy: 0.5393 - val_auc: 0.7964\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.7305 - accuracy: 0.5537 - auc: 0.7550 - val_loss: 6.6362 - val_accuracy: 0.5061 - val_auc: 0.7838\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.7060 - accuracy: 0.4084 - auc: 0.7168 - val_loss: 5.4625 - val_accuracy: 0.4736 - val_auc: 0.7676\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.1260 - accuracy: 0.4365 - auc: 0.7017 - val_loss: 5.7248 - val_accuracy: 0.5064 - val_auc: 0.7757\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 8.1228 - accuracy: 0.4102 - auc: 0.6935 - val_loss: 8.6452 - val_accuracy: 0.7502 - val_auc: 0.7305\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 5.2890 - accuracy: 0.4607 - auc: 0.6920 - val_loss: 4.2543 - val_accuracy: 0.4572 - val_auc: 0.7526\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.6342 - accuracy: 0.3515 - auc: 0.6951 - val_loss: 8.5644 - val_accuracy: 0.4800 - val_auc: 0.7896\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 5.6752 - accuracy: 0.3884 - auc: 0.7103 - val_loss: 10.1754 - val_accuracy: 0.4732 - val_auc: 0.7920\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 7.3434 - accuracy: 0.5368 - auc: 0.7151 - val_loss: 3.7728 - val_accuracy: 0.8947 - val_auc: 0.8622\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.7633 - accuracy: 0.5621 - auc: 0.7491 - val_loss: 4.9645 - val_accuracy: 0.9720 - val_auc: 0.8997\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.0827 - accuracy: 0.8516 - auc: 0.7816 - val_loss: 7.2559 - val_accuracy: 0.4686 - val_auc: 0.7997\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.2479 - accuracy: 0.4798 - auc: 0.7312 - val_loss: 4.5566 - val_accuracy: 0.4655 - val_auc: 0.7796\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9370 - accuracy: 0.3298 - auc: 0.6678 - val_loss: 5.6599 - val_accuracy: 0.4818 - val_auc: 0.7342\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.1160 - accuracy: 0.3418 - auc: 0.6678 - val_loss: 6.9188 - val_accuracy: 0.4904 - val_auc: 0.7258\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.5962 - accuracy: 0.3602 - auc: 0.6910 - val_loss: 7.5193 - val_accuracy: 0.4794 - val_auc: 0.6910\n",
      "Epoch 23/100\n",
      "248832/250291 [============================>.] - ETA: 0s - loss: 6.4185 - accuracy: 0.3484 - auc: 0.6511Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 6.4205 - accuracy: 0.3484 - auc: 0.6507 - val_loss: 7.5879 - val_accuracy: 0.5081 - val_auc: 0.7386\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5503 - accuracy: 0.4675 - auc: 0.8476 - val_loss: 0.2979 - val_accuracy: 0.8460 - val_auc: 0.9527\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4023 - accuracy: 0.7931 - auc: 0.9065 - val_loss: 0.2767 - val_accuracy: 0.8996 - val_auc: 0.9576\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3578 - accuracy: 0.8897 - auc: 0.9241 - val_loss: 0.2745 - val_accuracy: 0.9065 - val_auc: 0.9566\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3586 - accuracy: 0.8951 - auc: 0.9170 - val_loss: 0.2674 - val_accuracy: 0.9031 - val_auc: 0.9595\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3536 - accuracy: 0.8965 - auc: 0.9205 - val_loss: 0.2582 - val_accuracy: 0.9023 - val_auc: 0.9606\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3369 - accuracy: 0.9055 - auc: 0.9266 - val_loss: 0.2605 - val_accuracy: 0.9056 - val_auc: 0.9602\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3421 - accuracy: 0.9050 - auc: 0.9265 - val_loss: 0.2573 - val_accuracy: 0.8972 - val_auc: 0.9604\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3456 - accuracy: 0.8987 - auc: 0.9251 - val_loss: 0.2581 - val_accuracy: 0.9066 - val_auc: 0.9600\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3448 - accuracy: 0.9034 - auc: 0.9239 - val_loss: 0.2621 - val_accuracy: 0.9173 - val_auc: 0.9607\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3512 - accuracy: 0.9094 - auc: 0.9231 - val_loss: 0.2575 - val_accuracy: 0.8949 - val_auc: 0.9613\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3413 - accuracy: 0.9119 - auc: 0.9277 - val_loss: 0.2555 - val_accuracy: 0.9042 - val_auc: 0.9606\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3498 - accuracy: 0.9092 - auc: 0.9197 - val_loss: 0.2581 - val_accuracy: 0.9062 - val_auc: 0.9605\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3451 - accuracy: 0.9096 - auc: 0.9214 - val_loss: 0.2535 - val_accuracy: 0.9085 - val_auc: 0.9615\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3314 - accuracy: 0.9095 - auc: 0.9313 - val_loss: 0.2600 - val_accuracy: 0.9147 - val_auc: 0.9607\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3348 - accuracy: 0.9162 - auc: 0.9279 - val_loss: 0.2705 - val_accuracy: 0.9230 - val_auc: 0.9598\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3346 - accuracy: 0.9169 - auc: 0.9280 - val_loss: 0.2570 - val_accuracy: 0.8971 - val_auc: 0.9610\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3316 - accuracy: 0.9155 - auc: 0.9314 - val_loss: 0.2579 - val_accuracy: 0.9049 - val_auc: 0.9614\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3496 - accuracy: 0.9157 - auc: 0.9212 - val_loss: 0.2533 - val_accuracy: 0.9091 - val_auc: 0.9616\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3405 - accuracy: 0.9170 - auc: 0.9267 - val_loss: 0.2537 - val_accuracy: 0.9095 - val_auc: 0.9620\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3361 - accuracy: 0.9156 - auc: 0.9293 - val_loss: 0.2608 - val_accuracy: 0.9248 - val_auc: 0.9606\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3327 - accuracy: 0.9186 - auc: 0.9295 - val_loss: 0.2603 - val_accuracy: 0.9207 - val_auc: 0.9601\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3478 - accuracy: 0.9168 - auc: 0.9243 - val_loss: 0.2556 - val_accuracy: 0.9058 - val_auc: 0.9619\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3362 - accuracy: 0.9176 - auc: 0.9275 - val_loss: 0.2606 - val_accuracy: 0.9044 - val_auc: 0.9596\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3310 - accuracy: 0.9173 - auc: 0.9299 - val_loss: 0.2585 - val_accuracy: 0.9114 - val_auc: 0.9604\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3382 - accuracy: 0.9209 - auc: 0.9264 - val_loss: 0.2528 - val_accuracy: 0.9165 - val_auc: 0.9624\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3378 - accuracy: 0.9215 - auc: 0.9258 - val_loss: 0.2600 - val_accuracy: 0.9049 - val_auc: 0.9611\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3287 - accuracy: 0.9232 - auc: 0.9331 - val_loss: 0.2622 - val_accuracy: 0.9118 - val_auc: 0.9587\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3457 - accuracy: 0.9206 - auc: 0.9239 - val_loss: 0.2576 - val_accuracy: 0.9111 - val_auc: 0.9609\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3407 - accuracy: 0.9203 - auc: 0.9261 - val_loss: 0.2642 - val_accuracy: 0.9103 - val_auc: 0.9588\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3235 - accuracy: 0.9218 - auc: 0.9318 - val_loss: 0.2710 - val_accuracy: 0.9209 - val_auc: 0.9584\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3324 - accuracy: 0.9233 - auc: 0.9307 - val_loss: 0.2727 - val_accuracy: 0.9262 - val_auc: 0.9583\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3453 - accuracy: 0.9187 - auc: 0.9252 - val_loss: 0.2592 - val_accuracy: 0.9119 - val_auc: 0.9612\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3275 - accuracy: 0.9193 - auc: 0.9316 - val_loss: 0.2629 - val_accuracy: 0.9212 - val_auc: 0.9606\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3427 - accuracy: 0.9232 - auc: 0.9238 - val_loss: 0.2638 - val_accuracy: 0.9150 - val_auc: 0.9597\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3346 - accuracy: 0.9227 - auc: 0.9254 - val_loss: 0.2577 - val_accuracy: 0.9185 - val_auc: 0.9613\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3113 - accuracy: 0.9279 - auc: 0.9378 - val_loss: 0.2767 - val_accuracy: 0.9323 - val_auc: 0.9592\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3351 - accuracy: 0.9244 - auc: 0.9268 - val_loss: 0.2563 - val_accuracy: 0.9198 - val_auc: 0.9617\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3265 - accuracy: 0.9251 - auc: 0.9312 - val_loss: 0.2632 - val_accuracy: 0.9221 - val_auc: 0.9589\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3302 - accuracy: 0.9266 - auc: 0.9296 - val_loss: 0.2640 - val_accuracy: 0.9163 - val_auc: 0.9599\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3291 - accuracy: 0.9216 - auc: 0.9281 - val_loss: 0.2687 - val_accuracy: 0.9129 - val_auc: 0.9586\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3448 - accuracy: 0.9233 - auc: 0.9244 - val_loss: 0.2667 - val_accuracy: 0.9107 - val_auc: 0.9590\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3223 - accuracy: 0.9263 - auc: 0.9339 - val_loss: 0.2634 - val_accuracy: 0.9267 - val_auc: 0.9602\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3302 - accuracy: 0.9254 - auc: 0.9278 - val_loss: 0.2642 - val_accuracy: 0.9191 - val_auc: 0.9600\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3292 - accuracy: 0.9253 - auc: 0.9322 - val_loss: 0.2669 - val_accuracy: 0.9239 - val_auc: 0.9591\n",
      "Epoch 45/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.3160 - accuracy: 0.9284 - auc: 0.9296Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3196 - accuracy: 0.9281 - auc: 0.9296 - val_loss: 0.2797 - val_accuracy: 0.9049 - val_auc: 0.9565\n",
      "Epoch 00045: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 0.5372 - accuracy: 0.8752 - auc: 0.8079 - val_loss: 0.3534 - val_accuracy: 0.8981 - val_auc: 0.9367\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4183 - accuracy: 0.9055 - auc: 0.8804 - val_loss: 0.2981 - val_accuracy: 0.9000 - val_auc: 0.9491\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3951 - accuracy: 0.9106 - auc: 0.8943 - val_loss: 0.2945 - val_accuracy: 0.8868 - val_auc: 0.9512\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3839 - accuracy: 0.9111 - auc: 0.9019 - val_loss: 0.3025 - val_accuracy: 0.9220 - val_auc: 0.9491\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3790 - accuracy: 0.9147 - auc: 0.9085 - val_loss: 0.2908 - val_accuracy: 0.9283 - val_auc: 0.9537\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3682 - accuracy: 0.9178 - auc: 0.9109 - val_loss: 0.2884 - val_accuracy: 0.9195 - val_auc: 0.9537\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3587 - accuracy: 0.9197 - auc: 0.9184 - val_loss: 0.2915 - val_accuracy: 0.9162 - val_auc: 0.9524\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3486 - accuracy: 0.9208 - auc: 0.9221 - val_loss: 0.3065 - val_accuracy: 0.9271 - val_auc: 0.9483\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3388 - accuracy: 0.9157 - auc: 0.9250 - val_loss: 0.3024 - val_accuracy: 0.9114 - val_auc: 0.9492\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3506 - accuracy: 0.9134 - auc: 0.9182 - val_loss: 0.3126 - val_accuracy: 0.9012 - val_auc: 0.9469\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3518 - accuracy: 0.9112 - auc: 0.9185 - val_loss: 0.3038 - val_accuracy: 0.9086 - val_auc: 0.9495\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3340 - accuracy: 0.9170 - auc: 0.9261 - val_loss: 0.3176 - val_accuracy: 0.9129 - val_auc: 0.9489\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3467 - accuracy: 0.9135 - auc: 0.9208 - val_loss: 0.3287 - val_accuracy: 0.9113 - val_auc: 0.9454\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3497 - accuracy: 0.9139 - auc: 0.9182 - val_loss: 0.3088 - val_accuracy: 0.9067 - val_auc: 0.9503\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3395 - accuracy: 0.9189 - auc: 0.9227 - val_loss: 0.3162 - val_accuracy: 0.9205 - val_auc: 0.9490\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3341 - accuracy: 0.9193 - auc: 0.9247 - val_loss: 0.3165 - val_accuracy: 0.9104 - val_auc: 0.9496\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3351 - accuracy: 0.9199 - auc: 0.9214 - val_loss: 0.3105 - val_accuracy: 0.9193 - val_auc: 0.9504\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3389 - accuracy: 0.9235 - auc: 0.9274 - val_loss: 0.3059 - val_accuracy: 0.9139 - val_auc: 0.9525\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3275 - accuracy: 0.9186 - auc: 0.9263 - val_loss: 0.3160 - val_accuracy: 0.9239 - val_auc: 0.9512\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3302 - accuracy: 0.9229 - auc: 0.9252 - val_loss: 0.3165 - val_accuracy: 0.9237 - val_auc: 0.9515\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3251 - accuracy: 0.9245 - auc: 0.9277 - val_loss: 0.3323 - val_accuracy: 0.9108 - val_auc: 0.9504\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3218 - accuracy: 0.9210 - auc: 0.9324 - val_loss: 0.3259 - val_accuracy: 0.9146 - val_auc: 0.9504\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3328 - accuracy: 0.9246 - auc: 0.9281 - val_loss: 0.3172 - val_accuracy: 0.9039 - val_auc: 0.9510\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3348 - accuracy: 0.9183 - auc: 0.9225 - val_loss: 0.3303 - val_accuracy: 0.9101 - val_auc: 0.9501\n",
      "Epoch 25/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.9221 - auc: 0.9251Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3325 - accuracy: 0.9222 - auc: 0.9249 - val_loss: 0.3400 - val_accuracy: 0.9164 - val_auc: 0.9486\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6170 - accuracy: 0.8860 - auc: 0.7651 - val_loss: 0.3792 - val_accuracy: 0.9223 - val_auc: 0.9387\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4639 - accuracy: 0.9173 - auc: 0.8489 - val_loss: 0.3469 - val_accuracy: 0.9304 - val_auc: 0.9440\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4561 - accuracy: 0.9120 - auc: 0.8534 - val_loss: 0.3084 - val_accuracy: 0.8896 - val_auc: 0.9528\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4078 - accuracy: 0.9073 - auc: 0.8883 - val_loss: 0.2890 - val_accuracy: 0.8972 - val_auc: 0.9537\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3894 - accuracy: 0.8954 - auc: 0.8958 - val_loss: 0.2893 - val_accuracy: 0.8808 - val_auc: 0.9516\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3719 - accuracy: 0.8904 - auc: 0.9059 - val_loss: 0.2828 - val_accuracy: 0.8881 - val_auc: 0.9566\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3703 - accuracy: 0.8805 - auc: 0.9044 - val_loss: 0.2779 - val_accuracy: 0.8417 - val_auc: 0.9560\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3661 - accuracy: 0.7083 - auc: 0.9069 - val_loss: 0.2749 - val_accuracy: 0.8298 - val_auc: 0.9558\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3505 - accuracy: 0.6999 - auc: 0.9131 - val_loss: 0.2801 - val_accuracy: 0.8385 - val_auc: 0.9567\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3421 - accuracy: 0.6985 - auc: 0.9167 - val_loss: 0.2911 - val_accuracy: 0.8395 - val_auc: 0.9542\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3487 - accuracy: 0.7037 - auc: 0.9171 - val_loss: 0.2875 - val_accuracy: 0.8285 - val_auc: 0.9529\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3504 - accuracy: 0.6953 - auc: 0.9172 - val_loss: 0.2928 - val_accuracy: 0.8450 - val_auc: 0.9551\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3457 - accuracy: 0.7008 - auc: 0.9153 - val_loss: 0.3141 - val_accuracy: 0.8469 - val_auc: 0.9530\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3421 - accuracy: 0.7046 - auc: 0.9188 - val_loss: 0.3090 - val_accuracy: 0.8387 - val_auc: 0.9518\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3446 - accuracy: 0.7061 - auc: 0.9148 - val_loss: 0.3064 - val_accuracy: 0.8259 - val_auc: 0.9503\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3276 - accuracy: 0.7084 - auc: 0.9223 - val_loss: 0.3111 - val_accuracy: 0.8562 - val_auc: 0.9521\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3348 - accuracy: 0.7077 - auc: 0.9134 - val_loss: 0.3285 - val_accuracy: 0.8448 - val_auc: 0.9502\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3298 - accuracy: 0.7062 - auc: 0.9178 - val_loss: 0.3288 - val_accuracy: 0.8496 - val_auc: 0.9498\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3247 - accuracy: 0.7056 - auc: 0.9287 - val_loss: 0.3229 - val_accuracy: 0.8580 - val_auc: 0.9508\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3315 - accuracy: 0.7061 - auc: 0.9193 - val_loss: 0.3257 - val_accuracy: 0.8488 - val_auc: 0.9500\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3264 - accuracy: 0.7014 - auc: 0.9253 - val_loss: 0.3433 - val_accuracy: 0.8534 - val_auc: 0.9478\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3280 - accuracy: 0.7339 - auc: 0.9241 - val_loss: 0.3409 - val_accuracy: 0.8445 - val_auc: 0.9486\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3207 - accuracy: 0.7058 - auc: 0.9257 - val_loss: 0.3459 - val_accuracy: 0.8472 - val_auc: 0.9495\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3275 - accuracy: 0.6995 - auc: 0.9212 - val_loss: 0.3594 - val_accuracy: 0.8444 - val_auc: 0.9495\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3319 - accuracy: 0.6979 - auc: 0.9175 - val_loss: 0.3394 - val_accuracy: 0.8379 - val_auc: 0.9515\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3287 - accuracy: 0.7029 - auc: 0.9196 - val_loss: 0.3708 - val_accuracy: 0.8328 - val_auc: 0.9464\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3338 - accuracy: 0.7018 - auc: 0.9208 - val_loss: 0.3500 - val_accuracy: 0.8139 - val_auc: 0.9418\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3379 - accuracy: 0.6969 - auc: 0.9212 - val_loss: 0.3301 - val_accuracy: 0.8522 - val_auc: 0.9507\n",
      "Epoch 29/100\n",
      "242688/250290 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.7080 - auc: 0.9203Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3246 - accuracy: 0.7076 - auc: 0.9199 - val_loss: 0.3570 - val_accuracy: 0.8471 - val_auc: 0.9501\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.6313 - accuracy: 0.3899 - auc: 0.8308 - val_loss: 0.3468 - val_accuracy: 0.8696 - val_auc: 0.9439\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4043 - accuracy: 0.9000 - auc: 0.8990 - val_loss: 0.3254 - val_accuracy: 0.9077 - val_auc: 0.9441\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3671 - accuracy: 0.9133 - auc: 0.9137 - val_loss: 0.2828 - val_accuracy: 0.9099 - val_auc: 0.9549\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3644 - accuracy: 0.9171 - auc: 0.9141 - val_loss: 0.2811 - val_accuracy: 0.9172 - val_auc: 0.9561\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3640 - accuracy: 0.9203 - auc: 0.9142 - val_loss: 0.2804 - val_accuracy: 0.9129 - val_auc: 0.9566\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3632 - accuracy: 0.9192 - auc: 0.9182 - val_loss: 0.2735 - val_accuracy: 0.9251 - val_auc: 0.9594\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3403 - accuracy: 0.9242 - auc: 0.9272 - val_loss: 0.2717 - val_accuracy: 0.9287 - val_auc: 0.9582\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3602 - accuracy: 0.9203 - auc: 0.9166 - val_loss: 0.2859 - val_accuracy: 0.9223 - val_auc: 0.9528\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3560 - accuracy: 0.9222 - auc: 0.9234 - val_loss: 0.2753 - val_accuracy: 0.9240 - val_auc: 0.9555\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3596 - accuracy: 0.9222 - auc: 0.9115 - val_loss: 0.2827 - val_accuracy: 0.9104 - val_auc: 0.9534\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3471 - accuracy: 0.9230 - auc: 0.9236 - val_loss: 0.2901 - val_accuracy: 0.9178 - val_auc: 0.9527\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3539 - accuracy: 0.9262 - auc: 0.9205 - val_loss: 0.2827 - val_accuracy: 0.9167 - val_auc: 0.9549\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3478 - accuracy: 0.9246 - auc: 0.9244 - val_loss: 0.2799 - val_accuracy: 0.9314 - val_auc: 0.9545\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3393 - accuracy: 0.9263 - auc: 0.9285 - val_loss: 0.2803 - val_accuracy: 0.9256 - val_auc: 0.9544\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3397 - accuracy: 0.9269 - auc: 0.9232 - val_loss: 0.2865 - val_accuracy: 0.9141 - val_auc: 0.9530\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3450 - accuracy: 0.9262 - auc: 0.9236 - val_loss: 0.2919 - val_accuracy: 0.9116 - val_auc: 0.9513\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3364 - accuracy: 0.9265 - auc: 0.9260 - val_loss: 0.2915 - val_accuracy: 0.9334 - val_auc: 0.9551\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3349 - accuracy: 0.9317 - auc: 0.9243 - val_loss: 0.3005 - val_accuracy: 0.9338 - val_auc: 0.9527\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3506 - accuracy: 0.9287 - auc: 0.9231 - val_loss: 0.2989 - val_accuracy: 0.9141 - val_auc: 0.9512\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3255 - accuracy: 0.9279 - auc: 0.9305 - val_loss: 0.2946 - val_accuracy: 0.9263 - val_auc: 0.9507\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3404 - accuracy: 0.9288 - auc: 0.9271 - val_loss: 0.2799 - val_accuracy: 0.9176 - val_auc: 0.9547\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3376 - accuracy: 0.9267 - auc: 0.9232 - val_loss: 0.3125 - val_accuracy: 0.9369 - val_auc: 0.9491\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3342 - accuracy: 0.9311 - auc: 0.9253 - val_loss: 0.2847 - val_accuracy: 0.9293 - val_auc: 0.9549\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3382 - accuracy: 0.9316 - auc: 0.9263 - val_loss: 0.2853 - val_accuracy: 0.9340 - val_auc: 0.9549\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3272 - accuracy: 0.9306 - auc: 0.9314 - val_loss: 0.2835 - val_accuracy: 0.9152 - val_auc: 0.9557\n",
      "Epoch 26/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.9310 - auc: 0.9244Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3374 - accuracy: 0.9308 - auc: 0.9247 - val_loss: 0.2933 - val_accuracy: 0.9148 - val_auc: 0.9532\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.6103 - accuracy: 0.3326 - auc: 0.8458 - val_loss: 0.3267 - val_accuracy: 0.8154 - val_auc: 0.9523\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4052 - accuracy: 0.8765 - auc: 0.9065 - val_loss: 0.2825 - val_accuracy: 0.8941 - val_auc: 0.9598\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3620 - accuracy: 0.9103 - auc: 0.9214 - val_loss: 0.2753 - val_accuracy: 0.9059 - val_auc: 0.9617\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3561 - accuracy: 0.9143 - auc: 0.9230 - val_loss: 0.2776 - val_accuracy: 0.8998 - val_auc: 0.9566\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3558 - accuracy: 0.9156 - auc: 0.9217 - val_loss: 0.2804 - val_accuracy: 0.9253 - val_auc: 0.9537\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3499 - accuracy: 0.9204 - auc: 0.9224 - val_loss: 0.2824 - val_accuracy: 0.9180 - val_auc: 0.9515\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3546 - accuracy: 0.9182 - auc: 0.9225 - val_loss: 0.2863 - val_accuracy: 0.9237 - val_auc: 0.9501\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3405 - accuracy: 0.9210 - auc: 0.9270 - val_loss: 0.2888 - val_accuracy: 0.9050 - val_auc: 0.9495\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3523 - accuracy: 0.9189 - auc: 0.9248 - val_loss: 0.2819 - val_accuracy: 0.9275 - val_auc: 0.9522\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3348 - accuracy: 0.9232 - auc: 0.9310 - val_loss: 0.2802 - val_accuracy: 0.9243 - val_auc: 0.9525\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3557 - accuracy: 0.9216 - auc: 0.9209 - val_loss: 0.2782 - val_accuracy: 0.9171 - val_auc: 0.9538\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3334 - accuracy: 0.9203 - auc: 0.9318 - val_loss: 0.2935 - val_accuracy: 0.9300 - val_auc: 0.9503\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3331 - accuracy: 0.9256 - auc: 0.9317 - val_loss: 0.2878 - val_accuracy: 0.9284 - val_auc: 0.9514\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3498 - accuracy: 0.9238 - auc: 0.9243 - val_loss: 0.2753 - val_accuracy: 0.9145 - val_auc: 0.9549\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3395 - accuracy: 0.9229 - auc: 0.9264 - val_loss: 0.2845 - val_accuracy: 0.9198 - val_auc: 0.9531\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3323 - accuracy: 0.9249 - auc: 0.9309 - val_loss: 0.2926 - val_accuracy: 0.9330 - val_auc: 0.9528\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3430 - accuracy: 0.9284 - auc: 0.9308 - val_loss: 0.2931 - val_accuracy: 0.9052 - val_auc: 0.9520\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3428 - accuracy: 0.9248 - auc: 0.9310 - val_loss: 0.2959 - val_accuracy: 0.9118 - val_auc: 0.9502\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3382 - accuracy: 0.9258 - auc: 0.9287 - val_loss: 0.3019 - val_accuracy: 0.9227 - val_auc: 0.9486\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3378 - accuracy: 0.9265 - auc: 0.9316 - val_loss: 0.2887 - val_accuracy: 0.9240 - val_auc: 0.9507\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3372 - accuracy: 0.9245 - auc: 0.9319 - val_loss: 0.2878 - val_accuracy: 0.9291 - val_auc: 0.9512\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3253 - accuracy: 0.9277 - auc: 0.9382 - val_loss: 0.2806 - val_accuracy: 0.9268 - val_auc: 0.9543\n",
      "Epoch 23/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.9248 - auc: 0.9325Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3380 - accuracy: 0.9248 - auc: 0.9326 - val_loss: 0.2828 - val_accuracy: 0.9180 - val_auc: 0.9536\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5200 - accuracy: 0.6772 - auc: 0.8550 - val_loss: 0.2901 - val_accuracy: 0.8491 - val_auc: 0.9512\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3649 - accuracy: 0.8085 - auc: 0.9273 - val_loss: 0.2783 - val_accuracy: 0.8900 - val_auc: 0.9540\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3210 - accuracy: 0.8729 - auc: 0.9402 - val_loss: 0.2740 - val_accuracy: 0.8843 - val_auc: 0.9552\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3291 - accuracy: 0.8744 - auc: 0.9390 - val_loss: 0.2593 - val_accuracy: 0.8840 - val_auc: 0.9599\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3144 - accuracy: 0.8770 - auc: 0.9439 - val_loss: 0.2615 - val_accuracy: 0.8853 - val_auc: 0.9589\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3086 - accuracy: 0.8853 - auc: 0.9444 - val_loss: 0.2722 - val_accuracy: 0.9012 - val_auc: 0.9553\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2996 - accuracy: 0.8826 - auc: 0.9479 - val_loss: 0.2804 - val_accuracy: 0.8954 - val_auc: 0.9550\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2943 - accuracy: 0.8568 - auc: 0.9492 - val_loss: 0.2735 - val_accuracy: 0.8904 - val_auc: 0.9565\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2878 - accuracy: 0.8282 - auc: 0.9511 - val_loss: 0.2950 - val_accuracy: 0.8923 - val_auc: 0.9544\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3048 - accuracy: 0.8154 - auc: 0.9459 - val_loss: 0.2765 - val_accuracy: 0.8794 - val_auc: 0.9570\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2930 - accuracy: 0.8207 - auc: 0.9503 - val_loss: 0.2879 - val_accuracy: 0.8719 - val_auc: 0.9525\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2831 - accuracy: 0.8196 - auc: 0.9543 - val_loss: 0.3059 - val_accuracy: 0.8914 - val_auc: 0.9517\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2700 - accuracy: 0.8295 - auc: 0.9578 - val_loss: 0.2968 - val_accuracy: 0.8907 - val_auc: 0.9564\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2778 - accuracy: 0.8287 - auc: 0.9538 - val_loss: 0.2960 - val_accuracy: 0.8824 - val_auc: 0.9540\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2709 - accuracy: 0.8203 - auc: 0.9575 - val_loss: 0.3272 - val_accuracy: 0.8991 - val_auc: 0.9520\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2709 - accuracy: 0.8236 - auc: 0.9555 - val_loss: 0.3396 - val_accuracy: 0.8912 - val_auc: 0.9491\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2820 - accuracy: 0.8165 - auc: 0.9560 - val_loss: 0.3657 - val_accuracy: 0.9034 - val_auc: 0.9459\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2642 - accuracy: 0.8270 - auc: 0.9568 - val_loss: 0.3629 - val_accuracy: 0.8887 - val_auc: 0.9445\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2712 - accuracy: 0.8176 - auc: 0.9562 - val_loss: 0.3753 - val_accuracy: 0.8927 - val_auc: 0.9446\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2554 - accuracy: 0.8165 - auc: 0.9594 - val_loss: 0.3974 - val_accuracy: 0.9006 - val_auc: 0.9442\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2734 - accuracy: 0.8148 - auc: 0.9558 - val_loss: 0.3677 - val_accuracy: 0.8887 - val_auc: 0.9432\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2702 - accuracy: 0.8136 - auc: 0.9571 - val_loss: 0.3844 - val_accuracy: 0.8917 - val_auc: 0.9448\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2523 - accuracy: 0.8209 - auc: 0.9624 - val_loss: 0.4402 - val_accuracy: 0.9023 - val_auc: 0.9409\n",
      "Epoch 24/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.8217 - auc: 0.9591Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2560 - accuracy: 0.8217 - auc: 0.9591 - val_loss: 0.4236 - val_accuracy: 0.9013 - val_auc: 0.9426\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5130 - accuracy: 0.8209 - auc: 0.8594 - val_loss: 0.3360 - val_accuracy: 0.9039 - val_auc: 0.9432\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3789 - accuracy: 0.9044 - auc: 0.9227 - val_loss: 0.2913 - val_accuracy: 0.9119 - val_auc: 0.9539\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3344 - accuracy: 0.9085 - auc: 0.9397 - val_loss: 0.2844 - val_accuracy: 0.9101 - val_auc: 0.9539\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3258 - accuracy: 0.9124 - auc: 0.9408 - val_loss: 0.2847 - val_accuracy: 0.9007 - val_auc: 0.9520\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3068 - accuracy: 0.9115 - auc: 0.9464 - val_loss: 0.2770 - val_accuracy: 0.9105 - val_auc: 0.9551\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2881 - accuracy: 0.9108 - auc: 0.9543 - val_loss: 0.2904 - val_accuracy: 0.9023 - val_auc: 0.9539\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3009 - accuracy: 0.9138 - auc: 0.9510 - val_loss: 0.3010 - val_accuracy: 0.8932 - val_auc: 0.9490\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2901 - accuracy: 0.9076 - auc: 0.9520 - val_loss: 0.3086 - val_accuracy: 0.9094 - val_auc: 0.9494\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2904 - accuracy: 0.9088 - auc: 0.9521 - val_loss: 0.3181 - val_accuracy: 0.9108 - val_auc: 0.9482\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2841 - accuracy: 0.9095 - auc: 0.9539 - val_loss: 0.3341 - val_accuracy: 0.9031 - val_auc: 0.9453\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2757 - accuracy: 0.9117 - auc: 0.9555 - val_loss: 0.3322 - val_accuracy: 0.9056 - val_auc: 0.9470\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2777 - accuracy: 0.9090 - auc: 0.9551 - val_loss: 0.3486 - val_accuracy: 0.9137 - val_auc: 0.9464\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2844 - accuracy: 0.9102 - auc: 0.9546 - val_loss: 0.3260 - val_accuracy: 0.9132 - val_auc: 0.9477\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2754 - accuracy: 0.9141 - auc: 0.9568 - val_loss: 0.3592 - val_accuracy: 0.9251 - val_auc: 0.9438\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2717 - accuracy: 0.9121 - auc: 0.9579 - val_loss: 0.3362 - val_accuracy: 0.9112 - val_auc: 0.9455\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2686 - accuracy: 0.9137 - auc: 0.9601 - val_loss: 0.3637 - val_accuracy: 0.9259 - val_auc: 0.9424\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2566 - accuracy: 0.9169 - auc: 0.9615 - val_loss: 0.3892 - val_accuracy: 0.9141 - val_auc: 0.9431\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2611 - accuracy: 0.9123 - auc: 0.9597 - val_loss: 0.3967 - val_accuracy: 0.9154 - val_auc: 0.9422\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2607 - accuracy: 0.9136 - auc: 0.9603 - val_loss: 0.4201 - val_accuracy: 0.9152 - val_auc: 0.9408\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2705 - accuracy: 0.9156 - auc: 0.9586 - val_loss: 0.4046 - val_accuracy: 0.9230 - val_auc: 0.9407\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2557 - accuracy: 0.9178 - auc: 0.9623 - val_loss: 0.4338 - val_accuracy: 0.9073 - val_auc: 0.9403\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2636 - accuracy: 0.9141 - auc: 0.9585 - val_loss: 0.4629 - val_accuracy: 0.9211 - val_auc: 0.9394\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2706 - accuracy: 0.9124 - auc: 0.9582 - val_loss: 0.4636 - val_accuracy: 0.9218 - val_auc: 0.9373\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2604 - accuracy: 0.9160 - auc: 0.9615 - val_loss: 0.4110 - val_accuracy: 0.9230 - val_auc: 0.9411\n",
      "Epoch 25/100\n",
      "246784/250290 [============================>.] - ETA: 0s - loss: 0.2574 - accuracy: 0.9157 - auc: 0.9609Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2584 - accuracy: 0.9157 - auc: 0.9609 - val_loss: 0.3920 - val_accuracy: 0.9188 - val_auc: 0.9435\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5260 - accuracy: 0.6286 - auc: 0.8643 - val_loss: 0.3178 - val_accuracy: 0.8577 - val_auc: 0.9455\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3674 - accuracy: 0.8667 - auc: 0.9255 - val_loss: 0.2959 - val_accuracy: 0.9038 - val_auc: 0.9497\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3197 - accuracy: 0.8936 - auc: 0.9416 - val_loss: 0.2682 - val_accuracy: 0.8887 - val_auc: 0.9582\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3316 - accuracy: 0.8975 - auc: 0.9376 - val_loss: 0.2678 - val_accuracy: 0.9095 - val_auc: 0.9576\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3168 - accuracy: 0.9010 - auc: 0.9451 - val_loss: 0.2707 - val_accuracy: 0.9148 - val_auc: 0.9564\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2959 - accuracy: 0.9054 - auc: 0.9487 - val_loss: 0.2806 - val_accuracy: 0.9075 - val_auc: 0.9534\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3004 - accuracy: 0.8989 - auc: 0.9468 - val_loss: 0.2750 - val_accuracy: 0.9115 - val_auc: 0.9544\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2953 - accuracy: 0.8999 - auc: 0.9486 - val_loss: 0.2826 - val_accuracy: 0.8974 - val_auc: 0.9529\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2827 - accuracy: 0.8983 - auc: 0.9526 - val_loss: 0.2986 - val_accuracy: 0.9103 - val_auc: 0.9512\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2944 - accuracy: 0.9005 - auc: 0.9497 - val_loss: 0.3094 - val_accuracy: 0.9040 - val_auc: 0.9493\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2817 - accuracy: 0.9045 - auc: 0.9532 - val_loss: 0.3097 - val_accuracy: 0.8924 - val_auc: 0.9529\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2872 - accuracy: 0.8993 - auc: 0.9518 - val_loss: 0.3155 - val_accuracy: 0.9106 - val_auc: 0.9492\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2736 - accuracy: 0.9059 - auc: 0.9562 - val_loss: 0.3302 - val_accuracy: 0.9147 - val_auc: 0.9514\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2680 - accuracy: 0.9026 - auc: 0.9581 - val_loss: 0.3371 - val_accuracy: 0.9126 - val_auc: 0.9528\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2770 - accuracy: 0.9033 - auc: 0.9555 - val_loss: 0.3198 - val_accuracy: 0.8983 - val_auc: 0.9496\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2803 - accuracy: 0.9032 - auc: 0.9534 - val_loss: 0.3291 - val_accuracy: 0.9044 - val_auc: 0.9507\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2744 - accuracy: 0.9048 - auc: 0.9548 - val_loss: 0.3523 - val_accuracy: 0.9272 - val_auc: 0.9476\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2757 - accuracy: 0.9046 - auc: 0.9551 - val_loss: 0.3380 - val_accuracy: 0.9130 - val_auc: 0.9481\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2709 - accuracy: 0.9084 - auc: 0.9570 - val_loss: 0.3492 - val_accuracy: 0.9139 - val_auc: 0.9500\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2700 - accuracy: 0.9036 - auc: 0.9571 - val_loss: 0.3687 - val_accuracy: 0.9197 - val_auc: 0.9510\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2587 - accuracy: 0.9118 - auc: 0.9600 - val_loss: 0.3776 - val_accuracy: 0.9178 - val_auc: 0.9504\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2682 - accuracy: 0.9092 - auc: 0.9572 - val_loss: 0.3743 - val_accuracy: 0.9076 - val_auc: 0.9495\n",
      "Epoch 23/100\n",
      "246784/250290 [============================>.] - ETA: 0s - loss: 0.2811 - accuracy: 0.9084 - auc: 0.9540Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2802 - accuracy: 0.9085 - auc: 0.9541 - val_loss: 0.3984 - val_accuracy: 0.9210 - val_auc: 0.9470\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 0.6553 - accuracy: 0.8599 - auc: 0.8016 - val_loss: 0.3685 - val_accuracy: 0.8821 - val_auc: 0.9315\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4275 - accuracy: 0.8823 - auc: 0.8996 - val_loss: 0.3062 - val_accuracy: 0.8910 - val_auc: 0.9474\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3610 - accuracy: 0.8979 - auc: 0.9267 - val_loss: 0.2834 - val_accuracy: 0.9176 - val_auc: 0.9531\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3401 - accuracy: 0.8976 - auc: 0.9317 - val_loss: 0.2768 - val_accuracy: 0.8944 - val_auc: 0.9540\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3290 - accuracy: 0.8945 - auc: 0.9372 - val_loss: 0.2819 - val_accuracy: 0.8800 - val_auc: 0.9534\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3301 - accuracy: 0.8905 - auc: 0.9386 - val_loss: 0.2920 - val_accuracy: 0.9015 - val_auc: 0.9507\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3061 - accuracy: 0.8967 - auc: 0.9464 - val_loss: 0.2932 - val_accuracy: 0.8663 - val_auc: 0.9550\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2999 - accuracy: 0.8952 - auc: 0.9469 - val_loss: 0.2913 - val_accuracy: 0.8987 - val_auc: 0.9512\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3044 - accuracy: 0.8960 - auc: 0.9471 - val_loss: 0.3160 - val_accuracy: 0.9049 - val_auc: 0.9468\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2751 - accuracy: 0.9008 - auc: 0.9554 - val_loss: 0.3120 - val_accuracy: 0.9062 - val_auc: 0.9497\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2934 - accuracy: 0.8961 - auc: 0.9494 - val_loss: 0.3124 - val_accuracy: 0.9001 - val_auc: 0.9504\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2698 - accuracy: 0.8993 - auc: 0.9562 - val_loss: 0.3231 - val_accuracy: 0.9045 - val_auc: 0.9482\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2853 - accuracy: 0.9026 - auc: 0.9522 - val_loss: 0.3328 - val_accuracy: 0.9008 - val_auc: 0.9465\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2680 - accuracy: 0.9007 - auc: 0.9563 - val_loss: 0.3590 - val_accuracy: 0.9073 - val_auc: 0.9443\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2787 - accuracy: 0.9019 - auc: 0.9533 - val_loss: 0.3471 - val_accuracy: 0.8851 - val_auc: 0.9464\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2722 - accuracy: 0.8930 - auc: 0.9553 - val_loss: 0.3522 - val_accuracy: 0.9076 - val_auc: 0.9456\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2685 - accuracy: 0.9009 - auc: 0.9566 - val_loss: 0.3595 - val_accuracy: 0.8996 - val_auc: 0.9417\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2626 - accuracy: 0.8925 - auc: 0.9586 - val_loss: 0.3944 - val_accuracy: 0.9117 - val_auc: 0.9423\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2725 - accuracy: 0.9025 - auc: 0.9560 - val_loss: 0.3751 - val_accuracy: 0.9005 - val_auc: 0.9420\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2531 - accuracy: 0.9061 - auc: 0.9599 - val_loss: 0.3967 - val_accuracy: 0.8955 - val_auc: 0.9423\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2583 - accuracy: 0.9006 - auc: 0.9598 - val_loss: 0.4306 - val_accuracy: 0.9101 - val_auc: 0.9415\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2667 - accuracy: 0.9020 - auc: 0.9571 - val_loss: 0.4280 - val_accuracy: 0.9069 - val_auc: 0.9391\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2666 - accuracy: 0.9055 - auc: 0.9572 - val_loss: 0.4174 - val_accuracy: 0.8977 - val_auc: 0.9400\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2666 - accuracy: 0.9017 - auc: 0.9567 - val_loss: 0.4301 - val_accuracy: 0.9085 - val_auc: 0.9377\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2592 - accuracy: 0.9006 - auc: 0.9580 - val_loss: 0.4434 - val_accuracy: 0.9033 - val_auc: 0.9406\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2683 - accuracy: 0.9051 - auc: 0.9550 - val_loss: 0.4473 - val_accuracy: 0.9201 - val_auc: 0.9420\n",
      "Epoch 27/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.9065 - auc: 0.9578Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2649 - accuracy: 0.9064 - auc: 0.9578 - val_loss: 0.4396 - val_accuracy: 0.9079 - val_auc: 0.9433\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5954 - accuracy: 0.8368 - auc: 0.8306 - val_loss: 0.3101 - val_accuracy: 0.9065 - val_auc: 0.9485\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4062 - accuracy: 0.8881 - auc: 0.9024 - val_loss: 0.3012 - val_accuracy: 0.9010 - val_auc: 0.9505\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3582 - accuracy: 0.9004 - auc: 0.9287 - val_loss: 0.2908 - val_accuracy: 0.9000 - val_auc: 0.9515\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3338 - accuracy: 0.9006 - auc: 0.9380 - val_loss: 0.2720 - val_accuracy: 0.9151 - val_auc: 0.9554\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3332 - accuracy: 0.9093 - auc: 0.9378 - val_loss: 0.2676 - val_accuracy: 0.9137 - val_auc: 0.9581\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3185 - accuracy: 0.9104 - auc: 0.9447 - val_loss: 0.2761 - val_accuracy: 0.9104 - val_auc: 0.9542\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3134 - accuracy: 0.9142 - auc: 0.9450 - val_loss: 0.2849 - val_accuracy: 0.9138 - val_auc: 0.9527\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3071 - accuracy: 0.9118 - auc: 0.9466 - val_loss: 0.3057 - val_accuracy: 0.9132 - val_auc: 0.9508\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2958 - accuracy: 0.9076 - auc: 0.9498 - val_loss: 0.3010 - val_accuracy: 0.9010 - val_auc: 0.9516\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2877 - accuracy: 0.9074 - auc: 0.9530 - val_loss: 0.3080 - val_accuracy: 0.9027 - val_auc: 0.9502\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2717 - accuracy: 0.9088 - auc: 0.9592 - val_loss: 0.3273 - val_accuracy: 0.9134 - val_auc: 0.9496\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2765 - accuracy: 0.9086 - auc: 0.9565 - val_loss: 0.3290 - val_accuracy: 0.9193 - val_auc: 0.9514\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2739 - accuracy: 0.9121 - auc: 0.9572 - val_loss: 0.3383 - val_accuracy: 0.9046 - val_auc: 0.9525\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2773 - accuracy: 0.9065 - auc: 0.9556 - val_loss: 0.3149 - val_accuracy: 0.8979 - val_auc: 0.9543\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2839 - accuracy: 0.9032 - auc: 0.9547 - val_loss: 0.3379 - val_accuracy: 0.9090 - val_auc: 0.9499\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2709 - accuracy: 0.9046 - auc: 0.9570 - val_loss: 0.3408 - val_accuracy: 0.9039 - val_auc: 0.9534\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2576 - accuracy: 0.9053 - auc: 0.9608 - val_loss: 0.3558 - val_accuracy: 0.9146 - val_auc: 0.9507\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2579 - accuracy: 0.9072 - auc: 0.9611 - val_loss: 0.3774 - val_accuracy: 0.9036 - val_auc: 0.9478\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2604 - accuracy: 0.9028 - auc: 0.9602 - val_loss: 0.4082 - val_accuracy: 0.9087 - val_auc: 0.9466\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2617 - accuracy: 0.9017 - auc: 0.9592 - val_loss: 0.3992 - val_accuracy: 0.8987 - val_auc: 0.9481\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2773 - accuracy: 0.8954 - auc: 0.9555 - val_loss: 0.3895 - val_accuracy: 0.9027 - val_auc: 0.9474\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2711 - accuracy: 0.9026 - auc: 0.9585 - val_loss: 0.3840 - val_accuracy: 0.9038 - val_auc: 0.9452\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2618 - accuracy: 0.9036 - auc: 0.9607 - val_loss: 0.3688 - val_accuracy: 0.9075 - val_auc: 0.9493\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2537 - accuracy: 0.9108 - auc: 0.9621 - val_loss: 0.4099 - val_accuracy: 0.9079 - val_auc: 0.9501\n",
      "Epoch 25/100\n",
      "248832/250291 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9061 - auc: 0.9626Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2507 - accuracy: 0.9062 - auc: 0.9625 - val_loss: 0.4219 - val_accuracy: 0.9217 - val_auc: 0.9461\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5622 - accuracy: 0.8665 - auc: 0.8561 - val_loss: 0.3130 - val_accuracy: 0.9181 - val_auc: 0.9519\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3424 - accuracy: 0.9053 - auc: 0.9391 - val_loss: 0.2857 - val_accuracy: 0.9016 - val_auc: 0.9536\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3260 - accuracy: 0.9060 - auc: 0.9431 - val_loss: 0.2723 - val_accuracy: 0.9247 - val_auc: 0.9559\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3206 - accuracy: 0.9074 - auc: 0.9436 - val_loss: 0.2677 - val_accuracy: 0.9116 - val_auc: 0.9615\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3050 - accuracy: 0.9081 - auc: 0.9520 - val_loss: 0.2698 - val_accuracy: 0.9236 - val_auc: 0.9581\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3185 - accuracy: 0.9103 - auc: 0.9477 - val_loss: 0.2798 - val_accuracy: 0.9031 - val_auc: 0.9566\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3054 - accuracy: 0.9125 - auc: 0.9499 - val_loss: 0.2813 - val_accuracy: 0.9210 - val_auc: 0.9543\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2984 - accuracy: 0.9121 - auc: 0.9530 - val_loss: 0.2896 - val_accuracy: 0.9226 - val_auc: 0.9502\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2966 - accuracy: 0.9146 - auc: 0.9529 - val_loss: 0.2734 - val_accuracy: 0.9164 - val_auc: 0.9550\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2933 - accuracy: 0.9115 - auc: 0.9545 - val_loss: 0.2888 - val_accuracy: 0.9071 - val_auc: 0.9534\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2815 - accuracy: 0.9123 - auc: 0.9573 - val_loss: 0.2834 - val_accuracy: 0.9077 - val_auc: 0.9562\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2798 - accuracy: 0.9137 - auc: 0.9579 - val_loss: 0.3027 - val_accuracy: 0.9131 - val_auc: 0.9500\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2703 - accuracy: 0.9163 - auc: 0.9616 - val_loss: 0.3111 - val_accuracy: 0.9236 - val_auc: 0.9500\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2710 - accuracy: 0.9166 - auc: 0.9593 - val_loss: 0.2964 - val_accuracy: 0.9211 - val_auc: 0.9517\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2855 - accuracy: 0.9149 - auc: 0.9586 - val_loss: 0.3095 - val_accuracy: 0.9090 - val_auc: 0.9533\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2793 - accuracy: 0.9169 - auc: 0.9601 - val_loss: 0.2890 - val_accuracy: 0.9218 - val_auc: 0.9531\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2689 - accuracy: 0.9151 - auc: 0.9613 - val_loss: 0.3163 - val_accuracy: 0.9177 - val_auc: 0.9511\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2738 - accuracy: 0.9189 - auc: 0.9608 - val_loss: 0.3175 - val_accuracy: 0.9326 - val_auc: 0.9507\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2623 - accuracy: 0.9171 - auc: 0.9626 - val_loss: 0.3476 - val_accuracy: 0.9229 - val_auc: 0.9483\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2683 - accuracy: 0.9160 - auc: 0.9608 - val_loss: 0.3329 - val_accuracy: 0.9320 - val_auc: 0.9474\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2465 - accuracy: 0.9194 - auc: 0.9652 - val_loss: 0.3486 - val_accuracy: 0.9195 - val_auc: 0.9468\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2600 - accuracy: 0.9132 - auc: 0.9620 - val_loss: 0.3546 - val_accuracy: 0.9232 - val_auc: 0.9457\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2738 - accuracy: 0.9166 - auc: 0.9620 - val_loss: 0.3434 - val_accuracy: 0.9088 - val_auc: 0.9488\n",
      "Epoch 24/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2680 - accuracy: 0.9159 - auc: 0.9616Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2667 - accuracy: 0.9163 - auc: 0.9621 - val_loss: 0.3744 - val_accuracy: 0.9304 - val_auc: 0.9459\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.4826 - accuracy: 0.7567 - auc: 0.8845 - val_loss: 0.2980 - val_accuracy: 0.8354 - val_auc: 0.9512\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3262 - accuracy: 0.8358 - auc: 0.9394 - val_loss: 0.2701 - val_accuracy: 0.8648 - val_auc: 0.9581\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3131 - accuracy: 0.8598 - auc: 0.9464 - val_loss: 0.2647 - val_accuracy: 0.8996 - val_auc: 0.9584\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2918 - accuracy: 0.8760 - auc: 0.9507 - val_loss: 0.2759 - val_accuracy: 0.9066 - val_auc: 0.9568\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2974 - accuracy: 0.8839 - auc: 0.9507 - val_loss: 0.2819 - val_accuracy: 0.9043 - val_auc: 0.9531\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2886 - accuracy: 0.8850 - auc: 0.9523 - val_loss: 0.2972 - val_accuracy: 0.8891 - val_auc: 0.9487\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2672 - accuracy: 0.8911 - auc: 0.9589 - val_loss: 0.3203 - val_accuracy: 0.9265 - val_auc: 0.9522\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2844 - accuracy: 0.8848 - auc: 0.9561 - val_loss: 0.2928 - val_accuracy: 0.9065 - val_auc: 0.9538\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2768 - accuracy: 0.8811 - auc: 0.9554 - val_loss: 0.2825 - val_accuracy: 0.8962 - val_auc: 0.9554\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2606 - accuracy: 0.8881 - auc: 0.9599 - val_loss: 0.2889 - val_accuracy: 0.9082 - val_auc: 0.9547\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2652 - accuracy: 0.8883 - auc: 0.9592 - val_loss: 0.3080 - val_accuracy: 0.9114 - val_auc: 0.9529\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2680 - accuracy: 0.8938 - auc: 0.9588 - val_loss: 0.3133 - val_accuracy: 0.9111 - val_auc: 0.9528\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2674 - accuracy: 0.8953 - auc: 0.9603 - val_loss: 0.3072 - val_accuracy: 0.9081 - val_auc: 0.9537\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2662 - accuracy: 0.8949 - auc: 0.9599 - val_loss: 0.3023 - val_accuracy: 0.9010 - val_auc: 0.9517\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2511 - accuracy: 0.8894 - auc: 0.9630 - val_loss: 0.3234 - val_accuracy: 0.8990 - val_auc: 0.9504\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2403 - accuracy: 0.8814 - auc: 0.9653 - val_loss: 0.3379 - val_accuracy: 0.8951 - val_auc: 0.9492\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2388 - accuracy: 0.8659 - auc: 0.9670 - val_loss: 0.3541 - val_accuracy: 0.8971 - val_auc: 0.9481\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2484 - accuracy: 0.8873 - auc: 0.9645 - val_loss: 0.3671 - val_accuracy: 0.9079 - val_auc: 0.9442\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2483 - accuracy: 0.8913 - auc: 0.9644 - val_loss: 0.3842 - val_accuracy: 0.9105 - val_auc: 0.9422\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2476 - accuracy: 0.8672 - auc: 0.9643 - val_loss: 0.3924 - val_accuracy: 0.9084 - val_auc: 0.9464\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2274 - accuracy: 0.8782 - auc: 0.9685 - val_loss: 0.4101 - val_accuracy: 0.9032 - val_auc: 0.9452\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2349 - accuracy: 0.8631 - auc: 0.9666 - val_loss: 0.4224 - val_accuracy: 0.8966 - val_auc: 0.9425\n",
      "Epoch 23/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2241 - accuracy: 0.8676 - auc: 0.9692Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2240 - accuracy: 0.8675 - auc: 0.9693 - val_loss: 0.4433 - val_accuracy: 0.8933 - val_auc: 0.9381\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.4985 - accuracy: 0.8014 - auc: 0.8645 - val_loss: 0.3016 - val_accuracy: 0.8914 - val_auc: 0.9478\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3625 - accuracy: 0.8888 - auc: 0.9304 - val_loss: 0.2924 - val_accuracy: 0.9003 - val_auc: 0.9504\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3223 - accuracy: 0.8996 - auc: 0.9416 - val_loss: 0.2875 - val_accuracy: 0.9215 - val_auc: 0.9514\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3227 - accuracy: 0.8983 - auc: 0.9402 - val_loss: 0.2786 - val_accuracy: 0.9072 - val_auc: 0.9572\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3141 - accuracy: 0.9029 - auc: 0.9459 - val_loss: 0.2740 - val_accuracy: 0.9053 - val_auc: 0.9562\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2926 - accuracy: 0.9061 - auc: 0.9512 - val_loss: 0.2912 - val_accuracy: 0.9241 - val_auc: 0.9507\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2953 - accuracy: 0.9064 - auc: 0.9509 - val_loss: 0.2804 - val_accuracy: 0.9163 - val_auc: 0.9532\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2946 - accuracy: 0.9053 - auc: 0.9507 - val_loss: 0.2960 - val_accuracy: 0.9273 - val_auc: 0.9521\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2869 - accuracy: 0.9076 - auc: 0.9545 - val_loss: 0.2965 - val_accuracy: 0.8948 - val_auc: 0.9522\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2841 - accuracy: 0.9084 - auc: 0.9541 - val_loss: 0.3195 - val_accuracy: 0.9043 - val_auc: 0.9481\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2687 - accuracy: 0.9079 - auc: 0.9575 - val_loss: 0.3277 - val_accuracy: 0.9098 - val_auc: 0.9506\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2706 - accuracy: 0.9083 - auc: 0.9568 - val_loss: 0.3266 - val_accuracy: 0.9149 - val_auc: 0.9489\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2647 - accuracy: 0.9112 - auc: 0.9597 - val_loss: 0.3593 - val_accuracy: 0.8963 - val_auc: 0.9500\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2561 - accuracy: 0.9091 - auc: 0.9612 - val_loss: 0.3798 - val_accuracy: 0.9282 - val_auc: 0.9472\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2635 - accuracy: 0.9048 - auc: 0.9597 - val_loss: 0.3650 - val_accuracy: 0.9064 - val_auc: 0.9475\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2615 - accuracy: 0.9060 - auc: 0.9597 - val_loss: 0.3619 - val_accuracy: 0.9188 - val_auc: 0.9484\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2575 - accuracy: 0.9100 - auc: 0.9612 - val_loss: 0.4067 - val_accuracy: 0.9074 - val_auc: 0.9466\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2579 - accuracy: 0.9099 - auc: 0.9625 - val_loss: 0.4305 - val_accuracy: 0.9164 - val_auc: 0.9462\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2518 - accuracy: 0.9095 - auc: 0.9631 - val_loss: 0.4250 - val_accuracy: 0.9221 - val_auc: 0.9444\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2587 - accuracy: 0.9074 - auc: 0.9619 - val_loss: 0.3707 - val_accuracy: 0.9171 - val_auc: 0.9469\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2440 - accuracy: 0.9103 - auc: 0.9646 - val_loss: 0.4417 - val_accuracy: 0.9160 - val_auc: 0.9435\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2317 - accuracy: 0.9088 - auc: 0.9685 - val_loss: 0.5160 - val_accuracy: 0.9172 - val_auc: 0.9418\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2418 - accuracy: 0.9049 - auc: 0.9659 - val_loss: 0.5341 - val_accuracy: 0.9303 - val_auc: 0.9402\n",
      "Epoch 24/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.9100 - auc: 0.9646Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2484 - accuracy: 0.9094 - auc: 0.9647 - val_loss: 0.4726 - val_accuracy: 0.8976 - val_auc: 0.9447\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.4801 - accuracy: 0.8436 - auc: 0.8827 - val_loss: 0.3042 - val_accuracy: 0.8911 - val_auc: 0.9558\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3445 - accuracy: 0.8916 - auc: 0.9324 - val_loss: 0.2915 - val_accuracy: 0.9063 - val_auc: 0.9513\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3193 - accuracy: 0.9059 - auc: 0.9440 - val_loss: 0.2853 - val_accuracy: 0.9127 - val_auc: 0.9513\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3013 - accuracy: 0.9033 - auc: 0.9490 - val_loss: 0.2888 - val_accuracy: 0.9394 - val_auc: 0.9546\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3068 - accuracy: 0.9051 - auc: 0.9475 - val_loss: 0.2787 - val_accuracy: 0.9098 - val_auc: 0.9537\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2843 - accuracy: 0.9065 - auc: 0.9554 - val_loss: 0.2729 - val_accuracy: 0.9144 - val_auc: 0.9556\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2894 - accuracy: 0.9061 - auc: 0.9538 - val_loss: 0.2742 - val_accuracy: 0.9198 - val_auc: 0.9567\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2765 - accuracy: 0.9105 - auc: 0.9566 - val_loss: 0.2881 - val_accuracy: 0.9094 - val_auc: 0.9530\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2854 - accuracy: 0.9054 - auc: 0.9553 - val_loss: 0.2962 - val_accuracy: 0.9080 - val_auc: 0.9519\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2880 - accuracy: 0.9083 - auc: 0.9582 - val_loss: 0.2983 - val_accuracy: 0.9306 - val_auc: 0.9531\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2758 - accuracy: 0.9073 - auc: 0.9600 - val_loss: 0.3036 - val_accuracy: 0.9095 - val_auc: 0.9525\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2585 - accuracy: 0.9119 - auc: 0.9621 - val_loss: 0.3385 - val_accuracy: 0.9160 - val_auc: 0.9478\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.2676 - accuracy: 0.9060 - auc: 0.9596 - val_loss: 0.3252 - val_accuracy: 0.9191 - val_auc: 0.9456\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.2551 - accuracy: 0.9122 - auc: 0.9629 - val_loss: 0.3455 - val_accuracy: 0.9327 - val_auc: 0.9464\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2527 - accuracy: 0.9148 - auc: 0.9624 - val_loss: 0.3430 - val_accuracy: 0.9304 - val_auc: 0.9453\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2586 - accuracy: 0.9096 - auc: 0.9618 - val_loss: 0.3305 - val_accuracy: 0.9205 - val_auc: 0.9461\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2593 - accuracy: 0.9129 - auc: 0.9621 - val_loss: 0.3437 - val_accuracy: 0.9356 - val_auc: 0.9433\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2427 - accuracy: 0.9126 - auc: 0.9666 - val_loss: 0.3763 - val_accuracy: 0.9394 - val_auc: 0.9416\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2483 - accuracy: 0.9211 - auc: 0.9660 - val_loss: 0.3728 - val_accuracy: 0.9184 - val_auc: 0.9410\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2582 - accuracy: 0.9127 - auc: 0.9624 - val_loss: 0.3740 - val_accuracy: 0.9153 - val_auc: 0.9416\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2443 - accuracy: 0.9141 - auc: 0.9656 - val_loss: 0.4038 - val_accuracy: 0.9270 - val_auc: 0.9426\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2543 - accuracy: 0.9145 - auc: 0.9640 - val_loss: 0.3775 - val_accuracy: 0.9120 - val_auc: 0.9429\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2478 - accuracy: 0.9162 - auc: 0.9649 - val_loss: 0.3672 - val_accuracy: 0.9270 - val_auc: 0.9432\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2536 - accuracy: 0.9176 - auc: 0.9634 - val_loss: 0.3751 - val_accuracy: 0.9155 - val_auc: 0.9411\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2444 - accuracy: 0.9167 - auc: 0.9649 - val_loss: 0.4138 - val_accuracy: 0.9213 - val_auc: 0.9404\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2383 - accuracy: 0.9175 - auc: 0.9676 - val_loss: 0.4161 - val_accuracy: 0.9312 - val_auc: 0.9384\n",
      "Epoch 27/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9167 - auc: 0.9666Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2421 - accuracy: 0.9166 - auc: 0.9664 - val_loss: 0.4527 - val_accuracy: 0.9205 - val_auc: 0.9375\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.4683 - accuracy: 0.8330 - auc: 0.8913 - val_loss: 0.2949 - val_accuracy: 0.8882 - val_auc: 0.9491\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3477 - accuracy: 0.8843 - auc: 0.9342 - val_loss: 0.2907 - val_accuracy: 0.9075 - val_auc: 0.9478\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3221 - accuracy: 0.9020 - auc: 0.9424 - val_loss: 0.2886 - val_accuracy: 0.9066 - val_auc: 0.9521\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3110 - accuracy: 0.9004 - auc: 0.9477 - val_loss: 0.2964 - val_accuracy: 0.9250 - val_auc: 0.9507\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3098 - accuracy: 0.9030 - auc: 0.9497 - val_loss: 0.2754 - val_accuracy: 0.8904 - val_auc: 0.9554\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2990 - accuracy: 0.9036 - auc: 0.9518 - val_loss: 0.2853 - val_accuracy: 0.9235 - val_auc: 0.9526\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2838 - accuracy: 0.9094 - auc: 0.9557 - val_loss: 0.2871 - val_accuracy: 0.9202 - val_auc: 0.9536\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2794 - accuracy: 0.9075 - auc: 0.9567 - val_loss: 0.2946 - val_accuracy: 0.9243 - val_auc: 0.9524\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2670 - accuracy: 0.9080 - auc: 0.9595 - val_loss: 0.2947 - val_accuracy: 0.9253 - val_auc: 0.9535\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2610 - accuracy: 0.9089 - auc: 0.9619 - val_loss: 0.3284 - val_accuracy: 0.9308 - val_auc: 0.9519\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2604 - accuracy: 0.9091 - auc: 0.9618 - val_loss: 0.3382 - val_accuracy: 0.9151 - val_auc: 0.9482\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2668 - accuracy: 0.9047 - auc: 0.9601 - val_loss: 0.3321 - val_accuracy: 0.8973 - val_auc: 0.9479\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2686 - accuracy: 0.9058 - auc: 0.9606 - val_loss: 0.3552 - val_accuracy: 0.9136 - val_auc: 0.9468\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2696 - accuracy: 0.9073 - auc: 0.9621 - val_loss: 0.3269 - val_accuracy: 0.9257 - val_auc: 0.9464\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2619 - accuracy: 0.9159 - auc: 0.9618 - val_loss: 0.3900 - val_accuracy: 0.9265 - val_auc: 0.9435\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2443 - accuracy: 0.9104 - auc: 0.9660 - val_loss: 0.4180 - val_accuracy: 0.9139 - val_auc: 0.9416\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2848 - accuracy: 0.9106 - auc: 0.9602 - val_loss: 0.3685 - val_accuracy: 0.9131 - val_auc: 0.9434\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2473 - accuracy: 0.9081 - auc: 0.9651 - val_loss: 0.3976 - val_accuracy: 0.9270 - val_auc: 0.9436\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2442 - accuracy: 0.9139 - auc: 0.9664 - val_loss: 0.4328 - val_accuracy: 0.9078 - val_auc: 0.9409\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2540 - accuracy: 0.9110 - auc: 0.9640 - val_loss: 0.4391 - val_accuracy: 0.9216 - val_auc: 0.9388\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2519 - accuracy: 0.9112 - auc: 0.9649 - val_loss: 0.4340 - val_accuracy: 0.9247 - val_auc: 0.9424\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2482 - accuracy: 0.9074 - auc: 0.9644 - val_loss: 0.4480 - val_accuracy: 0.9126 - val_auc: 0.9438\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2302 - accuracy: 0.9087 - auc: 0.9685 - val_loss: 0.5228 - val_accuracy: 0.9218 - val_auc: 0.9417\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2606 - accuracy: 0.9080 - auc: 0.9628 - val_loss: 0.4634 - val_accuracy: 0.9062 - val_auc: 0.9377\n",
      "Epoch 25/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.9031 - auc: 0.9671Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2558 - accuracy: 0.9031 - auc: 0.9669 - val_loss: 0.4764 - val_accuracy: 0.9284 - val_auc: 0.9324\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 18us/sample - loss: 0.5160 - accuracy: 0.8096 - auc: 0.8773 - val_loss: 0.2919 - val_accuracy: 0.8904 - val_auc: 0.9570\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3441 - accuracy: 0.8835 - auc: 0.9340 - val_loss: 0.2784 - val_accuracy: 0.8969 - val_auc: 0.9583\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3250 - accuracy: 0.8930 - auc: 0.9429 - val_loss: 0.2796 - val_accuracy: 0.8947 - val_auc: 0.9564\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2971 - accuracy: 0.8985 - auc: 0.9510 - val_loss: 0.2780 - val_accuracy: 0.9110 - val_auc: 0.9585\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3188 - accuracy: 0.8901 - auc: 0.9452 - val_loss: 0.2787 - val_accuracy: 0.9259 - val_auc: 0.9558\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2779 - accuracy: 0.9081 - auc: 0.9573 - val_loss: 0.2761 - val_accuracy: 0.9165 - val_auc: 0.9560\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3021 - accuracy: 0.9048 - auc: 0.9528 - val_loss: 0.2956 - val_accuracy: 0.8837 - val_auc: 0.9573\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2933 - accuracy: 0.9005 - auc: 0.9536 - val_loss: 0.2644 - val_accuracy: 0.9059 - val_auc: 0.9586\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2852 - accuracy: 0.9019 - auc: 0.9557 - val_loss: 0.2879 - val_accuracy: 0.9291 - val_auc: 0.9562\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2815 - accuracy: 0.9059 - auc: 0.9573 - val_loss: 0.2662 - val_accuracy: 0.9014 - val_auc: 0.9582\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2784 - accuracy: 0.9050 - auc: 0.9591 - val_loss: 0.2930 - val_accuracy: 0.8990 - val_auc: 0.9549\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2713 - accuracy: 0.9083 - auc: 0.9590 - val_loss: 0.2781 - val_accuracy: 0.9154 - val_auc: 0.9571\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2688 - accuracy: 0.9025 - auc: 0.9603 - val_loss: 0.3217 - val_accuracy: 0.9229 - val_auc: 0.9506\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2672 - accuracy: 0.9081 - auc: 0.9613 - val_loss: 0.3164 - val_accuracy: 0.9057 - val_auc: 0.9475\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2642 - accuracy: 0.9092 - auc: 0.9603 - val_loss: 0.3135 - val_accuracy: 0.9228 - val_auc: 0.9512\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2576 - accuracy: 0.9095 - auc: 0.9641 - val_loss: 0.3046 - val_accuracy: 0.9175 - val_auc: 0.9519\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2665 - accuracy: 0.9087 - auc: 0.9612 - val_loss: 0.3061 - val_accuracy: 0.9074 - val_auc: 0.9513\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2558 - accuracy: 0.9143 - auc: 0.9639 - val_loss: 0.3292 - val_accuracy: 0.8994 - val_auc: 0.9523\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2554 - accuracy: 0.9125 - auc: 0.9641 - val_loss: 0.3345 - val_accuracy: 0.9144 - val_auc: 0.9486\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2402 - accuracy: 0.9119 - auc: 0.9674 - val_loss: 0.3798 - val_accuracy: 0.9327 - val_auc: 0.9438\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2670 - accuracy: 0.9113 - auc: 0.9642 - val_loss: 0.3809 - val_accuracy: 0.9160 - val_auc: 0.9438\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2439 - accuracy: 0.9130 - auc: 0.9679 - val_loss: 0.3966 - val_accuracy: 0.9199 - val_auc: 0.9425\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2394 - accuracy: 0.9104 - auc: 0.9674 - val_loss: 0.3494 - val_accuracy: 0.9166 - val_auc: 0.9510\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2302 - accuracy: 0.9148 - auc: 0.9696 - val_loss: 0.3829 - val_accuracy: 0.8971 - val_auc: 0.9465\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2279 - accuracy: 0.9116 - auc: 0.9695 - val_loss: 0.4694 - val_accuracy: 0.9227 - val_auc: 0.9389\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2508 - accuracy: 0.9111 - auc: 0.9658 - val_loss: 0.4442 - val_accuracy: 0.9158 - val_auc: 0.9415\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2346 - accuracy: 0.9105 - auc: 0.9681 - val_loss: 0.4302 - val_accuracy: 0.9192 - val_auc: 0.9406\n",
      "Epoch 28/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9102 - auc: 0.9672Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2373 - accuracy: 0.9102 - auc: 0.9670 - val_loss: 0.4287 - val_accuracy: 0.9190 - val_auc: 0.9443\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.4763 - accuracy: 0.7573 - auc: 0.8936 - val_loss: 0.2953 - val_accuracy: 0.8670 - val_auc: 0.9496\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3504 - accuracy: 0.8451 - auc: 0.9340 - val_loss: 0.2735 - val_accuracy: 0.8763 - val_auc: 0.9574\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3256 - accuracy: 0.8701 - auc: 0.9421 - val_loss: 0.2879 - val_accuracy: 0.9097 - val_auc: 0.9534\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2908 - accuracy: 0.8978 - auc: 0.9519 - val_loss: 0.2970 - val_accuracy: 0.8840 - val_auc: 0.9526\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3007 - accuracy: 0.8894 - auc: 0.9497 - val_loss: 0.2904 - val_accuracy: 0.9017 - val_auc: 0.9545\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2861 - accuracy: 0.8950 - auc: 0.9546 - val_loss: 0.2972 - val_accuracy: 0.9162 - val_auc: 0.9526\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2892 - accuracy: 0.9000 - auc: 0.9545 - val_loss: 0.2872 - val_accuracy: 0.9090 - val_auc: 0.9521\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2713 - accuracy: 0.9055 - auc: 0.9593 - val_loss: 0.3123 - val_accuracy: 0.9136 - val_auc: 0.9511\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2937 - accuracy: 0.8986 - auc: 0.9544 - val_loss: 0.3095 - val_accuracy: 0.9095 - val_auc: 0.9517\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2637 - accuracy: 0.9084 - auc: 0.9602 - val_loss: 0.3153 - val_accuracy: 0.9149 - val_auc: 0.9497\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2677 - accuracy: 0.9051 - auc: 0.9589 - val_loss: 0.3143 - val_accuracy: 0.9068 - val_auc: 0.9516\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2513 - accuracy: 0.9123 - auc: 0.9641 - val_loss: 0.3400 - val_accuracy: 0.9062 - val_auc: 0.9481\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2626 - accuracy: 0.9057 - auc: 0.9606 - val_loss: 0.3670 - val_accuracy: 0.9128 - val_auc: 0.9463\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2652 - accuracy: 0.9057 - auc: 0.9619 - val_loss: 0.3648 - val_accuracy: 0.9249 - val_auc: 0.9472\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2580 - accuracy: 0.9064 - auc: 0.9616 - val_loss: 0.3583 - val_accuracy: 0.9016 - val_auc: 0.9474\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2606 - accuracy: 0.9045 - auc: 0.9612 - val_loss: 0.3504 - val_accuracy: 0.8962 - val_auc: 0.9455\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2610 - accuracy: 0.9063 - auc: 0.9632 - val_loss: 0.4047 - val_accuracy: 0.9195 - val_auc: 0.9459\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2834 - accuracy: 0.9050 - auc: 0.9607 - val_loss: 0.3906 - val_accuracy: 0.9094 - val_auc: 0.9465\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2661 - accuracy: 0.9075 - auc: 0.9611 - val_loss: 0.4393 - val_accuracy: 0.9212 - val_auc: 0.9438\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2413 - accuracy: 0.9114 - auc: 0.9670 - val_loss: 0.4278 - val_accuracy: 0.9191 - val_auc: 0.9459\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2523 - accuracy: 0.9109 - auc: 0.9633 - val_loss: 0.4163 - val_accuracy: 0.9234 - val_auc: 0.9442\n",
      "Epoch 22/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9153 - auc: 0.9676Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2359 - accuracy: 0.9152 - auc: 0.9675 - val_loss: 0.4616 - val_accuracy: 0.9165 - val_auc: 0.9415\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5119 - accuracy: 0.7603 - auc: 0.8839 - val_loss: 0.3167 - val_accuracy: 0.9209 - val_auc: 0.9452\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3719 - accuracy: 0.8381 - auc: 0.9289 - val_loss: 0.2956 - val_accuracy: 0.8767 - val_auc: 0.9517\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3232 - accuracy: 0.8748 - auc: 0.9403 - val_loss: 0.2950 - val_accuracy: 0.9038 - val_auc: 0.9502\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3248 - accuracy: 0.8791 - auc: 0.9417 - val_loss: 0.2850 - val_accuracy: 0.8752 - val_auc: 0.9537\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2978 - accuracy: 0.8890 - auc: 0.9495 - val_loss: 0.2693 - val_accuracy: 0.9000 - val_auc: 0.9578\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2925 - accuracy: 0.8948 - auc: 0.9517 - val_loss: 0.3116 - val_accuracy: 0.8815 - val_auc: 0.9546\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2759 - accuracy: 0.9001 - auc: 0.9564 - val_loss: 0.3041 - val_accuracy: 0.9158 - val_auc: 0.9488\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2729 - accuracy: 0.8996 - auc: 0.9569 - val_loss: 0.2906 - val_accuracy: 0.8958 - val_auc: 0.9542\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2657 - accuracy: 0.9036 - auc: 0.9587 - val_loss: 0.3484 - val_accuracy: 0.9177 - val_auc: 0.9466\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2875 - accuracy: 0.8988 - auc: 0.9547 - val_loss: 0.3496 - val_accuracy: 0.9178 - val_auc: 0.9459\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3455 - accuracy: 0.8887 - auc: 0.9542 - val_loss: 0.3412 - val_accuracy: 0.9091 - val_auc: 0.9497\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2965 - accuracy: 0.9000 - auc: 0.9534 - val_loss: 0.3056 - val_accuracy: 0.9180 - val_auc: 0.9528\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2484 - accuracy: 0.9097 - auc: 0.9638 - val_loss: 0.3320 - val_accuracy: 0.9133 - val_auc: 0.9506\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2504 - accuracy: 0.9052 - auc: 0.9639 - val_loss: 0.3340 - val_accuracy: 0.9155 - val_auc: 0.9465\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2531 - accuracy: 0.9025 - auc: 0.9631 - val_loss: 0.3669 - val_accuracy: 0.9205 - val_auc: 0.9437\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2569 - accuracy: 0.9043 - auc: 0.9633 - val_loss: 0.3638 - val_accuracy: 0.8999 - val_auc: 0.9497\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2451 - accuracy: 0.9067 - auc: 0.9649 - val_loss: 0.3706 - val_accuracy: 0.9139 - val_auc: 0.9472\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2530 - accuracy: 0.9046 - auc: 0.9629 - val_loss: 0.3568 - val_accuracy: 0.9195 - val_auc: 0.9457\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2336 - accuracy: 0.9089 - auc: 0.9676 - val_loss: 0.3783 - val_accuracy: 0.9129 - val_auc: 0.9468\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2431 - accuracy: 0.9078 - auc: 0.9653 - val_loss: 0.3910 - val_accuracy: 0.9235 - val_auc: 0.9478\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2415 - accuracy: 0.9063 - auc: 0.9658 - val_loss: 0.3781 - val_accuracy: 0.9130 - val_auc: 0.9466\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2387 - accuracy: 0.9081 - auc: 0.9665 - val_loss: 0.3819 - val_accuracy: 0.9138 - val_auc: 0.9450\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2493 - accuracy: 0.9020 - auc: 0.9640 - val_loss: 0.4148 - val_accuracy: 0.9116 - val_auc: 0.9442\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2539 - accuracy: 0.9035 - auc: 0.9631 - val_loss: 0.4172 - val_accuracy: 0.9032 - val_auc: 0.9447\n",
      "Epoch 25/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2419 - accuracy: 0.9061 - auc: 0.9664Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2419 - accuracy: 0.9061 - auc: 0.9665 - val_loss: 0.4472 - val_accuracy: 0.9246 - val_auc: 0.9439\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.4860 - accuracy: 0.8661 - auc: 0.8815 - val_loss: 0.3114 - val_accuracy: 0.9073 - val_auc: 0.9448\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3260 - accuracy: 0.9041 - auc: 0.9417 - val_loss: 0.2974 - val_accuracy: 0.9480 - val_auc: 0.9543\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3308 - accuracy: 0.9061 - auc: 0.9389 - val_loss: 0.2833 - val_accuracy: 0.9000 - val_auc: 0.9565\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3021 - accuracy: 0.9108 - auc: 0.9500 - val_loss: 0.2810 - val_accuracy: 0.9002 - val_auc: 0.9575\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3171 - accuracy: 0.9051 - auc: 0.9481 - val_loss: 0.2954 - val_accuracy: 0.9365 - val_auc: 0.9529\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2941 - accuracy: 0.9076 - auc: 0.9544 - val_loss: 0.2836 - val_accuracy: 0.9031 - val_auc: 0.9572\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2914 - accuracy: 0.9120 - auc: 0.9550 - val_loss: 0.2781 - val_accuracy: 0.9183 - val_auc: 0.9550\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3055 - accuracy: 0.9085 - auc: 0.9516 - val_loss: 0.2848 - val_accuracy: 0.9112 - val_auc: 0.9561\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2945 - accuracy: 0.9124 - auc: 0.9550 - val_loss: 0.2711 - val_accuracy: 0.9139 - val_auc: 0.9577\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2846 - accuracy: 0.9104 - auc: 0.9578 - val_loss: 0.2870 - val_accuracy: 0.9265 - val_auc: 0.9563\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2783 - accuracy: 0.9113 - auc: 0.9581 - val_loss: 0.2959 - val_accuracy: 0.9304 - val_auc: 0.9505\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2909 - accuracy: 0.9192 - auc: 0.9566 - val_loss: 0.2944 - val_accuracy: 0.9199 - val_auc: 0.9531\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2751 - accuracy: 0.9114 - auc: 0.9585 - val_loss: 0.2994 - val_accuracy: 0.9006 - val_auc: 0.9521\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2574 - accuracy: 0.9179 - auc: 0.9638 - val_loss: 0.3323 - val_accuracy: 0.9357 - val_auc: 0.9483\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2638 - accuracy: 0.9166 - auc: 0.9623 - val_loss: 0.3117 - val_accuracy: 0.9224 - val_auc: 0.9494\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2553 - accuracy: 0.9178 - auc: 0.9638 - val_loss: 0.3355 - val_accuracy: 0.9361 - val_auc: 0.9468\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2439 - accuracy: 0.9192 - auc: 0.9671 - val_loss: 0.3405 - val_accuracy: 0.9370 - val_auc: 0.9482\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2500 - accuracy: 0.9183 - auc: 0.9652 - val_loss: 0.3656 - val_accuracy: 0.9223 - val_auc: 0.9445\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2726 - accuracy: 0.9141 - auc: 0.9603 - val_loss: 0.3048 - val_accuracy: 0.9259 - val_auc: 0.9524\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2495 - accuracy: 0.9190 - auc: 0.9653 - val_loss: 0.3622 - val_accuracy: 0.9401 - val_auc: 0.9444\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2544 - accuracy: 0.9199 - auc: 0.9644 - val_loss: 0.3746 - val_accuracy: 0.9117 - val_auc: 0.9421\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2540 - accuracy: 0.9178 - auc: 0.9654 - val_loss: 0.3421 - val_accuracy: 0.9243 - val_auc: 0.9474\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2471 - accuracy: 0.9157 - auc: 0.9664 - val_loss: 0.3777 - val_accuracy: 0.9356 - val_auc: 0.9464\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2415 - accuracy: 0.9191 - auc: 0.9663 - val_loss: 0.3884 - val_accuracy: 0.9148 - val_auc: 0.9454\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2435 - accuracy: 0.9204 - auc: 0.9675 - val_loss: 0.4427 - val_accuracy: 0.9260 - val_auc: 0.9416\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2562 - accuracy: 0.9233 - auc: 0.9668 - val_loss: 0.3522 - val_accuracy: 0.9347 - val_auc: 0.9479\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2498 - accuracy: 0.9207 - auc: 0.9662 - val_loss: 0.4234 - val_accuracy: 0.9350 - val_auc: 0.9443\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2341 - accuracy: 0.9225 - auc: 0.9694 - val_loss: 0.4460 - val_accuracy: 0.9275 - val_auc: 0.9418\n",
      "Epoch 29/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.9201 - auc: 0.9703Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2293 - accuracy: 0.9202 - auc: 0.9699 - val_loss: 0.4756 - val_accuracy: 0.9307 - val_auc: 0.9393\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 18us/sample - loss: 0.4564 - accuracy: 0.8384 - auc: 0.8928 - val_loss: 0.2774 - val_accuracy: 0.9134 - val_auc: 0.9554\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3345 - accuracy: 0.8999 - auc: 0.9398 - val_loss: 0.2981 - val_accuracy: 0.9407 - val_auc: 0.9517\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3262 - accuracy: 0.9069 - auc: 0.9440 - val_loss: 0.3152 - val_accuracy: 0.8827 - val_auc: 0.9497\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2937 - accuracy: 0.9075 - auc: 0.9530 - val_loss: 0.2862 - val_accuracy: 0.9327 - val_auc: 0.9508\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2903 - accuracy: 0.9078 - auc: 0.9547 - val_loss: 0.3187 - val_accuracy: 0.9251 - val_auc: 0.9450\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3244 - accuracy: 0.9040 - auc: 0.9478 - val_loss: 0.3046 - val_accuracy: 0.9518 - val_auc: 0.9514\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2743 - accuracy: 0.9132 - auc: 0.9598 - val_loss: 0.2863 - val_accuracy: 0.9130 - val_auc: 0.9535\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2703 - accuracy: 0.9103 - auc: 0.9614 - val_loss: 0.3356 - val_accuracy: 0.9200 - val_auc: 0.9499\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2850 - accuracy: 0.9150 - auc: 0.9594 - val_loss: 0.3056 - val_accuracy: 0.9027 - val_auc: 0.9512\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2777 - accuracy: 0.9082 - auc: 0.9591 - val_loss: 0.3041 - val_accuracy: 0.9227 - val_auc: 0.9510\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2780 - accuracy: 0.9124 - auc: 0.9583 - val_loss: 0.3118 - val_accuracy: 0.9074 - val_auc: 0.9499\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2588 - accuracy: 0.9122 - auc: 0.9632 - val_loss: 0.3243 - val_accuracy: 0.9249 - val_auc: 0.9501\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2568 - accuracy: 0.9180 - auc: 0.9640 - val_loss: 0.3289 - val_accuracy: 0.9079 - val_auc: 0.9508\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2552 - accuracy: 0.9145 - auc: 0.9646 - val_loss: 0.3572 - val_accuracy: 0.9181 - val_auc: 0.9445\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2576 - accuracy: 0.9150 - auc: 0.9636 - val_loss: 0.3414 - val_accuracy: 0.8880 - val_auc: 0.9470\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2524 - accuracy: 0.9150 - auc: 0.9653 - val_loss: 0.3681 - val_accuracy: 0.9404 - val_auc: 0.9473\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2443 - accuracy: 0.9182 - auc: 0.9666 - val_loss: 0.4267 - val_accuracy: 0.9244 - val_auc: 0.9404\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2504 - accuracy: 0.9160 - auc: 0.9652 - val_loss: 0.4013 - val_accuracy: 0.8982 - val_auc: 0.9404\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2453 - accuracy: 0.9170 - auc: 0.9663 - val_loss: 0.4154 - val_accuracy: 0.9149 - val_auc: 0.9418\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2589 - accuracy: 0.9137 - auc: 0.9631 - val_loss: 0.3919 - val_accuracy: 0.9175 - val_auc: 0.9448\n",
      "Epoch 21/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9177 - auc: 0.9688Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2373 - accuracy: 0.9176 - auc: 0.9689 - val_loss: 0.4236 - val_accuracy: 0.9271 - val_auc: 0.9433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6746 - accuracy: 0.4098 - auc: 0.7195 - val_loss: 0.4536 - val_accuracy: 0.6713 - val_auc: 0.9134\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5221 - accuracy: 0.5643 - auc: 0.8224 - val_loss: 0.3844 - val_accuracy: 0.7912 - val_auc: 0.9373\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4565 - accuracy: 0.8393 - auc: 0.8740 - val_loss: 0.3409 - val_accuracy: 0.8491 - val_auc: 0.9443\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4239 - accuracy: 0.8642 - auc: 0.8874 - val_loss: 0.3171 - val_accuracy: 0.8706 - val_auc: 0.9475\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3914 - accuracy: 0.8789 - auc: 0.9035 - val_loss: 0.3050 - val_accuracy: 0.8817 - val_auc: 0.9493\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3927 - accuracy: 0.8853 - auc: 0.9001 - val_loss: 0.2994 - val_accuracy: 0.8899 - val_auc: 0.9502\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3867 - accuracy: 0.8925 - auc: 0.9035 - val_loss: 0.2940 - val_accuracy: 0.8850 - val_auc: 0.9505\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3921 - accuracy: 0.8862 - auc: 0.8999 - val_loss: 0.2863 - val_accuracy: 0.8893 - val_auc: 0.9535\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3708 - accuracy: 0.8906 - auc: 0.9119 - val_loss: 0.2836 - val_accuracy: 0.8875 - val_auc: 0.9542\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3589 - accuracy: 0.8912 - auc: 0.9146 - val_loss: 0.2811 - val_accuracy: 0.8880 - val_auc: 0.9546\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3585 - accuracy: 0.8935 - auc: 0.9128 - val_loss: 0.2806 - val_accuracy: 0.8900 - val_auc: 0.9548\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3507 - accuracy: 0.8941 - auc: 0.9173 - val_loss: 0.2805 - val_accuracy: 0.8910 - val_auc: 0.9551\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3549 - accuracy: 0.8947 - auc: 0.9168 - val_loss: 0.2814 - val_accuracy: 0.8860 - val_auc: 0.9541\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3510 - accuracy: 0.8930 - auc: 0.9192 - val_loss: 0.2843 - val_accuracy: 0.8876 - val_auc: 0.9541\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3505 - accuracy: 0.7783 - auc: 0.9176 - val_loss: 0.2842 - val_accuracy: 0.8739 - val_auc: 0.9536\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3328 - accuracy: 0.7198 - auc: 0.9253 - val_loss: 0.2838 - val_accuracy: 0.8777 - val_auc: 0.9539\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3390 - accuracy: 0.7244 - auc: 0.9235 - val_loss: 0.2833 - val_accuracy: 0.8747 - val_auc: 0.9545\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3383 - accuracy: 0.7240 - auc: 0.9219 - val_loss: 0.2825 - val_accuracy: 0.8734 - val_auc: 0.9545\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3318 - accuracy: 0.7247 - auc: 0.9262 - val_loss: 0.2847 - val_accuracy: 0.8782 - val_auc: 0.9549\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3404 - accuracy: 0.7280 - auc: 0.9175 - val_loss: 0.2910 - val_accuracy: 0.8802 - val_auc: 0.9536\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3274 - accuracy: 0.7276 - auc: 0.9270 - val_loss: 0.2910 - val_accuracy: 0.8804 - val_auc: 0.9532\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3236 - accuracy: 0.7310 - auc: 0.9297 - val_loss: 0.2840 - val_accuracy: 0.8734 - val_auc: 0.9545\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3224 - accuracy: 0.7261 - auc: 0.9298 - val_loss: 0.2830 - val_accuracy: 0.8725 - val_auc: 0.9551\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3329 - accuracy: 0.7262 - auc: 0.9243 - val_loss: 0.2866 - val_accuracy: 0.8753 - val_auc: 0.9547\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3203 - accuracy: 0.7278 - auc: 0.9289 - val_loss: 0.2888 - val_accuracy: 0.8785 - val_auc: 0.9552\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3340 - accuracy: 0.7276 - auc: 0.9264 - val_loss: 0.2854 - val_accuracy: 0.8736 - val_auc: 0.9553\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3284 - accuracy: 0.7300 - auc: 0.9270 - val_loss: 0.2833 - val_accuracy: 0.8736 - val_auc: 0.9550\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3396 - accuracy: 0.7273 - auc: 0.9233 - val_loss: 0.2897 - val_accuracy: 0.8728 - val_auc: 0.9531\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3256 - accuracy: 0.7249 - auc: 0.9291 - val_loss: 0.2879 - val_accuracy: 0.8729 - val_auc: 0.9543\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3258 - accuracy: 0.7281 - auc: 0.9287 - val_loss: 0.2886 - val_accuracy: 0.8696 - val_auc: 0.9546\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3285 - accuracy: 0.7270 - auc: 0.9264 - val_loss: 0.2912 - val_accuracy: 0.8708 - val_auc: 0.9541\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3228 - accuracy: 0.7276 - auc: 0.9304 - val_loss: 0.2964 - val_accuracy: 0.8771 - val_auc: 0.9539\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3228 - accuracy: 0.7312 - auc: 0.9298 - val_loss: 0.2944 - val_accuracy: 0.8738 - val_auc: 0.9536\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3236 - accuracy: 0.7287 - auc: 0.9281 - val_loss: 0.2930 - val_accuracy: 0.8736 - val_auc: 0.9541\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3170 - accuracy: 0.7308 - auc: 0.9298 - val_loss: 0.2958 - val_accuracy: 0.8755 - val_auc: 0.9537\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3189 - accuracy: 0.7303 - auc: 0.9305 - val_loss: 0.2961 - val_accuracy: 0.8732 - val_auc: 0.9533\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3169 - accuracy: 0.7307 - auc: 0.9292 - val_loss: 0.2994 - val_accuracy: 0.8763 - val_auc: 0.9532\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3151 - accuracy: 0.7309 - auc: 0.9324 - val_loss: 0.2982 - val_accuracy: 0.8751 - val_auc: 0.9530\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3199 - accuracy: 0.7304 - auc: 0.9321 - val_loss: 0.2999 - val_accuracy: 0.8756 - val_auc: 0.9529\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3155 - accuracy: 0.7321 - auc: 0.9302 - val_loss: 0.3016 - val_accuracy: 0.8807 - val_auc: 0.9532\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3120 - accuracy: 0.7339 - auc: 0.9326 - val_loss: 0.3032 - val_accuracy: 0.8786 - val_auc: 0.9522\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3163 - accuracy: 0.7308 - auc: 0.9309 - val_loss: 0.2982 - val_accuracy: 0.8819 - val_auc: 0.9533\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3190 - accuracy: 0.7352 - auc: 0.9292 - val_loss: 0.3004 - val_accuracy: 0.8738 - val_auc: 0.9531\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3124 - accuracy: 0.7308 - auc: 0.9327 - val_loss: 0.3002 - val_accuracy: 0.8749 - val_auc: 0.9536\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3208 - accuracy: 0.7280 - auc: 0.9302 - val_loss: 0.3009 - val_accuracy: 0.8740 - val_auc: 0.9539\n",
      "Epoch 46/100\n",
      "246784/250290 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.7291 - auc: 0.9282Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3215 - accuracy: 0.7291 - auc: 0.9285 - val_loss: 0.3054 - val_accuracy: 0.8742 - val_auc: 0.9530\n",
      "Epoch 00046: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6853 - accuracy: 0.5647 - auc: 0.7435 - val_loss: 0.4993 - val_accuracy: 0.7333 - val_auc: 0.9162\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4875 - accuracy: 0.8186 - auc: 0.8876 - val_loss: 0.4139 - val_accuracy: 0.8548 - val_auc: 0.9544\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4320 - accuracy: 0.8779 - auc: 0.9151 - val_loss: 0.3819 - val_accuracy: 0.8938 - val_auc: 0.9578\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4000 - accuracy: 0.8952 - auc: 0.9291 - val_loss: 0.3600 - val_accuracy: 0.9042 - val_auc: 0.9588\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3856 - accuracy: 0.9093 - auc: 0.9248 - val_loss: 0.3444 - val_accuracy: 0.9125 - val_auc: 0.9593\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3704 - accuracy: 0.9127 - auc: 0.9384 - val_loss: 0.3347 - val_accuracy: 0.9129 - val_auc: 0.9587\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3585 - accuracy: 0.9153 - auc: 0.9382 - val_loss: 0.3272 - val_accuracy: 0.9192 - val_auc: 0.9598\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3602 - accuracy: 0.9212 - auc: 0.9346 - val_loss: 0.3212 - val_accuracy: 0.9122 - val_auc: 0.9608\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3613 - accuracy: 0.9163 - auc: 0.9309 - val_loss: 0.3177 - val_accuracy: 0.9199 - val_auc: 0.9567\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3332 - accuracy: 0.9186 - auc: 0.9457 - val_loss: 0.3109 - val_accuracy: 0.9183 - val_auc: 0.9600\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3612 - accuracy: 0.9214 - auc: 0.9285 - val_loss: 0.3089 - val_accuracy: 0.9248 - val_auc: 0.9572\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3486 - accuracy: 0.9208 - auc: 0.9361 - val_loss: 0.3062 - val_accuracy: 0.9218 - val_auc: 0.9572\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3406 - accuracy: 0.9236 - auc: 0.9330 - val_loss: 0.3023 - val_accuracy: 0.9259 - val_auc: 0.9565\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3344 - accuracy: 0.9255 - auc: 0.9386 - val_loss: 0.2989 - val_accuracy: 0.9213 - val_auc: 0.9591\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3413 - accuracy: 0.9228 - auc: 0.9343 - val_loss: 0.2975 - val_accuracy: 0.9258 - val_auc: 0.9598\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3453 - accuracy: 0.9257 - auc: 0.9248 - val_loss: 0.2973 - val_accuracy: 0.9266 - val_auc: 0.9583\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3319 - accuracy: 0.9268 - auc: 0.9371 - val_loss: 0.2983 - val_accuracy: 0.9196 - val_auc: 0.9579\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3409 - accuracy: 0.9232 - auc: 0.9328 - val_loss: 0.2958 - val_accuracy: 0.9232 - val_auc: 0.9580\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3382 - accuracy: 0.9265 - auc: 0.9324 - val_loss: 0.2965 - val_accuracy: 0.9270 - val_auc: 0.9580\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3323 - accuracy: 0.9258 - auc: 0.9401 - val_loss: 0.3009 - val_accuracy: 0.9267 - val_auc: 0.9559\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3212 - accuracy: 0.9268 - auc: 0.9444 - val_loss: 0.2922 - val_accuracy: 0.9258 - val_auc: 0.9585\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3274 - accuracy: 0.9246 - auc: 0.9408 - val_loss: 0.2920 - val_accuracy: 0.9259 - val_auc: 0.9601\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3317 - accuracy: 0.9261 - auc: 0.9368 - val_loss: 0.2912 - val_accuracy: 0.9278 - val_auc: 0.9576\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3260 - accuracy: 0.9276 - auc: 0.9442 - val_loss: 0.2958 - val_accuracy: 0.9256 - val_auc: 0.9579\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3504 - accuracy: 0.9259 - auc: 0.9302 - val_loss: 0.2944 - val_accuracy: 0.9261 - val_auc: 0.9569\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3275 - accuracy: 0.9292 - auc: 0.9371 - val_loss: 0.2958 - val_accuracy: 0.9230 - val_auc: 0.9577\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3289 - accuracy: 0.9251 - auc: 0.9412 - val_loss: 0.2934 - val_accuracy: 0.9248 - val_auc: 0.9581\n",
      "Epoch 28/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.9268 - auc: 0.9389Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3330 - accuracy: 0.9268 - auc: 0.9383 - val_loss: 0.2949 - val_accuracy: 0.9231 - val_auc: 0.9576\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6403 - accuracy: 0.8095 - auc: 0.7163 - val_loss: 0.4313 - val_accuracy: 0.8746 - val_auc: 0.9033\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4894 - accuracy: 0.8585 - auc: 0.8520 - val_loss: 0.3702 - val_accuracy: 0.8959 - val_auc: 0.9397\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4333 - accuracy: 0.8793 - auc: 0.8832 - val_loss: 0.3372 - val_accuracy: 0.9019 - val_auc: 0.9477\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4025 - accuracy: 0.8949 - auc: 0.9113 - val_loss: 0.3158 - val_accuracy: 0.9083 - val_auc: 0.9545\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3809 - accuracy: 0.8991 - auc: 0.9144 - val_loss: 0.3040 - val_accuracy: 0.9141 - val_auc: 0.9554\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3701 - accuracy: 0.9070 - auc: 0.9185 - val_loss: 0.2955 - val_accuracy: 0.9098 - val_auc: 0.9568\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3575 - accuracy: 0.9072 - auc: 0.9257 - val_loss: 0.2870 - val_accuracy: 0.9098 - val_auc: 0.9583\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3542 - accuracy: 0.9114 - auc: 0.9233 - val_loss: 0.2835 - val_accuracy: 0.9144 - val_auc: 0.9575\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3569 - accuracy: 0.9108 - auc: 0.9194 - val_loss: 0.2814 - val_accuracy: 0.9166 - val_auc: 0.9573\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3486 - accuracy: 0.9134 - auc: 0.9265 - val_loss: 0.2796 - val_accuracy: 0.9197 - val_auc: 0.9571\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3411 - accuracy: 0.9179 - auc: 0.9315 - val_loss: 0.2758 - val_accuracy: 0.9163 - val_auc: 0.9579\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3424 - accuracy: 0.9154 - auc: 0.9298 - val_loss: 0.2713 - val_accuracy: 0.9166 - val_auc: 0.9596\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3456 - accuracy: 0.9174 - auc: 0.9251 - val_loss: 0.2700 - val_accuracy: 0.9176 - val_auc: 0.9598\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3373 - accuracy: 0.9162 - auc: 0.9304 - val_loss: 0.2726 - val_accuracy: 0.9200 - val_auc: 0.9587\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3407 - accuracy: 0.9207 - auc: 0.9247 - val_loss: 0.2718 - val_accuracy: 0.9216 - val_auc: 0.9590\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3343 - accuracy: 0.9173 - auc: 0.9339 - val_loss: 0.2720 - val_accuracy: 0.9185 - val_auc: 0.9582\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3339 - accuracy: 0.9196 - auc: 0.9305 - val_loss: 0.2699 - val_accuracy: 0.9189 - val_auc: 0.9588\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3479 - accuracy: 0.9186 - auc: 0.9252 - val_loss: 0.2691 - val_accuracy: 0.9171 - val_auc: 0.9579\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3312 - accuracy: 0.9193 - auc: 0.9330 - val_loss: 0.2661 - val_accuracy: 0.9172 - val_auc: 0.9587\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3343 - accuracy: 0.9190 - auc: 0.9306 - val_loss: 0.2685 - val_accuracy: 0.9181 - val_auc: 0.9578\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3336 - accuracy: 0.9186 - auc: 0.9311 - val_loss: 0.2697 - val_accuracy: 0.9177 - val_auc: 0.9571\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3348 - accuracy: 0.9192 - auc: 0.9303 - val_loss: 0.2719 - val_accuracy: 0.9181 - val_auc: 0.9554\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3341 - accuracy: 0.9164 - auc: 0.9312 - val_loss: 0.2734 - val_accuracy: 0.9167 - val_auc: 0.9552\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3223 - accuracy: 0.9203 - auc: 0.9360 - val_loss: 0.2737 - val_accuracy: 0.9191 - val_auc: 0.9550\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3193 - accuracy: 0.9211 - auc: 0.9383 - val_loss: 0.2693 - val_accuracy: 0.9161 - val_auc: 0.9562\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3300 - accuracy: 0.9207 - auc: 0.9316 - val_loss: 0.2726 - val_accuracy: 0.9219 - val_auc: 0.9557\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3280 - accuracy: 0.9215 - auc: 0.9344 - val_loss: 0.2729 - val_accuracy: 0.9205 - val_auc: 0.9550\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3267 - accuracy: 0.9207 - auc: 0.9338 - val_loss: 0.2737 - val_accuracy: 0.9196 - val_auc: 0.9548\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3205 - accuracy: 0.9223 - auc: 0.9380 - val_loss: 0.2753 - val_accuracy: 0.9204 - val_auc: 0.9540\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3418 - accuracy: 0.9228 - auc: 0.9237 - val_loss: 0.2725 - val_accuracy: 0.9224 - val_auc: 0.9552\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3230 - accuracy: 0.9212 - auc: 0.9354 - val_loss: 0.2723 - val_accuracy: 0.9227 - val_auc: 0.9553\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3287 - accuracy: 0.9221 - auc: 0.9306 - val_loss: 0.2737 - val_accuracy: 0.9253 - val_auc: 0.9550\n",
      "Epoch 33/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.9253 - auc: 0.9328Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3237 - accuracy: 0.9253 - auc: 0.9321 - val_loss: 0.2764 - val_accuracy: 0.9240 - val_auc: 0.9543\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 0.6127 - accuracy: 0.6927 - auc: 0.7655 - val_loss: 0.4449 - val_accuracy: 0.8195 - val_auc: 0.9264\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4638 - accuracy: 0.8475 - auc: 0.8798 - val_loss: 0.3761 - val_accuracy: 0.8927 - val_auc: 0.9366\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4159 - accuracy: 0.8939 - auc: 0.8974 - val_loss: 0.3462 - val_accuracy: 0.8990 - val_auc: 0.9423\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3903 - accuracy: 0.9004 - auc: 0.9055 - val_loss: 0.3252 - val_accuracy: 0.9068 - val_auc: 0.9461\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3843 - accuracy: 0.9045 - auc: 0.9110 - val_loss: 0.3152 - val_accuracy: 0.9094 - val_auc: 0.9477\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3743 - accuracy: 0.9095 - auc: 0.9183 - val_loss: 0.3085 - val_accuracy: 0.9109 - val_auc: 0.9496\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3572 - accuracy: 0.9126 - auc: 0.9225 - val_loss: 0.3021 - val_accuracy: 0.9106 - val_auc: 0.9500\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3596 - accuracy: 0.9121 - auc: 0.9187 - val_loss: 0.2981 - val_accuracy: 0.9175 - val_auc: 0.9501\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3554 - accuracy: 0.9212 - auc: 0.9160 - val_loss: 0.2937 - val_accuracy: 0.9156 - val_auc: 0.9505\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3375 - accuracy: 0.9174 - auc: 0.9276 - val_loss: 0.2931 - val_accuracy: 0.9164 - val_auc: 0.9508\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3412 - accuracy: 0.9177 - auc: 0.9293 - val_loss: 0.2923 - val_accuracy: 0.9168 - val_auc: 0.9502\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3466 - accuracy: 0.9182 - auc: 0.9240 - val_loss: 0.2902 - val_accuracy: 0.9212 - val_auc: 0.9508\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3502 - accuracy: 0.9219 - auc: 0.9229 - val_loss: 0.2926 - val_accuracy: 0.9204 - val_auc: 0.9499\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3446 - accuracy: 0.9208 - auc: 0.9243 - val_loss: 0.2894 - val_accuracy: 0.9199 - val_auc: 0.9513\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3410 - accuracy: 0.9192 - auc: 0.9296 - val_loss: 0.2900 - val_accuracy: 0.9207 - val_auc: 0.9508\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3329 - accuracy: 0.9220 - auc: 0.9306 - val_loss: 0.2893 - val_accuracy: 0.9183 - val_auc: 0.9508\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3430 - accuracy: 0.9198 - auc: 0.9254 - val_loss: 0.2883 - val_accuracy: 0.9187 - val_auc: 0.9504\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3425 - accuracy: 0.9202 - auc: 0.9267 - val_loss: 0.2880 - val_accuracy: 0.9192 - val_auc: 0.9506\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3316 - accuracy: 0.9209 - auc: 0.9311 - val_loss: 0.2878 - val_accuracy: 0.9224 - val_auc: 0.9503\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3337 - accuracy: 0.9256 - auc: 0.9304 - val_loss: 0.2888 - val_accuracy: 0.9215 - val_auc: 0.9496\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3251 - accuracy: 0.9220 - auc: 0.9347 - val_loss: 0.2891 - val_accuracy: 0.9199 - val_auc: 0.9497\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3423 - accuracy: 0.9213 - auc: 0.9262 - val_loss: 0.2884 - val_accuracy: 0.9222 - val_auc: 0.9502\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3210 - accuracy: 0.9256 - auc: 0.9354 - val_loss: 0.2893 - val_accuracy: 0.9218 - val_auc: 0.9497\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3199 - accuracy: 0.9229 - auc: 0.9378 - val_loss: 0.2908 - val_accuracy: 0.9253 - val_auc: 0.9496\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3355 - accuracy: 0.9273 - auc: 0.9269 - val_loss: 0.2913 - val_accuracy: 0.9211 - val_auc: 0.9501\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3405 - accuracy: 0.9237 - auc: 0.9261 - val_loss: 0.2950 - val_accuracy: 0.9225 - val_auc: 0.9487\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3360 - accuracy: 0.9249 - auc: 0.9300 - val_loss: 0.2958 - val_accuracy: 0.9219 - val_auc: 0.9487\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3315 - accuracy: 0.9250 - auc: 0.9294 - val_loss: 0.3009 - val_accuracy: 0.9278 - val_auc: 0.9480\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3372 - accuracy: 0.9262 - auc: 0.9305 - val_loss: 0.2998 - val_accuracy: 0.9207 - val_auc: 0.9473\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3318 - accuracy: 0.9246 - auc: 0.9308 - val_loss: 0.3000 - val_accuracy: 0.9249 - val_auc: 0.9477\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3319 - accuracy: 0.9261 - auc: 0.9297 - val_loss: 0.2999 - val_accuracy: 0.9193 - val_auc: 0.9476\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3291 - accuracy: 0.9246 - auc: 0.9322 - val_loss: 0.3018 - val_accuracy: 0.9209 - val_auc: 0.9473\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3274 - accuracy: 0.9246 - auc: 0.9324 - val_loss: 0.3011 - val_accuracy: 0.9251 - val_auc: 0.9478\n",
      "Epoch 34/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.3343 - accuracy: 0.9268 - auc: 0.9277Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3336 - accuracy: 0.9268 - auc: 0.9280 - val_loss: 0.3010 - val_accuracy: 0.9225 - val_auc: 0.9482\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.8096 - accuracy: 0.7790 - auc: 0.6913 - val_loss: 0.4640 - val_accuracy: 0.8555 - val_auc: 0.8888\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5555 - accuracy: 0.8407 - auc: 0.8195 - val_loss: 0.4117 - val_accuracy: 0.8901 - val_auc: 0.9221\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4880 - accuracy: 0.8795 - auc: 0.8614 - val_loss: 0.3721 - val_accuracy: 0.9066 - val_auc: 0.9309\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4452 - accuracy: 0.8973 - auc: 0.8833 - val_loss: 0.3394 - val_accuracy: 0.9099 - val_auc: 0.9420\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4186 - accuracy: 0.9025 - auc: 0.8944 - val_loss: 0.3247 - val_accuracy: 0.9128 - val_auc: 0.9474\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3987 - accuracy: 0.9094 - auc: 0.9002 - val_loss: 0.3187 - val_accuracy: 0.9211 - val_auc: 0.9502\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4146 - accuracy: 0.9137 - auc: 0.9027 - val_loss: 0.3117 - val_accuracy: 0.9229 - val_auc: 0.9507\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3757 - accuracy: 0.9205 - auc: 0.9129 - val_loss: 0.3055 - val_accuracy: 0.9191 - val_auc: 0.9516\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3783 - accuracy: 0.9174 - auc: 0.9098 - val_loss: 0.3010 - val_accuracy: 0.9156 - val_auc: 0.9520\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3555 - accuracy: 0.9160 - auc: 0.9191 - val_loss: 0.2971 - val_accuracy: 0.9216 - val_auc: 0.9524\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3773 - accuracy: 0.9184 - auc: 0.9117 - val_loss: 0.2952 - val_accuracy: 0.9228 - val_auc: 0.9526\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3662 - accuracy: 0.9203 - auc: 0.9175 - val_loss: 0.2895 - val_accuracy: 0.9202 - val_auc: 0.9540\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3625 - accuracy: 0.9207 - auc: 0.9165 - val_loss: 0.2871 - val_accuracy: 0.9203 - val_auc: 0.9546\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3569 - accuracy: 0.9189 - auc: 0.9183 - val_loss: 0.2889 - val_accuracy: 0.9199 - val_auc: 0.9538\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3608 - accuracy: 0.9211 - auc: 0.9179 - val_loss: 0.2869 - val_accuracy: 0.9216 - val_auc: 0.9545\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3591 - accuracy: 0.9222 - auc: 0.9177 - val_loss: 0.2876 - val_accuracy: 0.9184 - val_auc: 0.9533\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3543 - accuracy: 0.9224 - auc: 0.9186 - val_loss: 0.2856 - val_accuracy: 0.9198 - val_auc: 0.9531\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3503 - accuracy: 0.9224 - auc: 0.9198 - val_loss: 0.2870 - val_accuracy: 0.9223 - val_auc: 0.9524\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3455 - accuracy: 0.9220 - auc: 0.9247 - val_loss: 0.2843 - val_accuracy: 0.9187 - val_auc: 0.9530\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3379 - accuracy: 0.9213 - auc: 0.9277 - val_loss: 0.2819 - val_accuracy: 0.9185 - val_auc: 0.9524\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3371 - accuracy: 0.9238 - auc: 0.9271 - val_loss: 0.2866 - val_accuracy: 0.9175 - val_auc: 0.9519\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3431 - accuracy: 0.9205 - auc: 0.9205 - val_loss: 0.2860 - val_accuracy: 0.9233 - val_auc: 0.9524\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3337 - accuracy: 0.9225 - auc: 0.9283 - val_loss: 0.2879 - val_accuracy: 0.9219 - val_auc: 0.9519\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3350 - accuracy: 0.9210 - auc: 0.9278 - val_loss: 0.2939 - val_accuracy: 0.9203 - val_auc: 0.9508\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3424 - accuracy: 0.9249 - auc: 0.9244 - val_loss: 0.2944 - val_accuracy: 0.9196 - val_auc: 0.9508\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3261 - accuracy: 0.9208 - auc: 0.9320 - val_loss: 0.2927 - val_accuracy: 0.9172 - val_auc: 0.9514\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3402 - accuracy: 0.9242 - auc: 0.9248 - val_loss: 0.2971 - val_accuracy: 0.9212 - val_auc: 0.9508\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3152 - accuracy: 0.9237 - auc: 0.9370 - val_loss: 0.2974 - val_accuracy: 0.9197 - val_auc: 0.9505\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3305 - accuracy: 0.9224 - auc: 0.9289 - val_loss: 0.3033 - val_accuracy: 0.9193 - val_auc: 0.9493\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3173 - accuracy: 0.9257 - auc: 0.9340 - val_loss: 0.3035 - val_accuracy: 0.9161 - val_auc: 0.9495\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3265 - accuracy: 0.9213 - auc: 0.9306 - val_loss: 0.3099 - val_accuracy: 0.9173 - val_auc: 0.9484\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3266 - accuracy: 0.9218 - auc: 0.9295 - val_loss: 0.3132 - val_accuracy: 0.9226 - val_auc: 0.9487\n",
      "Epoch 33/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.9238 - auc: 0.9285Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3287 - accuracy: 0.9238 - auc: 0.9285 - val_loss: 0.3164 - val_accuracy: 0.9194 - val_auc: 0.9484\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6874 - accuracy: 0.8022 - auc: 0.7269 - val_loss: 0.3919 - val_accuracy: 0.8860 - val_auc: 0.9201\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4833 - accuracy: 0.8494 - auc: 0.8585 - val_loss: 0.3425 - val_accuracy: 0.8869 - val_auc: 0.9412\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4006 - accuracy: 0.8698 - auc: 0.9097 - val_loss: 0.3085 - val_accuracy: 0.8933 - val_auc: 0.9504\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3758 - accuracy: 0.8814 - auc: 0.9213 - val_loss: 0.2923 - val_accuracy: 0.9023 - val_auc: 0.9546\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3536 - accuracy: 0.8945 - auc: 0.9310 - val_loss: 0.2823 - val_accuracy: 0.9089 - val_auc: 0.9571\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3364 - accuracy: 0.9001 - auc: 0.9403 - val_loss: 0.2762 - val_accuracy: 0.9110 - val_auc: 0.9577\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3162 - accuracy: 0.9057 - auc: 0.9443 - val_loss: 0.2703 - val_accuracy: 0.9105 - val_auc: 0.9588\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3125 - accuracy: 0.9073 - auc: 0.9471 - val_loss: 0.2685 - val_accuracy: 0.9121 - val_auc: 0.9595\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3115 - accuracy: 0.9041 - auc: 0.9485 - val_loss: 0.2687 - val_accuracy: 0.9121 - val_auc: 0.9584\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2967 - accuracy: 0.9082 - auc: 0.9517 - val_loss: 0.2646 - val_accuracy: 0.9145 - val_auc: 0.9590\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2993 - accuracy: 0.9090 - auc: 0.9518 - val_loss: 0.2645 - val_accuracy: 0.9143 - val_auc: 0.9586\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2873 - accuracy: 0.9116 - auc: 0.9546 - val_loss: 0.2632 - val_accuracy: 0.9118 - val_auc: 0.9588\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2866 - accuracy: 0.9129 - auc: 0.9538 - val_loss: 0.2658 - val_accuracy: 0.9139 - val_auc: 0.9583\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2834 - accuracy: 0.9138 - auc: 0.9558 - val_loss: 0.2643 - val_accuracy: 0.9215 - val_auc: 0.9584\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2857 - accuracy: 0.9161 - auc: 0.9552 - val_loss: 0.2663 - val_accuracy: 0.9152 - val_auc: 0.9577\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2873 - accuracy: 0.9119 - auc: 0.9542 - val_loss: 0.2637 - val_accuracy: 0.9159 - val_auc: 0.9581\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2806 - accuracy: 0.9149 - auc: 0.9567 - val_loss: 0.2659 - val_accuracy: 0.9117 - val_auc: 0.9577\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2796 - accuracy: 0.9151 - auc: 0.9562 - val_loss: 0.2677 - val_accuracy: 0.9160 - val_auc: 0.9569\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2800 - accuracy: 0.9153 - auc: 0.9562 - val_loss: 0.2715 - val_accuracy: 0.9161 - val_auc: 0.9560\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2800 - accuracy: 0.9156 - auc: 0.9569 - val_loss: 0.2716 - val_accuracy: 0.9162 - val_auc: 0.9560\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2743 - accuracy: 0.9153 - auc: 0.9588 - val_loss: 0.2732 - val_accuracy: 0.9176 - val_auc: 0.9552\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2720 - accuracy: 0.9170 - auc: 0.9585 - val_loss: 0.2709 - val_accuracy: 0.9150 - val_auc: 0.9558\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2714 - accuracy: 0.9173 - auc: 0.9592 - val_loss: 0.2734 - val_accuracy: 0.9150 - val_auc: 0.9548\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2556 - accuracy: 0.9180 - auc: 0.9636 - val_loss: 0.2773 - val_accuracy: 0.9200 - val_auc: 0.9545\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2624 - accuracy: 0.9163 - auc: 0.9619 - val_loss: 0.2812 - val_accuracy: 0.9199 - val_auc: 0.9539\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2647 - accuracy: 0.9171 - auc: 0.9611 - val_loss: 0.2824 - val_accuracy: 0.9154 - val_auc: 0.9540\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2651 - accuracy: 0.9160 - auc: 0.9607 - val_loss: 0.2879 - val_accuracy: 0.9193 - val_auc: 0.9519\n",
      "Epoch 28/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2604 - accuracy: 0.9202 - auc: 0.9623Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2597 - accuracy: 0.9203 - auc: 0.9623 - val_loss: 0.2871 - val_accuracy: 0.9177 - val_auc: 0.9522\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.8870 - accuracy: 0.3550 - auc: 0.6436 - val_loss: 0.5439 - val_accuracy: 0.5702 - val_auc: 0.8678\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5332 - accuracy: 0.6216 - auc: 0.8602 - val_loss: 0.3912 - val_accuracy: 0.8051 - val_auc: 0.9217\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4355 - accuracy: 0.7518 - auc: 0.9024 - val_loss: 0.3298 - val_accuracy: 0.8721 - val_auc: 0.9361\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3775 - accuracy: 0.7966 - auc: 0.9183 - val_loss: 0.3079 - val_accuracy: 0.8825 - val_auc: 0.9433\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3628 - accuracy: 0.8157 - auc: 0.9243 - val_loss: 0.2955 - val_accuracy: 0.8861 - val_auc: 0.9475\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3341 - accuracy: 0.8259 - auc: 0.9347 - val_loss: 0.2914 - val_accuracy: 0.8897 - val_auc: 0.9494\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3320 - accuracy: 0.8308 - auc: 0.9352 - val_loss: 0.2924 - val_accuracy: 0.8884 - val_auc: 0.9499\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3195 - accuracy: 0.8351 - auc: 0.9404 - val_loss: 0.2930 - val_accuracy: 0.8874 - val_auc: 0.9498\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3081 - accuracy: 0.8368 - auc: 0.9424 - val_loss: 0.2939 - val_accuracy: 0.8902 - val_auc: 0.9504\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3029 - accuracy: 0.8447 - auc: 0.9450 - val_loss: 0.2941 - val_accuracy: 0.8922 - val_auc: 0.9513\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3040 - accuracy: 0.8414 - auc: 0.9444 - val_loss: 0.2957 - val_accuracy: 0.8886 - val_auc: 0.9506\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2918 - accuracy: 0.8466 - auc: 0.9488 - val_loss: 0.2969 - val_accuracy: 0.8926 - val_auc: 0.9512\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2916 - accuracy: 0.8481 - auc: 0.9472 - val_loss: 0.3030 - val_accuracy: 0.8943 - val_auc: 0.9513\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.2821 - accuracy: 0.8517 - auc: 0.9512 - val_loss: 0.3052 - val_accuracy: 0.8951 - val_auc: 0.9498\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2822 - accuracy: 0.8471 - auc: 0.9515 - val_loss: 0.3047 - val_accuracy: 0.8923 - val_auc: 0.9506\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2836 - accuracy: 0.8487 - auc: 0.9504 - val_loss: 0.3104 - val_accuracy: 0.8944 - val_auc: 0.9506\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2792 - accuracy: 0.8503 - auc: 0.9523 - val_loss: 0.3169 - val_accuracy: 0.8921 - val_auc: 0.9499\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2686 - accuracy: 0.8514 - auc: 0.9551 - val_loss: 0.3170 - val_accuracy: 0.8941 - val_auc: 0.9496\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2670 - accuracy: 0.8557 - auc: 0.9542 - val_loss: 0.3242 - val_accuracy: 0.8966 - val_auc: 0.9494\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2666 - accuracy: 0.8532 - auc: 0.9560 - val_loss: 0.3304 - val_accuracy: 0.8971 - val_auc: 0.9486\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2723 - accuracy: 0.8547 - auc: 0.9539 - val_loss: 0.3355 - val_accuracy: 0.8929 - val_auc: 0.9470\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2707 - accuracy: 0.8521 - auc: 0.9552 - val_loss: 0.3455 - val_accuracy: 0.8942 - val_auc: 0.9456\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2665 - accuracy: 0.8542 - auc: 0.9555 - val_loss: 0.3502 - val_accuracy: 0.8936 - val_auc: 0.9448\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2622 - accuracy: 0.8521 - auc: 0.9564 - val_loss: 0.3610 - val_accuracy: 0.8961 - val_auc: 0.9445\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2458 - accuracy: 0.8567 - auc: 0.9601 - val_loss: 0.3658 - val_accuracy: 0.8971 - val_auc: 0.9449\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2548 - accuracy: 0.8576 - auc: 0.9581 - val_loss: 0.3708 - val_accuracy: 0.8967 - val_auc: 0.9437\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2432 - accuracy: 0.8553 - auc: 0.9612 - val_loss: 0.3796 - val_accuracy: 0.9024 - val_auc: 0.9440\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2543 - accuracy: 0.8571 - auc: 0.9584 - val_loss: 0.3813 - val_accuracy: 0.9015 - val_auc: 0.9448\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2550 - accuracy: 0.8594 - auc: 0.9579 - val_loss: 0.3806 - val_accuracy: 0.8988 - val_auc: 0.9451\n",
      "Epoch 30/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.8562 - auc: 0.9582Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2478 - accuracy: 0.8562 - auc: 0.9582 - val_loss: 0.3866 - val_accuracy: 0.9000 - val_auc: 0.9449\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 0.7021 - accuracy: 0.3129 - auc: 0.7554 - val_loss: 0.4461 - val_accuracy: 0.7302 - val_auc: 0.9300\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4542 - accuracy: 0.7252 - auc: 0.8933 - val_loss: 0.3434 - val_accuracy: 0.8673 - val_auc: 0.9411\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3940 - accuracy: 0.8369 - auc: 0.9137 - val_loss: 0.3161 - val_accuracy: 0.8786 - val_auc: 0.9490\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3673 - accuracy: 0.8556 - auc: 0.9266 - val_loss: 0.2969 - val_accuracy: 0.8922 - val_auc: 0.9513\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3453 - accuracy: 0.8689 - auc: 0.9297 - val_loss: 0.2905 - val_accuracy: 0.8952 - val_auc: 0.9524\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3279 - accuracy: 0.8804 - auc: 0.9380 - val_loss: 0.2852 - val_accuracy: 0.8991 - val_auc: 0.9535\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3130 - accuracy: 0.8828 - auc: 0.9432 - val_loss: 0.2781 - val_accuracy: 0.9049 - val_auc: 0.9545\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3057 - accuracy: 0.8941 - auc: 0.9455 - val_loss: 0.2747 - val_accuracy: 0.9037 - val_auc: 0.9553\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3020 - accuracy: 0.8894 - auc: 0.9467 - val_loss: 0.2761 - val_accuracy: 0.9060 - val_auc: 0.9546\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2977 - accuracy: 0.8940 - auc: 0.9479 - val_loss: 0.2724 - val_accuracy: 0.9078 - val_auc: 0.9553\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2994 - accuracy: 0.8968 - auc: 0.9478 - val_loss: 0.2672 - val_accuracy: 0.9083 - val_auc: 0.9575\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2917 - accuracy: 0.9017 - auc: 0.9502 - val_loss: 0.2669 - val_accuracy: 0.9036 - val_auc: 0.9570\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2775 - accuracy: 0.8980 - auc: 0.9549 - val_loss: 0.2689 - val_accuracy: 0.9106 - val_auc: 0.9565\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2867 - accuracy: 0.9015 - auc: 0.9522 - val_loss: 0.2714 - val_accuracy: 0.9109 - val_auc: 0.9557\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2831 - accuracy: 0.9038 - auc: 0.9535 - val_loss: 0.2746 - val_accuracy: 0.9091 - val_auc: 0.9548\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2778 - accuracy: 0.9043 - auc: 0.9552 - val_loss: 0.2780 - val_accuracy: 0.9119 - val_auc: 0.9538\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2821 - accuracy: 0.9060 - auc: 0.9533 - val_loss: 0.2800 - val_accuracy: 0.9105 - val_auc: 0.9530\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2758 - accuracy: 0.9039 - auc: 0.9555 - val_loss: 0.2799 - val_accuracy: 0.9114 - val_auc: 0.9530\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2747 - accuracy: 0.9054 - auc: 0.9559 - val_loss: 0.2801 - val_accuracy: 0.9096 - val_auc: 0.9533\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2712 - accuracy: 0.9070 - auc: 0.9568 - val_loss: 0.2826 - val_accuracy: 0.9098 - val_auc: 0.9526\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2715 - accuracy: 0.9078 - auc: 0.9566 - val_loss: 0.2851 - val_accuracy: 0.9126 - val_auc: 0.9523\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2726 - accuracy: 0.9074 - auc: 0.9568 - val_loss: 0.2864 - val_accuracy: 0.9125 - val_auc: 0.9524\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2686 - accuracy: 0.9081 - auc: 0.9572 - val_loss: 0.2851 - val_accuracy: 0.9145 - val_auc: 0.9536\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2598 - accuracy: 0.9120 - auc: 0.9603 - val_loss: 0.2915 - val_accuracy: 0.9134 - val_auc: 0.9518\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2670 - accuracy: 0.9084 - auc: 0.9586 - val_loss: 0.2903 - val_accuracy: 0.9147 - val_auc: 0.9522\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.2699 - accuracy: 0.9084 - auc: 0.9569 - val_loss: 0.2954 - val_accuracy: 0.9152 - val_auc: 0.9514\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2619 - accuracy: 0.9096 - auc: 0.9605 - val_loss: 0.2974 - val_accuracy: 0.9160 - val_auc: 0.9508\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.2571 - accuracy: 0.9103 - auc: 0.9614 - val_loss: 0.3014 - val_accuracy: 0.9157 - val_auc: 0.9508\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2665 - accuracy: 0.9101 - auc: 0.9580 - val_loss: 0.3059 - val_accuracy: 0.9150 - val_auc: 0.9504\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2705 - accuracy: 0.9100 - auc: 0.9573 - val_loss: 0.3029 - val_accuracy: 0.9157 - val_auc: 0.9501\n",
      "Epoch 31/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.2627 - accuracy: 0.9104 - auc: 0.9589Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2619 - accuracy: 0.9105 - auc: 0.9592 - val_loss: 0.3033 - val_accuracy: 0.9171 - val_auc: 0.9501\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.8668 - accuracy: 0.9200 - auc: 0.6487 - val_loss: 0.4623 - val_accuracy: 0.9348 - val_auc: 0.8942\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5127 - accuracy: 0.8866 - auc: 0.8474 - val_loss: 0.3943 - val_accuracy: 0.9083 - val_auc: 0.9243\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4739 - accuracy: 0.8815 - auc: 0.8779 - val_loss: 0.3629 - val_accuracy: 0.9037 - val_auc: 0.9330\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3964 - accuracy: 0.8957 - auc: 0.9107 - val_loss: 0.3408 - val_accuracy: 0.9134 - val_auc: 0.9377\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3928 - accuracy: 0.9033 - auc: 0.9121 - val_loss: 0.3260 - val_accuracy: 0.9126 - val_auc: 0.9402\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3620 - accuracy: 0.9055 - auc: 0.9272 - val_loss: 0.3086 - val_accuracy: 0.9098 - val_auc: 0.9451\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3492 - accuracy: 0.9079 - auc: 0.9321 - val_loss: 0.3014 - val_accuracy: 0.9129 - val_auc: 0.9461\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3438 - accuracy: 0.9076 - auc: 0.9320 - val_loss: 0.2930 - val_accuracy: 0.9148 - val_auc: 0.9481\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3389 - accuracy: 0.9088 - auc: 0.9344 - val_loss: 0.2904 - val_accuracy: 0.9111 - val_auc: 0.9496\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3182 - accuracy: 0.9090 - auc: 0.9428 - val_loss: 0.2861 - val_accuracy: 0.9134 - val_auc: 0.9506\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3327 - accuracy: 0.9134 - auc: 0.9381 - val_loss: 0.2846 - val_accuracy: 0.9092 - val_auc: 0.9507\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3205 - accuracy: 0.9089 - auc: 0.9412 - val_loss: 0.2835 - val_accuracy: 0.9155 - val_auc: 0.9511\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2987 - accuracy: 0.9121 - auc: 0.9502 - val_loss: 0.2812 - val_accuracy: 0.9129 - val_auc: 0.9517\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3087 - accuracy: 0.9098 - auc: 0.9454 - val_loss: 0.2832 - val_accuracy: 0.9164 - val_auc: 0.9510\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3079 - accuracy: 0.9105 - auc: 0.9453 - val_loss: 0.2856 - val_accuracy: 0.9157 - val_auc: 0.9506\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3074 - accuracy: 0.9130 - auc: 0.9457 - val_loss: 0.2876 - val_accuracy: 0.9152 - val_auc: 0.9504\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2851 - accuracy: 0.9109 - auc: 0.9541 - val_loss: 0.2886 - val_accuracy: 0.9162 - val_auc: 0.9511\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2862 - accuracy: 0.9111 - auc: 0.9523 - val_loss: 0.2922 - val_accuracy: 0.9148 - val_auc: 0.9507\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2787 - accuracy: 0.9132 - auc: 0.9545 - val_loss: 0.2947 - val_accuracy: 0.9183 - val_auc: 0.9502\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2722 - accuracy: 0.9125 - auc: 0.9563 - val_loss: 0.2979 - val_accuracy: 0.9183 - val_auc: 0.9501\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2749 - accuracy: 0.9115 - auc: 0.9557 - val_loss: 0.3005 - val_accuracy: 0.9148 - val_auc: 0.9499\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2706 - accuracy: 0.9125 - auc: 0.9567 - val_loss: 0.3052 - val_accuracy: 0.9156 - val_auc: 0.9498\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2696 - accuracy: 0.9101 - auc: 0.9572 - val_loss: 0.3077 - val_accuracy: 0.9154 - val_auc: 0.9500\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2619 - accuracy: 0.9085 - auc: 0.9583 - val_loss: 0.3127 - val_accuracy: 0.9159 - val_auc: 0.9498\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2638 - accuracy: 0.9093 - auc: 0.9585 - val_loss: 0.3174 - val_accuracy: 0.9183 - val_auc: 0.9490\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2604 - accuracy: 0.9101 - auc: 0.9594 - val_loss: 0.3207 - val_accuracy: 0.9167 - val_auc: 0.9493\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2620 - accuracy: 0.9086 - auc: 0.9587 - val_loss: 0.3222 - val_accuracy: 0.9149 - val_auc: 0.9490\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2605 - accuracy: 0.9067 - auc: 0.9594 - val_loss: 0.3275 - val_accuracy: 0.9150 - val_auc: 0.9485\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2551 - accuracy: 0.9105 - auc: 0.9602 - val_loss: 0.3307 - val_accuracy: 0.9114 - val_auc: 0.9483\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2641 - accuracy: 0.9032 - auc: 0.9577 - val_loss: 0.3374 - val_accuracy: 0.9138 - val_auc: 0.9476\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2489 - accuracy: 0.9054 - auc: 0.9626 - val_loss: 0.3394 - val_accuracy: 0.9111 - val_auc: 0.9480\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2456 - accuracy: 0.9042 - auc: 0.9624 - val_loss: 0.3454 - val_accuracy: 0.9145 - val_auc: 0.9483\n",
      "Epoch 33/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2448 - accuracy: 0.9038 - auc: 0.9624Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2454 - accuracy: 0.9039 - auc: 0.9625 - val_loss: 0.3564 - val_accuracy: 0.9152 - val_auc: 0.9461\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.6192 - accuracy: 0.4003 - auc: 0.8189 - val_loss: 0.4042 - val_accuracy: 0.7507 - val_auc: 0.9283\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4330 - accuracy: 0.6205 - auc: 0.9068 - val_loss: 0.3339 - val_accuracy: 0.8613 - val_auc: 0.9434\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3905 - accuracy: 0.8224 - auc: 0.9228 - val_loss: 0.3029 - val_accuracy: 0.8872 - val_auc: 0.9502\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3742 - accuracy: 0.8623 - auc: 0.9260 - val_loss: 0.2867 - val_accuracy: 0.8882 - val_auc: 0.9535\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3378 - accuracy: 0.8702 - auc: 0.9391 - val_loss: 0.2763 - val_accuracy: 0.9010 - val_auc: 0.9550\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3140 - accuracy: 0.8861 - auc: 0.9463 - val_loss: 0.2694 - val_accuracy: 0.9024 - val_auc: 0.9562\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3113 - accuracy: 0.8923 - auc: 0.9453 - val_loss: 0.2673 - val_accuracy: 0.9014 - val_auc: 0.9567\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2915 - accuracy: 0.8929 - auc: 0.9535 - val_loss: 0.2652 - val_accuracy: 0.9089 - val_auc: 0.9569\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2828 - accuracy: 0.8979 - auc: 0.9561 - val_loss: 0.2643 - val_accuracy: 0.9138 - val_auc: 0.9579\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2837 - accuracy: 0.9031 - auc: 0.9551 - val_loss: 0.2634 - val_accuracy: 0.9088 - val_auc: 0.9578\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2880 - accuracy: 0.9027 - auc: 0.9525 - val_loss: 0.2658 - val_accuracy: 0.9064 - val_auc: 0.9566\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2671 - accuracy: 0.9032 - auc: 0.9598 - val_loss: 0.2672 - val_accuracy: 0.9091 - val_auc: 0.9567\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2773 - accuracy: 0.9042 - auc: 0.9569 - val_loss: 0.2694 - val_accuracy: 0.9109 - val_auc: 0.9564\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2788 - accuracy: 0.9063 - auc: 0.9559 - val_loss: 0.2674 - val_accuracy: 0.9105 - val_auc: 0.9568\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2787 - accuracy: 0.9033 - auc: 0.9563 - val_loss: 0.2709 - val_accuracy: 0.9130 - val_auc: 0.9550\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2713 - accuracy: 0.9113 - auc: 0.9580 - val_loss: 0.2705 - val_accuracy: 0.9080 - val_auc: 0.9557\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2667 - accuracy: 0.9023 - auc: 0.9592 - val_loss: 0.2756 - val_accuracy: 0.9097 - val_auc: 0.9548\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2684 - accuracy: 0.9081 - auc: 0.9588 - val_loss: 0.2810 - val_accuracy: 0.9103 - val_auc: 0.9534\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2561 - accuracy: 0.9045 - auc: 0.9626 - val_loss: 0.2822 - val_accuracy: 0.9100 - val_auc: 0.9536\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2710 - accuracy: 0.9058 - auc: 0.9575 - val_loss: 0.2847 - val_accuracy: 0.9140 - val_auc: 0.9529\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2567 - accuracy: 0.9105 - auc: 0.9629 - val_loss: 0.2906 - val_accuracy: 0.9113 - val_auc: 0.9525\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2602 - accuracy: 0.9082 - auc: 0.9613 - val_loss: 0.2941 - val_accuracy: 0.9170 - val_auc: 0.9514\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2652 - accuracy: 0.9093 - auc: 0.9594 - val_loss: 0.2984 - val_accuracy: 0.9152 - val_auc: 0.9504\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2667 - accuracy: 0.9100 - auc: 0.9594 - val_loss: 0.3017 - val_accuracy: 0.9139 - val_auc: 0.9498\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2473 - accuracy: 0.9101 - auc: 0.9659 - val_loss: 0.3067 - val_accuracy: 0.9141 - val_auc: 0.9495\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2516 - accuracy: 0.9118 - auc: 0.9627 - val_loss: 0.3091 - val_accuracy: 0.9156 - val_auc: 0.9494\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2584 - accuracy: 0.9110 - auc: 0.9613 - val_loss: 0.3104 - val_accuracy: 0.9159 - val_auc: 0.9499\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2610 - accuracy: 0.9092 - auc: 0.9598 - val_loss: 0.3131 - val_accuracy: 0.9152 - val_auc: 0.9490\n",
      "Epoch 29/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2570 - accuracy: 0.9103 - auc: 0.9615Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2562 - accuracy: 0.9104 - auc: 0.9617 - val_loss: 0.3173 - val_accuracy: 0.9172 - val_auc: 0.9484\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.7661 - accuracy: 0.6787 - auc: 0.7028 - val_loss: 0.4108 - val_accuracy: 0.8233 - val_auc: 0.9154\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4799 - accuracy: 0.8050 - auc: 0.8834 - val_loss: 0.3399 - val_accuracy: 0.8808 - val_auc: 0.9360\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3777 - accuracy: 0.8575 - auc: 0.9215 - val_loss: 0.3059 - val_accuracy: 0.8882 - val_auc: 0.9444\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3385 - accuracy: 0.8742 - auc: 0.9383 - val_loss: 0.2870 - val_accuracy: 0.9040 - val_auc: 0.9495\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3058 - accuracy: 0.8860 - auc: 0.9468 - val_loss: 0.2737 - val_accuracy: 0.9068 - val_auc: 0.9539\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2987 - accuracy: 0.8935 - auc: 0.9484 - val_loss: 0.2741 - val_accuracy: 0.8996 - val_auc: 0.9538\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2894 - accuracy: 0.8861 - auc: 0.9519 - val_loss: 0.2640 - val_accuracy: 0.9091 - val_auc: 0.9573\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2802 - accuracy: 0.8944 - auc: 0.9542 - val_loss: 0.2607 - val_accuracy: 0.9020 - val_auc: 0.9584\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2755 - accuracy: 0.8959 - auc: 0.9558 - val_loss: 0.2636 - val_accuracy: 0.9009 - val_auc: 0.9576\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2635 - accuracy: 0.8957 - auc: 0.9588 - val_loss: 0.2680 - val_accuracy: 0.9057 - val_auc: 0.9565\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2599 - accuracy: 0.8961 - auc: 0.9599 - val_loss: 0.2661 - val_accuracy: 0.9100 - val_auc: 0.9574\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2641 - accuracy: 0.8948 - auc: 0.9583 - val_loss: 0.2631 - val_accuracy: 0.9062 - val_auc: 0.9585\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2527 - accuracy: 0.8954 - auc: 0.9619 - val_loss: 0.2676 - val_accuracy: 0.9102 - val_auc: 0.9571\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2397 - accuracy: 0.8994 - auc: 0.9653 - val_loss: 0.2732 - val_accuracy: 0.9106 - val_auc: 0.9563\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2403 - accuracy: 0.8952 - auc: 0.9650 - val_loss: 0.2788 - val_accuracy: 0.9138 - val_auc: 0.9557\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2412 - accuracy: 0.8979 - auc: 0.9645 - val_loss: 0.2825 - val_accuracy: 0.9098 - val_auc: 0.9548\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2322 - accuracy: 0.8953 - auc: 0.9669 - val_loss: 0.2872 - val_accuracy: 0.9145 - val_auc: 0.9543\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2261 - accuracy: 0.8988 - auc: 0.9685 - val_loss: 0.2822 - val_accuracy: 0.9167 - val_auc: 0.9559\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2238 - accuracy: 0.9031 - auc: 0.9690 - val_loss: 0.2875 - val_accuracy: 0.9145 - val_auc: 0.9555\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2343 - accuracy: 0.8960 - auc: 0.9660 - val_loss: 0.2941 - val_accuracy: 0.9157 - val_auc: 0.9538\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2180 - accuracy: 0.9014 - auc: 0.9704 - val_loss: 0.2987 - val_accuracy: 0.9177 - val_auc: 0.9541\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2191 - accuracy: 0.8995 - auc: 0.9698 - val_loss: 0.3036 - val_accuracy: 0.9161 - val_auc: 0.9539\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2314 - accuracy: 0.8963 - auc: 0.9669 - val_loss: 0.3123 - val_accuracy: 0.9162 - val_auc: 0.9528\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2236 - accuracy: 0.8988 - auc: 0.9690 - val_loss: 0.3162 - val_accuracy: 0.9174 - val_auc: 0.9514\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2189 - accuracy: 0.9007 - auc: 0.9698 - val_loss: 0.3264 - val_accuracy: 0.9177 - val_auc: 0.9508\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2180 - accuracy: 0.8996 - auc: 0.9701 - val_loss: 0.3231 - val_accuracy: 0.9167 - val_auc: 0.9533\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2179 - accuracy: 0.8999 - auc: 0.9700 - val_loss: 0.3205 - val_accuracy: 0.9138 - val_auc: 0.9524\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2147 - accuracy: 0.8978 - auc: 0.9711 - val_loss: 0.3314 - val_accuracy: 0.9180 - val_auc: 0.9518\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2090 - accuracy: 0.8994 - auc: 0.9724 - val_loss: 0.3455 - val_accuracy: 0.9216 - val_auc: 0.9509\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2106 - accuracy: 0.9021 - auc: 0.9717 - val_loss: 0.3485 - val_accuracy: 0.9191 - val_auc: 0.9511\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2018 - accuracy: 0.9012 - auc: 0.9737 - val_loss: 0.3618 - val_accuracy: 0.9230 - val_auc: 0.9495\n",
      "Epoch 32/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9029 - auc: 0.9741Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2002 - accuracy: 0.9029 - auc: 0.9739 - val_loss: 0.3716 - val_accuracy: 0.9228 - val_auc: 0.9490\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 18us/sample - loss: 0.7149 - accuracy: 0.4082 - auc: 0.7842 - val_loss: 0.3941 - val_accuracy: 0.7164 - val_auc: 0.9350\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4353 - accuracy: 0.7064 - auc: 0.9060 - val_loss: 0.3101 - val_accuracy: 0.8569 - val_auc: 0.9480\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3684 - accuracy: 0.7929 - auc: 0.9258 - val_loss: 0.2886 - val_accuracy: 0.8745 - val_auc: 0.9517\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3326 - accuracy: 0.8192 - auc: 0.9361 - val_loss: 0.2795 - val_accuracy: 0.8825 - val_auc: 0.9536\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3116 - accuracy: 0.8351 - auc: 0.9451 - val_loss: 0.2705 - val_accuracy: 0.8909 - val_auc: 0.9564\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2951 - accuracy: 0.8472 - auc: 0.9514 - val_loss: 0.2690 - val_accuracy: 0.8988 - val_auc: 0.9566\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2735 - accuracy: 0.8605 - auc: 0.9567 - val_loss: 0.2694 - val_accuracy: 0.9043 - val_auc: 0.9570\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2754 - accuracy: 0.8647 - auc: 0.9556 - val_loss: 0.2710 - val_accuracy: 0.8982 - val_auc: 0.9567\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2569 - accuracy: 0.8685 - auc: 0.9611 - val_loss: 0.2742 - val_accuracy: 0.9107 - val_auc: 0.9567\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2568 - accuracy: 0.8735 - auc: 0.9603 - val_loss: 0.2749 - val_accuracy: 0.9044 - val_auc: 0.9565\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2581 - accuracy: 0.8703 - auc: 0.9609 - val_loss: 0.2800 - val_accuracy: 0.9087 - val_auc: 0.9556\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2550 - accuracy: 0.8778 - auc: 0.9622 - val_loss: 0.2822 - val_accuracy: 0.9102 - val_auc: 0.9547\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2477 - accuracy: 0.8790 - auc: 0.9634 - val_loss: 0.2797 - val_accuracy: 0.9074 - val_auc: 0.9558\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2546 - accuracy: 0.8788 - auc: 0.9634 - val_loss: 0.2829 - val_accuracy: 0.9082 - val_auc: 0.9549\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2286 - accuracy: 0.8821 - auc: 0.9688 - val_loss: 0.2890 - val_accuracy: 0.9111 - val_auc: 0.9545\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2371 - accuracy: 0.8841 - auc: 0.9666 - val_loss: 0.2942 - val_accuracy: 0.9125 - val_auc: 0.9536\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2290 - accuracy: 0.8850 - auc: 0.9683 - val_loss: 0.3049 - val_accuracy: 0.9130 - val_auc: 0.9510\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2363 - accuracy: 0.8829 - auc: 0.9669 - val_loss: 0.3089 - val_accuracy: 0.9138 - val_auc: 0.9506\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2272 - accuracy: 0.8877 - auc: 0.9686 - val_loss: 0.3123 - val_accuracy: 0.9144 - val_auc: 0.9504\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2302 - accuracy: 0.8886 - auc: 0.9678 - val_loss: 0.3140 - val_accuracy: 0.9123 - val_auc: 0.9489\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2222 - accuracy: 0.8847 - auc: 0.9701 - val_loss: 0.3237 - val_accuracy: 0.9171 - val_auc: 0.9490\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2221 - accuracy: 0.8909 - auc: 0.9698 - val_loss: 0.3229 - val_accuracy: 0.9134 - val_auc: 0.9489\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2230 - accuracy: 0.8888 - auc: 0.9698 - val_loss: 0.3262 - val_accuracy: 0.9132 - val_auc: 0.9494\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2154 - accuracy: 0.8867 - auc: 0.9712 - val_loss: 0.3445 - val_accuracy: 0.9226 - val_auc: 0.9462\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2121 - accuracy: 0.8989 - auc: 0.9723 - val_loss: 0.3486 - val_accuracy: 0.9205 - val_auc: 0.9468\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2163 - accuracy: 0.8967 - auc: 0.9712 - val_loss: 0.3514 - val_accuracy: 0.9186 - val_auc: 0.9455\n",
      "Epoch 27/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.2210 - accuracy: 0.8923 - auc: 0.9703Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2205 - accuracy: 0.8923 - auc: 0.9701 - val_loss: 0.3521 - val_accuracy: 0.9170 - val_auc: 0.9450\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6936 - accuracy: 0.8093 - auc: 0.7686 - val_loss: 0.3979 - val_accuracy: 0.8798 - val_auc: 0.9212\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4312 - accuracy: 0.8618 - auc: 0.8944 - val_loss: 0.3541 - val_accuracy: 0.8977 - val_auc: 0.9347\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3707 - accuracy: 0.8907 - auc: 0.9214 - val_loss: 0.3346 - val_accuracy: 0.8983 - val_auc: 0.9388\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3376 - accuracy: 0.8948 - auc: 0.9402 - val_loss: 0.3101 - val_accuracy: 0.9080 - val_auc: 0.9427\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3338 - accuracy: 0.9010 - auc: 0.9389 - val_loss: 0.2965 - val_accuracy: 0.9092 - val_auc: 0.9494\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3170 - accuracy: 0.9060 - auc: 0.9451 - val_loss: 0.2889 - val_accuracy: 0.9085 - val_auc: 0.9518\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2997 - accuracy: 0.9052 - auc: 0.9490 - val_loss: 0.2831 - val_accuracy: 0.9174 - val_auc: 0.9522\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2906 - accuracy: 0.9097 - auc: 0.9522 - val_loss: 0.2806 - val_accuracy: 0.9156 - val_auc: 0.9530\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2893 - accuracy: 0.9102 - auc: 0.9524 - val_loss: 0.2751 - val_accuracy: 0.9102 - val_auc: 0.9550\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2751 - accuracy: 0.9097 - auc: 0.9571 - val_loss: 0.2744 - val_accuracy: 0.9142 - val_auc: 0.9549\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2725 - accuracy: 0.9117 - auc: 0.9582 - val_loss: 0.2719 - val_accuracy: 0.9162 - val_auc: 0.9554\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2678 - accuracy: 0.9143 - auc: 0.9588 - val_loss: 0.2723 - val_accuracy: 0.9189 - val_auc: 0.9556\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2645 - accuracy: 0.9140 - auc: 0.9599 - val_loss: 0.2703 - val_accuracy: 0.9195 - val_auc: 0.9561\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2549 - accuracy: 0.9135 - auc: 0.9628 - val_loss: 0.2703 - val_accuracy: 0.9220 - val_auc: 0.9567\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2584 - accuracy: 0.9168 - auc: 0.9615 - val_loss: 0.2700 - val_accuracy: 0.9134 - val_auc: 0.9568\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2641 - accuracy: 0.9112 - auc: 0.9595 - val_loss: 0.2696 - val_accuracy: 0.9216 - val_auc: 0.9564\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2556 - accuracy: 0.9144 - auc: 0.9623 - val_loss: 0.2725 - val_accuracy: 0.9231 - val_auc: 0.9562\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2381 - accuracy: 0.9190 - auc: 0.9669 - val_loss: 0.2728 - val_accuracy: 0.9192 - val_auc: 0.9562\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2416 - accuracy: 0.9180 - auc: 0.9660 - val_loss: 0.2798 - val_accuracy: 0.9160 - val_auc: 0.9546\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2451 - accuracy: 0.9146 - auc: 0.9645 - val_loss: 0.2850 - val_accuracy: 0.9226 - val_auc: 0.9538\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2450 - accuracy: 0.9179 - auc: 0.9647 - val_loss: 0.2839 - val_accuracy: 0.9177 - val_auc: 0.9537\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2403 - accuracy: 0.9153 - auc: 0.9657 - val_loss: 0.2880 - val_accuracy: 0.9186 - val_auc: 0.9534\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2370 - accuracy: 0.9168 - auc: 0.9666 - val_loss: 0.2977 - val_accuracy: 0.9199 - val_auc: 0.9515\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2326 - accuracy: 0.9170 - auc: 0.9676 - val_loss: 0.3050 - val_accuracy: 0.9229 - val_auc: 0.9500\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2305 - accuracy: 0.9157 - auc: 0.9679 - val_loss: 0.3092 - val_accuracy: 0.9272 - val_auc: 0.9506\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2345 - accuracy: 0.9181 - auc: 0.9669 - val_loss: 0.3027 - val_accuracy: 0.9224 - val_auc: 0.9524\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2343 - accuracy: 0.9165 - auc: 0.9670 - val_loss: 0.3019 - val_accuracy: 0.9208 - val_auc: 0.9525\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2239 - accuracy: 0.9167 - auc: 0.9700 - val_loss: 0.3125 - val_accuracy: 0.9266 - val_auc: 0.9503\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2244 - accuracy: 0.9187 - auc: 0.9693 - val_loss: 0.3125 - val_accuracy: 0.9190 - val_auc: 0.9513\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2185 - accuracy: 0.9172 - auc: 0.9709 - val_loss: 0.3148 - val_accuracy: 0.9200 - val_auc: 0.9520\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2288 - accuracy: 0.9152 - auc: 0.9679 - val_loss: 0.3191 - val_accuracy: 0.9227 - val_auc: 0.9503\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2200 - accuracy: 0.9151 - auc: 0.9703 - val_loss: 0.3263 - val_accuracy: 0.9221 - val_auc: 0.9496\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2236 - accuracy: 0.9176 - auc: 0.9694 - val_loss: 0.3338 - val_accuracy: 0.9223 - val_auc: 0.9479\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2180 - accuracy: 0.9149 - auc: 0.9706 - val_loss: 0.3371 - val_accuracy: 0.9241 - val_auc: 0.9491\n",
      "Epoch 35/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2162 - accuracy: 0.9171 - auc: 0.9712Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2149 - accuracy: 0.9169 - auc: 0.9715 - val_loss: 0.3394 - val_accuracy: 0.9195 - val_auc: 0.9486\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.6937 - accuracy: 0.4312 - auc: 0.7730 - val_loss: 0.3975 - val_accuracy: 0.8012 - val_auc: 0.9180\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4473 - accuracy: 0.7462 - auc: 0.8955 - val_loss: 0.3236 - val_accuracy: 0.8657 - val_auc: 0.9372\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3736 - accuracy: 0.8113 - auc: 0.9246 - val_loss: 0.2983 - val_accuracy: 0.8921 - val_auc: 0.9456\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3362 - accuracy: 0.8365 - auc: 0.9345 - val_loss: 0.2867 - val_accuracy: 0.8881 - val_auc: 0.9497\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3217 - accuracy: 0.8406 - auc: 0.9398 - val_loss: 0.2849 - val_accuracy: 0.8926 - val_auc: 0.9501\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3008 - accuracy: 0.8512 - auc: 0.9469 - val_loss: 0.2796 - val_accuracy: 0.8991 - val_auc: 0.9523\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2974 - accuracy: 0.8573 - auc: 0.9478 - val_loss: 0.2777 - val_accuracy: 0.9030 - val_auc: 0.9532\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2751 - accuracy: 0.8682 - auc: 0.9547 - val_loss: 0.2796 - val_accuracy: 0.9010 - val_auc: 0.9531\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2705 - accuracy: 0.8671 - auc: 0.9558 - val_loss: 0.2829 - val_accuracy: 0.9010 - val_auc: 0.9521\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2676 - accuracy: 0.8683 - auc: 0.9573 - val_loss: 0.2844 - val_accuracy: 0.9040 - val_auc: 0.9527\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2524 - accuracy: 0.8749 - auc: 0.9611 - val_loss: 0.2874 - val_accuracy: 0.9016 - val_auc: 0.9511\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2492 - accuracy: 0.8747 - auc: 0.9623 - val_loss: 0.2902 - val_accuracy: 0.9043 - val_auc: 0.9512\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2473 - accuracy: 0.8766 - auc: 0.9631 - val_loss: 0.2925 - val_accuracy: 0.9065 - val_auc: 0.9517\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2438 - accuracy: 0.8793 - auc: 0.9638 - val_loss: 0.2976 - val_accuracy: 0.9075 - val_auc: 0.9507\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2454 - accuracy: 0.8796 - auc: 0.9633 - val_loss: 0.2986 - val_accuracy: 0.9027 - val_auc: 0.9504\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2379 - accuracy: 0.8784 - auc: 0.9652 - val_loss: 0.3062 - val_accuracy: 0.9083 - val_auc: 0.9499\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2301 - accuracy: 0.8832 - auc: 0.9678 - val_loss: 0.3121 - val_accuracy: 0.9103 - val_auc: 0.9499\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2455 - accuracy: 0.8810 - auc: 0.9634 - val_loss: 0.3122 - val_accuracy: 0.9022 - val_auc: 0.9490\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2334 - accuracy: 0.8796 - auc: 0.9669 - val_loss: 0.3162 - val_accuracy: 0.9060 - val_auc: 0.9485\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2293 - accuracy: 0.8822 - auc: 0.9675 - val_loss: 0.3219 - val_accuracy: 0.9107 - val_auc: 0.9478\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2228 - accuracy: 0.8866 - auc: 0.9692 - val_loss: 0.3286 - val_accuracy: 0.9109 - val_auc: 0.9467\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2214 - accuracy: 0.8876 - auc: 0.9694 - val_loss: 0.3360 - val_accuracy: 0.9099 - val_auc: 0.9462\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2205 - accuracy: 0.8873 - auc: 0.9696 - val_loss: 0.3379 - val_accuracy: 0.9102 - val_auc: 0.9463\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2243 - accuracy: 0.8848 - auc: 0.9685 - val_loss: 0.3463 - val_accuracy: 0.9084 - val_auc: 0.9454\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2217 - accuracy: 0.8877 - auc: 0.9693 - val_loss: 0.3540 - val_accuracy: 0.9112 - val_auc: 0.9447\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2159 - accuracy: 0.8881 - auc: 0.9710 - val_loss: 0.3637 - val_accuracy: 0.9175 - val_auc: 0.9438\n",
      "Epoch 27/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.8923 - auc: 0.9698Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2196 - accuracy: 0.8921 - auc: 0.9700 - val_loss: 0.3651 - val_accuracy: 0.9110 - val_auc: 0.9431\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.6184 - accuracy: 0.6113 - auc: 0.8217 - val_loss: 0.3760 - val_accuracy: 0.8398 - val_auc: 0.9383\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4108 - accuracy: 0.8292 - auc: 0.9205 - val_loss: 0.3145 - val_accuracy: 0.8884 - val_auc: 0.9476\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3492 - accuracy: 0.8729 - auc: 0.9360 - val_loss: 0.2879 - val_accuracy: 0.9012 - val_auc: 0.9533\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3272 - accuracy: 0.8862 - auc: 0.9437 - val_loss: 0.2778 - val_accuracy: 0.9110 - val_auc: 0.9549\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3036 - accuracy: 0.8918 - auc: 0.9486 - val_loss: 0.2738 - val_accuracy: 0.9111 - val_auc: 0.9552\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2950 - accuracy: 0.8986 - auc: 0.9496 - val_loss: 0.2737 - val_accuracy: 0.9067 - val_auc: 0.9546\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2817 - accuracy: 0.9010 - auc: 0.9556 - val_loss: 0.2736 - val_accuracy: 0.9118 - val_auc: 0.9539\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2749 - accuracy: 0.9032 - auc: 0.9579 - val_loss: 0.2737 - val_accuracy: 0.9144 - val_auc: 0.9536\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2675 - accuracy: 0.9062 - auc: 0.9594 - val_loss: 0.2760 - val_accuracy: 0.9153 - val_auc: 0.9532\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2686 - accuracy: 0.9105 - auc: 0.9583 - val_loss: 0.2780 - val_accuracy: 0.9149 - val_auc: 0.9525\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2543 - accuracy: 0.9069 - auc: 0.9638 - val_loss: 0.2808 - val_accuracy: 0.9205 - val_auc: 0.9520\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2511 - accuracy: 0.9122 - auc: 0.9641 - val_loss: 0.2824 - val_accuracy: 0.9143 - val_auc: 0.9511\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2509 - accuracy: 0.9090 - auc: 0.9640 - val_loss: 0.2871 - val_accuracy: 0.9196 - val_auc: 0.9510\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2498 - accuracy: 0.9125 - auc: 0.9641 - val_loss: 0.2859 - val_accuracy: 0.9150 - val_auc: 0.9512\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2507 - accuracy: 0.9101 - auc: 0.9638 - val_loss: 0.2853 - val_accuracy: 0.9130 - val_auc: 0.9509\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2412 - accuracy: 0.9116 - auc: 0.9665 - val_loss: 0.2864 - val_accuracy: 0.9144 - val_auc: 0.9515\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2471 - accuracy: 0.9091 - auc: 0.9646 - val_loss: 0.2869 - val_accuracy: 0.9239 - val_auc: 0.9525\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2447 - accuracy: 0.9143 - auc: 0.9652 - val_loss: 0.2882 - val_accuracy: 0.9175 - val_auc: 0.9511\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2290 - accuracy: 0.9158 - auc: 0.9697 - val_loss: 0.2914 - val_accuracy: 0.9212 - val_auc: 0.9515\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2367 - accuracy: 0.9148 - auc: 0.9674 - val_loss: 0.2932 - val_accuracy: 0.9175 - val_auc: 0.9505\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2414 - accuracy: 0.9136 - auc: 0.9658 - val_loss: 0.2980 - val_accuracy: 0.9249 - val_auc: 0.9501\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2409 - accuracy: 0.9152 - auc: 0.9662 - val_loss: 0.2968 - val_accuracy: 0.9162 - val_auc: 0.9500\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2340 - accuracy: 0.9124 - auc: 0.9677 - val_loss: 0.2986 - val_accuracy: 0.9233 - val_auc: 0.9504\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2324 - accuracy: 0.9177 - auc: 0.9688 - val_loss: 0.3026 - val_accuracy: 0.9222 - val_auc: 0.9502\n",
      "Epoch 25/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2283 - accuracy: 0.9169 - auc: 0.9694Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2305 - accuracy: 0.9167 - auc: 0.9690 - val_loss: 0.3082 - val_accuracy: 0.9203 - val_auc: 0.9503\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5622 - accuracy: 0.7348 - auc: 0.8379 - val_loss: 0.3599 - val_accuracy: 0.8637 - val_auc: 0.9390\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3934 - accuracy: 0.8454 - auc: 0.9190 - val_loss: 0.3146 - val_accuracy: 0.8970 - val_auc: 0.9462\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3436 - accuracy: 0.8750 - auc: 0.9366 - val_loss: 0.2909 - val_accuracy: 0.9020 - val_auc: 0.9513\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3245 - accuracy: 0.8869 - auc: 0.9440 - val_loss: 0.2764 - val_accuracy: 0.9034 - val_auc: 0.9540\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2896 - accuracy: 0.8889 - auc: 0.9517 - val_loss: 0.2656 - val_accuracy: 0.9086 - val_auc: 0.9578\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2890 - accuracy: 0.8926 - auc: 0.9526 - val_loss: 0.2630 - val_accuracy: 0.9092 - val_auc: 0.9589\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2716 - accuracy: 0.8954 - auc: 0.9571 - val_loss: 0.2611 - val_accuracy: 0.9091 - val_auc: 0.9590\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2583 - accuracy: 0.9013 - auc: 0.9611 - val_loss: 0.2607 - val_accuracy: 0.9139 - val_auc: 0.9592\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2618 - accuracy: 0.9027 - auc: 0.9599 - val_loss: 0.2607 - val_accuracy: 0.9137 - val_auc: 0.9592\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2417 - accuracy: 0.9046 - auc: 0.9655 - val_loss: 0.2591 - val_accuracy: 0.9097 - val_auc: 0.9594\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2500 - accuracy: 0.9026 - auc: 0.9631 - val_loss: 0.2605 - val_accuracy: 0.9092 - val_auc: 0.9596\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2374 - accuracy: 0.9055 - auc: 0.9668 - val_loss: 0.2590 - val_accuracy: 0.9165 - val_auc: 0.9603\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2365 - accuracy: 0.9087 - auc: 0.9666 - val_loss: 0.2613 - val_accuracy: 0.9174 - val_auc: 0.9597\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2330 - accuracy: 0.9082 - auc: 0.9673 - val_loss: 0.2619 - val_accuracy: 0.9212 - val_auc: 0.9602\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2384 - accuracy: 0.9110 - auc: 0.9657 - val_loss: 0.2656 - val_accuracy: 0.9187 - val_auc: 0.9585\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2331 - accuracy: 0.9096 - auc: 0.9671 - val_loss: 0.2656 - val_accuracy: 0.9133 - val_auc: 0.9589\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2236 - accuracy: 0.9089 - auc: 0.9693 - val_loss: 0.2693 - val_accuracy: 0.9162 - val_auc: 0.9585\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2237 - accuracy: 0.9084 - auc: 0.9693 - val_loss: 0.2763 - val_accuracy: 0.9231 - val_auc: 0.9580\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2248 - accuracy: 0.9127 - auc: 0.9689 - val_loss: 0.2722 - val_accuracy: 0.9183 - val_auc: 0.9585\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2223 - accuracy: 0.9102 - auc: 0.9695 - val_loss: 0.2759 - val_accuracy: 0.9211 - val_auc: 0.9578\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2199 - accuracy: 0.9126 - auc: 0.9702 - val_loss: 0.2811 - val_accuracy: 0.9184 - val_auc: 0.9567\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2217 - accuracy: 0.9127 - auc: 0.9698 - val_loss: 0.2793 - val_accuracy: 0.9146 - val_auc: 0.9570\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2104 - accuracy: 0.9114 - auc: 0.9724 - val_loss: 0.2840 - val_accuracy: 0.9197 - val_auc: 0.9572\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2219 - accuracy: 0.9111 - auc: 0.9698 - val_loss: 0.2877 - val_accuracy: 0.9208 - val_auc: 0.9568\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2165 - accuracy: 0.9116 - auc: 0.9713 - val_loss: 0.2845 - val_accuracy: 0.9195 - val_auc: 0.9577\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2158 - accuracy: 0.9122 - auc: 0.9713 - val_loss: 0.2894 - val_accuracy: 0.9220 - val_auc: 0.9576\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2094 - accuracy: 0.9141 - auc: 0.9729 - val_loss: 0.2995 - val_accuracy: 0.9245 - val_auc: 0.9555\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2077 - accuracy: 0.9137 - auc: 0.9730 - val_loss: 0.3014 - val_accuracy: 0.9255 - val_auc: 0.9553\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2052 - accuracy: 0.9180 - auc: 0.9736 - val_loss: 0.3067 - val_accuracy: 0.9209 - val_auc: 0.9544\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2074 - accuracy: 0.9130 - auc: 0.9731 - val_loss: 0.3059 - val_accuracy: 0.9194 - val_auc: 0.9539\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.1975 - accuracy: 0.9151 - auc: 0.9750 - val_loss: 0.3220 - val_accuracy: 0.9250 - val_auc: 0.9525\n",
      "Epoch 32/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9161 - auc: 0.9736Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2055 - accuracy: 0.9160 - auc: 0.9734 - val_loss: 0.3251 - val_accuracy: 0.9212 - val_auc: 0.9513\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5763 - accuracy: 0.7258 - auc: 0.8199 - val_loss: 0.3614 - val_accuracy: 0.8646 - val_auc: 0.9313\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3943 - accuracy: 0.8563 - auc: 0.9195 - val_loss: 0.3191 - val_accuracy: 0.8895 - val_auc: 0.9438\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3451 - accuracy: 0.8796 - auc: 0.9309 - val_loss: 0.2954 - val_accuracy: 0.9016 - val_auc: 0.9510\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3144 - accuracy: 0.8880 - auc: 0.9445 - val_loss: 0.2834 - val_accuracy: 0.9049 - val_auc: 0.9537\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3071 - accuracy: 0.8958 - auc: 0.9465 - val_loss: 0.2767 - val_accuracy: 0.9074 - val_auc: 0.9551\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2827 - accuracy: 0.9005 - auc: 0.9539 - val_loss: 0.2717 - val_accuracy: 0.9105 - val_auc: 0.9561\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2631 - accuracy: 0.9048 - auc: 0.9598 - val_loss: 0.2724 - val_accuracy: 0.9097 - val_auc: 0.9561\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2657 - accuracy: 0.9009 - auc: 0.9586 - val_loss: 0.2752 - val_accuracy: 0.9145 - val_auc: 0.9558\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2542 - accuracy: 0.9077 - auc: 0.9620 - val_loss: 0.2748 - val_accuracy: 0.9119 - val_auc: 0.9560\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2423 - accuracy: 0.9091 - auc: 0.9655 - val_loss: 0.2741 - val_accuracy: 0.9108 - val_auc: 0.9564\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2412 - accuracy: 0.9089 - auc: 0.9655 - val_loss: 0.2746 - val_accuracy: 0.9126 - val_auc: 0.9566\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2433 - accuracy: 0.9100 - auc: 0.9646 - val_loss: 0.2825 - val_accuracy: 0.9207 - val_auc: 0.9548\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2415 - accuracy: 0.9115 - auc: 0.9652 - val_loss: 0.2844 - val_accuracy: 0.9162 - val_auc: 0.9546\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2357 - accuracy: 0.9096 - auc: 0.9668 - val_loss: 0.2870 - val_accuracy: 0.9153 - val_auc: 0.9538\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2314 - accuracy: 0.9116 - auc: 0.9679 - val_loss: 0.2897 - val_accuracy: 0.9207 - val_auc: 0.9539\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2311 - accuracy: 0.9141 - auc: 0.9679 - val_loss: 0.2909 - val_accuracy: 0.9149 - val_auc: 0.9530\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2262 - accuracy: 0.9135 - auc: 0.9689 - val_loss: 0.2996 - val_accuracy: 0.9186 - val_auc: 0.9522\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2311 - accuracy: 0.9131 - auc: 0.9678 - val_loss: 0.2983 - val_accuracy: 0.9219 - val_auc: 0.9515\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2252 - accuracy: 0.9161 - auc: 0.9694 - val_loss: 0.3006 - val_accuracy: 0.9178 - val_auc: 0.9514\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2245 - accuracy: 0.9108 - auc: 0.9695 - val_loss: 0.3027 - val_accuracy: 0.9212 - val_auc: 0.9510\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2213 - accuracy: 0.9128 - auc: 0.9700 - val_loss: 0.3153 - val_accuracy: 0.9249 - val_auc: 0.9493\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2176 - accuracy: 0.9149 - auc: 0.9712 - val_loss: 0.3113 - val_accuracy: 0.9218 - val_auc: 0.9492\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2154 - accuracy: 0.9148 - auc: 0.9717 - val_loss: 0.3249 - val_accuracy: 0.9237 - val_auc: 0.9476\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2115 - accuracy: 0.9173 - auc: 0.9726 - val_loss: 0.3353 - val_accuracy: 0.9235 - val_auc: 0.9457\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2197 - accuracy: 0.9167 - auc: 0.9706 - val_loss: 0.3338 - val_accuracy: 0.9211 - val_auc: 0.9453\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2074 - accuracy: 0.9165 - auc: 0.9733 - val_loss: 0.3437 - val_accuracy: 0.9283 - val_auc: 0.9450\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2050 - accuracy: 0.9182 - auc: 0.9739 - val_loss: 0.3493 - val_accuracy: 0.9254 - val_auc: 0.9442\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2004 - accuracy: 0.9164 - auc: 0.9747 - val_loss: 0.3641 - val_accuracy: 0.9246 - val_auc: 0.9433\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2009 - accuracy: 0.9166 - auc: 0.9745 - val_loss: 0.3799 - val_accuracy: 0.9287 - val_auc: 0.9400\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2010 - accuracy: 0.9192 - auc: 0.9746 - val_loss: 0.3818 - val_accuracy: 0.9275 - val_auc: 0.9406\n",
      "Epoch 31/100\n",
      "246784/250290 [============================>.] - ETA: 0s - loss: 0.2072 - accuracy: 0.9180 - auc: 0.9732Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2074 - accuracy: 0.9179 - auc: 0.9732 - val_loss: 0.3720 - val_accuracy: 0.9252 - val_auc: 0.9443\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.6548 - accuracy: 0.5473 - auc: 0.7970 - val_loss: 0.3893 - val_accuracy: 0.8224 - val_auc: 0.9256\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3988 - accuracy: 0.8062 - auc: 0.9151 - val_loss: 0.3118 - val_accuracy: 0.8908 - val_auc: 0.9420\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3542 - accuracy: 0.8585 - auc: 0.9298 - val_loss: 0.2911 - val_accuracy: 0.8952 - val_auc: 0.9506\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3237 - accuracy: 0.8639 - auc: 0.9393 - val_loss: 0.2769 - val_accuracy: 0.9013 - val_auc: 0.9545\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2927 - accuracy: 0.8748 - auc: 0.9499 - val_loss: 0.2689 - val_accuracy: 0.9050 - val_auc: 0.9565\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2733 - accuracy: 0.8819 - auc: 0.9554 - val_loss: 0.2679 - val_accuracy: 0.9052 - val_auc: 0.9567\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2681 - accuracy: 0.8827 - auc: 0.9565 - val_loss: 0.2693 - val_accuracy: 0.9044 - val_auc: 0.9566\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2606 - accuracy: 0.8879 - auc: 0.9587 - val_loss: 0.2687 - val_accuracy: 0.9080 - val_auc: 0.9564\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2591 - accuracy: 0.8864 - auc: 0.9589 - val_loss: 0.2715 - val_accuracy: 0.9082 - val_auc: 0.9556\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2533 - accuracy: 0.8913 - auc: 0.9608 - val_loss: 0.2720 - val_accuracy: 0.9059 - val_auc: 0.9554\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2395 - accuracy: 0.8941 - auc: 0.9647 - val_loss: 0.2748 - val_accuracy: 0.9105 - val_auc: 0.9554\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2431 - accuracy: 0.8952 - auc: 0.9636 - val_loss: 0.2741 - val_accuracy: 0.9106 - val_auc: 0.9557\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2393 - accuracy: 0.8989 - auc: 0.9647 - val_loss: 0.2742 - val_accuracy: 0.9029 - val_auc: 0.9553\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2365 - accuracy: 0.8949 - auc: 0.9654 - val_loss: 0.2818 - val_accuracy: 0.9112 - val_auc: 0.9533\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2229 - accuracy: 0.8994 - auc: 0.9692 - val_loss: 0.2906 - val_accuracy: 0.9138 - val_auc: 0.9525\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2297 - accuracy: 0.9010 - auc: 0.9671 - val_loss: 0.2873 - val_accuracy: 0.9126 - val_auc: 0.9535\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2230 - accuracy: 0.9003 - auc: 0.9690 - val_loss: 0.2924 - val_accuracy: 0.9128 - val_auc: 0.9532\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2254 - accuracy: 0.9005 - auc: 0.9680 - val_loss: 0.2955 - val_accuracy: 0.9108 - val_auc: 0.9530\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2233 - accuracy: 0.9017 - auc: 0.9686 - val_loss: 0.2985 - val_accuracy: 0.9114 - val_auc: 0.9528\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2171 - accuracy: 0.9045 - auc: 0.9701 - val_loss: 0.3039 - val_accuracy: 0.9143 - val_auc: 0.9524\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2210 - accuracy: 0.9038 - auc: 0.9692 - val_loss: 0.3079 - val_accuracy: 0.9125 - val_auc: 0.9511\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2101 - accuracy: 0.9051 - auc: 0.9721 - val_loss: 0.3138 - val_accuracy: 0.9198 - val_auc: 0.9522\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2193 - accuracy: 0.9065 - auc: 0.9697 - val_loss: 0.3253 - val_accuracy: 0.9188 - val_auc: 0.9501\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2167 - accuracy: 0.9047 - auc: 0.9702 - val_loss: 0.3217 - val_accuracy: 0.9179 - val_auc: 0.9508\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2191 - accuracy: 0.9035 - auc: 0.9697 - val_loss: 0.3272 - val_accuracy: 0.9191 - val_auc: 0.9503\n",
      "Epoch 26/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2064 - accuracy: 0.9096 - auc: 0.9728Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2094 - accuracy: 0.9096 - auc: 0.9721 - val_loss: 0.3387 - val_accuracy: 0.9209 - val_auc: 0.9502\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.7194 - accuracy: 0.5479 - auc: 0.7830 - val_loss: 0.4052 - val_accuracy: 0.8051 - val_auc: 0.9320\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4487 - accuracy: 0.7958 - auc: 0.8992 - val_loss: 0.3398 - val_accuracy: 0.8774 - val_auc: 0.9432\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3704 - accuracy: 0.8594 - auc: 0.9270 - val_loss: 0.3067 - val_accuracy: 0.8977 - val_auc: 0.9489\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3306 - accuracy: 0.8763 - auc: 0.9380 - val_loss: 0.2896 - val_accuracy: 0.9060 - val_auc: 0.9512\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3100 - accuracy: 0.8856 - auc: 0.9441 - val_loss: 0.2851 - val_accuracy: 0.9020 - val_auc: 0.9525\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2799 - accuracy: 0.8924 - auc: 0.9548 - val_loss: 0.2785 - val_accuracy: 0.9097 - val_auc: 0.9530\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2913 - accuracy: 0.8894 - auc: 0.9498 - val_loss: 0.2729 - val_accuracy: 0.9111 - val_auc: 0.9544\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2711 - accuracy: 0.8948 - auc: 0.9563 - val_loss: 0.2722 - val_accuracy: 0.9126 - val_auc: 0.9549\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2671 - accuracy: 0.9001 - auc: 0.9573 - val_loss: 0.2709 - val_accuracy: 0.9135 - val_auc: 0.9559\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2587 - accuracy: 0.8992 - auc: 0.9596 - val_loss: 0.2715 - val_accuracy: 0.9154 - val_auc: 0.9562\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2585 - accuracy: 0.9038 - auc: 0.9597 - val_loss: 0.2696 - val_accuracy: 0.9098 - val_auc: 0.9557\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2530 - accuracy: 0.9026 - auc: 0.9620 - val_loss: 0.2712 - val_accuracy: 0.9119 - val_auc: 0.9558\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2448 - accuracy: 0.9011 - auc: 0.9640 - val_loss: 0.2762 - val_accuracy: 0.9202 - val_auc: 0.9555\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2367 - accuracy: 0.9052 - auc: 0.9659 - val_loss: 0.2773 - val_accuracy: 0.9179 - val_auc: 0.9547\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.2366 - accuracy: 0.9057 - auc: 0.9660 - val_loss: 0.2776 - val_accuracy: 0.9066 - val_auc: 0.9541\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2309 - accuracy: 0.9050 - auc: 0.9676 - val_loss: 0.2839 - val_accuracy: 0.9144 - val_auc: 0.9533\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2352 - accuracy: 0.9063 - auc: 0.9664 - val_loss: 0.2848 - val_accuracy: 0.9117 - val_auc: 0.9520\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2228 - accuracy: 0.9074 - auc: 0.9697 - val_loss: 0.2861 - val_accuracy: 0.9171 - val_auc: 0.9528\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2290 - accuracy: 0.9072 - auc: 0.9680 - val_loss: 0.2868 - val_accuracy: 0.9229 - val_auc: 0.9542\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2129 - accuracy: 0.9096 - auc: 0.9721 - val_loss: 0.2933 - val_accuracy: 0.9201 - val_auc: 0.9520\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2188 - accuracy: 0.9089 - auc: 0.9704 - val_loss: 0.2932 - val_accuracy: 0.9198 - val_auc: 0.9530\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2225 - accuracy: 0.9089 - auc: 0.9695 - val_loss: 0.2970 - val_accuracy: 0.9168 - val_auc: 0.9516\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2158 - accuracy: 0.9118 - auc: 0.9709 - val_loss: 0.3029 - val_accuracy: 0.9201 - val_auc: 0.9508\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2109 - accuracy: 0.9093 - auc: 0.9722 - val_loss: 0.3043 - val_accuracy: 0.9239 - val_auc: 0.9509\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2073 - accuracy: 0.9148 - auc: 0.9731 - val_loss: 0.3142 - val_accuracy: 0.9236 - val_auc: 0.9499\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2077 - accuracy: 0.9130 - auc: 0.9730 - val_loss: 0.3186 - val_accuracy: 0.9186 - val_auc: 0.9491\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2086 - accuracy: 0.9111 - auc: 0.9728 - val_loss: 0.3253 - val_accuracy: 0.9192 - val_auc: 0.9493\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2000 - accuracy: 0.9113 - auc: 0.9750 - val_loss: 0.3368 - val_accuracy: 0.9279 - val_auc: 0.9478\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.1987 - accuracy: 0.9133 - auc: 0.9750 - val_loss: 0.3451 - val_accuracy: 0.9287 - val_auc: 0.9476\n",
      "Epoch 30/100\n",
      "248832/250291 [============================>.] - ETA: 0s - loss: 0.2009 - accuracy: 0.9164 - auc: 0.9743Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2015 - accuracy: 0.9165 - auc: 0.9743 - val_loss: 0.3463 - val_accuracy: 0.9249 - val_auc: 0.9478\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 18us/sample - loss: 0.7609 - accuracy: 0.6093 - auc: 0.7883 - val_loss: 0.3689 - val_accuracy: 0.8448 - val_auc: 0.9245\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4222 - accuracy: 0.8122 - auc: 0.9125 - val_loss: 0.3068 - val_accuracy: 0.8941 - val_auc: 0.9445\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3565 - accuracy: 0.8497 - auc: 0.9302 - val_loss: 0.2876 - val_accuracy: 0.8916 - val_auc: 0.9502\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3073 - accuracy: 0.8636 - auc: 0.9473 - val_loss: 0.2786 - val_accuracy: 0.9000 - val_auc: 0.9527\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2933 - accuracy: 0.8725 - auc: 0.9501 - val_loss: 0.2760 - val_accuracy: 0.9061 - val_auc: 0.9539\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2788 - accuracy: 0.8760 - auc: 0.9539 - val_loss: 0.2764 - val_accuracy: 0.9013 - val_auc: 0.9539\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2738 - accuracy: 0.8776 - auc: 0.9587 - val_loss: 0.2725 - val_accuracy: 0.9042 - val_auc: 0.9552\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2654 - accuracy: 0.8810 - auc: 0.9583 - val_loss: 0.2719 - val_accuracy: 0.8992 - val_auc: 0.9554\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2587 - accuracy: 0.8804 - auc: 0.9599 - val_loss: 0.2781 - val_accuracy: 0.9012 - val_auc: 0.9543\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2541 - accuracy: 0.8795 - auc: 0.9615 - val_loss: 0.2814 - val_accuracy: 0.9045 - val_auc: 0.9533\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2416 - accuracy: 0.8843 - auc: 0.9645 - val_loss: 0.2849 - val_accuracy: 0.9022 - val_auc: 0.9526\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2323 - accuracy: 0.8872 - auc: 0.9677 - val_loss: 0.2954 - val_accuracy: 0.9145 - val_auc: 0.9520\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2337 - accuracy: 0.8917 - auc: 0.9665 - val_loss: 0.2974 - val_accuracy: 0.9085 - val_auc: 0.9509\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2225 - accuracy: 0.8927 - auc: 0.9690 - val_loss: 0.3031 - val_accuracy: 0.9131 - val_auc: 0.9515\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2318 - accuracy: 0.8941 - auc: 0.9667 - val_loss: 0.3039 - val_accuracy: 0.9085 - val_auc: 0.9509\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2200 - accuracy: 0.8926 - auc: 0.9701 - val_loss: 0.3107 - val_accuracy: 0.9123 - val_auc: 0.9507\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2151 - accuracy: 0.8959 - auc: 0.9711 - val_loss: 0.3152 - val_accuracy: 0.9114 - val_auc: 0.9509\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2198 - accuracy: 0.8937 - auc: 0.9697 - val_loss: 0.3191 - val_accuracy: 0.9110 - val_auc: 0.9505\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2069 - accuracy: 0.8979 - auc: 0.9730 - val_loss: 0.3295 - val_accuracy: 0.9191 - val_auc: 0.9495\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2175 - accuracy: 0.9002 - auc: 0.9706 - val_loss: 0.3324 - val_accuracy: 0.9172 - val_auc: 0.9486\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2204 - accuracy: 0.8972 - auc: 0.9697 - val_loss: 0.3373 - val_accuracy: 0.9137 - val_auc: 0.9472\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2067 - accuracy: 0.8976 - auc: 0.9731 - val_loss: 0.3378 - val_accuracy: 0.9144 - val_auc: 0.9480\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.1996 - accuracy: 0.9019 - auc: 0.9746 - val_loss: 0.3472 - val_accuracy: 0.9191 - val_auc: 0.9477\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2010 - accuracy: 0.9039 - auc: 0.9741 - val_loss: 0.3542 - val_accuracy: 0.9167 - val_auc: 0.9472\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2047 - accuracy: 0.9019 - auc: 0.9735 - val_loss: 0.3633 - val_accuracy: 0.9185 - val_auc: 0.9459\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.1972 - accuracy: 0.9038 - auc: 0.9751 - val_loss: 0.3691 - val_accuracy: 0.9178 - val_auc: 0.9451\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.1980 - accuracy: 0.9033 - auc: 0.9745 - val_loss: 0.3753 - val_accuracy: 0.9140 - val_auc: 0.9447\n",
      "Epoch 28/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.1954 - accuracy: 0.9037 - auc: 0.9752Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.1953 - accuracy: 0.9037 - auc: 0.9753 - val_loss: 0.3937 - val_accuracy: 0.9190 - val_auc: 0.9426\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.7018 - accuracy: 0.8256 - auc: 0.7877 - val_loss: 0.3766 - val_accuracy: 0.9217 - val_auc: 0.9230\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5844 - accuracy: 0.8946 - auc: 0.8273 - val_loss: 0.3532 - val_accuracy: 0.9241 - val_auc: 0.9442\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5089 - accuracy: 0.8942 - auc: 0.8746 - val_loss: 0.3926 - val_accuracy: 0.8889 - val_auc: 0.9354\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6709 - accuracy: 0.7884 - auc: 0.8363 - val_loss: 0.9588 - val_accuracy: 0.5501 - val_auc: 0.8683\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7507 - accuracy: 0.6549 - auc: 0.7877 - val_loss: 0.7784 - val_accuracy: 0.5777 - val_auc: 0.8006\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6424 - accuracy: 0.4885 - auc: 0.7275 - val_loss: 0.4979 - val_accuracy: 0.9110 - val_auc: 0.8734\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5091 - accuracy: 0.6244 - auc: 0.8099 - val_loss: 0.4194 - val_accuracy: 0.6402 - val_auc: 0.9412\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4745 - accuracy: 0.5471 - auc: 0.8183 - val_loss: 0.3664 - val_accuracy: 0.6582 - val_auc: 0.9432\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4765 - accuracy: 0.4947 - auc: 0.8139 - val_loss: 0.3566 - val_accuracy: 0.9207 - val_auc: 0.9436\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4434 - accuracy: 0.6872 - auc: 0.8398 - val_loss: 0.4126 - val_accuracy: 0.6634 - val_auc: 0.9456\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4602 - accuracy: 0.5856 - auc: 0.8342 - val_loss: 0.4274 - val_accuracy: 0.6944 - val_auc: 0.9161\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4665 - accuracy: 0.5283 - auc: 0.8078 - val_loss: 0.4335 - val_accuracy: 0.6789 - val_auc: 0.9205\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4569 - accuracy: 0.4868 - auc: 0.8109 - val_loss: 0.4438 - val_accuracy: 0.6960 - val_auc: 0.9215\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4722 - accuracy: 0.4893 - auc: 0.8088 - val_loss: 0.4823 - val_accuracy: 0.6781 - val_auc: 0.8838\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5026 - accuracy: 0.4887 - auc: 0.7664 - val_loss: 0.4551 - val_accuracy: 0.6975 - val_auc: 0.8573\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5038 - accuracy: 0.4996 - auc: 0.7640 - val_loss: 0.4997 - val_accuracy: 0.6991 - val_auc: 0.8629\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4994 - accuracy: 0.4998 - auc: 0.7883 - val_loss: 0.4131 - val_accuracy: 0.6994 - val_auc: 0.9098\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4802 - accuracy: 0.4954 - auc: 0.8107 - val_loss: 0.4223 - val_accuracy: 0.7040 - val_auc: 0.9354\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6287 - accuracy: 0.4862 - auc: 0.7744 - val_loss: 0.9503 - val_accuracy: 0.6962 - val_auc: 0.8355\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6930 - accuracy: 0.4454 - auc: 0.7181 - val_loss: 0.6982 - val_accuracy: 0.6324 - val_auc: 0.8051\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5588 - accuracy: 0.4398 - auc: 0.7171 - val_loss: 0.9040 - val_accuracy: 0.6555 - val_auc: 0.8115\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5427 - accuracy: 0.4583 - auc: 0.7334 - val_loss: 0.6644 - val_accuracy: 0.6493 - val_auc: 0.8185\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5234 - accuracy: 0.4612 - auc: 0.7254 - val_loss: 0.6291 - val_accuracy: 0.6536 - val_auc: 0.8157\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5073 - accuracy: 0.4658 - auc: 0.7424 - val_loss: 0.6553 - val_accuracy: 0.6708 - val_auc: 0.8218\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5015 - accuracy: 0.4773 - auc: 0.7347 - val_loss: 0.6785 - val_accuracy: 0.6813 - val_auc: 0.8283\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5209 - accuracy: 0.4816 - auc: 0.7323 - val_loss: 0.7351 - val_accuracy: 0.6759 - val_auc: 0.8257\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5154 - accuracy: 0.4795 - auc: 0.7384 - val_loss: 0.6220 - val_accuracy: 0.6737 - val_auc: 0.8241\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5065 - accuracy: 0.4803 - auc: 0.7415 - val_loss: 0.5546 - val_accuracy: 0.6700 - val_auc: 0.8316\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5219 - accuracy: 0.4802 - auc: 0.7367 - val_loss: 0.6576 - val_accuracy: 0.6833 - val_auc: 0.8307\n",
      "Epoch 30/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.4867 - auc: 0.7526Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5082 - accuracy: 0.4869 - auc: 0.7531 - val_loss: 0.7055 - val_accuracy: 0.6789 - val_auc: 0.8286\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6177 - accuracy: 0.8593 - auc: 0.7931 - val_loss: 0.3731 - val_accuracy: 0.8951 - val_auc: 0.9277\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5330 - accuracy: 0.8932 - auc: 0.8507 - val_loss: 0.3884 - val_accuracy: 0.9173 - val_auc: 0.9324\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6002 - accuracy: 0.8886 - auc: 0.8294 - val_loss: 0.4882 - val_accuracy: 0.8992 - val_auc: 0.9326\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6128 - accuracy: 0.9181 - auc: 0.8506 - val_loss: 0.3807 - val_accuracy: 0.9352 - val_auc: 0.9416\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4754 - accuracy: 0.9232 - auc: 0.8607 - val_loss: 0.4779 - val_accuracy: 0.9009 - val_auc: 0.9387\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5096 - accuracy: 0.8451 - auc: 0.8578 - val_loss: 0.7033 - val_accuracy: 0.7212 - val_auc: 0.8567\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5295 - accuracy: 0.6517 - auc: 0.8206 - val_loss: 0.6220 - val_accuracy: 0.6722 - val_auc: 0.9293\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5026 - accuracy: 0.6181 - auc: 0.8164 - val_loss: 0.6036 - val_accuracy: 0.6459 - val_auc: 0.9307\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4704 - accuracy: 0.5650 - auc: 0.8142 - val_loss: 0.5597 - val_accuracy: 0.6635 - val_auc: 0.9364\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4649 - accuracy: 0.5112 - auc: 0.8228 - val_loss: 0.5720 - val_accuracy: 0.6801 - val_auc: 0.9407\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4418 - accuracy: 0.6412 - auc: 0.8403 - val_loss: 0.5640 - val_accuracy: 0.9315 - val_auc: 0.9454\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4305 - accuracy: 0.5631 - auc: 0.8348 - val_loss: 0.6080 - val_accuracy: 0.7013 - val_auc: 0.9461\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4480 - accuracy: 0.5202 - auc: 0.8410 - val_loss: 0.4892 - val_accuracy: 0.9439 - val_auc: 0.9395\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4846 - accuracy: 0.5547 - auc: 0.8090 - val_loss: 0.5480 - val_accuracy: 0.6823 - val_auc: 0.9121\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4649 - accuracy: 0.5039 - auc: 0.8106 - val_loss: 0.6163 - val_accuracy: 0.6867 - val_auc: 0.9174\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4561 - accuracy: 0.4878 - auc: 0.8111 - val_loss: 0.5917 - val_accuracy: 0.6823 - val_auc: 0.9175\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5005 - accuracy: 0.4920 - auc: 0.7448 - val_loss: 0.9937 - val_accuracy: 0.6908 - val_auc: 0.8311\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5051 - accuracy: 0.4899 - auc: 0.7526 - val_loss: 0.7236 - val_accuracy: 0.6687 - val_auc: 0.8304\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5582 - accuracy: 0.4628 - auc: 0.7243 - val_loss: 1.0833 - val_accuracy: 0.6694 - val_auc: 0.8202\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5778 - accuracy: 0.4706 - auc: 0.7216 - val_loss: 1.7998 - val_accuracy: 0.6412 - val_auc: 0.8260\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5209 - accuracy: 0.4684 - auc: 0.7340 - val_loss: 1.5963 - val_accuracy: 0.6652 - val_auc: 0.8224\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4999 - accuracy: 0.4686 - auc: 0.7266 - val_loss: 1.5607 - val_accuracy: 0.6946 - val_auc: 0.8294\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5190 - accuracy: 0.4784 - auc: 0.7263 - val_loss: 1.0160 - val_accuracy: 0.6847 - val_auc: 0.8256\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4985 - accuracy: 0.4764 - auc: 0.7359 - val_loss: 1.1271 - val_accuracy: 0.7002 - val_auc: 0.8329\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5004 - accuracy: 0.4891 - auc: 0.7364 - val_loss: 1.2342 - val_accuracy: 0.6869 - val_auc: 0.8263\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5030 - accuracy: 0.4820 - auc: 0.7303 - val_loss: 1.1600 - val_accuracy: 0.6845 - val_auc: 0.8237\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5235 - accuracy: 0.4792 - auc: 0.7414 - val_loss: 1.1146 - val_accuracy: 0.6829 - val_auc: 0.8229\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5251 - accuracy: 0.4713 - auc: 0.7253 - val_loss: 1.9428 - val_accuracy: 0.6825 - val_auc: 0.8252\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5012 - accuracy: 0.4775 - auc: 0.7222 - val_loss: 1.4561 - val_accuracy: 0.6708 - val_auc: 0.8253\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.5242 - accuracy: 0.4726 - auc: 0.7318 - val_loss: 2.0003 - val_accuracy: 0.6865 - val_auc: 0.8201\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5517 - accuracy: 0.4719 - auc: 0.7331 - val_loss: 1.5569 - val_accuracy: 0.6795 - val_auc: 0.8230\n",
      "Epoch 32/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.5738 - accuracy: 0.4728 - auc: 0.7437Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5736 - accuracy: 0.4729 - auc: 0.7437 - val_loss: 0.9652 - val_accuracy: 0.6672 - val_auc: 0.8228\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6425 - accuracy: 0.8591 - auc: 0.7796 - val_loss: 0.3703 - val_accuracy: 0.8677 - val_auc: 0.9254\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5215 - accuracy: 0.8861 - auc: 0.8602 - val_loss: 0.4508 - val_accuracy: 0.9374 - val_auc: 0.9293\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5606 - accuracy: 0.8953 - auc: 0.8505 - val_loss: 0.4129 - val_accuracy: 0.8873 - val_auc: 0.9272\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6041 - accuracy: 0.6848 - auc: 0.7634 - val_loss: 0.7218 - val_accuracy: 0.8745 - val_auc: 0.9040\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6391 - accuracy: 0.8466 - auc: 0.7849 - val_loss: 0.8504 - val_accuracy: 0.6203 - val_auc: 0.9400\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6187 - accuracy: 0.4007 - auc: 0.7199 - val_loss: 0.7663 - val_accuracy: 0.6189 - val_auc: 0.8445\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6372 - accuracy: 0.4102 - auc: 0.7507 - val_loss: 0.7466 - val_accuracy: 0.6282 - val_auc: 0.8607\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5046 - accuracy: 0.6916 - auc: 0.8291 - val_loss: 0.4904 - val_accuracy: 0.9515 - val_auc: 0.9347\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5044 - accuracy: 0.6777 - auc: 0.8134 - val_loss: 0.6800 - val_accuracy: 0.9304 - val_auc: 0.9306\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4624 - accuracy: 0.6864 - auc: 0.8261 - val_loss: 0.5695 - val_accuracy: 0.9348 - val_auc: 0.9343\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5071 - accuracy: 0.5634 - auc: 0.7989 - val_loss: 0.6465 - val_accuracy: 0.6564 - val_auc: 0.8633\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4850 - accuracy: 0.4369 - auc: 0.7863 - val_loss: 0.6736 - val_accuracy: 0.6610 - val_auc: 0.8731\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5055 - accuracy: 0.4457 - auc: 0.7746 - val_loss: 0.6182 - val_accuracy: 0.6488 - val_auc: 0.8753\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4918 - accuracy: 0.4528 - auc: 0.7838 - val_loss: 0.5328 - val_accuracy: 0.6705 - val_auc: 0.8988\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4912 - accuracy: 0.5009 - auc: 0.7802 - val_loss: 0.5702 - val_accuracy: 0.6634 - val_auc: 0.8732\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5054 - accuracy: 0.4709 - auc: 0.7558 - val_loss: 0.5941 - val_accuracy: 0.6901 - val_auc: 0.8911\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4885 - accuracy: 0.4644 - auc: 0.7754 - val_loss: 0.6460 - val_accuracy: 0.6785 - val_auc: 0.8969\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4665 - accuracy: 0.4775 - auc: 0.7826 - val_loss: 0.6829 - val_accuracy: 0.6953 - val_auc: 0.8929\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4721 - accuracy: 0.4885 - auc: 0.7823 - val_loss: 0.5160 - val_accuracy: 0.6929 - val_auc: 0.8997\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4599 - accuracy: 0.5083 - auc: 0.8205 - val_loss: 0.6406 - val_accuracy: 0.9414 - val_auc: 0.9397\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4897 - accuracy: 0.4950 - auc: 0.7774 - val_loss: 0.5424 - val_accuracy: 0.6998 - val_auc: 0.8874\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4887 - accuracy: 0.4899 - auc: 0.7801 - val_loss: 0.6820 - val_accuracy: 0.6976 - val_auc: 0.8873\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4715 - accuracy: 0.4959 - auc: 0.7889 - val_loss: 0.5459 - val_accuracy: 0.6905 - val_auc: 0.8913\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4775 - accuracy: 0.4836 - auc: 0.7716 - val_loss: 0.5522 - val_accuracy: 0.7046 - val_auc: 0.8930\n",
      "Epoch 25/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.4770 - accuracy: 0.4895 - auc: 0.7833Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4768 - accuracy: 0.4894 - auc: 0.7839 - val_loss: 0.7090 - val_accuracy: 0.7018 - val_auc: 0.8886\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 0.5887 - accuracy: 0.8857 - auc: 0.8015 - val_loss: 0.5508 - val_accuracy: 0.6904 - val_auc: 0.9267\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5462 - accuracy: 0.8885 - auc: 0.8429 - val_loss: 0.3532 - val_accuracy: 0.9015 - val_auc: 0.9485\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5953 - accuracy: 0.9004 - auc: 0.8411 - val_loss: 0.4108 - val_accuracy: 0.8368 - val_auc: 0.9481\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5687 - accuracy: 0.7890 - auc: 0.8009 - val_loss: 0.3806 - val_accuracy: 0.9167 - val_auc: 0.9259\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4866 - accuracy: 0.9186 - auc: 0.8342 - val_loss: 0.3608 - val_accuracy: 0.9507 - val_auc: 0.9437\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4311 - accuracy: 0.9282 - auc: 0.8592 - val_loss: 0.3176 - val_accuracy: 0.9316 - val_auc: 0.9474\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4297 - accuracy: 0.9309 - auc: 0.8661 - val_loss: 0.3720 - val_accuracy: 0.9397 - val_auc: 0.9443\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5640 - accuracy: 0.8948 - auc: 0.8370 - val_loss: 0.3733 - val_accuracy: 0.6302 - val_auc: 0.9411\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6681 - accuracy: 0.5766 - auc: 0.7984 - val_loss: 0.3787 - val_accuracy: 0.9011 - val_auc: 0.9443\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5253 - accuracy: 0.6545 - auc: 0.8194 - val_loss: 0.4495 - val_accuracy: 0.9077 - val_auc: 0.9406\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5489 - accuracy: 0.8415 - auc: 0.8282 - val_loss: 0.4275 - val_accuracy: 0.9147 - val_auc: 0.9404\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4501 - accuracy: 0.8779 - auc: 0.8449 - val_loss: 0.3361 - val_accuracy: 0.9240 - val_auc: 0.9476\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5160 - accuracy: 0.7989 - auc: 0.8240 - val_loss: 0.5170 - val_accuracy: 0.6712 - val_auc: 0.9380\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4529 - accuracy: 0.7687 - auc: 0.8298 - val_loss: 0.5026 - val_accuracy: 0.9025 - val_auc: 0.9467\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4705 - accuracy: 0.7412 - auc: 0.8363 - val_loss: 0.4968 - val_accuracy: 0.6761 - val_auc: 0.9469\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5102 - accuracy: 0.5606 - auc: 0.8091 - val_loss: 0.6642 - val_accuracy: 0.7010 - val_auc: 0.8874\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5217 - accuracy: 0.4524 - auc: 0.7868 - val_loss: 0.6317 - val_accuracy: 0.7129 - val_auc: 0.8835\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5406 - accuracy: 0.4980 - auc: 0.7617 - val_loss: 0.6841 - val_accuracy: 0.4540 - val_auc: 0.8570\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5124 - accuracy: 0.4515 - auc: 0.7811 - val_loss: 0.4629 - val_accuracy: 0.6731 - val_auc: 0.8978\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5870 - accuracy: 0.5824 - auc: 0.7974 - val_loss: 0.8818 - val_accuracy: 0.6412 - val_auc: 0.9013\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4687 - accuracy: 0.7381 - auc: 0.8285 - val_loss: 1.0429 - val_accuracy: 0.9320 - val_auc: 0.9260\n",
      "Epoch 22/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.7942 - accuracy: 0.5320 - auc: 0.7594Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7894 - accuracy: 0.5295 - auc: 0.7596 - val_loss: 1.1488 - val_accuracy: 0.5911 - val_auc: 0.8536\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.7712 - accuracy: 0.8433 - auc: 0.7708 - val_loss: 0.3904 - val_accuracy: 0.9470 - val_auc: 0.9282\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6070 - accuracy: 0.8890 - auc: 0.8232 - val_loss: 0.4110 - val_accuracy: 0.9001 - val_auc: 0.9395\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5937 - accuracy: 0.8981 - auc: 0.8341 - val_loss: 0.3565 - val_accuracy: 0.9131 - val_auc: 0.9328\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6109 - accuracy: 0.8960 - auc: 0.8332 - val_loss: 0.5957 - val_accuracy: 0.8689 - val_auc: 0.9260\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5345 - accuracy: 0.8784 - auc: 0.7708 - val_loss: 0.4677 - val_accuracy: 0.8925 - val_auc: 0.9345\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6295 - accuracy: 0.8396 - auc: 0.7648 - val_loss: 0.5945 - val_accuracy: 0.9783 - val_auc: 0.8240\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6354 - accuracy: 0.3225 - auc: 0.6697 - val_loss: 0.5353 - val_accuracy: 0.5947 - val_auc: 0.8119\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5867 - accuracy: 0.3287 - auc: 0.6649 - val_loss: 0.5095 - val_accuracy: 0.6326 - val_auc: 0.8252\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5911 - accuracy: 0.3362 - auc: 0.6605 - val_loss: 0.5324 - val_accuracy: 0.6847 - val_auc: 0.8305\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5720 - accuracy: 0.3575 - auc: 0.6647 - val_loss: 0.4859 - val_accuracy: 0.7248 - val_auc: 0.8513\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5881 - accuracy: 0.3631 - auc: 0.6705 - val_loss: 0.6134 - val_accuracy: 0.7146 - val_auc: 0.8398\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5981 - accuracy: 0.3443 - auc: 0.6587 - val_loss: 1.1460 - val_accuracy: 0.6325 - val_auc: 0.8036\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6517 - accuracy: 0.2995 - auc: 0.6478 - val_loss: 0.8364 - val_accuracy: 0.5508 - val_auc: 0.7778\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5923 - accuracy: 0.3240 - auc: 0.6546 - val_loss: 0.7674 - val_accuracy: 0.5868 - val_auc: 0.7968\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5896 - accuracy: 0.3083 - auc: 0.6534 - val_loss: 0.6331 - val_accuracy: 0.6168 - val_auc: 0.8118\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5702 - accuracy: 0.3232 - auc: 0.6726 - val_loss: 0.7108 - val_accuracy: 0.6572 - val_auc: 0.8257\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5801 - accuracy: 0.3364 - auc: 0.6797 - val_loss: 0.5535 - val_accuracy: 0.6575 - val_auc: 0.8323\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5729 - accuracy: 0.3363 - auc: 0.6660 - val_loss: 0.6268 - val_accuracy: 0.6540 - val_auc: 0.8264\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5760 - accuracy: 0.3306 - auc: 0.6737 - val_loss: 0.5226 - val_accuracy: 0.6383 - val_auc: 0.8259\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5618 - accuracy: 0.3406 - auc: 0.6823 - val_loss: 0.5936 - val_accuracy: 0.6882 - val_auc: 0.8645\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5450 - accuracy: 0.4106 - auc: 0.7380 - val_loss: 0.5024 - val_accuracy: 0.6918 - val_auc: 0.8937\n",
      "Epoch 22/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.3968 - auc: 0.7502Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5415 - accuracy: 0.4069 - auc: 0.7499 - val_loss: 0.6198 - val_accuracy: 0.9195 - val_auc: 0.8973\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.9326 - accuracy: 0.7730 - auc: 0.7838 - val_loss: 0.4192 - val_accuracy: 0.8859 - val_auc: 0.9122\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6547 - accuracy: 0.8666 - auc: 0.8475 - val_loss: 0.5324 - val_accuracy: 0.9452 - val_auc: 0.9174\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9114 - accuracy: 0.8572 - auc: 0.8266 - val_loss: 0.7735 - val_accuracy: 0.9190 - val_auc: 0.9244\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9607 - accuracy: 0.8762 - auc: 0.8231 - val_loss: 0.5572 - val_accuracy: 0.9022 - val_auc: 0.9337\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6098 - accuracy: 0.9033 - auc: 0.8466 - val_loss: 0.5685 - val_accuracy: 0.9095 - val_auc: 0.9407\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5803 - accuracy: 0.8468 - auc: 0.8472 - val_loss: 0.4789 - val_accuracy: 0.9455 - val_auc: 0.9407\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6263 - accuracy: 0.8040 - auc: 0.8761 - val_loss: 0.4665 - val_accuracy: 0.8876 - val_auc: 0.9363\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5497 - accuracy: 0.8046 - auc: 0.8659 - val_loss: 0.4468 - val_accuracy: 0.9414 - val_auc: 0.9414\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4601 - accuracy: 0.7509 - auc: 0.8645 - val_loss: 0.4009 - val_accuracy: 0.6886 - val_auc: 0.9427\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4209 - accuracy: 0.7648 - auc: 0.8911 - val_loss: 0.4385 - val_accuracy: 0.8972 - val_auc: 0.9437\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4542 - accuracy: 0.7343 - auc: 0.8759 - val_loss: 0.5058 - val_accuracy: 0.6872 - val_auc: 0.9425\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4330 - accuracy: 0.5971 - auc: 0.8757 - val_loss: 0.3405 - val_accuracy: 0.9228 - val_auc: 0.9508\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4514 - accuracy: 0.6512 - auc: 0.8712 - val_loss: 0.4395 - val_accuracy: 0.6969 - val_auc: 0.9382\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4243 - accuracy: 0.5841 - auc: 0.8690 - val_loss: 0.5151 - val_accuracy: 0.7254 - val_auc: 0.9386\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4318 - accuracy: 0.7519 - auc: 0.8906 - val_loss: 0.5704 - val_accuracy: 0.7160 - val_auc: 0.9409\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4632 - accuracy: 0.5396 - auc: 0.8519 - val_loss: 0.6923 - val_accuracy: 0.9385 - val_auc: 0.9265\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4499 - accuracy: 0.5965 - auc: 0.8611 - val_loss: 0.5844 - val_accuracy: 0.7086 - val_auc: 0.9398\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4121 - accuracy: 0.6259 - auc: 0.8726 - val_loss: 0.5237 - val_accuracy: 0.7053 - val_auc: 0.9389\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4539 - accuracy: 0.5677 - auc: 0.8550 - val_loss: 0.7717 - val_accuracy: 0.7105 - val_auc: 0.8822\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4834 - accuracy: 0.5524 - auc: 0.8132 - val_loss: 0.5858 - val_accuracy: 0.6739 - val_auc: 0.8927\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4746 - accuracy: 0.5473 - auc: 0.7982 - val_loss: 0.6153 - val_accuracy: 0.7032 - val_auc: 0.9148\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4533 - accuracy: 0.5471 - auc: 0.8134 - val_loss: 0.6442 - val_accuracy: 0.6970 - val_auc: 0.9321\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4358 - accuracy: 0.5484 - auc: 0.8485 - val_loss: 0.4882 - val_accuracy: 0.6927 - val_auc: 0.9314\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4156 - accuracy: 0.5541 - auc: 0.8565 - val_loss: 0.4741 - val_accuracy: 0.7043 - val_auc: 0.9445\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4304 - accuracy: 0.5543 - auc: 0.8504 - val_loss: 0.6441 - val_accuracy: 0.7064 - val_auc: 0.9178\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4283 - accuracy: 0.5600 - auc: 0.8587 - val_loss: 0.4668 - val_accuracy: 0.6789 - val_auc: 0.9379\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4057 - accuracy: 0.6374 - auc: 0.8698 - val_loss: 0.5999 - val_accuracy: 0.6686 - val_auc: 0.9358\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4675 - accuracy: 0.5473 - auc: 0.8385 - val_loss: 0.7328 - val_accuracy: 0.6770 - val_auc: 0.8849\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3929 - accuracy: 0.6428 - auc: 0.8725 - val_loss: 0.9113 - val_accuracy: 0.7290 - val_auc: 0.9137\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5556 - accuracy: 0.5532 - auc: 0.8017 - val_loss: 1.1604 - val_accuracy: 0.6765 - val_auc: 0.8720\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1061 - accuracy: 0.5248 - auc: 0.7760 - val_loss: 2.6315 - val_accuracy: 0.6626 - val_auc: 0.8196\n",
      "Epoch 32/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 1.6814 - accuracy: 0.4961 - auc: 0.7419Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6597 - accuracy: 0.4963 - auc: 0.7419 - val_loss: 2.7563 - val_accuracy: 0.6317 - val_auc: 0.8126\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.8388 - accuracy: 0.7776 - auc: 0.7882 - val_loss: 0.4328 - val_accuracy: 0.9120 - val_auc: 0.9219\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7949 - accuracy: 0.8617 - auc: 0.8360 - val_loss: 0.5061 - val_accuracy: 0.9098 - val_auc: 0.9333\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7223 - accuracy: 0.8750 - auc: 0.8444 - val_loss: 0.5740 - val_accuracy: 0.8965 - val_auc: 0.9055\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1232 - accuracy: 0.8093 - auc: 0.7933 - val_loss: 0.6106 - val_accuracy: 0.5581 - val_auc: 0.9305\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6587 - accuracy: 0.7682 - auc: 0.8042 - val_loss: 0.4789 - val_accuracy: 0.9525 - val_auc: 0.9357\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5522 - accuracy: 0.9205 - auc: 0.8410 - val_loss: 0.4934 - val_accuracy: 0.8779 - val_auc: 0.9407\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5322 - accuracy: 0.7879 - auc: 0.8560 - val_loss: 0.5879 - val_accuracy: 0.6501 - val_auc: 0.9121\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4981 - accuracy: 0.5185 - auc: 0.8176 - val_loss: 0.6272 - val_accuracy: 0.6535 - val_auc: 0.9123\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4950 - accuracy: 0.5203 - auc: 0.8269 - val_loss: 0.5717 - val_accuracy: 0.6838 - val_auc: 0.9193\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4404 - accuracy: 0.5379 - auc: 0.8397 - val_loss: 0.5753 - val_accuracy: 0.6972 - val_auc: 0.9394\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4451 - accuracy: 0.5388 - auc: 0.8430 - val_loss: 0.5448 - val_accuracy: 0.7067 - val_auc: 0.9419\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4195 - accuracy: 0.5524 - auc: 0.8500 - val_loss: 0.6091 - val_accuracy: 0.7295 - val_auc: 0.9405\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4242 - accuracy: 0.5641 - auc: 0.8610 - val_loss: 0.5460 - val_accuracy: 0.7146 - val_auc: 0.9420\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4167 - accuracy: 0.6115 - auc: 0.8669 - val_loss: 0.5836 - val_accuracy: 0.7249 - val_auc: 0.9422\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4094 - accuracy: 0.6184 - auc: 0.8724 - val_loss: 0.5235 - val_accuracy: 0.7037 - val_auc: 0.9377\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4057 - accuracy: 0.5959 - auc: 0.8655 - val_loss: 0.5699 - val_accuracy: 0.7023 - val_auc: 0.9352\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4053 - accuracy: 0.6072 - auc: 0.8690 - val_loss: 0.6480 - val_accuracy: 0.7159 - val_auc: 0.9361\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4263 - accuracy: 0.6227 - auc: 0.8760 - val_loss: 0.7221 - val_accuracy: 0.5245 - val_auc: 0.8548\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4691 - accuracy: 0.5706 - auc: 0.8503 - val_loss: 0.9015 - val_accuracy: 0.6878 - val_auc: 0.8680\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5799 - accuracy: 0.5281 - auc: 0.7983 - val_loss: 1.0384 - val_accuracy: 0.6967 - val_auc: 0.8505\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4738 - accuracy: 0.5480 - auc: 0.8020 - val_loss: 0.8948 - val_accuracy: 0.7032 - val_auc: 0.8976\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4647 - accuracy: 0.5516 - auc: 0.8471 - val_loss: 0.9985 - val_accuracy: 0.7043 - val_auc: 0.9160\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4934 - accuracy: 0.5507 - auc: 0.8042 - val_loss: 1.5196 - val_accuracy: 0.7115 - val_auc: 0.8292\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4769 - accuracy: 0.5501 - auc: 0.7725 - val_loss: 1.3370 - val_accuracy: 0.6901 - val_auc: 0.8258\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4639 - accuracy: 0.5567 - auc: 0.7803 - val_loss: 1.2900 - val_accuracy: 0.7140 - val_auc: 0.8390\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4548 - accuracy: 0.5638 - auc: 0.7757 - val_loss: 1.3112 - val_accuracy: 0.7158 - val_auc: 0.8398\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4743 - accuracy: 0.5605 - auc: 0.7828 - val_loss: 1.3392 - val_accuracy: 0.7205 - val_auc: 0.8393\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4575 - accuracy: 0.5757 - auc: 0.7761 - val_loss: 1.3125 - val_accuracy: 0.7311 - val_auc: 0.8429\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4698 - accuracy: 0.5724 - auc: 0.7799 - val_loss: 1.1143 - val_accuracy: 0.6262 - val_auc: 0.7702\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4738 - accuracy: 0.5593 - auc: 0.7709 - val_loss: 1.6517 - val_accuracy: 0.7083 - val_auc: 0.8278\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4541 - accuracy: 0.5716 - auc: 0.7733 - val_loss: 1.4685 - val_accuracy: 0.7200 - val_auc: 0.8339\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4544 - accuracy: 0.5697 - auc: 0.7908 - val_loss: 1.3802 - val_accuracy: 0.7215 - val_auc: 0.8344\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4611 - accuracy: 0.5643 - auc: 0.7794 - val_loss: 1.4798 - val_accuracy: 0.7156 - val_auc: 0.8339\n",
      "Epoch 34/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.5633 - auc: 0.7756Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4664 - accuracy: 0.5633 - auc: 0.7757 - val_loss: 1.4274 - val_accuracy: 0.7158 - val_auc: 0.8365\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.9633 - accuracy: 0.7985 - auc: 0.7823 - val_loss: 0.8478 - val_accuracy: 0.7586 - val_auc: 0.8354\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7066 - accuracy: 0.8609 - auc: 0.8276 - val_loss: 0.4013 - val_accuracy: 0.8428 - val_auc: 0.9252\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6160 - accuracy: 0.8706 - auc: 0.8634 - val_loss: 0.4493 - val_accuracy: 0.9132 - val_auc: 0.9159\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6362 - accuracy: 0.7853 - auc: 0.8507 - val_loss: 0.4822 - val_accuracy: 0.6927 - val_auc: 0.8716\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6486 - accuracy: 0.5474 - auc: 0.8062 - val_loss: 0.4214 - val_accuracy: 0.5817 - val_auc: 0.9280\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4837 - accuracy: 0.7188 - auc: 0.8612 - val_loss: 0.3916 - val_accuracy: 0.7044 - val_auc: 0.9419\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5742 - accuracy: 0.5693 - auc: 0.8440 - val_loss: 0.6030 - val_accuracy: 0.7307 - val_auc: 0.9372\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5802 - accuracy: 0.5844 - auc: 0.8544 - val_loss: 0.5203 - val_accuracy: 0.8788 - val_auc: 0.9238\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4939 - accuracy: 0.6604 - auc: 0.8688 - val_loss: 0.4340 - val_accuracy: 0.6905 - val_auc: 0.9278\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4786 - accuracy: 0.5747 - auc: 0.8364 - val_loss: 0.5485 - val_accuracy: 0.7163 - val_auc: 0.9351\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8209 - accuracy: 0.6340 - auc: 0.8382 - val_loss: 1.3420 - val_accuracy: 0.7126 - val_auc: 0.9304\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5722 - accuracy: 0.5751 - auc: 0.8178 - val_loss: 1.3276 - val_accuracy: 0.7111 - val_auc: 0.8405\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.8029 - accuracy: 0.5016 - auc: 0.7330 - val_loss: 3.2178 - val_accuracy: 0.6411 - val_auc: 0.8078\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7546 - accuracy: 0.4746 - auc: 0.7409 - val_loss: 2.2418 - val_accuracy: 0.6340 - val_auc: 0.8048\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0452 - accuracy: 0.4665 - auc: 0.7223 - val_loss: 2.3377 - val_accuracy: 0.6121 - val_auc: 0.7978\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5588 - accuracy: 0.5000 - auc: 0.7427 - val_loss: 2.4498 - val_accuracy: 0.6589 - val_auc: 0.8169\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8696 - accuracy: 0.5210 - auc: 0.7575 - val_loss: 3.3856 - val_accuracy: 0.6448 - val_auc: 0.8133\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5454 - accuracy: 0.5241 - auc: 0.7621 - val_loss: 3.2363 - val_accuracy: 0.6521 - val_auc: 0.8205\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5175 - accuracy: 0.5407 - auc: 0.7690 - val_loss: 4.0694 - val_accuracy: 0.6697 - val_auc: 0.8217\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5048 - accuracy: 0.5573 - auc: 0.7672 - val_loss: 3.3482 - val_accuracy: 0.7009 - val_auc: 0.8386\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8571 - accuracy: 0.5606 - auc: 0.7788 - val_loss: 0.8084 - val_accuracy: 0.6697 - val_auc: 0.8333\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4604 - accuracy: 0.5745 - auc: 0.7898 - val_loss: 1.4983 - val_accuracy: 0.6913 - val_auc: 0.8389\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4656 - accuracy: 0.5776 - auc: 0.7870 - val_loss: 1.3599 - val_accuracy: 0.6656 - val_auc: 0.8396\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4406 - accuracy: 0.5810 - auc: 0.7859 - val_loss: 1.4860 - val_accuracy: 0.7010 - val_auc: 0.8428\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4467 - accuracy: 0.5934 - auc: 0.7956 - val_loss: 1.2717 - val_accuracy: 0.7150 - val_auc: 0.8506\n",
      "Epoch 26/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.4570 - accuracy: 0.5919 - auc: 0.7903Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4572 - accuracy: 0.5919 - auc: 0.7910 - val_loss: 1.3557 - val_accuracy: 0.7099 - val_auc: 0.8516\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.9398 - accuracy: 0.7557 - auc: 0.7610 - val_loss: 0.5811 - val_accuracy: 0.9052 - val_auc: 0.9077\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 4s 18us/sample - loss: 0.9383 - accuracy: 0.8294 - auc: 0.8135 - val_loss: 0.5650 - val_accuracy: 0.8919 - val_auc: 0.9238\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9403 - accuracy: 0.8196 - auc: 0.8261 - val_loss: 0.6861 - val_accuracy: 0.9312 - val_auc: 0.9280\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1456 - accuracy: 0.7501 - auc: 0.8251 - val_loss: 1.8248 - val_accuracy: 0.8389 - val_auc: 0.8874\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2097 - accuracy: 0.5676 - auc: 0.7856 - val_loss: 0.8709 - val_accuracy: 0.5848 - val_auc: 0.8018\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8640 - accuracy: 0.5630 - auc: 0.7749 - val_loss: 1.3106 - val_accuracy: 0.6853 - val_auc: 0.8701\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9343 - accuracy: 0.5434 - auc: 0.8102 - val_loss: 1.2970 - val_accuracy: 0.9656 - val_auc: 0.9086\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.7962 - accuracy: 0.5595 - auc: 0.7955 - val_loss: 1.2352 - val_accuracy: 0.6466 - val_auc: 0.8883\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9045 - accuracy: 0.5019 - auc: 0.7686 - val_loss: 0.8158 - val_accuracy: 0.5993 - val_auc: 0.7823\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8399 - accuracy: 0.4994 - auc: 0.7489 - val_loss: 1.9738 - val_accuracy: 0.6321 - val_auc: 0.8033\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5298 - accuracy: 0.5263 - auc: 0.7909 - val_loss: 2.0467 - val_accuracy: 0.6665 - val_auc: 0.8300\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6913 - accuracy: 0.5310 - auc: 0.7760 - val_loss: 1.5745 - val_accuracy: 0.6539 - val_auc: 0.8340\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5010 - accuracy: 0.5347 - auc: 0.7917 - val_loss: 1.0915 - val_accuracy: 0.6375 - val_auc: 0.8876\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4597 - accuracy: 0.5386 - auc: 0.8377 - val_loss: 1.0863 - val_accuracy: 0.6693 - val_auc: 0.9289\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4336 - accuracy: 0.5570 - auc: 0.8452 - val_loss: 1.1741 - val_accuracy: 0.6702 - val_auc: 0.9303\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4117 - accuracy: 0.5536 - auc: 0.8520 - val_loss: 1.0409 - val_accuracy: 0.6782 - val_auc: 0.9319\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7806 - accuracy: 0.6111 - auc: 0.8147 - val_loss: 1.2075 - val_accuracy: 0.6402 - val_auc: 0.8669\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4509 - accuracy: 0.5480 - auc: 0.8038 - val_loss: 1.1650 - val_accuracy: 0.6717 - val_auc: 0.8761\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5463 - accuracy: 0.5523 - auc: 0.8061 - val_loss: 0.9991 - val_accuracy: 0.6814 - val_auc: 0.8778\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5721 - accuracy: 0.5741 - auc: 0.8259 - val_loss: 0.9868 - val_accuracy: 0.7206 - val_auc: 0.9199\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4229 - accuracy: 0.5926 - auc: 0.8648 - val_loss: 1.1600 - val_accuracy: 0.7175 - val_auc: 0.9322\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4106 - accuracy: 0.5861 - auc: 0.8612 - val_loss: 1.1968 - val_accuracy: 0.7240 - val_auc: 0.9059\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4213 - accuracy: 0.6012 - auc: 0.8521 - val_loss: 1.0721 - val_accuracy: 0.7409 - val_auc: 0.8607\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4326 - accuracy: 0.6102 - auc: 0.8145 - val_loss: 0.9789 - val_accuracy: 0.7492 - val_auc: 0.8765\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4288 - accuracy: 0.6104 - auc: 0.8267 - val_loss: 0.9788 - val_accuracy: 0.7470 - val_auc: 0.8892\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4224 - accuracy: 0.6114 - auc: 0.8282 - val_loss: 1.0742 - val_accuracy: 0.7563 - val_auc: 0.8874\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4334 - accuracy: 0.6160 - auc: 0.8366 - val_loss: 0.7834 - val_accuracy: 0.7294 - val_auc: 0.8864\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3984 - accuracy: 0.6198 - auc: 0.8406 - val_loss: 0.8775 - val_accuracy: 0.7470 - val_auc: 0.8884\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3991 - accuracy: 0.6282 - auc: 0.8519 - val_loss: 0.7293 - val_accuracy: 0.7441 - val_auc: 0.8946\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4010 - accuracy: 0.6316 - auc: 0.8409 - val_loss: 0.8777 - val_accuracy: 0.7565 - val_auc: 0.8903\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4030 - accuracy: 0.6264 - auc: 0.8406 - val_loss: 0.7763 - val_accuracy: 0.7496 - val_auc: 0.8980\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4067 - accuracy: 0.6304 - auc: 0.8443 - val_loss: 0.8800 - val_accuracy: 0.7565 - val_auc: 0.9009\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3952 - accuracy: 0.6418 - auc: 0.8606 - val_loss: 0.9082 - val_accuracy: 0.7624 - val_auc: 0.9136\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4512 - accuracy: 0.6299 - auc: 0.8570 - val_loss: 1.0281 - val_accuracy: 0.7402 - val_auc: 0.8566\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4211 - accuracy: 0.6281 - auc: 0.8148 - val_loss: 1.0592 - val_accuracy: 0.7572 - val_auc: 0.8596\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4276 - accuracy: 0.6403 - auc: 0.8153 - val_loss: 0.7778 - val_accuracy: 0.7463 - val_auc: 0.8608\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4254 - accuracy: 0.6301 - auc: 0.8126 - val_loss: 0.7288 - val_accuracy: 0.7377 - val_auc: 0.8584\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4281 - accuracy: 0.6367 - auc: 0.8147 - val_loss: 0.9431 - val_accuracy: 0.7466 - val_auc: 0.8572\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4056 - accuracy: 0.6421 - auc: 0.8200 - val_loss: 1.0151 - val_accuracy: 0.7612 - val_auc: 0.8651\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4268 - accuracy: 0.6328 - auc: 0.8163 - val_loss: 1.2176 - val_accuracy: 0.7414 - val_auc: 0.8535\n",
      "Epoch 41/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.4193 - accuracy: 0.6342 - auc: 0.8189Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4191 - accuracy: 0.6340 - auc: 0.8189 - val_loss: 1.2294 - val_accuracy: 0.7552 - val_auc: 0.8569\n",
      "Epoch 00041: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 1.0305 - accuracy: 0.5751 - auc: 0.7339 - val_loss: 0.7242 - val_accuracy: 0.7174 - val_auc: 0.9176\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 5s 18us/sample - loss: 0.9899 - accuracy: 0.6258 - auc: 0.7715 - val_loss: 0.9857 - val_accuracy: 0.7570 - val_auc: 0.9219\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0462 - accuracy: 0.6023 - auc: 0.7892 - val_loss: 0.4921 - val_accuracy: 0.6505 - val_auc: 0.9044\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6543 - accuracy: 0.6017 - auc: 0.8363 - val_loss: 0.6150 - val_accuracy: 0.7482 - val_auc: 0.8802\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5224 - accuracy: 0.6498 - auc: 0.8384 - val_loss: 0.6160 - val_accuracy: 0.7856 - val_auc: 0.9090\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4686 - accuracy: 0.6885 - auc: 0.8597 - val_loss: 0.6709 - val_accuracy: 0.7648 - val_auc: 0.9104\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5008 - accuracy: 0.6921 - auc: 0.8574 - val_loss: 0.8377 - val_accuracy: 0.7981 - val_auc: 0.8891\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4814 - accuracy: 0.6939 - auc: 0.8489 - val_loss: 0.8962 - val_accuracy: 0.7943 - val_auc: 0.8861\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6986 - accuracy: 0.6932 - auc: 0.8479 - val_loss: 1.1550 - val_accuracy: 0.8113 - val_auc: 0.8789\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7421 - accuracy: 0.6704 - auc: 0.8296 - val_loss: 1.5803 - val_accuracy: 0.7683 - val_auc: 0.8643\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5034 - accuracy: 0.6616 - auc: 0.8337 - val_loss: 1.4958 - val_accuracy: 0.7615 - val_auc: 0.8820\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4538 - accuracy: 0.6699 - auc: 0.8459 - val_loss: 1.0990 - val_accuracy: 0.7711 - val_auc: 0.8913\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5986 - accuracy: 0.6590 - auc: 0.8475 - val_loss: 1.6194 - val_accuracy: 0.7583 - val_auc: 0.8906\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6734 - accuracy: 0.6671 - auc: 0.8475 - val_loss: 2.7086 - val_accuracy: 0.7830 - val_auc: 0.8991\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5629 - accuracy: 0.6637 - auc: 0.8370 - val_loss: 2.3272 - val_accuracy: 0.7117 - val_auc: 0.8643\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5435 - accuracy: 0.6156 - auc: 0.8176 - val_loss: 2.5075 - val_accuracy: 0.7228 - val_auc: 0.8538\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5074 - accuracy: 0.6218 - auc: 0.8276 - val_loss: 1.4796 - val_accuracy: 0.7244 - val_auc: 0.8803\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4262 - accuracy: 0.6318 - auc: 0.8412 - val_loss: 1.4112 - val_accuracy: 0.7377 - val_auc: 0.8895\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4781 - accuracy: 0.6361 - auc: 0.8484 - val_loss: 1.8686 - val_accuracy: 0.7226 - val_auc: 0.8870\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6878 - accuracy: 0.6132 - auc: 0.8212 - val_loss: 2.0509 - val_accuracy: 0.7143 - val_auc: 0.8831\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4586 - accuracy: 0.6151 - auc: 0.8402 - val_loss: 2.7263 - val_accuracy: 0.7204 - val_auc: 0.8752\n",
      "Epoch 22/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.4480 - accuracy: 0.6264 - auc: 0.8375Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4480 - accuracy: 0.6265 - auc: 0.8369 - val_loss: 2.5436 - val_accuracy: 0.7221 - val_auc: 0.8823\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.4959 - accuracy: 0.7130 - auc: 0.7913 - val_loss: 0.7578 - val_accuracy: 0.9323 - val_auc: 0.8804\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 1.5775 - accuracy: 0.8263 - auc: 0.8272 - val_loss: 3.4367 - val_accuracy: 0.8863 - val_auc: 0.9071\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9557 - accuracy: 0.8202 - auc: 0.8160 - val_loss: 1.1232 - val_accuracy: 0.8534 - val_auc: 0.8975\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9736 - accuracy: 0.7945 - auc: 0.7924 - val_loss: 2.4601 - val_accuracy: 0.2563 - val_auc: 0.6838\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0673 - accuracy: 0.6300 - auc: 0.8141 - val_loss: 1.6136 - val_accuracy: 0.8207 - val_auc: 0.8160\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8903 - accuracy: 0.6357 - auc: 0.8097 - val_loss: 1.6703 - val_accuracy: 0.9198 - val_auc: 0.8523\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1391 - accuracy: 0.5026 - auc: 0.7824 - val_loss: 2.4855 - val_accuracy: 0.6226 - val_auc: 0.8379\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0956 - accuracy: 0.5022 - auc: 0.7825 - val_loss: 2.1670 - val_accuracy: 0.5852 - val_auc: 0.8181\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4196 - accuracy: 0.4427 - auc: 0.7395 - val_loss: 2.3836 - val_accuracy: 0.5667 - val_auc: 0.8426\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9377 - accuracy: 0.5633 - auc: 0.7688 - val_loss: 2.0056 - val_accuracy: 0.6551 - val_auc: 0.8593\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2074 - accuracy: 0.5771 - auc: 0.8087 - val_loss: 2.3065 - val_accuracy: 0.6080 - val_auc: 0.8987\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7698 - accuracy: 0.5094 - auc: 0.8239 - val_loss: 1.7611 - val_accuracy: 0.6343 - val_auc: 0.8642\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7085 - accuracy: 0.5090 - auc: 0.8054 - val_loss: 1.5326 - val_accuracy: 0.6426 - val_auc: 0.8673\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7523 - accuracy: 0.5019 - auc: 0.8002 - val_loss: 1.4149 - val_accuracy: 0.5863 - val_auc: 0.8457\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6013 - accuracy: 0.4948 - auc: 0.7760 - val_loss: 1.7782 - val_accuracy: 0.6053 - val_auc: 0.9004\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1194 - accuracy: 0.5123 - auc: 0.8059 - val_loss: 1.2998 - val_accuracy: 0.6175 - val_auc: 0.9190\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6672 - accuracy: 0.5143 - auc: 0.7804 - val_loss: 1.1579 - val_accuracy: 0.6237 - val_auc: 0.8469\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5157 - accuracy: 0.5327 - auc: 0.7969 - val_loss: 1.2809 - val_accuracy: 0.6510 - val_auc: 0.8583\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5128 - accuracy: 0.5577 - auc: 0.8173 - val_loss: 1.1328 - val_accuracy: 0.6625 - val_auc: 0.8730\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5659 - accuracy: 0.5546 - auc: 0.8123 - val_loss: 1.2869 - val_accuracy: 0.6689 - val_auc: 0.8712\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4749 - accuracy: 0.5627 - auc: 0.8286 - val_loss: 1.2556 - val_accuracy: 0.6608 - val_auc: 0.8918\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5896 - accuracy: 0.5533 - auc: 0.8220 - val_loss: 1.4075 - val_accuracy: 0.6657 - val_auc: 0.8673\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6620 - accuracy: 0.5685 - auc: 0.8257 - val_loss: 1.9217 - val_accuracy: 0.6658 - val_auc: 0.8689\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5262 - accuracy: 0.5706 - auc: 0.8252 - val_loss: 1.9157 - val_accuracy: 0.6866 - val_auc: 0.8561\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6230 - accuracy: 0.5592 - auc: 0.8205 - val_loss: 1.9315 - val_accuracy: 0.6834 - val_auc: 0.9147\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8236 - accuracy: 0.5661 - auc: 0.8220 - val_loss: 2.0959 - val_accuracy: 0.6721 - val_auc: 0.8701\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5970 - accuracy: 0.5524 - auc: 0.8086 - val_loss: 1.8852 - val_accuracy: 0.6726 - val_auc: 0.8637\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6838 - accuracy: 0.5568 - auc: 0.8086 - val_loss: 3.0735 - val_accuracy: 0.6763 - val_auc: 0.9069\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6286 - accuracy: 0.5588 - auc: 0.8303 - val_loss: 1.7145 - val_accuracy: 0.6688 - val_auc: 0.8331\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5501 - accuracy: 0.5508 - auc: 0.7814 - val_loss: 1.6557 - val_accuracy: 0.6088 - val_auc: 0.8009\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5453 - accuracy: 0.5503 - auc: 0.7767 - val_loss: 2.7189 - val_accuracy: 0.6530 - val_auc: 0.8123\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5200 - accuracy: 0.5528 - auc: 0.7762 - val_loss: 2.6389 - val_accuracy: 0.6645 - val_auc: 0.8182\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5156 - accuracy: 0.5532 - auc: 0.7811 - val_loss: 2.6171 - val_accuracy: 0.6476 - val_auc: 0.8117\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4883 - accuracy: 0.5492 - auc: 0.7765 - val_loss: 2.6066 - val_accuracy: 0.6549 - val_auc: 0.8144\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5790 - accuracy: 0.5523 - auc: 0.7912 - val_loss: 2.2120 - val_accuracy: 0.6587 - val_auc: 0.8173\n",
      "Epoch 36/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.5534 - auc: 0.7735Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5296 - accuracy: 0.5535 - auc: 0.7739 - val_loss: 1.8822 - val_accuracy: 0.6614 - val_auc: 0.8221\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 7s 29us/sample - loss: 1.3123 - accuracy: 0.7493 - auc: 0.8085 - val_loss: 0.9074 - val_accuracy: 0.8848 - val_auc: 0.9105\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4393 - accuracy: 0.8284 - auc: 0.8371 - val_loss: 0.9702 - val_accuracy: 0.9137 - val_auc: 0.9090\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9287 - accuracy: 0.8150 - auc: 0.8112 - val_loss: 1.0008 - val_accuracy: 0.8338 - val_auc: 0.8842\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4828 - accuracy: 0.7073 - auc: 0.7634 - val_loss: 1.8258 - val_accuracy: 0.6146 - val_auc: 0.8936\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 1.7610 - accuracy: 0.7295 - auc: 0.7543 - val_loss: 1.7063 - val_accuracy: 0.5888 - val_auc: 0.9127\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4726 - accuracy: 0.5818 - auc: 0.7620 - val_loss: 1.2722 - val_accuracy: 0.6224 - val_auc: 0.8548\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7233 - accuracy: 0.5351 - auc: 0.7954 - val_loss: 1.4488 - val_accuracy: 0.6356 - val_auc: 0.8702\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0553 - accuracy: 0.4854 - auc: 0.7469 - val_loss: 1.9518 - val_accuracy: 0.6475 - val_auc: 0.8279\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8866 - accuracy: 0.4787 - auc: 0.7490 - val_loss: 1.8120 - val_accuracy: 0.6223 - val_auc: 0.8359\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7276 - accuracy: 0.4649 - auc: 0.7755 - val_loss: 1.4484 - val_accuracy: 0.5987 - val_auc: 0.8614\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7448 - accuracy: 0.4622 - auc: 0.7858 - val_loss: 1.6982 - val_accuracy: 0.6158 - val_auc: 0.8836\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5646 - accuracy: 0.4941 - auc: 0.8260 - val_loss: 1.2841 - val_accuracy: 0.6481 - val_auc: 0.9338\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5725 - accuracy: 0.4969 - auc: 0.8207 - val_loss: 1.4991 - val_accuracy: 0.6613 - val_auc: 0.8476\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5398 - accuracy: 0.5090 - auc: 0.7745 - val_loss: 1.3728 - val_accuracy: 0.6672 - val_auc: 0.8681\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6407 - accuracy: 0.5116 - auc: 0.7936 - val_loss: 1.3258 - val_accuracy: 0.6759 - val_auc: 0.8849\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4905 - accuracy: 0.5283 - auc: 0.8007 - val_loss: 1.4235 - val_accuracy: 0.6833 - val_auc: 0.8814\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5275 - accuracy: 0.5234 - auc: 0.7914 - val_loss: 1.2448 - val_accuracy: 0.6750 - val_auc: 0.8820\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5198 - accuracy: 0.5218 - auc: 0.7947 - val_loss: 1.2152 - val_accuracy: 0.6608 - val_auc: 0.8800\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4854 - accuracy: 0.5290 - auc: 0.8044 - val_loss: 1.2720 - val_accuracy: 0.6760 - val_auc: 0.8776\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6304 - accuracy: 0.5237 - auc: 0.7957 - val_loss: 1.5640 - val_accuracy: 0.6779 - val_auc: 0.8774\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5427 - accuracy: 0.5640 - auc: 0.8317 - val_loss: 1.9065 - val_accuracy: 0.6767 - val_auc: 0.84862 - accuracy: 0.\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5620 - accuracy: 0.5328 - auc: 0.7962 - val_loss: 1.6082 - val_accuracy: 0.6802 - val_auc: 0.8674\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4360 - accuracy: 0.5482 - auc: 0.8253 - val_loss: 1.5348 - val_accuracy: 0.6942 - val_auc: 0.9139\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5039 - accuracy: 0.5473 - auc: 0.7878 - val_loss: 1.8978 - val_accuracy: 0.6944 - val_auc: 0.8400\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4785 - accuracy: 0.5595 - auc: 0.7823 - val_loss: 2.1069 - val_accuracy: 0.7078 - val_auc: 0.8346\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4955 - accuracy: 0.5657 - auc: 0.7732 - val_loss: 2.3280 - val_accuracy: 0.7112 - val_auc: 0.8435\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4820 - accuracy: 0.5635 - auc: 0.7731 - val_loss: 2.0938 - val_accuracy: 0.7015 - val_auc: 0.8275\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4702 - accuracy: 0.5720 - auc: 0.7909 - val_loss: 2.1588 - val_accuracy: 0.7211 - val_auc: 0.8466\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4581 - accuracy: 0.5789 - auc: 0.7908 - val_loss: 2.2495 - val_accuracy: 0.7331 - val_auc: 0.8479\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4831 - accuracy: 0.5811 - auc: 0.7895 - val_loss: 2.3148 - val_accuracy: 0.7296 - val_auc: 0.8516\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4717 - accuracy: 0.5781 - auc: 0.7905 - val_loss: 2.4794 - val_accuracy: 0.7331 - val_auc: 0.8487\n",
      "Epoch 32/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.4485 - accuracy: 0.5783 - auc: 0.7908Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4471 - accuracy: 0.5784 - auc: 0.7916 - val_loss: 2.3634 - val_accuracy: 0.7261 - val_auc: 0.8463\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.5133 - accuracy: 0.6917 - auc: 0.7836 - val_loss: 0.6238 - val_accuracy: 0.9051 - val_auc: 0.8980\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4716 - accuracy: 0.8255 - auc: 0.8236 - val_loss: 1.1646 - val_accuracy: 0.6675 - val_auc: 0.8780\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5197 - accuracy: 0.8026 - auc: 0.8050 - val_loss: 0.7070 - val_accuracy: 0.8802 - val_auc: 0.9263\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3313 - accuracy: 0.8204 - auc: 0.8190 - val_loss: 1.0523 - val_accuracy: 0.8682 - val_auc: 0.8473\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2684 - accuracy: 0.5667 - auc: 0.7919 - val_loss: 1.5010 - val_accuracy: 0.6378 - val_auc: 0.9045\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1293 - accuracy: 0.7050 - auc: 0.8304 - val_loss: 0.8340 - val_accuracy: 0.6372 - val_auc: 0.9370\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3829 - accuracy: 0.6101 - auc: 0.8004 - val_loss: 1.9162 - val_accuracy: 0.5291 - val_auc: 0.7735\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6666 - accuracy: 0.5325 - auc: 0.7637 - val_loss: 1.7009 - val_accuracy: 0.5470 - val_auc: 0.7809\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2083 - accuracy: 0.5256 - auc: 0.7943 - val_loss: 3.7334 - val_accuracy: 0.6517 - val_auc: 0.8882\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1847 - accuracy: 0.5318 - auc: 0.8078 - val_loss: 3.0084 - val_accuracy: 0.6447 - val_auc: 0.8949\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7283 - accuracy: 0.5417 - auc: 0.8524 - val_loss: 2.7880 - val_accuracy: 0.6580 - val_auc: 0.9356\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7474 - accuracy: 0.5360 - auc: 0.8149 - val_loss: 2.8179 - val_accuracy: 0.6336 - val_auc: 0.8245\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6392 - accuracy: 0.5372 - auc: 0.8091 - val_loss: 3.2074 - val_accuracy: 0.6392 - val_auc: 0.9113\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8312 - accuracy: 0.5539 - auc: 0.8009 - val_loss: 1.6787 - val_accuracy: 0.6554 - val_auc: 0.8333\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6140 - accuracy: 0.5660 - auc: 0.8044 - val_loss: 1.7117 - val_accuracy: 0.6638 - val_auc: 0.8642\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5258 - accuracy: 0.5797 - auc: 0.8148 - val_loss: 1.8026 - val_accuracy: 0.6861 - val_auc: 0.8744\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4852 - accuracy: 0.5974 - auc: 0.8385 - val_loss: 2.3399 - val_accuracy: 0.6847 - val_auc: 0.8943\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4444 - accuracy: 0.6010 - auc: 0.8537 - val_loss: 2.8422 - val_accuracy: 0.7106 - val_auc: 0.9280\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4051 - accuracy: 0.6141 - auc: 0.8701 - val_loss: 3.3640 - val_accuracy: 0.7161 - val_auc: 0.9328\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4893 - accuracy: 0.6102 - auc: 0.8383 - val_loss: 2.1841 - val_accuracy: 0.6940 - val_auc: 0.8721\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4456 - accuracy: 0.6188 - auc: 0.8444 - val_loss: 2.5848 - val_accuracy: 0.7134 - val_auc: 0.8633\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5099 - accuracy: 0.6324 - auc: 0.8261 - val_loss: 1.7513 - val_accuracy: 0.7422 - val_auc: 0.8734\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4943 - accuracy: 0.6400 - auc: 0.8172 - val_loss: 1.5978 - val_accuracy: 0.7349 - val_auc: 0.8584\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4605 - accuracy: 0.6539 - auc: 0.8311 - val_loss: 1.7071 - val_accuracy: 0.7322 - val_auc: 0.8849\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5648 - accuracy: 0.6347 - auc: 0.8414 - val_loss: 3.1210 - val_accuracy: 0.7334 - val_auc: 0.8892\n",
      "Epoch 26/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.8380 - accuracy: 0.6293 - auc: 0.8410Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8375 - accuracy: 0.6292 - auc: 0.8409 - val_loss: 5.1305 - val_accuracy: 0.7150 - val_auc: 0.8878\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 1.8872 - accuracy: 0.7534 - auc: 0.7954 - val_loss: 0.9671 - val_accuracy: 0.7890 - val_auc: 0.8569\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5748 - accuracy: 0.8341 - auc: 0.8414 - val_loss: 0.9264 - val_accuracy: 0.8868 - val_auc: 0.9105\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.4916 - accuracy: 0.8338 - auc: 0.8149 - val_loss: 1.0783 - val_accuracy: 0.8674 - val_auc: 0.8882\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 1.3660 - accuracy: 0.8322 - auc: 0.7937 - val_loss: 1.6566 - val_accuracy: 0.8866 - val_auc: 0.9220\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 1.9804 - accuracy: 0.7653 - auc: 0.7908 - val_loss: 1.7126 - val_accuracy: 0.8432 - val_auc: 0.9154\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7054 - accuracy: 0.7716 - auc: 0.7817 - val_loss: 1.5346 - val_accuracy: 0.9041 - val_auc: 0.9076\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3860 - accuracy: 0.9066 - auc: 0.8026 - val_loss: 1.4472 - val_accuracy: 0.9447 - val_auc: 0.9085\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3255 - accuracy: 0.5642 - auc: 0.7380 - val_loss: 1.3234 - val_accuracy: 0.5257 - val_auc: 0.8343\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9062 - accuracy: 0.4443 - auc: 0.7539 - val_loss: 1.1187 - val_accuracy: 0.5302 - val_auc: 0.8404\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7599 - accuracy: 0.5624 - auc: 0.7867 - val_loss: 1.1924 - val_accuracy: 0.5511 - val_auc: 0.8976\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9854 - accuracy: 0.6189 - auc: 0.8111 - val_loss: 1.8632 - val_accuracy: 0.9299 - val_auc: 0.9238\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8179 - accuracy: 0.8967 - auc: 0.8549 - val_loss: 1.5074 - val_accuracy: 0.9411 - val_auc: 0.9219\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5403 - accuracy: 0.8951 - auc: 0.8589 - val_loss: 2.2589 - val_accuracy: 0.9217 - val_auc: 0.9282\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6485 - accuracy: 0.8832 - auc: 0.8555 - val_loss: 2.0368 - val_accuracy: 0.8853 - val_auc: 0.9237\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9031 - accuracy: 0.9142 - auc: 0.8446 - val_loss: 3.4265 - val_accuracy: 0.9472 - val_auc: 0.9232\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7706 - accuracy: 0.8060 - auc: 0.8429 - val_loss: 2.6859 - val_accuracy: 0.8946 - val_auc: 0.9253\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7818 - accuracy: 0.8057 - auc: 0.8335 - val_loss: 2.1964 - val_accuracy: 0.9234 - val_auc: 0.9218\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4995 - accuracy: 0.8200 - auc: 0.8427 - val_loss: 2.3341 - val_accuracy: 0.9623 - val_auc: 0.9137\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4535 - accuracy: 0.8897 - auc: 0.8450 - val_loss: 2.4794 - val_accuracy: 0.5607 - val_auc: 0.9239\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4890 - accuracy: 0.8598 - auc: 0.8560 - val_loss: 2.8232 - val_accuracy: 0.9509 - val_auc: 0.8811\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6749 - accuracy: 0.4914 - auc: 0.7322 - val_loss: 2.6604 - val_accuracy: 0.5708 - val_auc: 0.7627\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6811 - accuracy: 0.4611 - auc: 0.7264 - val_loss: 2.4995 - val_accuracy: 0.5655 - val_auc: 0.7748\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5152 - accuracy: 0.4464 - auc: 0.7326 - val_loss: 2.5416 - val_accuracy: 0.5677 - val_auc: 0.7782\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5561 - accuracy: 0.4464 - auc: 0.7451 - val_loss: 1.8820 - val_accuracy: 0.5615 - val_auc: 0.7912\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5221 - accuracy: 0.4512 - auc: 0.7342 - val_loss: 2.2432 - val_accuracy: 0.5757 - val_auc: 0.8069\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6395 - accuracy: 0.4595 - auc: 0.7543 - val_loss: 1.6700 - val_accuracy: 0.5930 - val_auc: 0.8273\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4829 - accuracy: 0.4654 - auc: 0.7684 - val_loss: 1.6387 - val_accuracy: 0.5931 - val_auc: 0.8519\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4843 - accuracy: 0.4660 - auc: 0.7841 - val_loss: 1.6026 - val_accuracy: 0.5882 - val_auc: 0.8443\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4638 - accuracy: 0.4856 - auc: 0.7935 - val_loss: 1.5746 - val_accuracy: 0.6610 - val_auc: 0.8640\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5455 - accuracy: 0.4908 - auc: 0.7835 - val_loss: 1.6384 - val_accuracy: 0.6131 - val_auc: 0.8327\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5017 - accuracy: 0.4793 - auc: 0.7706 - val_loss: 1.3305 - val_accuracy: 0.6138 - val_auc: 0.8399curacy: 0.4784 - a\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4790 - accuracy: 0.4907 - auc: 0.7833 - val_loss: 1.3978 - val_accuracy: 0.6313 - val_auc: 0.8468\n",
      "Epoch 33/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.4670 - accuracy: 0.5011 - auc: 0.7866Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4673 - accuracy: 0.5010 - auc: 0.7861 - val_loss: 1.2347 - val_accuracy: 0.6322 - val_auc: 0.8548\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 4s 15us/sample - loss: 1.7047 - accuracy: 0.7583 - auc: 0.7887 - val_loss: 0.7330 - val_accuracy: 0.8284 - val_auc: 0.9056\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4307 - accuracy: 0.8238 - auc: 0.8474 - val_loss: 1.3408 - val_accuracy: 0.9479 - val_auc: 0.8955\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5704 - accuracy: 0.8390 - auc: 0.8513 - val_loss: 1.7518 - val_accuracy: 0.9337 - val_auc: 0.8967\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.6107 - accuracy: 0.8252 - auc: 0.8132 - val_loss: 2.8073 - val_accuracy: 0.9761 - val_auc: 0.7837\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8180 - accuracy: 0.8223 - auc: 0.8163 - val_loss: 1.2764 - val_accuracy: 0.9016 - val_auc: 0.8864\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7952 - accuracy: 0.8705 - auc: 0.8427 - val_loss: 1.4316 - val_accuracy: 0.8573 - val_auc: 0.9057\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1007 - accuracy: 0.8338 - auc: 0.8371 - val_loss: 1.8216 - val_accuracy: 0.5965 - val_auc: 0.8897\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4331 - accuracy: 0.6775 - auc: 0.8090 - val_loss: 1.3377 - val_accuracy: 0.5591 - val_auc: 0.8892\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2249 - accuracy: 0.4818 - auc: 0.7740 - val_loss: 2.2907 - val_accuracy: 0.5944 - val_auc: 0.8508\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9765 - accuracy: 0.6278 - auc: 0.8325 - val_loss: 1.0467 - val_accuracy: 0.9085 - val_auc: 0.8663\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6762 - accuracy: 0.7410 - auc: 0.8403 - val_loss: 1.3702 - val_accuracy: 0.5903 - val_auc: 0.8646\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6229 - accuracy: 0.4472 - auc: 0.7444 - val_loss: 3.1182 - val_accuracy: 0.5388 - val_auc: 0.8289\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.6732 - accuracy: 0.5577 - auc: 0.7733 - val_loss: 2.4559 - val_accuracy: 0.5849 - val_auc: 0.9204\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6324 - accuracy: 0.7008 - auc: 0.8310 - val_loss: 2.3675 - val_accuracy: 0.9462 - val_auc: 0.9130\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2367 - accuracy: 0.7745 - auc: 0.8338 - val_loss: 2.7363 - val_accuracy: 0.8734 - val_auc: 0.7334\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0139 - accuracy: 0.6284 - auc: 0.7964 - val_loss: 3.0372 - val_accuracy: 0.6037 - val_auc: 0.8663 loss: 1.1501 - accuracy: 0.68\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2779 - accuracy: 0.5178 - auc: 0.7669 - val_loss: 3.4424 - val_accuracy: 0.5791 - val_auc: 0.9150\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4523 - accuracy: 0.5212 - auc: 0.7598 - val_loss: 2.2058 - val_accuracy: 0.5407 - val_auc: 0.8415\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9782 - accuracy: 0.4826 - auc: 0.7527 - val_loss: 2.1217 - val_accuracy: 0.5318 - val_auc: 0.8473\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6275 - accuracy: 0.4634 - auc: 0.7689 - val_loss: 2.0876 - val_accuracy: 0.5458 - val_auc: 0.8585\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6752 - accuracy: 0.6072 - auc: 0.8066 - val_loss: 2.3385 - val_accuracy: 0.9374 - val_auc: 0.9315\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0529 - accuracy: 0.7459 - auc: 0.8322 - val_loss: 2.2973 - val_accuracy: 0.5339 - val_auc: 0.8292\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7140 - accuracy: 0.5908 - auc: 0.8042 - val_loss: 2.8211 - val_accuracy: 0.9389 - val_auc: 0.9316\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5366 - accuracy: 0.8246 - auc: 0.8352 - val_loss: 2.9595 - val_accuracy: 0.5834 - val_auc: 0.9277\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6799 - accuracy: 0.7389 - auc: 0.8306 - val_loss: 2.4460 - val_accuracy: 0.9396 - val_auc: 0.9295\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0302 - accuracy: 0.7525 - auc: 0.8250 - val_loss: 2.3115 - val_accuracy: 0.5731 - val_auc: 0.7747\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6950 - accuracy: 0.4419 - auc: 0.7222 - val_loss: 2.7829 - val_accuracy: 0.6007 - val_auc: 0.7930\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7100 - accuracy: 0.4922 - auc: 0.7481 - val_loss: 3.0586 - val_accuracy: 0.6590 - val_auc: 0.8096\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9259 - accuracy: 0.4853 - auc: 0.7331 - val_loss: 3.3908 - val_accuracy: 0.5885 - val_auc: 0.7735\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7653 - accuracy: 0.4722 - auc: 0.7297 - val_loss: 3.9964 - val_accuracy: 0.6146 - val_auc: 0.7982\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6186 - accuracy: 0.4697 - auc: 0.7405 - val_loss: 4.1871 - val_accuracy: 0.6153 - val_auc: 0.7966\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5575 - accuracy: 0.4839 - auc: 0.7652 - val_loss: 4.2186 - val_accuracy: 0.6222 - val_auc: 0.8426\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5339 - accuracy: 0.4884 - auc: 0.7782 - val_loss: 4.2122 - val_accuracy: 0.6190 - val_auc: 0.8410\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8927 - accuracy: 0.4825 - auc: 0.7686 - val_loss: 4.4740 - val_accuracy: 0.6265 - val_auc: 0.8589\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6037 - accuracy: 0.5006 - auc: 0.7938 - val_loss: 3.9618 - val_accuracy: 0.6534 - val_auc: 0.8885\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7685 - accuracy: 0.4982 - auc: 0.7531 - val_loss: 5.1179 - val_accuracy: 0.6268 - val_auc: 0.7981\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5733 - accuracy: 0.4925 - auc: 0.7414 - val_loss: 6.1340 - val_accuracy: 0.6303 - val_auc: 0.8002\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5509 - accuracy: 0.4997 - auc: 0.7552 - val_loss: 5.9691 - val_accuracy: 0.6213 - val_auc: 0.7944\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5538 - accuracy: 0.5045 - auc: 0.7525 - val_loss: 6.2042 - val_accuracy: 0.6352 - val_auc: 0.7959\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6006 - accuracy: 0.5160 - auc: 0.7481 - val_loss: 5.4086 - val_accuracy: 0.6448 - val_auc: 0.8079\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5649 - accuracy: 0.5100 - auc: 0.7513 - val_loss: 3.9786 - val_accuracy: 0.6403 - val_auc: 0.8085\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5836 - accuracy: 0.5059 - auc: 0.7484 - val_loss: 3.4535 - val_accuracy: 0.6364 - val_auc: 0.8067\n",
      "Epoch 43/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.5104 - auc: 0.7576Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5327 - accuracy: 0.5106 - auc: 0.7575 - val_loss: 3.7981 - val_accuracy: 0.6539 - val_auc: 0.8126\n",
      "Epoch 00043: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 2.4534 - accuracy: 0.7166 - auc: 0.7944 - val_loss: 1.5779 - val_accuracy: 0.7172 - val_auc: 0.8876\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9414 - accuracy: 0.8078 - auc: 0.8299 - val_loss: 1.8359 - val_accuracy: 0.8550 - val_auc: 0.9180\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.6411 - accuracy: 0.8238 - auc: 0.8492 - val_loss: 2.9143 - val_accuracy: 0.9001 - val_auc: 0.8964\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.4076 - accuracy: 0.8195 - auc: 0.8361 - val_loss: 3.7110 - val_accuracy: 0.9050 - val_auc: 0.8843\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.6948 - accuracy: 0.8443 - auc: 0.8094 - val_loss: 1.4345 - val_accuracy: 0.7963 - val_auc: 0.8550\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0803 - accuracy: 0.8626 - auc: 0.8388 - val_loss: 2.6925 - val_accuracy: 0.8948 - val_auc: 0.9130\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.7506 - accuracy: 0.7866 - auc: 0.8090 - val_loss: 1.4109 - val_accuracy: 0.4648 - val_auc: 0.8077\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.6661 - accuracy: 0.7759 - auc: 0.7905 - val_loss: 2.3821 - val_accuracy: 0.5382 - val_auc: 0.8488\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3744 - accuracy: 0.7937 - auc: 0.8374 - val_loss: 2.5222 - val_accuracy: 0.5542 - val_auc: 0.9329\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7894 - accuracy: 0.8421 - auc: 0.8544 - val_loss: 2.2947 - val_accuracy: 0.9238 - val_auc: 0.9282\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1816 - accuracy: 0.8423 - auc: 0.8627 - val_loss: 2.4120 - val_accuracy: 0.8998 - val_auc: 0.9358\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9527 - accuracy: 0.8326 - auc: 0.8410 - val_loss: 2.1905 - val_accuracy: 0.5519 - val_auc: 0.8776\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0281 - accuracy: 0.6178 - auc: 0.8134 - val_loss: 1.1296 - val_accuracy: 0.9054 - val_auc: 0.9404\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7180 - accuracy: 0.8509 - auc: 0.8426 - val_loss: 1.2193 - val_accuracy: 0.9091 - val_auc: 0.9423\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8705 - accuracy: 0.7037 - auc: 0.8516 - val_loss: 1.9484 - val_accuracy: 0.9213 - val_auc: 0.9352\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7952 - accuracy: 0.6973 - auc: 0.8577 - val_loss: 2.1478 - val_accuracy: 0.9187 - val_auc: 0.9343\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7338 - accuracy: 0.5939 - auc: 0.8445 - val_loss: 2.1667 - val_accuracy: 0.9181 - val_auc: 0.9352\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5992 - accuracy: 0.6087 - auc: 0.8494 - val_loss: 2.7559 - val_accuracy: 0.6188 - val_auc: 0.8916\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5377 - accuracy: 0.5333 - auc: 0.8248 - val_loss: 2.5260 - val_accuracy: 0.6191 - val_auc: 0.8993\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5325 - accuracy: 0.5835 - auc: 0.8588 - val_loss: 2.2373 - val_accuracy: 0.9246 - val_auc: 0.9364\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7039 - accuracy: 0.5667 - auc: 0.7971 - val_loss: 2.0307 - val_accuracy: 0.6034 - val_auc: 0.8035\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6871 - accuracy: 0.5045 - auc: 0.7561 - val_loss: 2.8716 - val_accuracy: 0.6207 - val_auc: 0.8066\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5705 - accuracy: 0.5191 - auc: 0.7663 - val_loss: 3.0689 - val_accuracy: 0.6350 - val_auc: 0.8471\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6328 - accuracy: 0.5352 - auc: 0.7921 - val_loss: 2.9290 - val_accuracy: 0.6408 - val_auc: 0.8390\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5531 - accuracy: 0.5238 - auc: 0.7982 - val_loss: 3.2879 - val_accuracy: 0.6511 - val_auc: 0.7972\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5698 - accuracy: 0.5263 - auc: 0.7951 - val_loss: 2.4207 - val_accuracy: 0.6408 - val_auc: 0.8457\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5127 - accuracy: 0.5211 - auc: 0.8011 - val_loss: 1.8705 - val_accuracy: 0.6476 - val_auc: 0.8550\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4775 - accuracy: 0.5270 - auc: 0.7994 - val_loss: 2.0203 - val_accuracy: 0.6456 - val_auc: 0.7541\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4500 - accuracy: 0.5336 - auc: 0.8316 - val_loss: 1.8994 - val_accuracy: 0.6593 - val_auc: 0.8947\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4580 - accuracy: 0.5425 - auc: 0.8215 - val_loss: 2.0168 - val_accuracy: 0.6776 - val_auc: 0.8648\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5548 - accuracy: 0.5496 - auc: 0.8170 - val_loss: 2.3816 - val_accuracy: 0.6702 - val_auc: 0.8116\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5770 - accuracy: 0.5638 - auc: 0.7761 - val_loss: 3.1934 - val_accuracy: 0.6961 - val_auc: 0.8277\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5345 - accuracy: 0.5602 - auc: 0.7849 - val_loss: 3.8294 - val_accuracy: 0.6822 - val_auc: 0.8229\n",
      "Epoch 34/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.5333 - accuracy: 0.5460 - auc: 0.7716Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5317 - accuracy: 0.5461 - auc: 0.7716 - val_loss: 3.5182 - val_accuracy: 0.6705 - val_auc: 0.8189\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 1.9758 - accuracy: 0.7310 - auc: 0.7964 - val_loss: 1.3249 - val_accuracy: 0.7745 - val_auc: 0.8608\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0357 - accuracy: 0.7994 - auc: 0.8234 - val_loss: 1.6897 - val_accuracy: 0.8067 - val_auc: 0.9107\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.7726 - accuracy: 0.8069 - auc: 0.8355 - val_loss: 1.4382 - val_accuracy: 0.8016 - val_auc: 0.8237\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9131 - accuracy: 0.8192 - auc: 0.8208 - val_loss: 3.8942 - val_accuracy: 0.9159 - val_auc: 0.8815\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.0954 - accuracy: 0.8142 - auc: 0.8255 - val_loss: 3.3774 - val_accuracy: 0.9141 - val_auc: 0.9172\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.4131 - accuracy: 0.8697 - auc: 0.8169 - val_loss: 2.6650 - val_accuracy: 0.9095 - val_auc: 0.8563\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9986 - accuracy: 0.6360 - auc: 0.7892 - val_loss: 2.9747 - val_accuracy: 0.8810 - val_auc: 0.8652\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.2137 - accuracy: 0.7121 - auc: 0.8077 - val_loss: 3.9864 - val_accuracy: 0.6178 - val_auc: 0.9167\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.1268 - accuracy: 0.8085 - auc: 0.8274 - val_loss: 3.2214 - val_accuracy: 0.9175 - val_auc: 0.9021\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9410 - accuracy: 0.5827 - auc: 0.8081 - val_loss: 3.6657 - val_accuracy: 0.5857 - val_auc: 0.8336\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0544 - accuracy: 0.6264 - auc: 0.8197 - val_loss: 4.0292 - val_accuracy: 0.5947 - val_auc: 0.8743\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3875 - accuracy: 0.6311 - auc: 0.8419 - val_loss: 4.1706 - val_accuracy: 0.6108 - val_auc: 0.8570\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8120 - accuracy: 0.5280 - auc: 0.8181 - val_loss: 4.4055 - val_accuracy: 0.5923 - val_auc: 0.8553\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8195 - accuracy: 0.4896 - auc: 0.8181 - val_loss: 4.4432 - val_accuracy: 0.5724 - val_auc: 0.8338\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7357 - accuracy: 0.5320 - auc: 0.8285 - val_loss: 4.8285 - val_accuracy: 0.6065 - val_auc: 0.8691\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6312 - accuracy: 0.4964 - auc: 0.8172 - val_loss: 5.0970 - val_accuracy: 0.6080 - val_auc: 0.8625\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5874 - accuracy: 0.5060 - auc: 0.8195 - val_loss: 3.8155 - val_accuracy: 0.6210 - val_auc: 0.8626\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5871 - accuracy: 0.5197 - auc: 0.8386 - val_loss: 4.2024 - val_accuracy: 0.6406 - val_auc: 0.8265\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6392 - accuracy: 0.5551 - auc: 0.8263 - val_loss: 4.6240 - val_accuracy: 0.6430 - val_auc: 0.8697\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5294 - accuracy: 0.5432 - auc: 0.8475 - val_loss: 4.8510 - val_accuracy: 0.6665 - val_auc: 0.9269\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5512 - accuracy: 0.5357 - auc: 0.8404 - val_loss: 4.2009 - val_accuracy: 0.6342 - val_auc: 0.8689\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5867 - accuracy: 0.5275 - auc: 0.8355 - val_loss: 3.5905 - val_accuracy: 0.5886 - val_auc: 0.8571\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5319 - accuracy: 0.5655 - auc: 0.8437 - val_loss: 3.9727 - val_accuracy: 0.6266 - val_auc: 0.9201\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3964 - accuracy: 0.5439 - auc: 0.8387 - val_loss: 8.9703 - val_accuracy: 0.6434 - val_auc: 0.9185\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6374 - accuracy: 0.6428 - auc: 0.8720 - val_loss: 9.4319 - val_accuracy: 0.6494 - val_auc: 0.8941\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7831 - accuracy: 0.5410 - auc: 0.8468 - val_loss: 9.5435 - val_accuracy: 0.9829 - val_auc: 0.8404\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7575 - accuracy: 0.5341 - auc: 0.7706 - val_loss: 10.2776 - val_accuracy: 0.6129 - val_auc: 0.8446\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.6091 - accuracy: 0.4980 - auc: 0.8006 - val_loss: 9.3351 - val_accuracy: 0.6080 - val_auc: 0.8469\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5499 - accuracy: 0.4948 - auc: 0.8014 - val_loss: 7.8538 - val_accuracy: 0.6131 - val_auc: 0.8667\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5022 - accuracy: 0.5029 - auc: 0.8094 - val_loss: 6.1016 - val_accuracy: 0.6090 - val_auc: 0.8720\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4570 - accuracy: 0.5072 - auc: 0.8311 - val_loss: 6.7098 - val_accuracy: 0.6259 - val_auc: 0.9127\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4763 - accuracy: 0.5127 - auc: 0.7818 - val_loss: 6.7592 - val_accuracy: 0.6330 - val_auc: 0.8478\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4840 - accuracy: 0.5167 - auc: 0.8016 - val_loss: 6.2277 - val_accuracy: 0.6243 - val_auc: 0.8623\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4706 - accuracy: 0.5184 - auc: 0.8040 - val_loss: 6.3218 - val_accuracy: 0.6349 - val_auc: 0.8755\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4805 - accuracy: 0.5233 - auc: 0.8108 - val_loss: 7.4518 - val_accuracy: 0.6434 - val_auc: 0.8077\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4710 - accuracy: 0.5313 - auc: 0.7618 - val_loss: 7.6087 - val_accuracy: 0.6605 - val_auc: 0.8290\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4642 - accuracy: 0.5400 - auc: 0.7967 - val_loss: 6.6765 - val_accuracy: 0.6640 - val_auc: 0.8482\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4488 - accuracy: 0.5445 - auc: 0.8031 - val_loss: 6.4122 - val_accuracy: 0.6630 - val_auc: 0.8539\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4460 - accuracy: 0.5466 - auc: 0.8182 - val_loss: 5.6662 - val_accuracy: 0.6753 - val_auc: 0.9019\n",
      "Epoch 40/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.5466 - auc: 0.7984Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4847 - accuracy: 0.5466 - auc: 0.7977 - val_loss: 5.4026 - val_accuracy: 0.6684 - val_auc: 0.8174\n",
      "Epoch 00040: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 2.3363 - accuracy: 0.6811 - auc: 0.7858 - val_loss: 1.3131 - val_accuracy: 0.9255 - val_auc: 0.9035\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.6324 - accuracy: 0.7964 - auc: 0.8313 - val_loss: 1.5270 - val_accuracy: 0.9035 - val_auc: 0.9135\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.6769 - accuracy: 0.7944 - auc: 0.8176 - val_loss: 2.1859 - val_accuracy: 0.8702 - val_auc: 0.8889\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8006 - accuracy: 0.8504 - auc: 0.8368 - val_loss: 1.6581 - val_accuracy: 0.8783 - val_auc: 0.8974\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5577 - accuracy: 0.8557 - auc: 0.8481 - val_loss: 1.3996 - val_accuracy: 0.8923 - val_auc: 0.9280\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9860 - accuracy: 0.8658 - auc: 0.8475 - val_loss: 1.9610 - val_accuracy: 0.8763 - val_auc: 0.9219\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.6409 - accuracy: 0.8598 - auc: 0.8430 - val_loss: 3.6642 - val_accuracy: 0.9093 - val_auc: 0.9000\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4649 - accuracy: 0.8353 - auc: 0.8467 - val_loss: 2.2409 - val_accuracy: 0.8128 - val_auc: 0.8753\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.8403 - accuracy: 0.8959 - auc: 0.8445 - val_loss: 3.2052 - val_accuracy: 0.8878 - val_auc: 0.8906\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.6890 - accuracy: 0.8207 - auc: 0.8178 - val_loss: 4.9691 - val_accuracy: 0.8906 - val_auc: 0.8968\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5300 - accuracy: 0.7998 - auc: 0.8119 - val_loss: 4.6355 - val_accuracy: 0.5545 - val_auc: 0.8696\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2114 - accuracy: 0.6843 - auc: 0.8133 - val_loss: 5.0058 - val_accuracy: 0.5620 - val_auc: 0.8973\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5908 - accuracy: 0.6437 - auc: 0.7958 - val_loss: 3.4443 - val_accuracy: 0.5423 - val_auc: 0.8420\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9789 - accuracy: 0.5319 - auc: 0.7996 - val_loss: 3.7256 - val_accuracy: 0.5681 - val_auc: 0.8871\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0028 - accuracy: 0.4766 - auc: 0.7975 - val_loss: 3.3320 - val_accuracy: 0.6199 - val_auc: 0.8699\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7826 - accuracy: 0.5174 - auc: 0.8067 - val_loss: 3.5295 - val_accuracy: 0.5652 - val_auc: 0.8855\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9830 - accuracy: 0.4988 - auc: 0.8314 - val_loss: 2.6683 - val_accuracy: 0.5826 - val_auc: 0.9114\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5962 - accuracy: 0.5161 - auc: 0.8334 - val_loss: 3.8440 - val_accuracy: 0.5799 - val_auc: 0.9054\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7212 - accuracy: 0.7463 - auc: 0.8574 - val_loss: 3.1696 - val_accuracy: 0.5789 - val_auc: 0.9190\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5492 - accuracy: 0.6154 - auc: 0.8439 - val_loss: 4.3893 - val_accuracy: 0.6258 - val_auc: 0.9119\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8999 - accuracy: 0.5308 - auc: 0.8412 - val_loss: 3.2117 - val_accuracy: 0.9470 - val_auc: 0.8742\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9353 - accuracy: 0.5225 - auc: 0.7705 - val_loss: 4.2446 - val_accuracy: 0.6073 - val_auc: 0.8442\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6053 - accuracy: 0.5017 - auc: 0.7817 - val_loss: 5.3251 - val_accuracy: 0.6023 - val_auc: 0.7239\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6484 - accuracy: 0.5021 - auc: 0.7754 - val_loss: 5.2104 - val_accuracy: 0.5991 - val_auc: 0.8372\n",
      "Epoch 25/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 1.0484 - accuracy: 0.4968 - auc: 0.7449Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0473 - accuracy: 0.4968 - auc: 0.7449 - val_loss: 4.0577 - val_accuracy: 0.5884 - val_auc: 0.7890\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 2.3195 - accuracy: 0.7205 - auc: 0.7975 - val_loss: 1.3579 - val_accuracy: 0.8676 - val_auc: 0.9164\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.9592 - accuracy: 0.7951 - auc: 0.8254 - val_loss: 1.6454 - val_accuracy: 0.7864 - val_auc: 0.8862\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.3727 - accuracy: 0.8035 - auc: 0.8277 - val_loss: 1.5963 - val_accuracy: 0.8254 - val_auc: 0.9028\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.9539 - accuracy: 0.8360 - auc: 0.8370 - val_loss: 3.1034 - val_accuracy: 0.8764 - val_auc: 0.9122\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.7733 - accuracy: 0.8366 - auc: 0.8396 - val_loss: 1.6366 - val_accuracy: 0.5742 - val_auc: 0.8816\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9977 - accuracy: 0.8544 - auc: 0.8515 - val_loss: 1.8474 - val_accuracy: 0.7620 - val_auc: 0.8058\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.2931 - accuracy: 0.7802 - auc: 0.7941 - val_loss: 3.6901 - val_accuracy: 0.8720 - val_auc: 0.8823\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.2191 - accuracy: 0.7916 - auc: 0.8107 - val_loss: 2.3426 - val_accuracy: 0.8913 - val_auc: 0.8977\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.3448 - accuracy: 0.8436 - auc: 0.8571 - val_loss: 2.9978 - val_accuracy: 0.5582 - val_auc: 0.9251\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.6938 - accuracy: 0.6553 - auc: 0.8124 - val_loss: 3.6263 - val_accuracy: 0.9146 - val_auc: 0.8982\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.3241 - accuracy: 0.6044 - auc: 0.8074 - val_loss: 3.1878 - val_accuracy: 0.5459 - val_auc: 0.8477\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1476 - accuracy: 0.5194 - auc: 0.8122 - val_loss: 4.4590 - val_accuracy: 0.5617 - val_auc: 0.8541\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.1514 - accuracy: 0.6476 - auc: 0.8140 - val_loss: 6.3912 - val_accuracy: 0.5345 - val_auc: 0.8338\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.8249 - accuracy: 0.5424 - auc: 0.7797 - val_loss: 6.7786 - val_accuracy: 0.5730 - val_auc: 0.8594\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.8659 - accuracy: 0.6637 - auc: 0.8208 - val_loss: 6.1200 - val_accuracy: 0.9401 - val_auc: 0.9047\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7292 - accuracy: 0.5803 - auc: 0.8276 - val_loss: 5.4044 - val_accuracy: 0.9166 - val_auc: 0.9103\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2702 - accuracy: 0.5820 - auc: 0.8193 - val_loss: 5.0652 - val_accuracy: 0.5624 - val_auc: 0.8938\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5811 - accuracy: 0.5031 - auc: 0.7910 - val_loss: 5.6770 - val_accuracy: 0.9047 - val_auc: 0.8369\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8580 - accuracy: 0.6143 - auc: 0.8127 - val_loss: 7.7502 - val_accuracy: 0.5477 - val_auc: 0.8457\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 10.1267 - accuracy: 0.5172 - auc: 0.7937 - val_loss: 6.2807 - val_accuracy: 0.9508 - val_auc: 0.8564\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.6208 - accuracy: 0.5177 - auc: 0.7844 - val_loss: 7.6048 - val_accuracy: 0.5607 - val_auc: 0.8325\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 4.2621 - accuracy: 0.5671 - auc: 0.7823 - val_loss: 7.0052 - val_accuracy: 0.5608 - val_auc: 0.9204\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.1036 - accuracy: 0.6046 - auc: 0.8364 - val_loss: 7.1373 - val_accuracy: 0.9059 - val_auc: 0.9278\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5094 - accuracy: 0.7339 - auc: 0.8450 - val_loss: 7.1694 - val_accuracy: 0.5645 - val_auc: 0.9247\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0578 - accuracy: 0.6001 - auc: 0.8180 - val_loss: 7.3733 - val_accuracy: 0.9453 - val_auc: 0.8981\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 6.0218 - accuracy: 0.5506 - auc: 0.8115 - val_loss: 5.7831 - val_accuracy: 0.5574 - val_auc: 0.9121\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8057 - accuracy: 0.6845 - auc: 0.8310 - val_loss: 5.9333 - val_accuracy: 0.9203 - val_auc: 0.9266\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 10us/sample - loss: 2.3348 - accuracy: 0.4927 - auc: 0.7838 - val_loss: 5.2595 - val_accuracy: 0.5549 - val_auc: 0.8164\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9480 - accuracy: 0.4363 - auc: 0.7233 - val_loss: 5.8780 - val_accuracy: 0.5587 - val_auc: 0.7778\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.6258 - accuracy: 0.4476 - auc: 0.7232 - val_loss: 6.1099 - val_accuracy: 0.5675 - val_auc: 0.7784\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1195 - accuracy: 0.4593 - auc: 0.7401 - val_loss: 6.4670 - val_accuracy: 0.5706 - val_auc: 0.7821\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8707 - accuracy: 0.4552 - auc: 0.7332 - val_loss: 6.6546 - val_accuracy: 0.5741 - val_auc: 0.7798\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2001 - accuracy: 0.4655 - auc: 0.7403 - val_loss: 7.4775 - val_accuracy: 0.5838 - val_auc: 0.8032\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2856 - accuracy: 0.4721 - auc: 0.7444 - val_loss: 7.7739 - val_accuracy: 0.5800 - val_auc: 0.7833\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0066 - accuracy: 0.4845 - auc: 0.7460 - val_loss: 8.1708 - val_accuracy: 0.6086 - val_auc: 0.7948\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.3529 - accuracy: 0.4928 - auc: 0.7443 - val_loss: 8.1531 - val_accuracy: 0.6141 - val_auc: 0.7848\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.8257 - accuracy: 0.4938 - auc: 0.7382 - val_loss: 7.8377 - val_accuracy: 0.5976 - val_auc: 0.7848\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.2446 - accuracy: 0.4963 - auc: 0.7609 - val_loss: 7.8771 - val_accuracy: 0.6056 - val_auc: 0.7878\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.6430 - accuracy: 0.4949 - auc: 0.7505 - val_loss: 8.5449 - val_accuracy: 0.6103 - val_auc: 0.7881\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.9009 - accuracy: 0.4986 - auc: 0.7497 - val_loss: 5.9112 - val_accuracy: 0.6084 - val_auc: 0.7960\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7387 - accuracy: 0.5050 - auc: 0.7596 - val_loss: 6.8446 - val_accuracy: 0.6313 - val_auc: 0.8223\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2937 - accuracy: 0.5141 - auc: 0.7550 - val_loss: 7.2366 - val_accuracy: 0.6343 - val_auc: 0.8206\n",
      "Epoch 43/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.9618 - accuracy: 0.5166 - auc: 0.7646Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9614 - accuracy: 0.5166 - auc: 0.7643 - val_loss: 7.8007 - val_accuracy: 0.6114 - val_auc: 0.8061\n",
      "Epoch 00043: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 2.2222 - accuracy: 0.7101 - auc: 0.8000 - val_loss: 1.3641 - val_accuracy: 0.8382 - val_auc: 0.9068\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.4632 - accuracy: 0.8056 - auc: 0.8360 - val_loss: 2.3037 - val_accuracy: 0.7027 - val_auc: 0.8185\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.1271 - accuracy: 0.8116 - auc: 0.8404 - val_loss: 1.6149 - val_accuracy: 0.8653 - val_auc: 0.9038\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8778 - accuracy: 0.8425 - auc: 0.8582 - val_loss: 1.8909 - val_accuracy: 0.7914 - val_auc: 0.9207\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.2198 - accuracy: 0.8586 - auc: 0.8565 - val_loss: 1.6927 - val_accuracy: 0.8560 - val_auc: 0.9153\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 5.0348 - accuracy: 0.7076 - auc: 0.7726 - val_loss: 3.4819 - val_accuracy: 0.6003 - val_auc: 0.8297\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9826 - accuracy: 0.5206 - auc: 0.7819 - val_loss: 2.7936 - val_accuracy: 0.6128 - val_auc: 0.8151\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 2.6501 - accuracy: 0.4888 - auc: 0.7512 - val_loss: 2.8018 - val_accuracy: 0.4781 - val_auc: 0.7685\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8071 - accuracy: 0.5575 - auc: 0.7614 - val_loss: 3.5731 - val_accuracy: 0.5906 - val_auc: 0.8202\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.3290 - accuracy: 0.5025 - auc: 0.7667 - val_loss: 2.4351 - val_accuracy: 0.5328 - val_auc: 0.7908\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.2868 - accuracy: 0.5086 - auc: 0.7759 - val_loss: 4.3118 - val_accuracy: 0.5735 - val_auc: 0.8165\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.5850 - accuracy: 0.5057 - auc: 0.7716 - val_loss: 6.2543 - val_accuracy: 0.5976 - val_auc: 0.8293\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2279 - accuracy: 0.5140 - auc: 0.7830 - val_loss: 5.8714 - val_accuracy: 0.5999 - val_auc: 0.8433\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0459 - accuracy: 0.5067 - auc: 0.7900 - val_loss: 5.1765 - val_accuracy: 0.5942 - val_auc: 0.8661\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 1.0741 - accuracy: 0.5079 - auc: 0.8113 - val_loss: 4.5066 - val_accuracy: 0.6032 - val_auc: 0.9081\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3380 - accuracy: 0.5271 - auc: 0.8219 - val_loss: 4.9242 - val_accuracy: 0.6087 - val_auc: 0.9158\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8604 - accuracy: 0.5617 - auc: 0.8460 - val_loss: 4.7432 - val_accuracy: 0.6059 - val_auc: 0.9180\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.8981 - accuracy: 0.5283 - auc: 0.7687 - val_loss: 4.1181 - val_accuracy: 0.5739 - val_auc: 0.7930\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1399 - accuracy: 0.4944 - auc: 0.7764 - val_loss: 7.1299 - val_accuracy: 0.5969 - val_auc: 0.8331\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7876 - accuracy: 0.5059 - auc: 0.7859 - val_loss: 7.6839 - val_accuracy: 0.5996 - val_auc: 0.8494\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7124 - accuracy: 0.5034 - auc: 0.7891 - val_loss: 8.1372 - val_accuracy: 0.5973 - val_auc: 0.8163\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8011 - accuracy: 0.4940 - auc: 0.7956 - val_loss: 8.2263 - val_accuracy: 0.5829 - val_auc: 0.8405\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8096 - accuracy: 0.4919 - auc: 0.7931 - val_loss: 6.1073 - val_accuracy: 0.5927 - val_auc: 0.8500\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4701 - accuracy: 0.5758 - auc: 0.8281 - val_loss: 7.3812 - val_accuracy: 0.6092 - val_auc: 0.9225\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5449 - accuracy: 0.5361 - auc: 0.8411 - val_loss: 8.0923 - val_accuracy: 0.6066 - val_auc: 0.9171\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8434 - accuracy: 0.5474 - auc: 0.8421 - val_loss: 7.6895 - val_accuracy: 0.5846 - val_auc: 0.9173\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3947 - accuracy: 0.5205 - auc: 0.8073 - val_loss: 7.2774 - val_accuracy: 0.5714 - val_auc: 0.7669\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9731 - accuracy: 0.4911 - auc: 0.7426 - val_loss: 7.2806 - val_accuracy: 0.5808 - val_auc: 0.7757\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2792 - accuracy: 0.4906 - auc: 0.7479 - val_loss: 6.2252 - val_accuracy: 0.5987 - val_auc: 0.7912\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6760 - accuracy: 0.5075 - auc: 0.7546 - val_loss: 6.2632 - val_accuracy: 0.5759 - val_auc: 0.7760\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5901 - accuracy: 0.5095 - auc: 0.7622 - val_loss: 6.0985 - val_accuracy: 0.5810 - val_auc: 0.7780\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6185 - accuracy: 0.5030 - auc: 0.7519 - val_loss: 5.9832 - val_accuracy: 0.5861 - val_auc: 0.7731\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.6384 - accuracy: 0.5080 - auc: 0.7580 - val_loss: 6.2438 - val_accuracy: 0.5963 - val_auc: 0.7804\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5241 - accuracy: 0.5171 - auc: 0.7557 - val_loss: 6.8688 - val_accuracy: 0.6058 - val_auc: 0.7809\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5624 - accuracy: 0.5302 - auc: 0.7672 - val_loss: 6.7140 - val_accuracy: 0.6164 - val_auc: 0.7907\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5082 - accuracy: 0.5308 - auc: 0.7628 - val_loss: 5.9036 - val_accuracy: 0.6090 - val_auc: 0.7859\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5738 - accuracy: 0.5321 - auc: 0.7613 - val_loss: 4.9319 - val_accuracy: 0.6209 - val_auc: 0.7859\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5073 - accuracy: 0.5426 - auc: 0.7743 - val_loss: 5.0237 - val_accuracy: 0.6325 - val_auc: 0.8214\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.4618 - accuracy: 0.5614 - auc: 0.7980 - val_loss: 5.1350 - val_accuracy: 0.6494 - val_auc: 0.8090\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7156 - accuracy: 0.5631 - auc: 0.7690 - val_loss: 5.5836 - val_accuracy: 0.6656 - val_auc: 0.8124\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4940 - accuracy: 0.5805 - auc: 0.7853 - val_loss: 6.6288 - val_accuracy: 0.6797 - val_auc: 0.8265\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8914 - accuracy: 0.5555 - auc: 0.7828 - val_loss: 7.3125 - val_accuracy: 0.6344 - val_auc: 0.7946\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8373 - accuracy: 0.5403 - auc: 0.7709 - val_loss: 7.8183 - val_accuracy: 0.6192 - val_auc: 0.7884\n",
      "Epoch 44/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.6472 - accuracy: 0.5280 - auc: 0.7679Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6470 - accuracy: 0.5280 - auc: 0.7678 - val_loss: 6.5148 - val_accuracy: 0.6202 - val_auc: 0.7906\n",
      "Epoch 00044: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 0.6658 - accuracy: 0.5689 - auc: 0.7768 - val_loss: 0.3549 - val_accuracy: 0.8857 - val_auc: 0.9399\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4585 - accuracy: 0.8958 - auc: 0.8643 - val_loss: 0.3208 - val_accuracy: 0.8985 - val_auc: 0.9494\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4142 - accuracy: 0.8941 - auc: 0.8830 - val_loss: 0.2967 - val_accuracy: 0.8742 - val_auc: 0.9486\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3839 - accuracy: 0.8912 - auc: 0.9030 - val_loss: 0.2786 - val_accuracy: 0.8724 - val_auc: 0.9549\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3610 - accuracy: 0.8884 - auc: 0.9134 - val_loss: 0.2756 - val_accuracy: 0.8706 - val_auc: 0.9561\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3688 - accuracy: 0.7578 - auc: 0.9058 - val_loss: 0.2681 - val_accuracy: 0.8593 - val_auc: 0.9587\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3516 - accuracy: 0.6899 - auc: 0.9136 - val_loss: 0.2789 - val_accuracy: 0.8659 - val_auc: 0.9570\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3701 - accuracy: 0.6963 - auc: 0.9074 - val_loss: 0.2734 - val_accuracy: 0.8524 - val_auc: 0.9569\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3378 - accuracy: 0.7045 - auc: 0.9209 - val_loss: 0.2705 - val_accuracy: 0.8629 - val_auc: 0.9579\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3413 - accuracy: 0.7028 - auc: 0.9178 - val_loss: 0.2769 - val_accuracy: 0.8685 - val_auc: 0.9563\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3399 - accuracy: 0.7104 - auc: 0.9210 - val_loss: 0.2753 - val_accuracy: 0.8595 - val_auc: 0.9569\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3480 - accuracy: 0.7066 - auc: 0.9158 - val_loss: 0.2895 - val_accuracy: 0.8620 - val_auc: 0.9550\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3235 - accuracy: 0.7112 - auc: 0.9278 - val_loss: 0.2914 - val_accuracy: 0.8717 - val_auc: 0.9554\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3237 - accuracy: 0.7169 - auc: 0.9285 - val_loss: 0.2805 - val_accuracy: 0.8632 - val_auc: 0.9569\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3297 - accuracy: 0.7140 - auc: 0.9229 - val_loss: 0.2928 - val_accuracy: 0.8643 - val_auc: 0.9556\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3244 - accuracy: 0.7143 - auc: 0.9277 - val_loss: 0.2935 - val_accuracy: 0.8649 - val_auc: 0.9537\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3212 - accuracy: 0.7148 - auc: 0.9271 - val_loss: 0.2896 - val_accuracy: 0.8613 - val_auc: 0.9548\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3283 - accuracy: 0.7146 - auc: 0.9241 - val_loss: 0.2942 - val_accuracy: 0.8586 - val_auc: 0.9547\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3275 - accuracy: 0.7159 - auc: 0.9244 - val_loss: 0.2891 - val_accuracy: 0.8541 - val_auc: 0.9544\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3309 - accuracy: 0.7108 - auc: 0.9245 - val_loss: 0.2942 - val_accuracy: 0.8733 - val_auc: 0.9555\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3308 - accuracy: 0.7180 - auc: 0.9270 - val_loss: 0.2921 - val_accuracy: 0.8607 - val_auc: 0.9543\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3242 - accuracy: 0.7205 - auc: 0.9284 - val_loss: 0.2999 - val_accuracy: 0.8691 - val_auc: 0.9536\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3219 - accuracy: 0.7219 - auc: 0.9282 - val_loss: 0.3017 - val_accuracy: 0.8670 - val_auc: 0.9530\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3243 - accuracy: 0.7244 - auc: 0.9298 - val_loss: 0.3042 - val_accuracy: 0.8788 - val_auc: 0.9526\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3303 - accuracy: 0.7266 - auc: 0.9249 - val_loss: 0.2927 - val_accuracy: 0.8632 - val_auc: 0.9532\n",
      "Epoch 26/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3273 - accuracy: 0.7217 - auc: 0.9275Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3284 - accuracy: 0.7217 - auc: 0.9273 - val_loss: 0.2978 - val_accuracy: 0.8701 - val_auc: 0.9541\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5749 - accuracy: 0.5793 - auc: 0.8038 - val_loss: 0.3181 - val_accuracy: 0.8508 - val_auc: 0.9450\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4188 - accuracy: 0.7347 - auc: 0.8896 - val_loss: 0.2978 - val_accuracy: 0.8496 - val_auc: 0.9536\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3772 - accuracy: 0.7506 - auc: 0.9018 - val_loss: 0.2918 - val_accuracy: 0.8480 - val_auc: 0.9515\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3700 - accuracy: 0.7534 - auc: 0.9014 - val_loss: 0.2943 - val_accuracy: 0.8596 - val_auc: 0.9541\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3703 - accuracy: 0.7543 - auc: 0.9107 - val_loss: 0.2921 - val_accuracy: 0.8531 - val_auc: 0.9538\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3444 - accuracy: 0.7661 - auc: 0.9167 - val_loss: 0.3108 - val_accuracy: 0.8653 - val_auc: 0.9509\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3436 - accuracy: 0.7693 - auc: 0.9162 - val_loss: 0.3019 - val_accuracy: 0.8752 - val_auc: 0.9544\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3430 - accuracy: 0.7712 - auc: 0.9157 - val_loss: 0.3159 - val_accuracy: 0.8709 - val_auc: 0.9496\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3526 - accuracy: 0.7719 - auc: 0.9168 - val_loss: 0.3094 - val_accuracy: 0.8509 - val_auc: 0.9508\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3439 - accuracy: 0.7656 - auc: 0.9141 - val_loss: 0.3097 - val_accuracy: 0.8507 - val_auc: 0.9539\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3570 - accuracy: 0.7642 - auc: 0.9123 - val_loss: 0.3077 - val_accuracy: 0.8474 - val_auc: 0.9528\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3405 - accuracy: 0.7666 - auc: 0.9193 - val_loss: 0.3077 - val_accuracy: 0.8494 - val_auc: 0.9531\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3263 - accuracy: 0.7696 - auc: 0.9187 - val_loss: 0.3230 - val_accuracy: 0.8781 - val_auc: 0.9501\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3174 - accuracy: 0.7773 - auc: 0.9208 - val_loss: 0.3392 - val_accuracy: 0.8737 - val_auc: 0.9468\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3372 - accuracy: 0.7763 - auc: 0.9178 - val_loss: 0.3169 - val_accuracy: 0.8430 - val_auc: 0.9525\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3175 - accuracy: 0.7763 - auc: 0.9228 - val_loss: 0.3306 - val_accuracy: 0.8692 - val_auc: 0.9485\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3254 - accuracy: 0.7759 - auc: 0.9195 - val_loss: 0.3291 - val_accuracy: 0.8667 - val_auc: 0.9488\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3242 - accuracy: 0.7766 - auc: 0.9201 - val_loss: 0.3364 - val_accuracy: 0.8655 - val_auc: 0.9495\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3273 - accuracy: 0.7770 - auc: 0.9212 - val_loss: 0.3248 - val_accuracy: 0.8627 - val_auc: 0.9501\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3264 - accuracy: 0.7719 - auc: 0.9216 - val_loss: 0.3271 - val_accuracy: 0.8677 - val_auc: 0.9467\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3233 - accuracy: 0.7761 - auc: 0.9212 - val_loss: 0.3314 - val_accuracy: 0.8637 - val_auc: 0.9481\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3330 - accuracy: 0.7732 - auc: 0.9194 - val_loss: 0.3330 - val_accuracy: 0.8468 - val_auc: 0.9502\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3151 - accuracy: 0.7772 - auc: 0.9280 - val_loss: 0.3467 - val_accuracy: 0.8759 - val_auc: 0.9473\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3257 - accuracy: 0.7753 - auc: 0.9207 - val_loss: 0.3385 - val_accuracy: 0.8605 - val_auc: 0.9488\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3198 - accuracy: 0.7750 - auc: 0.9242 - val_loss: 0.3694 - val_accuracy: 0.8750 - val_auc: 0.9435\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3240 - accuracy: 0.7748 - auc: 0.9219 - val_loss: 0.3482 - val_accuracy: 0.8721 - val_auc: 0.9479\n",
      "Epoch 27/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3228 - accuracy: 0.7823 - auc: 0.9216Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3215 - accuracy: 0.7820 - auc: 0.9215 - val_loss: 0.3425 - val_accuracy: 0.8508 - val_auc: 0.9482\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5724 - accuracy: 0.4375 - auc: 0.8476 - val_loss: 0.3129 - val_accuracy: 0.8005 - val_auc: 0.9477\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3993 - accuracy: 0.6466 - auc: 0.9060 - val_loss: 0.2807 - val_accuracy: 0.8603 - val_auc: 0.9565\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3683 - accuracy: 0.8721 - auc: 0.9145 - val_loss: 0.2714 - val_accuracy: 0.9008 - val_auc: 0.9580\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3656 - accuracy: 0.8945 - auc: 0.9097 - val_loss: 0.2825 - val_accuracy: 0.9021 - val_auc: 0.9553\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3512 - accuracy: 0.8971 - auc: 0.9151 - val_loss: 0.2734 - val_accuracy: 0.9018 - val_auc: 0.9566\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3364 - accuracy: 0.9006 - auc: 0.9287 - val_loss: 0.2725 - val_accuracy: 0.8939 - val_auc: 0.9569\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3471 - accuracy: 0.8993 - auc: 0.9171 - val_loss: 0.2846 - val_accuracy: 0.9095 - val_auc: 0.9569\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3422 - accuracy: 0.9061 - auc: 0.9245 - val_loss: 0.2833 - val_accuracy: 0.9110 - val_auc: 0.9567\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3360 - accuracy: 0.9101 - auc: 0.9236 - val_loss: 0.2834 - val_accuracy: 0.9030 - val_auc: 0.9564\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3331 - accuracy: 0.9015 - auc: 0.9265 - val_loss: 0.2879 - val_accuracy: 0.9099 - val_auc: 0.9554\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3437 - accuracy: 0.9096 - auc: 0.9201 - val_loss: 0.2892 - val_accuracy: 0.8940 - val_auc: 0.9556\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3232 - accuracy: 0.9090 - auc: 0.9282 - val_loss: 0.2818 - val_accuracy: 0.9040 - val_auc: 0.9568\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3516 - accuracy: 0.9056 - auc: 0.9155 - val_loss: 0.2836 - val_accuracy: 0.9074 - val_auc: 0.9561\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3370 - accuracy: 0.9078 - auc: 0.9207 - val_loss: 0.2885 - val_accuracy: 0.9015 - val_auc: 0.9556\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3308 - accuracy: 0.9102 - auc: 0.9269 - val_loss: 0.2920 - val_accuracy: 0.9100 - val_auc: 0.9551\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3427 - accuracy: 0.9112 - auc: 0.9224 - val_loss: 0.2863 - val_accuracy: 0.9238 - val_auc: 0.9561\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3320 - accuracy: 0.9189 - auc: 0.9259 - val_loss: 0.2961 - val_accuracy: 0.9078 - val_auc: 0.9537\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3239 - accuracy: 0.9116 - auc: 0.9315 - val_loss: 0.2943 - val_accuracy: 0.9143 - val_auc: 0.9552\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3271 - accuracy: 0.9166 - auc: 0.9283 - val_loss: 0.2965 - val_accuracy: 0.9100 - val_auc: 0.9532\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3232 - accuracy: 0.9175 - auc: 0.9304 - val_loss: 0.2902 - val_accuracy: 0.9135 - val_auc: 0.9566\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3284 - accuracy: 0.9164 - auc: 0.9240 - val_loss: 0.2968 - val_accuracy: 0.9080 - val_auc: 0.9552\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3295 - accuracy: 0.9177 - auc: 0.9232 - val_loss: 0.2947 - val_accuracy: 0.9133 - val_auc: 0.9559\n",
      "Epoch 23/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3296 - accuracy: 0.9194 - auc: 0.9262Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3292 - accuracy: 0.9194 - auc: 0.9265 - val_loss: 0.2996 - val_accuracy: 0.8998 - val_auc: 0.9535\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.8237 - accuracy: 0.9034 - auc: 0.7202 - val_loss: 0.4348 - val_accuracy: 0.9000 - val_auc: 0.9131\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5037 - accuracy: 0.8906 - auc: 0.8083 - val_loss: 0.3678 - val_accuracy: 0.8512 - val_auc: 0.9432\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4497 - accuracy: 0.6397 - auc: 0.8479 - val_loss: 0.3293 - val_accuracy: 0.8203 - val_auc: 0.9495\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4390 - accuracy: 0.6185 - auc: 0.8570 - val_loss: 0.3391 - val_accuracy: 0.8156 - val_auc: 0.9477\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4252 - accuracy: 0.6210 - auc: 0.8613 - val_loss: 0.3109 - val_accuracy: 0.8218 - val_auc: 0.9522\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4072 - accuracy: 0.6462 - auc: 0.8661 - val_loss: 0.3203 - val_accuracy: 0.8242 - val_auc: 0.9511\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4036 - accuracy: 0.6455 - auc: 0.8729 - val_loss: 0.3150 - val_accuracy: 0.8268 - val_auc: 0.9515\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3690 - accuracy: 0.6721 - auc: 0.8888 - val_loss: 0.3053 - val_accuracy: 0.8614 - val_auc: 0.9514\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3651 - accuracy: 0.6927 - auc: 0.8913 - val_loss: 0.3261 - val_accuracy: 0.8362 - val_auc: 0.9489\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3828 - accuracy: 0.6818 - auc: 0.8868 - val_loss: 0.3110 - val_accuracy: 0.8311 - val_auc: 0.9534\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3652 - accuracy: 0.6955 - auc: 0.8915 - val_loss: 0.3143 - val_accuracy: 0.8409 - val_auc: 0.9516\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3659 - accuracy: 0.7010 - auc: 0.8985 - val_loss: 0.3199 - val_accuracy: 0.8331 - val_auc: 0.9488\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3579 - accuracy: 0.7042 - auc: 0.8991 - val_loss: 0.3256 - val_accuracy: 0.8491 - val_auc: 0.9469\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3554 - accuracy: 0.7068 - auc: 0.9004 - val_loss: 0.3180 - val_accuracy: 0.8549 - val_auc: 0.9503\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3482 - accuracy: 0.7098 - auc: 0.9109 - val_loss: 0.3074 - val_accuracy: 0.8425 - val_auc: 0.9510\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3398 - accuracy: 0.7122 - auc: 0.9197 - val_loss: 0.3135 - val_accuracy: 0.8569 - val_auc: 0.9512\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3324 - accuracy: 0.7125 - auc: 0.9235 - val_loss: 0.3117 - val_accuracy: 0.8580 - val_auc: 0.9516\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3229 - accuracy: 0.7139 - auc: 0.9245 - val_loss: 0.3237 - val_accuracy: 0.8598 - val_auc: 0.9489\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3270 - accuracy: 0.7102 - auc: 0.9222 - val_loss: 0.3218 - val_accuracy: 0.8572 - val_auc: 0.9504\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3345 - accuracy: 0.7083 - auc: 0.9213 - val_loss: 0.3201 - val_accuracy: 0.8592 - val_auc: 0.9501\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3121 - accuracy: 0.7150 - auc: 0.9288 - val_loss: 0.3294 - val_accuracy: 0.8650 - val_auc: 0.9489\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3272 - accuracy: 0.7160 - auc: 0.9272 - val_loss: 0.3117 - val_accuracy: 0.8627 - val_auc: 0.9511\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3213 - accuracy: 0.7128 - auc: 0.9241 - val_loss: 0.3262 - val_accuracy: 0.8568 - val_auc: 0.9500\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3230 - accuracy: 0.7124 - auc: 0.9244 - val_loss: 0.3329 - val_accuracy: 0.8718 - val_auc: 0.9478\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3175 - accuracy: 0.7175 - auc: 0.9291 - val_loss: 0.3315 - val_accuracy: 0.8564 - val_auc: 0.9481\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3291 - accuracy: 0.7077 - auc: 0.9219 - val_loss: 0.3317 - val_accuracy: 0.8574 - val_auc: 0.9484\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3115 - accuracy: 0.7140 - auc: 0.9281 - val_loss: 0.3230 - val_accuracy: 0.8649 - val_auc: 0.9494\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3207 - accuracy: 0.7112 - auc: 0.9268 - val_loss: 0.3279 - val_accuracy: 0.8606 - val_auc: 0.9489\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3113 - accuracy: 0.7178 - auc: 0.9268 - val_loss: 0.3446 - val_accuracy: 0.8700 - val_auc: 0.9483\n",
      "Epoch 30/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.7129 - auc: 0.9262Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3207 - accuracy: 0.7129 - auc: 0.9263 - val_loss: 0.3363 - val_accuracy: 0.8505 - val_auc: 0.9473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.6131 - accuracy: 0.5882 - auc: 0.7888 - val_loss: 0.3440 - val_accuracy: 0.8630 - val_auc: 0.9402\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4400 - accuracy: 0.7107 - auc: 0.8780 - val_loss: 0.3183 - val_accuracy: 0.8753 - val_auc: 0.9485\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4202 - accuracy: 0.7323 - auc: 0.8924 - val_loss: 0.3109 - val_accuracy: 0.8534 - val_auc: 0.9498\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3780 - accuracy: 0.7550 - auc: 0.9039 - val_loss: 0.3075 - val_accuracy: 0.8465 - val_auc: 0.9500\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3859 - accuracy: 0.7468 - auc: 0.8992 - val_loss: 0.3080 - val_accuracy: 0.8401 - val_auc: 0.9530\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3696 - accuracy: 0.7561 - auc: 0.9043 - val_loss: 0.3100 - val_accuracy: 0.8574 - val_auc: 0.9518\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3425 - accuracy: 0.7664 - auc: 0.9178 - val_loss: 0.3071 - val_accuracy: 0.8609 - val_auc: 0.9523\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3412 - accuracy: 0.7653 - auc: 0.9176 - val_loss: 0.3097 - val_accuracy: 0.8617 - val_auc: 0.9548\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3373 - accuracy: 0.7718 - auc: 0.9157 - val_loss: 0.3215 - val_accuracy: 0.8641 - val_auc: 0.9537\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3230 - accuracy: 0.7776 - auc: 0.9232 - val_loss: 0.3282 - val_accuracy: 0.8715 - val_auc: 0.9505\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3335 - accuracy: 0.7764 - auc: 0.9192 - val_loss: 0.3433 - val_accuracy: 0.8373 - val_auc: 0.9508\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3271 - accuracy: 0.7686 - auc: 0.9222 - val_loss: 0.3371 - val_accuracy: 0.8645 - val_auc: 0.9508\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3177 - accuracy: 0.7784 - auc: 0.9234 - val_loss: 0.3527 - val_accuracy: 0.8648 - val_auc: 0.9499\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3329 - accuracy: 0.7714 - auc: 0.9235 - val_loss: 0.3601 - val_accuracy: 0.8702 - val_auc: 0.9499\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3252 - accuracy: 0.7733 - auc: 0.9221 - val_loss: 0.3561 - val_accuracy: 0.8524 - val_auc: 0.9509\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3319 - accuracy: 0.7757 - auc: 0.9217 - val_loss: 0.3500 - val_accuracy: 0.8565 - val_auc: 0.9513\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3279 - accuracy: 0.7780 - auc: 0.9196 - val_loss: 0.3401 - val_accuracy: 0.8629 - val_auc: 0.9510\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.3292 - accuracy: 0.7773 - auc: 0.9209 - val_loss: 0.3569 - val_accuracy: 0.8402 - val_auc: 0.9509\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.3395 - accuracy: 0.7526 - auc: 0.9137 - val_loss: 0.3670 - val_accuracy: 0.8637 - val_auc: 0.9514\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 0.3068 - accuracy: 0.7754 - auc: 0.9246 - val_loss: 0.3852 - val_accuracy: 0.8716 - val_auc: 0.9503\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3347 - accuracy: 0.7696 - auc: 0.9211 - val_loss: 0.3644 - val_accuracy: 0.8725 - val_auc: 0.9503\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3284 - accuracy: 0.7762 - auc: 0.9239 - val_loss: 0.3823 - val_accuracy: 0.8697 - val_auc: 0.9492\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3175 - accuracy: 0.7763 - auc: 0.9242 - val_loss: 0.3834 - val_accuracy: 0.8731 - val_auc: 0.9502\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3246 - accuracy: 0.7752 - auc: 0.9239 - val_loss: 0.3789 - val_accuracy: 0.8595 - val_auc: 0.9501\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3189 - accuracy: 0.7789 - auc: 0.9276 - val_loss: 0.3880 - val_accuracy: 0.8729 - val_auc: 0.9494\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3184 - accuracy: 0.7814 - auc: 0.9247 - val_loss: 0.3700 - val_accuracy: 0.8654 - val_auc: 0.9516\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3285 - accuracy: 0.7699 - auc: 0.9224 - val_loss: 0.3500 - val_accuracy: 0.8562 - val_auc: 0.9524\n",
      "Epoch 28/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.7773 - auc: 0.9173Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3324 - accuracy: 0.7773 - auc: 0.9177 - val_loss: 0.3695 - val_accuracy: 0.8505 - val_auc: 0.9521\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 0.6312 - accuracy: 0.8554 - auc: 0.8247 - val_loss: 0.3474 - val_accuracy: 0.9013 - val_auc: 0.9420\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3825 - accuracy: 0.9009 - auc: 0.9251 - val_loss: 0.2969 - val_accuracy: 0.9075 - val_auc: 0.9515\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3635 - accuracy: 0.9085 - auc: 0.9285 - val_loss: 0.2718 - val_accuracy: 0.9124 - val_auc: 0.9581\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3386 - accuracy: 0.9073 - auc: 0.9379 - val_loss: 0.2648 - val_accuracy: 0.9177 - val_auc: 0.9590\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3326 - accuracy: 0.9067 - auc: 0.9423 - val_loss: 0.2580 - val_accuracy: 0.9105 - val_auc: 0.9616\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3214 - accuracy: 0.9071 - auc: 0.9420 - val_loss: 0.2671 - val_accuracy: 0.9225 - val_auc: 0.9594\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3093 - accuracy: 0.9114 - auc: 0.9477 - val_loss: 0.2658 - val_accuracy: 0.9147 - val_auc: 0.9575\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3106 - accuracy: 0.9099 - auc: 0.9464 - val_loss: 0.2574 - val_accuracy: 0.9071 - val_auc: 0.9604\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2933 - accuracy: 0.9054 - auc: 0.9516 - val_loss: 0.2677 - val_accuracy: 0.9023 - val_auc: 0.9570\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2915 - accuracy: 0.9050 - auc: 0.9513 - val_loss: 0.2779 - val_accuracy: 0.9176 - val_auc: 0.9559\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2927 - accuracy: 0.9058 - auc: 0.9513 - val_loss: 0.2815 - val_accuracy: 0.9066 - val_auc: 0.9530\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2818 - accuracy: 0.9062 - auc: 0.9543 - val_loss: 0.2837 - val_accuracy: 0.9111 - val_auc: 0.9539\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2905 - accuracy: 0.9045 - auc: 0.9525 - val_loss: 0.2889 - val_accuracy: 0.9140 - val_auc: 0.9526\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2690 - accuracy: 0.9083 - auc: 0.9584 - val_loss: 0.2960 - val_accuracy: 0.9030 - val_auc: 0.9542\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2743 - accuracy: 0.9034 - auc: 0.9562 - val_loss: 0.2939 - val_accuracy: 0.9032 - val_auc: 0.9518\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2723 - accuracy: 0.9043 - auc: 0.9567 - val_loss: 0.3045 - val_accuracy: 0.9102 - val_auc: 0.9521\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2804 - accuracy: 0.9005 - auc: 0.9553 - val_loss: 0.3077 - val_accuracy: 0.8961 - val_auc: 0.9528\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2759 - accuracy: 0.9026 - auc: 0.9551 - val_loss: 0.3184 - val_accuracy: 0.8967 - val_auc: 0.9509\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2735 - accuracy: 0.8996 - auc: 0.9548 - val_loss: 0.3210 - val_accuracy: 0.8975 - val_auc: 0.9501\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2580 - accuracy: 0.8994 - auc: 0.9615 - val_loss: 0.3343 - val_accuracy: 0.9070 - val_auc: 0.9499\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2605 - accuracy: 0.9028 - auc: 0.9594 - val_loss: 0.3347 - val_accuracy: 0.9164 - val_auc: 0.9517\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2607 - accuracy: 0.9010 - auc: 0.9589 - val_loss: 0.3386 - val_accuracy: 0.9028 - val_auc: 0.9503\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2752 - accuracy: 0.8979 - auc: 0.9581 - val_loss: 0.3383 - val_accuracy: 0.8972 - val_auc: 0.9507\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2999 - accuracy: 0.9047 - auc: 0.9542 - val_loss: 0.3558 - val_accuracy: 0.9065 - val_auc: 0.9481\n",
      "Epoch 25/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9084 - auc: 0.9597Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2641 - accuracy: 0.9083 - auc: 0.9597 - val_loss: 0.3398 - val_accuracy: 0.9001 - val_auc: 0.9503\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5353 - accuracy: 0.6479 - auc: 0.8586 - val_loss: 0.3323 - val_accuracy: 0.8645 - val_auc: 0.9394\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3586 - accuracy: 0.7995 - auc: 0.9273 - val_loss: 0.2908 - val_accuracy: 0.8804 - val_auc: 0.9499\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3248 - accuracy: 0.8674 - auc: 0.9388 - val_loss: 0.2793 - val_accuracy: 0.8796 - val_auc: 0.9540\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3153 - accuracy: 0.8747 - auc: 0.9424 - val_loss: 0.2786 - val_accuracy: 0.8932 - val_auc: 0.9543\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3074 - accuracy: 0.8831 - auc: 0.9467 - val_loss: 0.2816 - val_accuracy: 0.8848 - val_auc: 0.9540\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2991 - accuracy: 0.8808 - auc: 0.9473 - val_loss: 0.2947 - val_accuracy: 0.8952 - val_auc: 0.9516\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2929 - accuracy: 0.8894 - auc: 0.9502 - val_loss: 0.2952 - val_accuracy: 0.8823 - val_auc: 0.9511\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2907 - accuracy: 0.8538 - auc: 0.9523 - val_loss: 0.3017 - val_accuracy: 0.8965 - val_auc: 0.9536\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2774 - accuracy: 0.8903 - auc: 0.9543 - val_loss: 0.3294 - val_accuracy: 0.9053 - val_auc: 0.9509\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2757 - accuracy: 0.8755 - auc: 0.9553 - val_loss: 0.3196 - val_accuracy: 0.8906 - val_auc: 0.9505\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2709 - accuracy: 0.8187 - auc: 0.9549 - val_loss: 0.3327 - val_accuracy: 0.8990 - val_auc: 0.9508\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2627 - accuracy: 0.8252 - auc: 0.9580 - val_loss: 0.3468 - val_accuracy: 0.8986 - val_auc: 0.9478\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2693 - accuracy: 0.8292 - auc: 0.9579 - val_loss: 0.3432 - val_accuracy: 0.8948 - val_auc: 0.9500\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2645 - accuracy: 0.8313 - auc: 0.9574 - val_loss: 0.3484 - val_accuracy: 0.8843 - val_auc: 0.9481\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2583 - accuracy: 0.8243 - auc: 0.9594 - val_loss: 0.3515 - val_accuracy: 0.8902 - val_auc: 0.9455\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2524 - accuracy: 0.8250 - auc: 0.9604 - val_loss: 0.3620 - val_accuracy: 0.8891 - val_auc: 0.9463\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2590 - accuracy: 0.8215 - auc: 0.9583 - val_loss: 0.3745 - val_accuracy: 0.8919 - val_auc: 0.9434\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2595 - accuracy: 0.8178 - auc: 0.9585 - val_loss: 0.3770 - val_accuracy: 0.8910 - val_auc: 0.9424\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2486 - accuracy: 0.8183 - auc: 0.9621 - val_loss: 0.3866 - val_accuracy: 0.8949 - val_auc: 0.9428\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2540 - accuracy: 0.8232 - auc: 0.9575 - val_loss: 0.3993 - val_accuracy: 0.8830 - val_auc: 0.9412\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2614 - accuracy: 0.8134 - auc: 0.9593 - val_loss: 0.3839 - val_accuracy: 0.8816 - val_auc: 0.9426\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2524 - accuracy: 0.8141 - auc: 0.9596 - val_loss: 0.3910 - val_accuracy: 0.8945 - val_auc: 0.9446\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2538 - accuracy: 0.8166 - auc: 0.9614 - val_loss: 0.3935 - val_accuracy: 0.8884 - val_auc: 0.9420\n",
      "Epoch 24/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2506 - accuracy: 0.8107 - auc: 0.9611Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2506 - accuracy: 0.8108 - auc: 0.9611 - val_loss: 0.4213 - val_accuracy: 0.8964 - val_auc: 0.9413\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.6199 - accuracy: 0.8636 - auc: 0.8372 - val_loss: 0.3625 - val_accuracy: 0.8964 - val_auc: 0.9384\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3798 - accuracy: 0.9050 - auc: 0.9217 - val_loss: 0.3112 - val_accuracy: 0.9167 - val_auc: 0.9476\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3427 - accuracy: 0.9161 - auc: 0.9389 - val_loss: 0.3009 - val_accuracy: 0.8985 - val_auc: 0.9531\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3401 - accuracy: 0.9144 - auc: 0.9352 - val_loss: 0.2924 - val_accuracy: 0.9193 - val_auc: 0.9502\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3385 - accuracy: 0.9133 - auc: 0.9403 - val_loss: 0.2861 - val_accuracy: 0.9260 - val_auc: 0.9524\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3347 - accuracy: 0.9177 - auc: 0.9395 - val_loss: 0.2807 - val_accuracy: 0.9090 - val_auc: 0.9551\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3179 - accuracy: 0.9173 - auc: 0.9425 - val_loss: 0.2794 - val_accuracy: 0.9157 - val_auc: 0.9543\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3226 - accuracy: 0.9176 - auc: 0.9437 - val_loss: 0.2825 - val_accuracy: 0.9065 - val_auc: 0.9533\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2931 - accuracy: 0.9139 - auc: 0.9523 - val_loss: 0.2826 - val_accuracy: 0.9196 - val_auc: 0.9530\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3021 - accuracy: 0.9151 - auc: 0.9509 - val_loss: 0.2835 - val_accuracy: 0.9163 - val_auc: 0.9513\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2889 - accuracy: 0.9134 - auc: 0.9544 - val_loss: 0.2846 - val_accuracy: 0.9111 - val_auc: 0.9530\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2876 - accuracy: 0.9123 - auc: 0.9527 - val_loss: 0.2917 - val_accuracy: 0.9212 - val_auc: 0.9515\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2889 - accuracy: 0.9157 - auc: 0.9535 - val_loss: 0.2864 - val_accuracy: 0.9048 - val_auc: 0.9530\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2814 - accuracy: 0.9127 - auc: 0.9548 - val_loss: 0.2924 - val_accuracy: 0.9190 - val_auc: 0.9529\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2766 - accuracy: 0.9148 - auc: 0.9567 - val_loss: 0.2990 - val_accuracy: 0.9213 - val_auc: 0.9528\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2782 - accuracy: 0.9145 - auc: 0.9565 - val_loss: 0.3011 - val_accuracy: 0.9096 - val_auc: 0.9518\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2752 - accuracy: 0.9142 - auc: 0.9575 - val_loss: 0.2944 - val_accuracy: 0.9114 - val_auc: 0.9513\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2807 - accuracy: 0.9139 - auc: 0.9544 - val_loss: 0.2991 - val_accuracy: 0.9050 - val_auc: 0.9524\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2729 - accuracy: 0.9123 - auc: 0.9583 - val_loss: 0.3104 - val_accuracy: 0.9337 - val_auc: 0.9518\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2749 - accuracy: 0.9140 - auc: 0.9568 - val_loss: 0.3106 - val_accuracy: 0.9149 - val_auc: 0.9513\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2764 - accuracy: 0.9145 - auc: 0.9569 - val_loss: 0.3032 - val_accuracy: 0.9096 - val_auc: 0.9526\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2682 - accuracy: 0.9128 - auc: 0.9581 - val_loss: 0.3189 - val_accuracy: 0.9152 - val_auc: 0.9527\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2741 - accuracy: 0.9164 - auc: 0.9568 - val_loss: 0.3353 - val_accuracy: 0.9156 - val_auc: 0.9488\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.2613 - accuracy: 0.9128 - auc: 0.9613 - val_loss: 0.3500 - val_accuracy: 0.9205 - val_auc: 0.9470\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.2657 - accuracy: 0.9155 - auc: 0.9581 - val_loss: 0.3667 - val_accuracy: 0.9140 - val_auc: 0.9474\n",
      "Epoch 26/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9110 - auc: 0.9566Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2740 - accuracy: 0.9114 - auc: 0.9566 - val_loss: 0.3442 - val_accuracy: 0.9233 - val_auc: 0.9493\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.5665 - accuracy: 0.6026 - auc: 0.8580 - val_loss: 0.3115 - val_accuracy: 0.8380 - val_auc: 0.9475\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3990 - accuracy: 0.7346 - auc: 0.9235 - val_loss: 0.2866 - val_accuracy: 0.8674 - val_auc: 0.9524\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3230 - accuracy: 0.8451 - auc: 0.9427 - val_loss: 0.2705 - val_accuracy: 0.8997 - val_auc: 0.9562\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3200 - accuracy: 0.8762 - auc: 0.9411 - val_loss: 0.2647 - val_accuracy: 0.9004 - val_auc: 0.9586\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3139 - accuracy: 0.8953 - auc: 0.9449 - val_loss: 0.2695 - val_accuracy: 0.8981 - val_auc: 0.9567\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3023 - accuracy: 0.9002 - auc: 0.9473 - val_loss: 0.2693 - val_accuracy: 0.9000 - val_auc: 0.9571\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2924 - accuracy: 0.9009 - auc: 0.9503 - val_loss: 0.2730 - val_accuracy: 0.8948 - val_auc: 0.9559\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2888 - accuracy: 0.9042 - auc: 0.9508 - val_loss: 0.2736 - val_accuracy: 0.9153 - val_auc: 0.9558\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2828 - accuracy: 0.9069 - auc: 0.9529 - val_loss: 0.2675 - val_accuracy: 0.9030 - val_auc: 0.9575\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2807 - accuracy: 0.9076 - auc: 0.9533 - val_loss: 0.2696 - val_accuracy: 0.8992 - val_auc: 0.9575\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2787 - accuracy: 0.9063 - auc: 0.9547 - val_loss: 0.2751 - val_accuracy: 0.9125 - val_auc: 0.9562\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2821 - accuracy: 0.9050 - auc: 0.9533 - val_loss: 0.2744 - val_accuracy: 0.9154 - val_auc: 0.9557\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2792 - accuracy: 0.9098 - auc: 0.9540 - val_loss: 0.2750 - val_accuracy: 0.9008 - val_auc: 0.9563\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2714 - accuracy: 0.9078 - auc: 0.9575 - val_loss: 0.2855 - val_accuracy: 0.9138 - val_auc: 0.9541\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2593 - accuracy: 0.9065 - auc: 0.9597 - val_loss: 0.3021 - val_accuracy: 0.9174 - val_auc: 0.9524\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2694 - accuracy: 0.9091 - auc: 0.9574 - val_loss: 0.2872 - val_accuracy: 0.9046 - val_auc: 0.9541\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2778 - accuracy: 0.9044 - auc: 0.9538 - val_loss: 0.2878 - val_accuracy: 0.9063 - val_auc: 0.9536\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2646 - accuracy: 0.9101 - auc: 0.9585 - val_loss: 0.2844 - val_accuracy: 0.9104 - val_auc: 0.9548\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2760 - accuracy: 0.9118 - auc: 0.9543 - val_loss: 0.2880 - val_accuracy: 0.9138 - val_auc: 0.9548\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2661 - accuracy: 0.9069 - auc: 0.9571 - val_loss: 0.2929 - val_accuracy: 0.9079 - val_auc: 0.9539\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2677 - accuracy: 0.9103 - auc: 0.9564 - val_loss: 0.2982 - val_accuracy: 0.9068 - val_auc: 0.9529\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2599 - accuracy: 0.9104 - auc: 0.9607 - val_loss: 0.3124 - val_accuracy: 0.9150 - val_auc: 0.9511\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2545 - accuracy: 0.9100 - auc: 0.9608 - val_loss: 0.3265 - val_accuracy: 0.9196 - val_auc: 0.9526\n",
      "Epoch 24/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2621 - accuracy: 0.9128 - auc: 0.9586Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2609 - accuracy: 0.9129 - auc: 0.9588 - val_loss: 0.3219 - val_accuracy: 0.9258 - val_auc: 0.9518\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 20us/sample - loss: 0.4921 - accuracy: 0.6307 - auc: 0.8809 - val_loss: 0.3044 - val_accuracy: 0.8625 - val_auc: 0.9449\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3688 - accuracy: 0.7916 - auc: 0.9300 - val_loss: 0.2857 - val_accuracy: 0.9018 - val_auc: 0.9511\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3287 - accuracy: 0.8328 - auc: 0.9374 - val_loss: 0.2827 - val_accuracy: 0.8865 - val_auc: 0.9537\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3149 - accuracy: 0.8371 - auc: 0.9423 - val_loss: 0.2848 - val_accuracy: 0.8786 - val_auc: 0.9541\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2956 - accuracy: 0.8349 - auc: 0.9496 - val_loss: 0.2897 - val_accuracy: 0.8764 - val_auc: 0.9522\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3011 - accuracy: 0.8331 - auc: 0.9489 - val_loss: 0.2937 - val_accuracy: 0.8981 - val_auc: 0.9522\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2837 - accuracy: 0.8322 - auc: 0.9521 - val_loss: 0.3024 - val_accuracy: 0.9003 - val_auc: 0.9519\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2840 - accuracy: 0.8336 - auc: 0.9525 - val_loss: 0.2993 - val_accuracy: 0.8918 - val_auc: 0.9520\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2708 - accuracy: 0.8354 - auc: 0.9557 - val_loss: 0.3149 - val_accuracy: 0.8922 - val_auc: 0.9502\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2745 - accuracy: 0.8361 - auc: 0.9546 - val_loss: 0.3112 - val_accuracy: 0.8682 - val_auc: 0.9507\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2630 - accuracy: 0.8309 - auc: 0.9597 - val_loss: 0.3283 - val_accuracy: 0.8871 - val_auc: 0.9481\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2703 - accuracy: 0.8325 - auc: 0.9556 - val_loss: 0.3384 - val_accuracy: 0.8859 - val_auc: 0.9499\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2649 - accuracy: 0.8261 - auc: 0.9569 - val_loss: 0.3595 - val_accuracy: 0.8869 - val_auc: 0.9479\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2650 - accuracy: 0.8234 - auc: 0.9573 - val_loss: 0.3567 - val_accuracy: 0.8874 - val_auc: 0.9487\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2549 - accuracy: 0.8292 - auc: 0.9609 - val_loss: 0.3682 - val_accuracy: 0.8967 - val_auc: 0.9492\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2483 - accuracy: 0.8313 - auc: 0.9620 - val_loss: 0.3694 - val_accuracy: 0.8889 - val_auc: 0.9508\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2623 - accuracy: 0.8249 - auc: 0.9583 - val_loss: 0.3627 - val_accuracy: 0.8815 - val_auc: 0.9524\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2548 - accuracy: 0.8247 - auc: 0.9601 - val_loss: 0.3681 - val_accuracy: 0.8745 - val_auc: 0.9497\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2484 - accuracy: 0.8231 - auc: 0.9624 - val_loss: 0.4044 - val_accuracy: 0.8936 - val_auc: 0.9459\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2478 - accuracy: 0.8260 - auc: 0.9612 - val_loss: 0.4190 - val_accuracy: 0.8869 - val_auc: 0.9460\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2449 - accuracy: 0.8268 - auc: 0.9626 - val_loss: 0.4283 - val_accuracy: 0.8888 - val_auc: 0.9442\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2560 - accuracy: 0.8202 - auc: 0.9609 - val_loss: 0.4347 - val_accuracy: 0.8963 - val_auc: 0.9440\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2472 - accuracy: 0.8245 - auc: 0.9618 - val_loss: 0.4133 - val_accuracy: 0.8864 - val_auc: 0.9453\n",
      "Epoch 24/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2490 - accuracy: 0.8233 - auc: 0.9623Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2498 - accuracy: 0.8233 - auc: 0.9622 - val_loss: 0.4311 - val_accuracy: 0.8920 - val_auc: 0.9446\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.4469 - accuracy: 0.8714 - auc: 0.9076 - val_loss: 0.3070 - val_accuracy: 0.9133 - val_auc: 0.9505\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3321 - accuracy: 0.9063 - auc: 0.9401 - val_loss: 0.2975 - val_accuracy: 0.9008 - val_auc: 0.9551\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3093 - accuracy: 0.9082 - auc: 0.9500 - val_loss: 0.2776 - val_accuracy: 0.9128 - val_auc: 0.9586\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3128 - accuracy: 0.9085 - auc: 0.9475 - val_loss: 0.2779 - val_accuracy: 0.9268 - val_auc: 0.9583\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2953 - accuracy: 0.9190 - auc: 0.9541 - val_loss: 0.2764 - val_accuracy: 0.9044 - val_auc: 0.9580\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2928 - accuracy: 0.9113 - auc: 0.9534 - val_loss: 0.2702 - val_accuracy: 0.9183 - val_auc: 0.9582\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2862 - accuracy: 0.9122 - auc: 0.9557 - val_loss: 0.2740 - val_accuracy: 0.9205 - val_auc: 0.9563\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2799 - accuracy: 0.9144 - auc: 0.9594 - val_loss: 0.2836 - val_accuracy: 0.8973 - val_auc: 0.9576\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2755 - accuracy: 0.9165 - auc: 0.9591 - val_loss: 0.2944 - val_accuracy: 0.9149 - val_auc: 0.9543\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2944 - accuracy: 0.9142 - auc: 0.9550 - val_loss: 0.2741 - val_accuracy: 0.9067 - val_auc: 0.9581\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2707 - accuracy: 0.9153 - auc: 0.9596 - val_loss: 0.2748 - val_accuracy: 0.9228 - val_auc: 0.9559\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2608 - accuracy: 0.9179 - auc: 0.9619 - val_loss: 0.2758 - val_accuracy: 0.9169 - val_auc: 0.9559\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2678 - accuracy: 0.9162 - auc: 0.9606 - val_loss: 0.2879 - val_accuracy: 0.9291 - val_auc: 0.9533\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2733 - accuracy: 0.9140 - auc: 0.9596 - val_loss: 0.2962 - val_accuracy: 0.9201 - val_auc: 0.9503\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2670 - accuracy: 0.9168 - auc: 0.9616 - val_loss: 0.3002 - val_accuracy: 0.9233 - val_auc: 0.9511\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2579 - accuracy: 0.9172 - auc: 0.9632 - val_loss: 0.3083 - val_accuracy: 0.9080 - val_auc: 0.9505\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2589 - accuracy: 0.9133 - auc: 0.9635 - val_loss: 0.3160 - val_accuracy: 0.9206 - val_auc: 0.9504\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2584 - accuracy: 0.9171 - auc: 0.9629 - val_loss: 0.3282 - val_accuracy: 0.9142 - val_auc: 0.9494\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2624 - accuracy: 0.9171 - auc: 0.9621 - val_loss: 0.3347 - val_accuracy: 0.8936 - val_auc: 0.9502\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2641 - accuracy: 0.9158 - auc: 0.9630 - val_loss: 0.3366 - val_accuracy: 0.9164 - val_auc: 0.9476\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2486 - accuracy: 0.9176 - auc: 0.9655 - val_loss: 0.3557 - val_accuracy: 0.9227 - val_auc: 0.9484\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2460 - accuracy: 0.9176 - auc: 0.9655 - val_loss: 0.3639 - val_accuracy: 0.9122 - val_auc: 0.9488\n",
      "Epoch 23/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9170 - auc: 0.9637Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2544 - accuracy: 0.9170 - auc: 0.9638 - val_loss: 0.3728 - val_accuracy: 0.9143 - val_auc: 0.9471\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.5467 - accuracy: 0.8195 - auc: 0.8725 - val_loss: 0.3261 - val_accuracy: 0.9227 - val_auc: 0.9422\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3389 - accuracy: 0.8997 - auc: 0.9370 - val_loss: 0.2826 - val_accuracy: 0.8908 - val_auc: 0.9550\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3118 - accuracy: 0.8955 - auc: 0.9449 - val_loss: 0.2747 - val_accuracy: 0.9064 - val_auc: 0.9562\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2956 - accuracy: 0.9084 - auc: 0.9512 - val_loss: 0.2807 - val_accuracy: 0.8941 - val_auc: 0.9548\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2817 - accuracy: 0.9050 - auc: 0.9561 - val_loss: 0.2952 - val_accuracy: 0.9234 - val_auc: 0.9504\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2903 - accuracy: 0.9104 - auc: 0.9535 - val_loss: 0.2906 - val_accuracy: 0.9072 - val_auc: 0.9511\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2720 - accuracy: 0.9129 - auc: 0.9586 - val_loss: 0.2950 - val_accuracy: 0.9065 - val_auc: 0.9507\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2585 - accuracy: 0.9050 - auc: 0.9609 - val_loss: 0.3185 - val_accuracy: 0.9276 - val_auc: 0.9452\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2637 - accuracy: 0.9089 - auc: 0.9609 - val_loss: 0.3036 - val_accuracy: 0.8989 - val_auc: 0.9509\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2648 - accuracy: 0.9089 - auc: 0.9603 - val_loss: 0.3020 - val_accuracy: 0.9126 - val_auc: 0.9512\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2532 - accuracy: 0.9124 - auc: 0.9621 - val_loss: 0.3007 - val_accuracy: 0.9104 - val_auc: 0.9511\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2371 - accuracy: 0.9090 - auc: 0.9669 - val_loss: 0.3265 - val_accuracy: 0.9239 - val_auc: 0.9461\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2532 - accuracy: 0.9131 - auc: 0.9631 - val_loss: 0.3373 - val_accuracy: 0.9191 - val_auc: 0.9454\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2362 - accuracy: 0.9121 - auc: 0.9670 - val_loss: 0.3450 - val_accuracy: 0.9157 - val_auc: 0.9476\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2461 - accuracy: 0.9102 - auc: 0.9648 - val_loss: 0.3463 - val_accuracy: 0.9014 - val_auc: 0.9458\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2368 - accuracy: 0.9128 - auc: 0.9669 - val_loss: 0.3740 - val_accuracy: 0.9145 - val_auc: 0.9441\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2352 - accuracy: 0.9116 - auc: 0.9673 - val_loss: 0.3595 - val_accuracy: 0.9118 - val_auc: 0.9449\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2398 - accuracy: 0.9041 - auc: 0.9665 - val_loss: 0.3633 - val_accuracy: 0.8900 - val_auc: 0.9474\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2314 - accuracy: 0.9076 - auc: 0.9684 - val_loss: 0.3992 - val_accuracy: 0.9238 - val_auc: 0.9440\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2477 - accuracy: 0.9045 - auc: 0.9646 - val_loss: 0.4027 - val_accuracy: 0.9218 - val_auc: 0.9443\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2321 - accuracy: 0.9120 - auc: 0.9678 - val_loss: 0.4360 - val_accuracy: 0.9189 - val_auc: 0.9457\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2313 - accuracy: 0.9078 - auc: 0.9679 - val_loss: 0.4811 - val_accuracy: 0.9112 - val_auc: 0.9405\n",
      "Epoch 23/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2265 - accuracy: 0.9039 - auc: 0.9694Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2251 - accuracy: 0.9040 - auc: 0.9697 - val_loss: 0.5065 - val_accuracy: 0.9295 - val_auc: 0.9396\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.5271 - accuracy: 0.6991 - auc: 0.8685 - val_loss: 0.2981 - val_accuracy: 0.8868 - val_auc: 0.9484\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3297 - accuracy: 0.8705 - auc: 0.9366 - val_loss: 0.2868 - val_accuracy: 0.8713 - val_auc: 0.9521\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3042 - accuracy: 0.8749 - auc: 0.9464 - val_loss: 0.2611 - val_accuracy: 0.9040 - val_auc: 0.9590\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3036 - accuracy: 0.8915 - auc: 0.9461 - val_loss: 0.2768 - val_accuracy: 0.8932 - val_auc: 0.9565\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2827 - accuracy: 0.8988 - auc: 0.9523 - val_loss: 0.2651 - val_accuracy: 0.9048 - val_auc: 0.9580\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2777 - accuracy: 0.8981 - auc: 0.9543 - val_loss: 0.2740 - val_accuracy: 0.9073 - val_auc: 0.9574\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2724 - accuracy: 0.9039 - auc: 0.9565 - val_loss: 0.2783 - val_accuracy: 0.9151 - val_auc: 0.9559\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2666 - accuracy: 0.9054 - auc: 0.9579 - val_loss: 0.2770 - val_accuracy: 0.8947 - val_auc: 0.9552\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2644 - accuracy: 0.9026 - auc: 0.9585 - val_loss: 0.2892 - val_accuracy: 0.9131 - val_auc: 0.9544\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2523 - accuracy: 0.9067 - auc: 0.9625 - val_loss: 0.2894 - val_accuracy: 0.9006 - val_auc: 0.9557\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2551 - accuracy: 0.9054 - auc: 0.9618 - val_loss: 0.2916 - val_accuracy: 0.9058 - val_auc: 0.9556\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2492 - accuracy: 0.9056 - auc: 0.9630 - val_loss: 0.3139 - val_accuracy: 0.9158 - val_auc: 0.9545\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2449 - accuracy: 0.9058 - auc: 0.9638 - val_loss: 0.3130 - val_accuracy: 0.8976 - val_auc: 0.9535\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2483 - accuracy: 0.9056 - auc: 0.9637 - val_loss: 0.3167 - val_accuracy: 0.9119 - val_auc: 0.9539\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2523 - accuracy: 0.9034 - auc: 0.9627 - val_loss: 0.3376 - val_accuracy: 0.9066 - val_auc: 0.9508\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2400 - accuracy: 0.9063 - auc: 0.9653 - val_loss: 0.3488 - val_accuracy: 0.9121 - val_auc: 0.9503\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2468 - accuracy: 0.9046 - auc: 0.9634 - val_loss: 0.3378 - val_accuracy: 0.9226 - val_auc: 0.9534\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2328 - accuracy: 0.9066 - auc: 0.9667 - val_loss: 0.3755 - val_accuracy: 0.9211 - val_auc: 0.9475\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2305 - accuracy: 0.9066 - auc: 0.9677 - val_loss: 0.3882 - val_accuracy: 0.9128 - val_auc: 0.9449\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2433 - accuracy: 0.9031 - auc: 0.9644 - val_loss: 0.3795 - val_accuracy: 0.9009 - val_auc: 0.9480\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2529 - accuracy: 0.9027 - auc: 0.9622 - val_loss: 0.3972 - val_accuracy: 0.9038 - val_auc: 0.9438\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2280 - accuracy: 0.9011 - auc: 0.9677 - val_loss: 0.4281 - val_accuracy: 0.9202 - val_auc: 0.9427\n",
      "Epoch 23/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2237 - accuracy: 0.9093 - auc: 0.9687Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2253 - accuracy: 0.9092 - auc: 0.9684 - val_loss: 0.4579 - val_accuracy: 0.9125 - val_auc: 0.9411\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 0.5590 - accuracy: 0.8704 - auc: 0.8531 - val_loss: 0.3234 - val_accuracy: 0.9196 - val_auc: 0.9462\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3493 - accuracy: 0.9132 - auc: 0.9361 - val_loss: 0.3068 - val_accuracy: 0.9130 - val_auc: 0.9539\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3320 - accuracy: 0.9053 - auc: 0.9476 - val_loss: 0.2988 - val_accuracy: 0.9199 - val_auc: 0.9525\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3176 - accuracy: 0.9153 - auc: 0.9489 - val_loss: 0.2860 - val_accuracy: 0.9087 - val_auc: 0.9553\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3212 - accuracy: 0.9099 - auc: 0.9475 - val_loss: 0.2847 - val_accuracy: 0.9271 - val_auc: 0.9587\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3067 - accuracy: 0.9158 - auc: 0.9516 - val_loss: 0.2960 - val_accuracy: 0.9128 - val_auc: 0.9542\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3144 - accuracy: 0.9184 - auc: 0.9501 - val_loss: 0.2890 - val_accuracy: 0.9129 - val_auc: 0.9550\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2942 - accuracy: 0.9163 - auc: 0.9552 - val_loss: 0.2845 - val_accuracy: 0.9324 - val_auc: 0.9552\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3025 - accuracy: 0.9174 - auc: 0.9520 - val_loss: 0.2900 - val_accuracy: 0.9317 - val_auc: 0.9533\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2869 - accuracy: 0.9211 - auc: 0.9571 - val_loss: 0.2895 - val_accuracy: 0.9295 - val_auc: 0.9502\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2741 - accuracy: 0.9221 - auc: 0.9599 - val_loss: 0.2939 - val_accuracy: 0.9100 - val_auc: 0.9490\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2895 - accuracy: 0.9183 - auc: 0.9550 - val_loss: 0.3012 - val_accuracy: 0.9171 - val_auc: 0.9459\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2755 - accuracy: 0.9146 - auc: 0.9605 - val_loss: 0.3043 - val_accuracy: 0.9246 - val_auc: 0.9483\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2802 - accuracy: 0.9195 - auc: 0.9588 - val_loss: 0.2983 - val_accuracy: 0.9160 - val_auc: 0.9499\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2762 - accuracy: 0.9168 - auc: 0.9593 - val_loss: 0.2913 - val_accuracy: 0.9206 - val_auc: 0.9504\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2659 - accuracy: 0.9203 - auc: 0.9611 - val_loss: 0.3055 - val_accuracy: 0.9089 - val_auc: 0.9469\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2632 - accuracy: 0.9185 - auc: 0.9623 - val_loss: 0.3113 - val_accuracy: 0.9343 - val_auc: 0.9472\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2578 - accuracy: 0.9229 - auc: 0.9627 - val_loss: 0.3203 - val_accuracy: 0.9368 - val_auc: 0.9460\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2724 - accuracy: 0.9195 - auc: 0.9602 - val_loss: 0.3187 - val_accuracy: 0.9275 - val_auc: 0.9457\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2602 - accuracy: 0.9223 - auc: 0.9623 - val_loss: 0.3209 - val_accuracy: 0.9229 - val_auc: 0.9459\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2686 - accuracy: 0.9188 - auc: 0.9604 - val_loss: 0.3147 - val_accuracy: 0.9307 - val_auc: 0.9477\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2631 - accuracy: 0.9198 - auc: 0.9631 - val_loss: 0.3219 - val_accuracy: 0.9113 - val_auc: 0.9481\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2646 - accuracy: 0.9174 - auc: 0.9616 - val_loss: 0.3293 - val_accuracy: 0.9158 - val_auc: 0.9451\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2485 - accuracy: 0.9202 - auc: 0.9664 - val_loss: 0.3425 - val_accuracy: 0.9246 - val_auc: 0.9437\n",
      "Epoch 25/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2534 - accuracy: 0.9214 - auc: 0.9645Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2525 - accuracy: 0.9215 - auc: 0.9646 - val_loss: 0.3551 - val_accuracy: 0.9286 - val_auc: 0.9445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 19us/sample - loss: 0.6595 - accuracy: 0.8856 - auc: 0.8359 - val_loss: 0.3321 - val_accuracy: 0.8884 - val_auc: 0.9483\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3545 - accuracy: 0.9067 - auc: 0.9328 - val_loss: 0.2995 - val_accuracy: 0.9113 - val_auc: 0.9545\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3373 - accuracy: 0.9103 - auc: 0.9450 - val_loss: 0.2875 - val_accuracy: 0.9244 - val_auc: 0.9566\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3100 - accuracy: 0.9132 - auc: 0.9508 - val_loss: 0.2909 - val_accuracy: 0.9367 - val_auc: 0.9509\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3329 - accuracy: 0.9082 - auc: 0.9463 - val_loss: 0.2834 - val_accuracy: 0.9236 - val_auc: 0.9522\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3172 - accuracy: 0.9163 - auc: 0.9464 - val_loss: 0.2799 - val_accuracy: 0.9126 - val_auc: 0.9534\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3075 - accuracy: 0.9148 - auc: 0.9534 - val_loss: 0.2800 - val_accuracy: 0.9161 - val_auc: 0.9557\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2961 - accuracy: 0.9157 - auc: 0.9562 - val_loss: 0.2836 - val_accuracy: 0.9173 - val_auc: 0.9533\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2901 - accuracy: 0.9180 - auc: 0.9555 - val_loss: 0.2898 - val_accuracy: 0.9140 - val_auc: 0.9519\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2870 - accuracy: 0.9191 - auc: 0.9571 - val_loss: 0.2795 - val_accuracy: 0.9184 - val_auc: 0.9548\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2960 - accuracy: 0.9155 - auc: 0.9538 - val_loss: 0.2702 - val_accuracy: 0.9176 - val_auc: 0.9592\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2718 - accuracy: 0.9192 - auc: 0.9622 - val_loss: 0.2890 - val_accuracy: 0.9264 - val_auc: 0.9526\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2684 - accuracy: 0.9175 - auc: 0.9623 - val_loss: 0.2872 - val_accuracy: 0.9253 - val_auc: 0.9536\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2798 - accuracy: 0.9182 - auc: 0.9593 - val_loss: 0.2858 - val_accuracy: 0.9083 - val_auc: 0.9546\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2973 - accuracy: 0.9098 - auc: 0.9564 - val_loss: 0.2874 - val_accuracy: 0.9059 - val_auc: 0.9525\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2729 - accuracy: 0.9159 - auc: 0.9603 - val_loss: 0.2947 - val_accuracy: 0.9131 - val_auc: 0.9494\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2528 - accuracy: 0.9174 - auc: 0.9649 - val_loss: 0.3104 - val_accuracy: 0.9248 - val_auc: 0.9478\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2783 - accuracy: 0.9139 - auc: 0.9605 - val_loss: 0.3143 - val_accuracy: 0.9283 - val_auc: 0.9480\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2616 - accuracy: 0.9190 - auc: 0.9626 - val_loss: 0.3218 - val_accuracy: 0.9276 - val_auc: 0.9480\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2506 - accuracy: 0.9186 - auc: 0.9655 - val_loss: 0.3370 - val_accuracy: 0.9244 - val_auc: 0.9470\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2463 - accuracy: 0.9173 - auc: 0.9662 - val_loss: 0.3550 - val_accuracy: 0.9169 - val_auc: 0.9451\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2492 - accuracy: 0.9170 - auc: 0.9656 - val_loss: 0.3590 - val_accuracy: 0.9272 - val_auc: 0.9432\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2581 - accuracy: 0.9146 - auc: 0.9641 - val_loss: 0.3562 - val_accuracy: 0.9192 - val_auc: 0.9456\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2516 - accuracy: 0.9163 - auc: 0.9646 - val_loss: 0.3532 - val_accuracy: 0.9192 - val_auc: 0.9466\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2464 - accuracy: 0.9136 - auc: 0.9663 - val_loss: 0.3522 - val_accuracy: 0.9199 - val_auc: 0.9469\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2466 - accuracy: 0.9159 - auc: 0.9661 - val_loss: 0.3671 - val_accuracy: 0.9262 - val_auc: 0.9470\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2320 - accuracy: 0.9189 - auc: 0.9692 - val_loss: 0.3780 - val_accuracy: 0.9197 - val_auc: 0.9460\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2458 - accuracy: 0.9174 - auc: 0.9658 - val_loss: 0.3839 - val_accuracy: 0.9239 - val_auc: 0.9450\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2415 - accuracy: 0.9155 - auc: 0.9670 - val_loss: 0.3919 - val_accuracy: 0.9213 - val_auc: 0.9454\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2359 - accuracy: 0.9163 - auc: 0.9681 - val_loss: 0.4110 - val_accuracy: 0.9285 - val_auc: 0.9457\n",
      "Epoch 31/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9174 - auc: 0.9703Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2297 - accuracy: 0.9174 - auc: 0.9704 - val_loss: 0.4271 - val_accuracy: 0.9315 - val_auc: 0.9459\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5014 - accuracy: 0.7687 - auc: 0.8837 - val_loss: 0.3024 - val_accuracy: 0.8906 - val_auc: 0.9479\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3322 - accuracy: 0.8662 - auc: 0.9403 - val_loss: 0.2788 - val_accuracy: 0.8915 - val_auc: 0.9562\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2947 - accuracy: 0.8938 - auc: 0.9511 - val_loss: 0.2777 - val_accuracy: 0.9077 - val_auc: 0.9567\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2984 - accuracy: 0.8965 - auc: 0.9518 - val_loss: 0.2634 - val_accuracy: 0.8908 - val_auc: 0.9601\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2693 - accuracy: 0.9026 - auc: 0.9581 - val_loss: 0.2598 - val_accuracy: 0.8994 - val_auc: 0.9591\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2692 - accuracy: 0.8978 - auc: 0.9580 - val_loss: 0.2623 - val_accuracy: 0.9074 - val_auc: 0.9592\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2743 - accuracy: 0.8982 - auc: 0.9575 - val_loss: 0.2756 - val_accuracy: 0.9331 - val_auc: 0.9590\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2716 - accuracy: 0.9048 - auc: 0.9584 - val_loss: 0.2569 - val_accuracy: 0.9109 - val_auc: 0.9609\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2533 - accuracy: 0.9098 - auc: 0.9633 - val_loss: 0.2747 - val_accuracy: 0.9285 - val_auc: 0.9582\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2578 - accuracy: 0.9026 - auc: 0.9607 - val_loss: 0.2808 - val_accuracy: 0.9137 - val_auc: 0.9564\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2439 - accuracy: 0.9097 - auc: 0.9653 - val_loss: 0.2792 - val_accuracy: 0.8999 - val_auc: 0.9575\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2416 - accuracy: 0.9057 - auc: 0.9654 - val_loss: 0.2876 - val_accuracy: 0.9134 - val_auc: 0.9550\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2455 - accuracy: 0.9071 - auc: 0.9647 - val_loss: 0.2800 - val_accuracy: 0.9028 - val_auc: 0.9573\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2406 - accuracy: 0.9092 - auc: 0.9658 - val_loss: 0.2879 - val_accuracy: 0.9051 - val_auc: 0.9541\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2379 - accuracy: 0.9088 - auc: 0.9665 - val_loss: 0.3042 - val_accuracy: 0.9080 - val_auc: 0.9529\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2320 - accuracy: 0.9052 - auc: 0.9675 - val_loss: 0.3177 - val_accuracy: 0.9033 - val_auc: 0.9507\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2261 - accuracy: 0.9087 - auc: 0.9691 - val_loss: 0.3353 - val_accuracy: 0.9185 - val_auc: 0.9511curacy: 0.9096 - ETA: 0s - loss: 0.2279 - accuracy: 0.9094 - a\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2562 - accuracy: 0.9048 - auc: 0.9635 - val_loss: 0.3192 - val_accuracy: 0.9097 - val_auc: 0.9527\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2405 - accuracy: 0.9071 - auc: 0.9667 - val_loss: 0.3598 - val_accuracy: 0.9143 - val_auc: 0.9457\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2413 - accuracy: 0.9077 - auc: 0.9655 - val_loss: 0.3537 - val_accuracy: 0.9086 - val_auc: 0.9471\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2287 - accuracy: 0.9113 - auc: 0.9689 - val_loss: 0.3890 - val_accuracy: 0.9325 - val_auc: 0.9431\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2279 - accuracy: 0.9077 - auc: 0.9686 - val_loss: 0.3429 - val_accuracy: 0.9275 - val_auc: 0.9480\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2182 - accuracy: 0.9130 - auc: 0.9710 - val_loss: 0.3725 - val_accuracy: 0.9294 - val_auc: 0.9453\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2237 - accuracy: 0.9128 - auc: 0.9701 - val_loss: 0.3811 - val_accuracy: 0.9130 - val_auc: 0.9437\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2121 - accuracy: 0.9062 - auc: 0.9723 - val_loss: 0.4066 - val_accuracy: 0.9173 - val_auc: 0.9427\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2171 - accuracy: 0.9121 - auc: 0.9713 - val_loss: 0.4137 - val_accuracy: 0.9217 - val_auc: 0.9437\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2256 - accuracy: 0.9095 - auc: 0.9692 - val_loss: 0.4033 - val_accuracy: 0.9269 - val_auc: 0.9420\n",
      "Epoch 28/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2230 - accuracy: 0.9098 - auc: 0.9706Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2223 - accuracy: 0.9099 - auc: 0.9707 - val_loss: 0.3846 - val_accuracy: 0.9186 - val_auc: 0.9477\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5154 - accuracy: 0.8615 - auc: 0.8875 - val_loss: 0.3109 - val_accuracy: 0.8959 - val_auc: 0.9549\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3387 - accuracy: 0.9020 - auc: 0.9385 - val_loss: 0.2823 - val_accuracy: 0.9273 - val_auc: 0.9539\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3030 - accuracy: 0.9072 - auc: 0.9500 - val_loss: 0.2857 - val_accuracy: 0.9225 - val_auc: 0.9539\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3125 - accuracy: 0.9098 - auc: 0.9467 - val_loss: 0.2896 - val_accuracy: 0.9148 - val_auc: 0.9575\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2910 - accuracy: 0.9112 - auc: 0.9528 - val_loss: 0.2920 - val_accuracy: 0.9034 - val_auc: 0.9519\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2828 - accuracy: 0.9114 - auc: 0.9561 - val_loss: 0.2780 - val_accuracy: 0.9235 - val_auc: 0.9562\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2719 - accuracy: 0.9075 - auc: 0.9586 - val_loss: 0.2742 - val_accuracy: 0.9258 - val_auc: 0.9571\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2764 - accuracy: 0.9125 - auc: 0.9581 - val_loss: 0.2761 - val_accuracy: 0.9211 - val_auc: 0.9583\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2653 - accuracy: 0.9111 - auc: 0.9611 - val_loss: 0.2828 - val_accuracy: 0.9370 - val_auc: 0.9573\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2689 - accuracy: 0.9139 - auc: 0.9600 - val_loss: 0.2881 - val_accuracy: 0.9342 - val_auc: 0.9555\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2725 - accuracy: 0.9132 - auc: 0.9597 - val_loss: 0.2991 - val_accuracy: 0.9270 - val_auc: 0.9539\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2616 - accuracy: 0.9151 - auc: 0.9623 - val_loss: 0.3027 - val_accuracy: 0.9401 - val_auc: 0.9516\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2547 - accuracy: 0.9144 - auc: 0.9632 - val_loss: 0.3076 - val_accuracy: 0.9247 - val_auc: 0.9510\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2592 - accuracy: 0.9192 - auc: 0.9633 - val_loss: 0.3189 - val_accuracy: 0.9139 - val_auc: 0.9498\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2445 - accuracy: 0.9162 - auc: 0.9665 - val_loss: 0.3219 - val_accuracy: 0.9115 - val_auc: 0.9492\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2479 - accuracy: 0.9157 - auc: 0.9655 - val_loss: 0.3444 - val_accuracy: 0.9232 - val_auc: 0.9473\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2522 - accuracy: 0.9150 - auc: 0.9644 - val_loss: 0.3363 - val_accuracy: 0.9032 - val_auc: 0.9484s: 0.2540 - accuracy: 0.9162 - auc: \n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2275 - accuracy: 0.9198 - auc: 0.9704 - val_loss: 0.3726 - val_accuracy: 0.9203 - val_auc: 0.9474\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2328 - accuracy: 0.9160 - auc: 0.9682 - val_loss: 0.3595 - val_accuracy: 0.9186 - val_auc: 0.9491\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2354 - accuracy: 0.9211 - auc: 0.9684 - val_loss: 0.3780 - val_accuracy: 0.9246 - val_auc: 0.9442\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2401 - accuracy: 0.9167 - auc: 0.9674 - val_loss: 0.3803 - val_accuracy: 0.9186 - val_auc: 0.9451\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2330 - accuracy: 0.9149 - auc: 0.9683 - val_loss: 0.3987 - val_accuracy: 0.9288 - val_auc: 0.9430\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2262 - accuracy: 0.9164 - auc: 0.9698 - val_loss: 0.4245 - val_accuracy: 0.9282 - val_auc: 0.9433\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2193 - accuracy: 0.9190 - auc: 0.9710 - val_loss: 0.4244 - val_accuracy: 0.9239 - val_auc: 0.9428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2226 - accuracy: 0.9200 - auc: 0.9704 - val_loss: 0.4344 - val_accuracy: 0.9269 - val_auc: 0.9438\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2127 - accuracy: 0.9184 - auc: 0.9725 - val_loss: 0.4708 - val_accuracy: 0.9278 - val_auc: 0.9409\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2119 - accuracy: 0.9189 - auc: 0.9730 - val_loss: 0.5039 - val_accuracy: 0.9263 - val_auc: 0.9389\n",
      "Epoch 28/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2149 - accuracy: 0.9201 - auc: 0.9723Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2146 - accuracy: 0.9202 - auc: 0.9724 - val_loss: 0.4953 - val_accuracy: 0.9326 - val_auc: 0.9405\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.4709 - accuracy: 0.8259 - auc: 0.8811 - val_loss: 0.3114 - val_accuracy: 0.9071 - val_auc: 0.9478\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3389 - accuracy: 0.8905 - auc: 0.9369 - val_loss: 0.2857 - val_accuracy: 0.9093 - val_auc: 0.9573\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3162 - accuracy: 0.9024 - auc: 0.9423 - val_loss: 0.2752 - val_accuracy: 0.8926 - val_auc: 0.9581\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2962 - accuracy: 0.9034 - auc: 0.9494 - val_loss: 0.2754 - val_accuracy: 0.8944 - val_auc: 0.9562\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2851 - accuracy: 0.9037 - auc: 0.9546 - val_loss: 0.2859 - val_accuracy: 0.9060 - val_auc: 0.9515\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2885 - accuracy: 0.9031 - auc: 0.9526 - val_loss: 0.2839 - val_accuracy: 0.9205 - val_auc: 0.9534\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2939 - accuracy: 0.9027 - auc: 0.9525 - val_loss: 0.2968 - val_accuracy: 0.9263 - val_auc: 0.9513\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2713 - accuracy: 0.9095 - auc: 0.9585 - val_loss: 0.3010 - val_accuracy: 0.9012 - val_auc: 0.9513\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2914 - accuracy: 0.9027 - auc: 0.9553 - val_loss: 0.3048 - val_accuracy: 0.8983 - val_auc: 0.9508\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2655 - accuracy: 0.9082 - auc: 0.9592 - val_loss: 0.3044 - val_accuracy: 0.9083 - val_auc: 0.9508\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2649 - accuracy: 0.9078 - auc: 0.9599 - val_loss: 0.3203 - val_accuracy: 0.9237 - val_auc: 0.9510\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2430 - accuracy: 0.9111 - auc: 0.9650 - val_loss: 0.3418 - val_accuracy: 0.9236 - val_auc: 0.9490\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2642 - accuracy: 0.9050 - auc: 0.9606 - val_loss: 0.3522 - val_accuracy: 0.9126 - val_auc: 0.9493\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2545 - accuracy: 0.9056 - auc: 0.9621 - val_loss: 0.3565 - val_accuracy: 0.9163 - val_auc: 0.9499\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2499 - accuracy: 0.9112 - auc: 0.9637 - val_loss: 0.3487 - val_accuracy: 0.9105 - val_auc: 0.9508\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2417 - accuracy: 0.9079 - auc: 0.9657 - val_loss: 0.3529 - val_accuracy: 0.9252 - val_auc: 0.9496\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2531 - accuracy: 0.9108 - auc: 0.9636 - val_loss: 0.3776 - val_accuracy: 0.9160 - val_auc: 0.9471\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2296 - accuracy: 0.9137 - auc: 0.9685 - val_loss: 0.3804 - val_accuracy: 0.9104 - val_auc: 0.9471\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2466 - accuracy: 0.9110 - auc: 0.9672 - val_loss: 0.3860 - val_accuracy: 0.9145 - val_auc: 0.9485\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2304 - accuracy: 0.9125 - auc: 0.9683 - val_loss: 0.4202 - val_accuracy: 0.9175 - val_auc: 0.9487\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2432 - accuracy: 0.9075 - auc: 0.9650 - val_loss: 0.4275 - val_accuracy: 0.9195 - val_auc: 0.9470\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2315 - accuracy: 0.9140 - auc: 0.9678 - val_loss: 0.4033 - val_accuracy: 0.9189 - val_auc: 0.9493\n",
      "Epoch 23/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2315 - accuracy: 0.9134 - auc: 0.9683Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2305 - accuracy: 0.9134 - auc: 0.9686 - val_loss: 0.4471 - val_accuracy: 0.9258 - val_auc: 0.9453\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.4716 - accuracy: 0.8506 - auc: 0.8874 - val_loss: 0.3159 - val_accuracy: 0.9236 - val_auc: 0.9447\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3393 - accuracy: 0.8939 - auc: 0.9373 - val_loss: 0.2824 - val_accuracy: 0.9231 - val_auc: 0.9545\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3142 - accuracy: 0.9035 - auc: 0.9436 - val_loss: 0.2804 - val_accuracy: 0.9076 - val_auc: 0.9553\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3175 - accuracy: 0.9085 - auc: 0.9443 - val_loss: 0.2824 - val_accuracy: 0.8998 - val_auc: 0.9532\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2889 - accuracy: 0.9065 - auc: 0.9520 - val_loss: 0.2811 - val_accuracy: 0.9281 - val_auc: 0.9543\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3144 - accuracy: 0.9062 - auc: 0.9482 - val_loss: 0.2934 - val_accuracy: 0.9146 - val_auc: 0.9496\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2880 - accuracy: 0.9071 - auc: 0.9532 - val_loss: 0.2804 - val_accuracy: 0.9357 - val_auc: 0.9549\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.2854 - accuracy: 0.9102 - auc: 0.9552 - val_loss: 0.3125 - val_accuracy: 0.9188 - val_auc: 0.9471\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2770 - accuracy: 0.9122 - auc: 0.9582 - val_loss: 0.2868 - val_accuracy: 0.9211 - val_auc: 0.9527\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2835 - accuracy: 0.9064 - auc: 0.9545 - val_loss: 0.2856 - val_accuracy: 0.9231 - val_auc: 0.9533\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2589 - accuracy: 0.9107 - auc: 0.9624 - val_loss: 0.2941 - val_accuracy: 0.9223 - val_auc: 0.9514\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2499 - accuracy: 0.9147 - auc: 0.9640 - val_loss: 0.3198 - val_accuracy: 0.9112 - val_auc: 0.9498\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2621 - accuracy: 0.9098 - auc: 0.9619 - val_loss: 0.3050 - val_accuracy: 0.9217 - val_auc: 0.9514\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2615 - accuracy: 0.9102 - auc: 0.9628 - val_loss: 0.3124 - val_accuracy: 0.9350 - val_auc: 0.9497\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2536 - accuracy: 0.9130 - auc: 0.9639 - val_loss: 0.3086 - val_accuracy: 0.9207 - val_auc: 0.9507\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2467 - accuracy: 0.9123 - auc: 0.9652 - val_loss: 0.3409 - val_accuracy: 0.9352 - val_auc: 0.9495\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2493 - accuracy: 0.9182 - auc: 0.9658 - val_loss: 0.3351 - val_accuracy: 0.9175 - val_auc: 0.9488\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2566 - accuracy: 0.9087 - auc: 0.9628 - val_loss: 0.3364 - val_accuracy: 0.9136 - val_auc: 0.9486\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2476 - accuracy: 0.9128 - auc: 0.9653 - val_loss: 0.3198 - val_accuracy: 0.9095 - val_auc: 0.9522\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2243 - accuracy: 0.9161 - auc: 0.9697 - val_loss: 0.3452 - val_accuracy: 0.9133 - val_auc: 0.9462\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2500 - accuracy: 0.9095 - auc: 0.9648 - val_loss: 0.3471 - val_accuracy: 0.9231 - val_auc: 0.9487\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2372 - accuracy: 0.9140 - auc: 0.9671 - val_loss: 0.3513 - val_accuracy: 0.9208 - val_auc: 0.9479\n",
      "Epoch 23/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.2232 - accuracy: 0.9175 - auc: 0.9704Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2216 - accuracy: 0.9176 - auc: 0.9706 - val_loss: 0.3984 - val_accuracy: 0.9297 - val_auc: 0.9467\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 20us/sample - loss: 0.5013 - accuracy: 0.7572 - auc: 0.8920 - val_loss: 0.2964 - val_accuracy: 0.9074 - val_auc: 0.9473\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3399 - accuracy: 0.8475 - auc: 0.9368 - val_loss: 0.2854 - val_accuracy: 0.8911 - val_auc: 0.9518\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2956 - accuracy: 0.8712 - auc: 0.9512 - val_loss: 0.2809 - val_accuracy: 0.8938 - val_auc: 0.9528\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3200 - accuracy: 0.8611 - auc: 0.9471 - val_loss: 0.2840 - val_accuracy: 0.9056 - val_auc: 0.9521\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2999 - accuracy: 0.8840 - auc: 0.9514 - val_loss: 0.2859 - val_accuracy: 0.8798 - val_auc: 0.9514\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2679 - accuracy: 0.8915 - auc: 0.9590 - val_loss: 0.3056 - val_accuracy: 0.9045 - val_auc: 0.9518\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2744 - accuracy: 0.8882 - auc: 0.9571 - val_loss: 0.2771 - val_accuracy: 0.9052 - val_auc: 0.9573\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2432 - accuracy: 0.9003 - auc: 0.9649 - val_loss: 0.2927 - val_accuracy: 0.9011 - val_auc: 0.9554\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2504 - accuracy: 0.8978 - auc: 0.9633 - val_loss: 0.3029 - val_accuracy: 0.9048 - val_auc: 0.9543\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2370 - accuracy: 0.9000 - auc: 0.9662 - val_loss: 0.3215 - val_accuracy: 0.9125 - val_auc: 0.9527\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2377 - accuracy: 0.8984 - auc: 0.9662 - val_loss: 0.3329 - val_accuracy: 0.9188 - val_auc: 0.9526\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2427 - accuracy: 0.8981 - auc: 0.9661 - val_loss: 0.3414 - val_accuracy: 0.9150 - val_auc: 0.9500\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2298 - accuracy: 0.9039 - auc: 0.9682 - val_loss: 0.3529 - val_accuracy: 0.9052 - val_auc: 0.9491\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2245 - accuracy: 0.9012 - auc: 0.9696 - val_loss: 0.3587 - val_accuracy: 0.9165 - val_auc: 0.9482\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2288 - accuracy: 0.9030 - auc: 0.9684 - val_loss: 0.3627 - val_accuracy: 0.9101 - val_auc: 0.9499\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2413 - accuracy: 0.8969 - auc: 0.9659 - val_loss: 0.3746 - val_accuracy: 0.9199 - val_auc: 0.9498\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2430 - accuracy: 0.9047 - auc: 0.9654 - val_loss: 0.3586 - val_accuracy: 0.9194 - val_auc: 0.9493\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2517 - accuracy: 0.9019 - auc: 0.9669 - val_loss: 0.3409 - val_accuracy: 0.9141 - val_auc: 0.9487\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2246 - accuracy: 0.9046 - auc: 0.9698 - val_loss: 0.4023 - val_accuracy: 0.9161 - val_auc: 0.9433\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2169 - accuracy: 0.9067 - auc: 0.9717 - val_loss: 0.4368 - val_accuracy: 0.9212 - val_auc: 0.9429\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2096 - accuracy: 0.9063 - auc: 0.9727 - val_loss: 0.4694 - val_accuracy: 0.9251 - val_auc: 0.9432\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2201 - accuracy: 0.9033 - auc: 0.9708 - val_loss: 0.4924 - val_accuracy: 0.9334 - val_auc: 0.9429\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2123 - accuracy: 0.9074 - auc: 0.9722 - val_loss: 0.4813 - val_accuracy: 0.9203 - val_auc: 0.9437\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2115 - accuracy: 0.9080 - auc: 0.9728 - val_loss: 0.4794 - val_accuracy: 0.9192 - val_auc: 0.9428\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2223 - accuracy: 0.9030 - auc: 0.9703 - val_loss: 0.4659 - val_accuracy: 0.9211 - val_auc: 0.9423\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2160 - accuracy: 0.9056 - auc: 0.9716 - val_loss: 0.4983 - val_accuracy: 0.9239 - val_auc: 0.9415\n",
      "Epoch 27/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2262 - accuracy: 0.9056 - auc: 0.9700 ETA: 0s - loss: 0.2164 - accuracy: 0.Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2254 - accuracy: 0.9055 - auc: 0.9701 - val_loss: 0.5058 - val_accuracy: 0.9074 - val_auc: 0.9395\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 18us/sample - loss: 0.7260 - accuracy: 0.9232 - auc: 0.6440 - val_loss: 0.5192 - val_accuracy: 0.9437 - val_auc: 0.8542\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6142 - accuracy: 0.9160 - auc: 0.7485 - val_loss: 0.4712 - val_accuracy: 0.9353 - val_auc: 0.8965\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5838 - accuracy: 0.9189 - auc: 0.7860 - val_loss: 0.4311 - val_accuracy: 0.9322 - val_auc: 0.9255\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5601 - accuracy: 0.9217 - auc: 0.8085 - val_loss: 0.4082 - val_accuracy: 0.9296 - val_auc: 0.9357\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5152 - accuracy: 0.9245 - auc: 0.8424 - val_loss: 0.3854 - val_accuracy: 0.9243 - val_auc: 0.9432\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5146 - accuracy: 0.9209 - auc: 0.8497 - val_loss: 0.3650 - val_accuracy: 0.9179 - val_auc: 0.9493\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4942 - accuracy: 0.9209 - auc: 0.8608 - val_loss: 0.3489 - val_accuracy: 0.9132 - val_auc: 0.9532\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4626 - accuracy: 0.9216 - auc: 0.8740 - val_loss: 0.3382 - val_accuracy: 0.9131 - val_auc: 0.9553\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4475 - accuracy: 0.9211 - auc: 0.8818 - val_loss: 0.3221 - val_accuracy: 0.9083 - val_auc: 0.9566\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4279 - accuracy: 0.9218 - auc: 0.8900 - val_loss: 0.3143 - val_accuracy: 0.9047 - val_auc: 0.9574\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4195 - accuracy: 0.9217 - auc: 0.8935 - val_loss: 0.3081 - val_accuracy: 0.9060 - val_auc: 0.9574\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4161 - accuracy: 0.9223 - auc: 0.8937 - val_loss: 0.3016 - val_accuracy: 0.9014 - val_auc: 0.9578\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4106 - accuracy: 0.8252 - auc: 0.8939 - val_loss: 0.2961 - val_accuracy: 0.8945 - val_auc: 0.9590\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3902 - accuracy: 0.7806 - auc: 0.9044 - val_loss: 0.2882 - val_accuracy: 0.8943 - val_auc: 0.9592\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3867 - accuracy: 0.7795 - auc: 0.9040 - val_loss: 0.2893 - val_accuracy: 0.8946 - val_auc: 0.9594\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3782 - accuracy: 0.7848 - auc: 0.9076 - val_loss: 0.2870 - val_accuracy: 0.8947 - val_auc: 0.9590\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3656 - accuracy: 0.7839 - auc: 0.9140 - val_loss: 0.2845 - val_accuracy: 0.8941 - val_auc: 0.9590\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3677 - accuracy: 0.7858 - auc: 0.9103 - val_loss: 0.2806 - val_accuracy: 0.8920 - val_auc: 0.9596\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3633 - accuracy: 0.7853 - auc: 0.9150 - val_loss: 0.2835 - val_accuracy: 0.8910 - val_auc: 0.9587\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3511 - accuracy: 0.7865 - auc: 0.9171 - val_loss: 0.2791 - val_accuracy: 0.8922 - val_auc: 0.9590\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3523 - accuracy: 0.7837 - auc: 0.9150 - val_loss: 0.2781 - val_accuracy: 0.8909 - val_auc: 0.9596\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3523 - accuracy: 0.7838 - auc: 0.9151 - val_loss: 0.2785 - val_accuracy: 0.8851 - val_auc: 0.9590\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3442 - accuracy: 0.7827 - auc: 0.9159 - val_loss: 0.2814 - val_accuracy: 0.8855 - val_auc: 0.9590\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3434 - accuracy: 0.7837 - auc: 0.9182 - val_loss: 0.2787 - val_accuracy: 0.8871 - val_auc: 0.9592\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3474 - accuracy: 0.7855 - auc: 0.9156 - val_loss: 0.2774 - val_accuracy: 0.8817 - val_auc: 0.9591\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3330 - accuracy: 0.7836 - auc: 0.9213 - val_loss: 0.2777 - val_accuracy: 0.8867 - val_auc: 0.9589\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3302 - accuracy: 0.7833 - auc: 0.9221 - val_loss: 0.2791 - val_accuracy: 0.8861 - val_auc: 0.9592\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3327 - accuracy: 0.7878 - auc: 0.9191 - val_loss: 0.2779 - val_accuracy: 0.8849 - val_auc: 0.9590\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3324 - accuracy: 0.7824 - auc: 0.9207 - val_loss: 0.2761 - val_accuracy: 0.8812 - val_auc: 0.9595\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3278 - accuracy: 0.7848 - auc: 0.9237 - val_loss: 0.2766 - val_accuracy: 0.8812 - val_auc: 0.9592\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3254 - accuracy: 0.7863 - auc: 0.9234 - val_loss: 0.2766 - val_accuracy: 0.8840 - val_auc: 0.9597\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3220 - accuracy: 0.7879 - auc: 0.9233 - val_loss: 0.2777 - val_accuracy: 0.8831 - val_auc: 0.9595\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3278 - accuracy: 0.7855 - auc: 0.9240 - val_loss: 0.2771 - val_accuracy: 0.8825 - val_auc: 0.9598\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3295 - accuracy: 0.7838 - auc: 0.9251 - val_loss: 0.2788 - val_accuracy: 0.8800 - val_auc: 0.9583\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3261 - accuracy: 0.7813 - auc: 0.9220 - val_loss: 0.2826 - val_accuracy: 0.8758 - val_auc: 0.9579\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3218 - accuracy: 0.7839 - auc: 0.9235 - val_loss: 0.2834 - val_accuracy: 0.8767 - val_auc: 0.9583\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3208 - accuracy: 0.7854 - auc: 0.9222 - val_loss: 0.2830 - val_accuracy: 0.8805 - val_auc: 0.9583\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3213 - accuracy: 0.7869 - auc: 0.9251 - val_loss: 0.2840 - val_accuracy: 0.8819 - val_auc: 0.9579\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3226 - accuracy: 0.7865 - auc: 0.9244 - val_loss: 0.2826 - val_accuracy: 0.8819 - val_auc: 0.9587\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3210 - accuracy: 0.7866 - auc: 0.9224 - val_loss: 0.2823 - val_accuracy: 0.8781 - val_auc: 0.9582\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3189 - accuracy: 0.7864 - auc: 0.9275 - val_loss: 0.2835 - val_accuracy: 0.8811 - val_auc: 0.9591\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3222 - accuracy: 0.7856 - auc: 0.9270 - val_loss: 0.2858 - val_accuracy: 0.8784 - val_auc: 0.9582\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3168 - accuracy: 0.7866 - auc: 0.9285 - val_loss: 0.2877 - val_accuracy: 0.8760 - val_auc: 0.9577\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3207 - accuracy: 0.7821 - auc: 0.9236 - val_loss: 0.2861 - val_accuracy: 0.8754 - val_auc: 0.9575\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3208 - accuracy: 0.7869 - auc: 0.9252 - val_loss: 0.2876 - val_accuracy: 0.8787 - val_auc: 0.9580\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3177 - accuracy: 0.7856 - auc: 0.9260 - val_loss: 0.2842 - val_accuracy: 0.8779 - val_auc: 0.9577\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3093 - accuracy: 0.7878 - auc: 0.9300 - val_loss: 0.2863 - val_accuracy: 0.8796 - val_auc: 0.9576\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3110 - accuracy: 0.7905 - auc: 0.9279 - val_loss: 0.2880 - val_accuracy: 0.8827 - val_auc: 0.9583\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3083 - accuracy: 0.7897 - auc: 0.9324 - val_loss: 0.2845 - val_accuracy: 0.8798 - val_auc: 0.9573\n",
      "Epoch 50/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3191 - accuracy: 0.7846 - auc: 0.9274 - val_loss: 0.2883 - val_accuracy: 0.8780 - val_auc: 0.9573\n",
      "Epoch 51/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3221 - accuracy: 0.7883 - auc: 0.9264 - val_loss: 0.2865 - val_accuracy: 0.8764 - val_auc: 0.9573\n",
      "Epoch 52/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3128 - accuracy: 0.7879 - auc: 0.9268 - val_loss: 0.2866 - val_accuracy: 0.8799 - val_auc: 0.9574\n",
      "Epoch 53/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.7887 - auc: 0.9285Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3135 - accuracy: 0.7888 - auc: 0.9275 - val_loss: 0.2922 - val_accuracy: 0.8822 - val_auc: 0.9570\n",
      "Epoch 00053: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.9641 - accuracy: 0.2945 - auc: 0.5879 - val_loss: 0.6244 - val_accuracy: 0.3654 - val_auc: 0.7937\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6469 - accuracy: 0.3859 - auc: 0.7665 - val_loss: 0.5142 - val_accuracy: 0.5714 - val_auc: 0.8759\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5679 - accuracy: 0.4827 - auc: 0.8194 - val_loss: 0.4432 - val_accuracy: 0.7061 - val_auc: 0.9058\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4991 - accuracy: 0.5478 - auc: 0.8624 - val_loss: 0.3941 - val_accuracy: 0.7837 - val_auc: 0.9231\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4583 - accuracy: 0.6015 - auc: 0.8742 - val_loss: 0.3646 - val_accuracy: 0.8294 - val_auc: 0.9316\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4423 - accuracy: 0.6298 - auc: 0.8788 - val_loss: 0.3433 - val_accuracy: 0.8434 - val_auc: 0.9384\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4246 - accuracy: 0.6535 - auc: 0.8915 - val_loss: 0.3252 - val_accuracy: 0.8553 - val_auc: 0.9439\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4134 - accuracy: 0.6715 - auc: 0.8927 - val_loss: 0.3119 - val_accuracy: 0.8653 - val_auc: 0.9484\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3973 - accuracy: 0.6852 - auc: 0.9032 - val_loss: 0.3014 - val_accuracy: 0.8741 - val_auc: 0.9506\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3915 - accuracy: 0.6943 - auc: 0.9011 - val_loss: 0.2940 - val_accuracy: 0.8757 - val_auc: 0.9522\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3741 - accuracy: 0.7030 - auc: 0.9088 - val_loss: 0.2881 - val_accuracy: 0.8810 - val_auc: 0.9536\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3777 - accuracy: 0.7077 - auc: 0.9062 - val_loss: 0.2847 - val_accuracy: 0.8833 - val_auc: 0.9543\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3527 - accuracy: 0.7128 - auc: 0.9163 - val_loss: 0.2803 - val_accuracy: 0.8868 - val_auc: 0.9551\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3596 - accuracy: 0.7185 - auc: 0.9141 - val_loss: 0.2784 - val_accuracy: 0.8897 - val_auc: 0.9551\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3527 - accuracy: 0.7200 - auc: 0.9197 - val_loss: 0.2757 - val_accuracy: 0.8857 - val_auc: 0.9555\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3485 - accuracy: 0.7220 - auc: 0.9179 - val_loss: 0.2764 - val_accuracy: 0.8932 - val_auc: 0.9562\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3534 - accuracy: 0.7269 - auc: 0.9174 - val_loss: 0.2728 - val_accuracy: 0.8887 - val_auc: 0.9568\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3404 - accuracy: 0.7260 - auc: 0.9235 - val_loss: 0.2727 - val_accuracy: 0.8877 - val_auc: 0.9571\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3333 - accuracy: 0.7270 - auc: 0.9256 - val_loss: 0.2702 - val_accuracy: 0.8885 - val_auc: 0.9574\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3472 - accuracy: 0.7293 - auc: 0.9197 - val_loss: 0.2736 - val_accuracy: 0.8895 - val_auc: 0.9564\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3327 - accuracy: 0.7294 - auc: 0.9260 - val_loss: 0.2747 - val_accuracy: 0.8910 - val_auc: 0.9563\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3374 - accuracy: 0.7281 - auc: 0.9218 - val_loss: 0.2752 - val_accuracy: 0.8902 - val_auc: 0.9562\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3257 - accuracy: 0.7292 - auc: 0.9273 - val_loss: 0.2738 - val_accuracy: 0.8901 - val_auc: 0.9563\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3299 - accuracy: 0.7310 - auc: 0.9275 - val_loss: 0.2738 - val_accuracy: 0.8906 - val_auc: 0.9564\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3235 - accuracy: 0.7306 - auc: 0.9294 - val_loss: 0.2766 - val_accuracy: 0.8913 - val_auc: 0.9561\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3277 - accuracy: 0.7313 - auc: 0.9248 - val_loss: 0.2780 - val_accuracy: 0.8893 - val_auc: 0.9557\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3067 - accuracy: 0.7339 - auc: 0.9375 - val_loss: 0.2786 - val_accuracy: 0.8922 - val_auc: 0.9559\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3334 - accuracy: 0.7320 - auc: 0.9228 - val_loss: 0.2792 - val_accuracy: 0.8867 - val_auc: 0.9556\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3275 - accuracy: 0.7301 - auc: 0.9273 - val_loss: 0.2822 - val_accuracy: 0.8910 - val_auc: 0.9553\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3296 - accuracy: 0.7345 - auc: 0.9259 - val_loss: 0.2841 - val_accuracy: 0.8911 - val_auc: 0.9545\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3231 - accuracy: 0.7347 - auc: 0.9261 - val_loss: 0.2862 - val_accuracy: 0.8910 - val_auc: 0.9543\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3159 - accuracy: 0.7342 - auc: 0.9323 - val_loss: 0.2895 - val_accuracy: 0.8910 - val_auc: 0.9537\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3203 - accuracy: 0.7316 - auc: 0.9291 - val_loss: 0.2867 - val_accuracy: 0.8857 - val_auc: 0.9542\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3276 - accuracy: 0.7291 - auc: 0.9246 - val_loss: 0.2891 - val_accuracy: 0.8887 - val_auc: 0.9543\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3200 - accuracy: 0.7324 - auc: 0.9293 - val_loss: 0.2889 - val_accuracy: 0.8870 - val_auc: 0.9541\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3295 - accuracy: 0.7302 - auc: 0.9224 - val_loss: 0.2903 - val_accuracy: 0.8840 - val_auc: 0.9540\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3186 - accuracy: 0.7304 - auc: 0.9298 - val_loss: 0.2923 - val_accuracy: 0.8846 - val_auc: 0.9534\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3119 - accuracy: 0.7303 - auc: 0.9327 - val_loss: 0.2949 - val_accuracy: 0.8896 - val_auc: 0.9527\n",
      "Epoch 39/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3213 - accuracy: 0.7310 - auc: 0.9260Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3218 - accuracy: 0.7310 - auc: 0.9259 - val_loss: 0.2930 - val_accuracy: 0.8849 - val_auc: 0.9536\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.0776 - accuracy: 0.1351 - auc: 0.5022 - val_loss: 0.7257 - val_accuracy: 0.1245 - val_auc: 0.7472\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7056 - accuracy: 0.2725 - auc: 0.7202 - val_loss: 0.5581 - val_accuracy: 0.4055 - val_auc: 0.8855\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6044 - accuracy: 0.4313 - auc: 0.7981 - val_loss: 0.4593 - val_accuracy: 0.6751 - val_auc: 0.9112\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5228 - accuracy: 0.5424 - auc: 0.8356 - val_loss: 0.4040 - val_accuracy: 0.7785 - val_auc: 0.9236\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4788 - accuracy: 0.6262 - auc: 0.8606 - val_loss: 0.3650 - val_accuracy: 0.8255 - val_auc: 0.9341\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4417 - accuracy: 0.6875 - auc: 0.8767 - val_loss: 0.3366 - val_accuracy: 0.8493 - val_auc: 0.9407\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4039 - accuracy: 0.7191 - auc: 0.8948 - val_loss: 0.3159 - val_accuracy: 0.8652 - val_auc: 0.9466\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3969 - accuracy: 0.7391 - auc: 0.8943 - val_loss: 0.3065 - val_accuracy: 0.8683 - val_auc: 0.9492\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3931 - accuracy: 0.7456 - auc: 0.8959 - val_loss: 0.3008 - val_accuracy: 0.8742 - val_auc: 0.9508\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3781 - accuracy: 0.7537 - auc: 0.9023 - val_loss: 0.2976 - val_accuracy: 0.8764 - val_auc: 0.9518\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3790 - accuracy: 0.7567 - auc: 0.9027 - val_loss: 0.2967 - val_accuracy: 0.8762 - val_auc: 0.9523\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3695 - accuracy: 0.7611 - auc: 0.9061 - val_loss: 0.2915 - val_accuracy: 0.8784 - val_auc: 0.9526\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3596 - accuracy: 0.7635 - auc: 0.9086 - val_loss: 0.2932 - val_accuracy: 0.8809 - val_auc: 0.9534\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3631 - accuracy: 0.7679 - auc: 0.9082 - val_loss: 0.2943 - val_accuracy: 0.8797 - val_auc: 0.9543\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3597 - accuracy: 0.7691 - auc: 0.9069 - val_loss: 0.2908 - val_accuracy: 0.8757 - val_auc: 0.9543\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3457 - accuracy: 0.7659 - auc: 0.9134 - val_loss: 0.2934 - val_accuracy: 0.8772 - val_auc: 0.9539\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3554 - accuracy: 0.7702 - auc: 0.9113 - val_loss: 0.2907 - val_accuracy: 0.8760 - val_auc: 0.9534\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3582 - accuracy: 0.7679 - auc: 0.9080 - val_loss: 0.2938 - val_accuracy: 0.8754 - val_auc: 0.9540\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3488 - accuracy: 0.7666 - auc: 0.9112 - val_loss: 0.2912 - val_accuracy: 0.8734 - val_auc: 0.9547\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3517 - accuracy: 0.7707 - auc: 0.9110 - val_loss: 0.2909 - val_accuracy: 0.8754 - val_auc: 0.9547\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3376 - accuracy: 0.7699 - auc: 0.9168 - val_loss: 0.2915 - val_accuracy: 0.8747 - val_auc: 0.9540\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3387 - accuracy: 0.7766 - auc: 0.9179 - val_loss: 0.2923 - val_accuracy: 0.8792 - val_auc: 0.9543\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3426 - accuracy: 0.7778 - auc: 0.9166 - val_loss: 0.2880 - val_accuracy: 0.8776 - val_auc: 0.9552\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3360 - accuracy: 0.7734 - auc: 0.9172 - val_loss: 0.2834 - val_accuracy: 0.8759 - val_auc: 0.9564\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3346 - accuracy: 0.7749 - auc: 0.9192 - val_loss: 0.2825 - val_accuracy: 0.8752 - val_auc: 0.9558\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3426 - accuracy: 0.7756 - auc: 0.9157 - val_loss: 0.2900 - val_accuracy: 0.8741 - val_auc: 0.9549\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3243 - accuracy: 0.7767 - auc: 0.9211 - val_loss: 0.2942 - val_accuracy: 0.8766 - val_auc: 0.9544\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3374 - accuracy: 0.7779 - auc: 0.9172 - val_loss: 0.2948 - val_accuracy: 0.8758 - val_auc: 0.9544\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3355 - accuracy: 0.7779 - auc: 0.9187 - val_loss: 0.2956 - val_accuracy: 0.8731 - val_auc: 0.9546\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3295 - accuracy: 0.7776 - auc: 0.9204 - val_loss: 0.2972 - val_accuracy: 0.8712 - val_auc: 0.9541\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3284 - accuracy: 0.7744 - auc: 0.9218 - val_loss: 0.2984 - val_accuracy: 0.8716 - val_auc: 0.9543\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3286 - accuracy: 0.7776 - auc: 0.9195 - val_loss: 0.3009 - val_accuracy: 0.8745 - val_auc: 0.9546\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3331 - accuracy: 0.7763 - auc: 0.9185 - val_loss: 0.2987 - val_accuracy: 0.8718 - val_auc: 0.9547\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3234 - accuracy: 0.7785 - auc: 0.9222 - val_loss: 0.2967 - val_accuracy: 0.8737 - val_auc: 0.9549\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3237 - accuracy: 0.7793 - auc: 0.9230 - val_loss: 0.2997 - val_accuracy: 0.8734 - val_auc: 0.9544\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3256 - accuracy: 0.7781 - auc: 0.9206 - val_loss: 0.3018 - val_accuracy: 0.8709 - val_auc: 0.9542\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3216 - accuracy: 0.7777 - auc: 0.9200 - val_loss: 0.3059 - val_accuracy: 0.8718 - val_auc: 0.9538\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3215 - accuracy: 0.7786 - auc: 0.9202 - val_loss: 0.3130 - val_accuracy: 0.8718 - val_auc: 0.9536\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3187 - accuracy: 0.7800 - auc: 0.9243 - val_loss: 0.3076 - val_accuracy: 0.8718 - val_auc: 0.9543\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3248 - accuracy: 0.7790 - auc: 0.9221 - val_loss: 0.3110 - val_accuracy: 0.8683 - val_auc: 0.9536\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3291 - accuracy: 0.7778 - auc: 0.9198 - val_loss: 0.3152 - val_accuracy: 0.8689 - val_auc: 0.9526\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3120 - accuracy: 0.7773 - auc: 0.9251 - val_loss: 0.3110 - val_accuracy: 0.8720 - val_auc: 0.9543\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3223 - accuracy: 0.7804 - auc: 0.9222 - val_loss: 0.3138 - val_accuracy: 0.8686 - val_auc: 0.9534\n",
      "Epoch 44/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.3228 - accuracy: 0.7762 - auc: 0.9211Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3221 - accuracy: 0.7762 - auc: 0.9216 - val_loss: 0.3150 - val_accuracy: 0.8679 - val_auc: 0.9535\n",
      "Epoch 00044: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.7693 - accuracy: 0.9280 - auc: 0.6627 - val_loss: 0.4990 - val_accuracy: 0.9610 - val_auc: 0.8500\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5733 - accuracy: 0.9137 - auc: 0.7982 - val_loss: 0.3984 - val_accuracy: 0.9457 - val_auc: 0.9122\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4960 - accuracy: 0.9111 - auc: 0.8366 - val_loss: 0.3615 - val_accuracy: 0.9368 - val_auc: 0.9304\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4528 - accuracy: 0.9145 - auc: 0.8628 - val_loss: 0.3448 - val_accuracy: 0.9336 - val_auc: 0.9376\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4381 - accuracy: 0.9147 - auc: 0.8751 - val_loss: 0.3335 - val_accuracy: 0.9289 - val_auc: 0.9424\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4181 - accuracy: 0.9153 - auc: 0.8825 - val_loss: 0.3261 - val_accuracy: 0.9293 - val_auc: 0.9453\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4372 - accuracy: 0.9150 - auc: 0.8792 - val_loss: 0.3188 - val_accuracy: 0.9243 - val_auc: 0.9484\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4036 - accuracy: 0.9152 - auc: 0.8972 - val_loss: 0.3146 - val_accuracy: 0.9258 - val_auc: 0.9498\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4152 - accuracy: 0.9158 - auc: 0.8931 - val_loss: 0.3098 - val_accuracy: 0.9261 - val_auc: 0.9506\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3969 - accuracy: 0.9197 - auc: 0.8977 - val_loss: 0.3067 - val_accuracy: 0.9289 - val_auc: 0.9513\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3819 - accuracy: 0.9197 - auc: 0.9087 - val_loss: 0.3010 - val_accuracy: 0.9252 - val_auc: 0.9522\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3857 - accuracy: 0.9155 - auc: 0.9040 - val_loss: 0.2969 - val_accuracy: 0.9218 - val_auc: 0.9530\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3985 - accuracy: 0.9186 - auc: 0.9007 - val_loss: 0.2948 - val_accuracy: 0.9238 - val_auc: 0.9537\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3698 - accuracy: 0.9193 - auc: 0.9122 - val_loss: 0.2907 - val_accuracy: 0.9233 - val_auc: 0.9548\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3574 - accuracy: 0.9177 - auc: 0.9201 - val_loss: 0.2916 - val_accuracy: 0.9279 - val_auc: 0.9542\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3732 - accuracy: 0.9221 - auc: 0.9113 - val_loss: 0.2876 - val_accuracy: 0.9244 - val_auc: 0.9551\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3758 - accuracy: 0.9196 - auc: 0.9087 - val_loss: 0.2860 - val_accuracy: 0.9220 - val_auc: 0.9551\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3678 - accuracy: 0.9199 - auc: 0.9148 - val_loss: 0.2845 - val_accuracy: 0.9229 - val_auc: 0.9552\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3842 - accuracy: 0.9212 - auc: 0.9051 - val_loss: 0.2841 - val_accuracy: 0.9244 - val_auc: 0.9548\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3522 - accuracy: 0.9182 - auc: 0.9202 - val_loss: 0.2809 - val_accuracy: 0.9221 - val_auc: 0.9553\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3600 - accuracy: 0.9190 - auc: 0.9187 - val_loss: 0.2783 - val_accuracy: 0.9219 - val_auc: 0.9560\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3603 - accuracy: 0.9209 - auc: 0.9160 - val_loss: 0.2770 - val_accuracy: 0.9227 - val_auc: 0.9561\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3460 - accuracy: 0.9193 - auc: 0.9252 - val_loss: 0.2761 - val_accuracy: 0.9215 - val_auc: 0.9558\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3492 - accuracy: 0.9192 - auc: 0.9217 - val_loss: 0.2750 - val_accuracy: 0.9213 - val_auc: 0.9556\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3596 - accuracy: 0.9205 - auc: 0.9162 - val_loss: 0.2755 - val_accuracy: 0.9219 - val_auc: 0.9554\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3446 - accuracy: 0.9214 - auc: 0.9235 - val_loss: 0.2747 - val_accuracy: 0.9195 - val_auc: 0.9554\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3312 - accuracy: 0.9185 - auc: 0.9307 - val_loss: 0.2729 - val_accuracy: 0.9173 - val_auc: 0.9558\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3469 - accuracy: 0.9185 - auc: 0.9230 - val_loss: 0.2747 - val_accuracy: 0.9185 - val_auc: 0.9550\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3356 - accuracy: 0.9177 - auc: 0.9278 - val_loss: 0.2731 - val_accuracy: 0.9197 - val_auc: 0.9554\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3294 - accuracy: 0.9185 - auc: 0.9314 - val_loss: 0.2743 - val_accuracy: 0.9202 - val_auc: 0.9550\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3440 - accuracy: 0.9185 - auc: 0.9230 - val_loss: 0.2726 - val_accuracy: 0.9184 - val_auc: 0.9559\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3251 - accuracy: 0.9212 - auc: 0.9322 - val_loss: 0.2722 - val_accuracy: 0.9198 - val_auc: 0.9558\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3441 - accuracy: 0.9192 - auc: 0.9226 - val_loss: 0.2713 - val_accuracy: 0.9151 - val_auc: 0.9557\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3352 - accuracy: 0.9190 - auc: 0.9265 - val_loss: 0.2702 - val_accuracy: 0.9193 - val_auc: 0.9563\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3417 - accuracy: 0.9218 - auc: 0.9226 - val_loss: 0.2718 - val_accuracy: 0.9190 - val_auc: 0.9555\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3211 - accuracy: 0.9194 - auc: 0.9340 - val_loss: 0.2733 - val_accuracy: 0.9187 - val_auc: 0.9550\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3406 - accuracy: 0.9195 - auc: 0.9219 - val_loss: 0.2752 - val_accuracy: 0.9197 - val_auc: 0.9544\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3199 - accuracy: 0.9199 - auc: 0.9340 - val_loss: 0.2741 - val_accuracy: 0.9169 - val_auc: 0.9546\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3274 - accuracy: 0.9195 - auc: 0.9294 - val_loss: 0.2760 - val_accuracy: 0.9204 - val_auc: 0.9544\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3194 - accuracy: 0.9210 - auc: 0.9314 - val_loss: 0.2785 - val_accuracy: 0.9203 - val_auc: 0.9539\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3185 - accuracy: 0.9192 - auc: 0.9340 - val_loss: 0.2750 - val_accuracy: 0.9186 - val_auc: 0.9548\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3184 - accuracy: 0.9190 - auc: 0.9338 - val_loss: 0.2760 - val_accuracy: 0.9185 - val_auc: 0.9544\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3267 - accuracy: 0.9194 - auc: 0.9293 - val_loss: 0.2768 - val_accuracy: 0.9187 - val_auc: 0.9540\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3180 - accuracy: 0.9209 - auc: 0.9322 - val_loss: 0.2797 - val_accuracy: 0.9182 - val_auc: 0.9533\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3171 - accuracy: 0.9214 - auc: 0.9325 - val_loss: 0.2813 - val_accuracy: 0.9194 - val_auc: 0.9531\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3271 - accuracy: 0.9208 - auc: 0.9287 - val_loss: 0.2812 - val_accuracy: 0.9184 - val_auc: 0.9530\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3264 - accuracy: 0.9195 - auc: 0.9284 - val_loss: 0.2842 - val_accuracy: 0.9190 - val_auc: 0.9524\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3208 - accuracy: 0.9218 - auc: 0.9305 - val_loss: 0.2863 - val_accuracy: 0.9186 - val_auc: 0.9515\n",
      "Epoch 49/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3214 - accuracy: 0.9208 - auc: 0.9323 - val_loss: 0.2881 - val_accuracy: 0.9202 - val_auc: 0.9516\n",
      "Epoch 50/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3183 - accuracy: 0.9200 - auc: 0.9334 - val_loss: 0.2869 - val_accuracy: 0.9178 - val_auc: 0.9522\n",
      "Epoch 51/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3266 - accuracy: 0.9183 - auc: 0.9270 - val_loss: 0.2905 - val_accuracy: 0.9184 - val_auc: 0.9520\n",
      "Epoch 52/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3251 - accuracy: 0.9205 - auc: 0.9295 - val_loss: 0.2911 - val_accuracy: 0.9177 - val_auc: 0.9519\n",
      "Epoch 53/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3184 - accuracy: 0.9197 - auc: 0.9313 - val_loss: 0.2923 - val_accuracy: 0.9196 - val_auc: 0.9516\n",
      "Epoch 54/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.9214 - auc: 0.9337Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3137 - accuracy: 0.9214 - auc: 0.9339 - val_loss: 0.2933 - val_accuracy: 0.9204 - val_auc: 0.9513\n",
      "Epoch 00054: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 7s 28us/sample - loss: 0.9973 - accuracy: 0.2055 - auc: 0.6268 - val_loss: 0.7089 - val_accuracy: 0.1778 - val_auc: 0.7893\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7305 - accuracy: 0.3035 - auc: 0.7760 - val_loss: 0.5562 - val_accuracy: 0.4051 - val_auc: 0.8641\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6261 - accuracy: 0.4302 - auc: 0.8189 - val_loss: 0.4554 - val_accuracy: 0.6357 - val_auc: 0.9058\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5512 - accuracy: 0.5278 - auc: 0.8541 - val_loss: 0.3934 - val_accuracy: 0.7418 - val_auc: 0.9271\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4873 - accuracy: 0.5886 - auc: 0.8713 - val_loss: 0.3517 - val_accuracy: 0.7918 - val_auc: 0.9387\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4605 - accuracy: 0.6228 - auc: 0.8823 - val_loss: 0.3264 - val_accuracy: 0.8215 - val_auc: 0.9439\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4317 - accuracy: 0.6505 - auc: 0.8961 - val_loss: 0.3104 - val_accuracy: 0.8381 - val_auc: 0.9478\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4207 - accuracy: 0.6685 - auc: 0.8957 - val_loss: 0.2989 - val_accuracy: 0.8505 - val_auc: 0.9509\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3919 - accuracy: 0.6836 - auc: 0.9079 - val_loss: 0.2870 - val_accuracy: 0.8590 - val_auc: 0.9533\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3880 - accuracy: 0.6965 - auc: 0.9080 - val_loss: 0.2809 - val_accuracy: 0.8669 - val_auc: 0.9544\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3736 - accuracy: 0.7079 - auc: 0.9140 - val_loss: 0.2764 - val_accuracy: 0.8744 - val_auc: 0.9557\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3702 - accuracy: 0.7142 - auc: 0.9102 - val_loss: 0.2720 - val_accuracy: 0.8754 - val_auc: 0.9565\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3548 - accuracy: 0.7228 - auc: 0.9206 - val_loss: 0.2702 - val_accuracy: 0.8783 - val_auc: 0.9569\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3568 - accuracy: 0.7247 - auc: 0.9174 - val_loss: 0.2703 - val_accuracy: 0.8775 - val_auc: 0.9570\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3496 - accuracy: 0.7258 - auc: 0.9191 - val_loss: 0.2693 - val_accuracy: 0.8767 - val_auc: 0.9572\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3435 - accuracy: 0.7264 - auc: 0.9233 - val_loss: 0.2679 - val_accuracy: 0.8784 - val_auc: 0.9572\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3381 - accuracy: 0.7260 - auc: 0.9235 - val_loss: 0.2702 - val_accuracy: 0.8791 - val_auc: 0.9565\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3452 - accuracy: 0.7300 - auc: 0.9196 - val_loss: 0.2709 - val_accuracy: 0.8802 - val_auc: 0.9567\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3384 - accuracy: 0.7302 - auc: 0.9250 - val_loss: 0.2717 - val_accuracy: 0.8820 - val_auc: 0.9564\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3441 - accuracy: 0.7331 - auc: 0.9196 - val_loss: 0.2729 - val_accuracy: 0.8825 - val_auc: 0.9564\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3283 - accuracy: 0.7314 - auc: 0.9280 - val_loss: 0.2735 - val_accuracy: 0.8823 - val_auc: 0.9561\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3240 - accuracy: 0.7312 - auc: 0.9301 - val_loss: 0.2765 - val_accuracy: 0.8809 - val_auc: 0.9553\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3292 - accuracy: 0.7341 - auc: 0.9277 - val_loss: 0.2771 - val_accuracy: 0.8821 - val_auc: 0.9553\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3310 - accuracy: 0.7318 - auc: 0.9239 - val_loss: 0.2766 - val_accuracy: 0.8855 - val_auc: 0.9551\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3267 - accuracy: 0.7347 - auc: 0.9253 - val_loss: 0.2784 - val_accuracy: 0.8811 - val_auc: 0.9553\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3218 - accuracy: 0.7351 - auc: 0.9290 - val_loss: 0.2776 - val_accuracy: 0.8850 - val_auc: 0.9556\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3292 - accuracy: 0.7350 - auc: 0.9242 - val_loss: 0.2763 - val_accuracy: 0.8824 - val_auc: 0.9560\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3246 - accuracy: 0.7340 - auc: 0.9284 - val_loss: 0.2800 - val_accuracy: 0.8812 - val_auc: 0.9551\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3190 - accuracy: 0.7300 - auc: 0.9325 - val_loss: 0.2849 - val_accuracy: 0.8804 - val_auc: 0.9538\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3291 - accuracy: 0.7310 - auc: 0.9247 - val_loss: 0.2841 - val_accuracy: 0.8783 - val_auc: 0.9541\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3135 - accuracy: 0.7319 - auc: 0.9316 - val_loss: 0.2870 - val_accuracy: 0.8806 - val_auc: 0.9539\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3218 - accuracy: 0.7341 - auc: 0.9292 - val_loss: 0.2848 - val_accuracy: 0.8813 - val_auc: 0.9550\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3255 - accuracy: 0.7303 - auc: 0.9244 - val_loss: 0.2867 - val_accuracy: 0.8798 - val_auc: 0.9544\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3165 - accuracy: 0.7313 - auc: 0.9316 - val_loss: 0.2897 - val_accuracy: 0.8811 - val_auc: 0.9537\n",
      "Epoch 35/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3216 - accuracy: 0.7295 - auc: 0.9296Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3214 - accuracy: 0.7296 - auc: 0.9303 - val_loss: 0.2910 - val_accuracy: 0.8807 - val_auc: 0.9534\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.0093 - accuracy: 0.7212 - auc: 0.6304 - val_loss: 0.4876 - val_accuracy: 0.7806 - val_auc: 0.8611\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5583 - accuracy: 0.7897 - auc: 0.8357 - val_loss: 0.4089 - val_accuracy: 0.8494 - val_auc: 0.9135\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4692 - accuracy: 0.8414 - auc: 0.8839 - val_loss: 0.3636 - val_accuracy: 0.8735 - val_auc: 0.9339\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4232 - accuracy: 0.8629 - auc: 0.9029 - val_loss: 0.3438 - val_accuracy: 0.8861 - val_auc: 0.9402\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4049 - accuracy: 0.8737 - auc: 0.9118 - val_loss: 0.3212 - val_accuracy: 0.8976 - val_auc: 0.9489\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3844 - accuracy: 0.8864 - auc: 0.9210 - val_loss: 0.3087 - val_accuracy: 0.9036 - val_auc: 0.9520\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3487 - accuracy: 0.8942 - auc: 0.9354 - val_loss: 0.3002 - val_accuracy: 0.9077 - val_auc: 0.9525\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3420 - accuracy: 0.8992 - auc: 0.9394 - val_loss: 0.2922 - val_accuracy: 0.9098 - val_auc: 0.9526\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3305 - accuracy: 0.9048 - auc: 0.9427 - val_loss: 0.2855 - val_accuracy: 0.9089 - val_auc: 0.9545\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3168 - accuracy: 0.9024 - auc: 0.9487 - val_loss: 0.2807 - val_accuracy: 0.9127 - val_auc: 0.9552\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3182 - accuracy: 0.9082 - auc: 0.9465 - val_loss: 0.2776 - val_accuracy: 0.9153 - val_auc: 0.9554\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3073 - accuracy: 0.9094 - auc: 0.9517 - val_loss: 0.2748 - val_accuracy: 0.9117 - val_auc: 0.9560\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3011 - accuracy: 0.9063 - auc: 0.9530 - val_loss: 0.2726 - val_accuracy: 0.9152 - val_auc: 0.9565\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2990 - accuracy: 0.9104 - auc: 0.9540 - val_loss: 0.2696 - val_accuracy: 0.9147 - val_auc: 0.9569\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2863 - accuracy: 0.9126 - auc: 0.9567 - val_loss: 0.2679 - val_accuracy: 0.9156 - val_auc: 0.9573\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3020 - accuracy: 0.9102 - auc: 0.9508 - val_loss: 0.2685 - val_accuracy: 0.9168 - val_auc: 0.9570\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2922 - accuracy: 0.9118 - auc: 0.9532 - val_loss: 0.2660 - val_accuracy: 0.9159 - val_auc: 0.9575\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2909 - accuracy: 0.9128 - auc: 0.9554 - val_loss: 0.2673 - val_accuracy: 0.9142 - val_auc: 0.9573\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2858 - accuracy: 0.9143 - auc: 0.9552 - val_loss: 0.2672 - val_accuracy: 0.9145 - val_auc: 0.9569\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2868 - accuracy: 0.9122 - auc: 0.9550 - val_loss: 0.2687 - val_accuracy: 0.9150 - val_auc: 0.9566\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2878 - accuracy: 0.9128 - auc: 0.9542 - val_loss: 0.2673 - val_accuracy: 0.9128 - val_auc: 0.9571\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2896 - accuracy: 0.9145 - auc: 0.9541 - val_loss: 0.2683 - val_accuracy: 0.9156 - val_auc: 0.9573\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2783 - accuracy: 0.9118 - auc: 0.9584 - val_loss: 0.2690 - val_accuracy: 0.9160 - val_auc: 0.9565\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2731 - accuracy: 0.9144 - auc: 0.9595 - val_loss: 0.2687 - val_accuracy: 0.9144 - val_auc: 0.9569\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2720 - accuracy: 0.9129 - auc: 0.9601 - val_loss: 0.2706 - val_accuracy: 0.9174 - val_auc: 0.9564\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2752 - accuracy: 0.9150 - auc: 0.9581 - val_loss: 0.2703 - val_accuracy: 0.9155 - val_auc: 0.9568\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2727 - accuracy: 0.9136 - auc: 0.9594 - val_loss: 0.2719 - val_accuracy: 0.9188 - val_auc: 0.9556\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2718 - accuracy: 0.9176 - auc: 0.9592 - val_loss: 0.2738 - val_accuracy: 0.9207 - val_auc: 0.9556\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2752 - accuracy: 0.9169 - auc: 0.9575 - val_loss: 0.2730 - val_accuracy: 0.9202 - val_auc: 0.9556\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2718 - accuracy: 0.9167 - auc: 0.9594 - val_loss: 0.2730 - val_accuracy: 0.9170 - val_auc: 0.9555\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2742 - accuracy: 0.9166 - auc: 0.9585 - val_loss: 0.2751 - val_accuracy: 0.9171 - val_auc: 0.9553\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2738 - accuracy: 0.9154 - auc: 0.9594 - val_loss: 0.2780 - val_accuracy: 0.9176 - val_auc: 0.9539\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2662 - accuracy: 0.9159 - auc: 0.9613 - val_loss: 0.2774 - val_accuracy: 0.9194 - val_auc: 0.9542\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2667 - accuracy: 0.9150 - auc: 0.9603 - val_loss: 0.2800 - val_accuracy: 0.9188 - val_auc: 0.9543\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2590 - accuracy: 0.9166 - auc: 0.9635 - val_loss: 0.2819 - val_accuracy: 0.9210 - val_auc: 0.9533\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2732 - accuracy: 0.9179 - auc: 0.9578 - val_loss: 0.2857 - val_accuracy: 0.9192 - val_auc: 0.9518\n",
      "Epoch 37/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9179 - auc: 0.9609Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2672 - accuracy: 0.9179 - auc: 0.9610 - val_loss: 0.2860 - val_accuracy: 0.9163 - val_auc: 0.9518\n",
      "Epoch 00037: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.6636 - accuracy: 0.7103 - auc: 0.7236 - val_loss: 0.4539 - val_accuracy: 0.8270 - val_auc: 0.8987\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4928 - accuracy: 0.8108 - auc: 0.8643 - val_loss: 0.3825 - val_accuracy: 0.8694 - val_auc: 0.9310\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4244 - accuracy: 0.8465 - auc: 0.9004 - val_loss: 0.3435 - val_accuracy: 0.8853 - val_auc: 0.9417\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3739 - accuracy: 0.8707 - auc: 0.9236 - val_loss: 0.3166 - val_accuracy: 0.8986 - val_auc: 0.9479\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3670 - accuracy: 0.8818 - auc: 0.9247 - val_loss: 0.3028 - val_accuracy: 0.9005 - val_auc: 0.9500\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3369 - accuracy: 0.8866 - auc: 0.9365 - val_loss: 0.2901 - val_accuracy: 0.9055 - val_auc: 0.9525\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3309 - accuracy: 0.8924 - auc: 0.9377 - val_loss: 0.2815 - val_accuracy: 0.9067 - val_auc: 0.9550\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3238 - accuracy: 0.8935 - auc: 0.9401 - val_loss: 0.2772 - val_accuracy: 0.9091 - val_auc: 0.9557\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3122 - accuracy: 0.8975 - auc: 0.9450 - val_loss: 0.2720 - val_accuracy: 0.9069 - val_auc: 0.9568\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3051 - accuracy: 0.8979 - auc: 0.9467 - val_loss: 0.2699 - val_accuracy: 0.9098 - val_auc: 0.9574\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3017 - accuracy: 0.9010 - auc: 0.9485 - val_loss: 0.2687 - val_accuracy: 0.9103 - val_auc: 0.9572\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2984 - accuracy: 0.9010 - auc: 0.9488 - val_loss: 0.2691 - val_accuracy: 0.9107 - val_auc: 0.9569\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3014 - accuracy: 0.9025 - auc: 0.9471 - val_loss: 0.2716 - val_accuracy: 0.9121 - val_auc: 0.9560\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2864 - accuracy: 0.9070 - auc: 0.9526 - val_loss: 0.2721 - val_accuracy: 0.9110 - val_auc: 0.9561\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2894 - accuracy: 0.9045 - auc: 0.9513 - val_loss: 0.2693 - val_accuracy: 0.9093 - val_auc: 0.9566\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2923 - accuracy: 0.9049 - auc: 0.9508 - val_loss: 0.2705 - val_accuracy: 0.9114 - val_auc: 0.9564\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2831 - accuracy: 0.9021 - auc: 0.9535 - val_loss: 0.2717 - val_accuracy: 0.9123 - val_auc: 0.9560\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2817 - accuracy: 0.9069 - auc: 0.9538 - val_loss: 0.2733 - val_accuracy: 0.9124 - val_auc: 0.9558\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2746 - accuracy: 0.9076 - auc: 0.9562 - val_loss: 0.2738 - val_accuracy: 0.9103 - val_auc: 0.9559\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2766 - accuracy: 0.9046 - auc: 0.9557 - val_loss: 0.2759 - val_accuracy: 0.9128 - val_auc: 0.9550\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2586 - accuracy: 0.9082 - auc: 0.9610 - val_loss: 0.2760 - val_accuracy: 0.9140 - val_auc: 0.9551\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2666 - accuracy: 0.9075 - auc: 0.9591 - val_loss: 0.2772 - val_accuracy: 0.9160 - val_auc: 0.9555\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2705 - accuracy: 0.9093 - auc: 0.9578 - val_loss: 0.2797 - val_accuracy: 0.9150 - val_auc: 0.9549\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2697 - accuracy: 0.9070 - auc: 0.9576 - val_loss: 0.2827 - val_accuracy: 0.9139 - val_auc: 0.9542\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2675 - accuracy: 0.9080 - auc: 0.9580 - val_loss: 0.2816 - val_accuracy: 0.9146 - val_auc: 0.9549\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2644 - accuracy: 0.9096 - auc: 0.9589 - val_loss: 0.2813 - val_accuracy: 0.9147 - val_auc: 0.9554\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2678 - accuracy: 0.9095 - auc: 0.9580 - val_loss: 0.2834 - val_accuracy: 0.9147 - val_auc: 0.9549\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2624 - accuracy: 0.9101 - auc: 0.9592 - val_loss: 0.2830 - val_accuracy: 0.9125 - val_auc: 0.9552\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2691 - accuracy: 0.9073 - auc: 0.9576 - val_loss: 0.2867 - val_accuracy: 0.9118 - val_auc: 0.9546\n",
      "Epoch 30/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.9103 - auc: 0.9626Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2573 - accuracy: 0.9102 - auc: 0.9616 - val_loss: 0.2894 - val_accuracy: 0.9129 - val_auc: 0.9536\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.9056 - accuracy: 0.9090 - auc: 0.6304 - val_loss: 0.5272 - val_accuracy: 0.9462 - val_auc: 0.8559\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5890 - accuracy: 0.8838 - auc: 0.8017 - val_loss: 0.4181 - val_accuracy: 0.9185 - val_auc: 0.9121\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4833 - accuracy: 0.8810 - auc: 0.8667 - val_loss: 0.3717 - val_accuracy: 0.9102 - val_auc: 0.9307\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4347 - accuracy: 0.8868 - auc: 0.8943 - val_loss: 0.3425 - val_accuracy: 0.9156 - val_auc: 0.9390\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3993 - accuracy: 0.8915 - auc: 0.9127 - val_loss: 0.3224 - val_accuracy: 0.9104 - val_auc: 0.9440\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3931 - accuracy: 0.8948 - auc: 0.9095 - val_loss: 0.3071 - val_accuracy: 0.9133 - val_auc: 0.9481\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3664 - accuracy: 0.8997 - auc: 0.9222 - val_loss: 0.2980 - val_accuracy: 0.9114 - val_auc: 0.9519\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3561 - accuracy: 0.9004 - auc: 0.9269 - val_loss: 0.2933 - val_accuracy: 0.9139 - val_auc: 0.9530\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3506 - accuracy: 0.9043 - auc: 0.9303 - val_loss: 0.2885 - val_accuracy: 0.9127 - val_auc: 0.9536\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3256 - accuracy: 0.9046 - auc: 0.9401 - val_loss: 0.2843 - val_accuracy: 0.9169 - val_auc: 0.9544\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3267 - accuracy: 0.9089 - auc: 0.9377 - val_loss: 0.2810 - val_accuracy: 0.9159 - val_auc: 0.9550\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3168 - accuracy: 0.9073 - auc: 0.9436 - val_loss: 0.2784 - val_accuracy: 0.9149 - val_auc: 0.9553\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3255 - accuracy: 0.9084 - auc: 0.9393 - val_loss: 0.2774 - val_accuracy: 0.9147 - val_auc: 0.9552\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3201 - accuracy: 0.9049 - auc: 0.9416 - val_loss: 0.2757 - val_accuracy: 0.9129 - val_auc: 0.9554\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3124 - accuracy: 0.9070 - auc: 0.9435 - val_loss: 0.2764 - val_accuracy: 0.9138 - val_auc: 0.9549\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3071 - accuracy: 0.9123 - auc: 0.9452 - val_loss: 0.2757 - val_accuracy: 0.9170 - val_auc: 0.9550\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3114 - accuracy: 0.9113 - auc: 0.9458 - val_loss: 0.2760 - val_accuracy: 0.9165 - val_auc: 0.9547\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3071 - accuracy: 0.9130 - auc: 0.9479 - val_loss: 0.2776 - val_accuracy: 0.9145 - val_auc: 0.9538\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2995 - accuracy: 0.9083 - auc: 0.9481 - val_loss: 0.2805 - val_accuracy: 0.9155 - val_auc: 0.9525\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2993 - accuracy: 0.9104 - auc: 0.9482 - val_loss: 0.2841 - val_accuracy: 0.9155 - val_auc: 0.9521\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2962 - accuracy: 0.9088 - auc: 0.9500 - val_loss: 0.2803 - val_accuracy: 0.9142 - val_auc: 0.9526\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2976 - accuracy: 0.9098 - auc: 0.9495 - val_loss: 0.2814 - val_accuracy: 0.9157 - val_auc: 0.9521\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2893 - accuracy: 0.9129 - auc: 0.9517 - val_loss: 0.2801 - val_accuracy: 0.9148 - val_auc: 0.9527\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2839 - accuracy: 0.9113 - auc: 0.9522 - val_loss: 0.2838 - val_accuracy: 0.9155 - val_auc: 0.9518\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2830 - accuracy: 0.9126 - auc: 0.9544 - val_loss: 0.2859 - val_accuracy: 0.9142 - val_auc: 0.9515\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2815 - accuracy: 0.9100 - auc: 0.9541 - val_loss: 0.2850 - val_accuracy: 0.9127 - val_auc: 0.9521\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2830 - accuracy: 0.9130 - auc: 0.9529 - val_loss: 0.2856 - val_accuracy: 0.9135 - val_auc: 0.9524\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2750 - accuracy: 0.9100 - auc: 0.9555 - val_loss: 0.2876 - val_accuracy: 0.9153 - val_auc: 0.9516\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2789 - accuracy: 0.9118 - auc: 0.9544 - val_loss: 0.2881 - val_accuracy: 0.9135 - val_auc: 0.9518\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2793 - accuracy: 0.9087 - auc: 0.9540 - val_loss: 0.2866 - val_accuracy: 0.9147 - val_auc: 0.9523\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2691 - accuracy: 0.9130 - auc: 0.9580 - val_loss: 0.2890 - val_accuracy: 0.9141 - val_auc: 0.9522\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2641 - accuracy: 0.9103 - auc: 0.9586 - val_loss: 0.2900 - val_accuracy: 0.9171 - val_auc: 0.9522\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2707 - accuracy: 0.9123 - auc: 0.9563 - val_loss: 0.2898 - val_accuracy: 0.9149 - val_auc: 0.9525\n",
      "Epoch 34/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2741 - accuracy: 0.9107 - auc: 0.9545Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2739 - accuracy: 0.9107 - auc: 0.9549 - val_loss: 0.2902 - val_accuracy: 0.9140 - val_auc: 0.9525\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 1.0223 - accuracy: 0.0207 - auc: 0.7763 - val_loss: 0.7898 - val_accuracy: 0.0171 - val_auc: 0.8699\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7187 - accuracy: 0.1873 - auc: 0.8426 - val_loss: 0.5623 - val_accuracy: 0.2809 - val_auc: 0.9152\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5572 - accuracy: 0.4446 - auc: 0.8878 - val_loss: 0.4156 - val_accuracy: 0.6736 - val_auc: 0.9365\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4935 - accuracy: 0.5605 - auc: 0.9021 - val_loss: 0.3518 - val_accuracy: 0.7736 - val_auc: 0.9466\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4473 - accuracy: 0.6078 - auc: 0.9153 - val_loss: 0.3221 - val_accuracy: 0.8135 - val_auc: 0.9493\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4274 - accuracy: 0.6370 - auc: 0.9188 - val_loss: 0.3031 - val_accuracy: 0.8331 - val_auc: 0.9518\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4173 - accuracy: 0.6551 - auc: 0.9202 - val_loss: 0.2941 - val_accuracy: 0.8336 - val_auc: 0.9544\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3966 - accuracy: 0.6659 - auc: 0.9262 - val_loss: 0.2862 - val_accuracy: 0.8418 - val_auc: 0.9552\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3776 - accuracy: 0.6738 - auc: 0.9336 - val_loss: 0.2772 - val_accuracy: 0.8521 - val_auc: 0.9565\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3596 - accuracy: 0.6906 - auc: 0.9378 - val_loss: 0.2718 - val_accuracy: 0.8585 - val_auc: 0.9576\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3626 - accuracy: 0.6920 - auc: 0.9344 - val_loss: 0.2692 - val_accuracy: 0.8605 - val_auc: 0.9578\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3580 - accuracy: 0.6967 - auc: 0.9353 - val_loss: 0.2680 - val_accuracy: 0.8570 - val_auc: 0.9585\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3365 - accuracy: 0.7018 - auc: 0.9462 - val_loss: 0.2627 - val_accuracy: 0.8657 - val_auc: 0.9595\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3290 - accuracy: 0.7094 - auc: 0.9442 - val_loss: 0.2607 - val_accuracy: 0.8686 - val_auc: 0.9597\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3215 - accuracy: 0.7130 - auc: 0.9474 - val_loss: 0.2581 - val_accuracy: 0.8678 - val_auc: 0.9601\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3200 - accuracy: 0.7144 - auc: 0.9465 - val_loss: 0.2576 - val_accuracy: 0.8737 - val_auc: 0.9603\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3144 - accuracy: 0.7178 - auc: 0.9509 - val_loss: 0.2574 - val_accuracy: 0.8756 - val_auc: 0.9602\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3095 - accuracy: 0.7185 - auc: 0.9512 - val_loss: 0.2575 - val_accuracy: 0.8758 - val_auc: 0.9602\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3076 - accuracy: 0.7198 - auc: 0.9521 - val_loss: 0.2574 - val_accuracy: 0.8780 - val_auc: 0.9600\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3046 - accuracy: 0.7198 - auc: 0.9534 - val_loss: 0.2581 - val_accuracy: 0.8820 - val_auc: 0.9602\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2983 - accuracy: 0.7234 - auc: 0.9547 - val_loss: 0.2559 - val_accuracy: 0.8815 - val_auc: 0.9608\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2962 - accuracy: 0.7227 - auc: 0.9535 - val_loss: 0.2595 - val_accuracy: 0.8815 - val_auc: 0.9598\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2899 - accuracy: 0.7258 - auc: 0.9557 - val_loss: 0.2586 - val_accuracy: 0.8847 - val_auc: 0.9598\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2892 - accuracy: 0.7263 - auc: 0.9551 - val_loss: 0.2592 - val_accuracy: 0.8851 - val_auc: 0.9595\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2858 - accuracy: 0.7942 - auc: 0.9557 - val_loss: 0.2609 - val_accuracy: 0.8966 - val_auc: 0.9590\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2884 - accuracy: 0.8723 - auc: 0.9546 - val_loss: 0.2615 - val_accuracy: 0.8958 - val_auc: 0.9588\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2758 - accuracy: 0.8787 - auc: 0.9590 - val_loss: 0.2626 - val_accuracy: 0.9036 - val_auc: 0.9590\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2830 - accuracy: 0.8870 - auc: 0.9557 - val_loss: 0.2652 - val_accuracy: 0.9050 - val_auc: 0.9582\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2809 - accuracy: 0.8889 - auc: 0.9571 - val_loss: 0.2666 - val_accuracy: 0.9098 - val_auc: 0.9580\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2791 - accuracy: 0.8977 - auc: 0.9568 - val_loss: 0.2674 - val_accuracy: 0.9107 - val_auc: 0.9577\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2723 - accuracy: 0.8997 - auc: 0.9577 - val_loss: 0.2689 - val_accuracy: 0.9095 - val_auc: 0.9573\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2718 - accuracy: 0.8988 - auc: 0.9593 - val_loss: 0.2667 - val_accuracy: 0.9095 - val_auc: 0.9580\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2773 - accuracy: 0.9020 - auc: 0.9554 - val_loss: 0.2677 - val_accuracy: 0.9113 - val_auc: 0.9575\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2715 - accuracy: 0.9056 - auc: 0.9575 - val_loss: 0.2711 - val_accuracy: 0.9134 - val_auc: 0.9568\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2721 - accuracy: 0.9076 - auc: 0.9579 - val_loss: 0.2708 - val_accuracy: 0.9132 - val_auc: 0.9570\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2624 - accuracy: 0.9100 - auc: 0.9601 - val_loss: 0.2731 - val_accuracy: 0.9148 - val_auc: 0.9566\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2630 - accuracy: 0.9111 - auc: 0.9608 - val_loss: 0.2753 - val_accuracy: 0.9147 - val_auc: 0.9557\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2696 - accuracy: 0.9105 - auc: 0.9584 - val_loss: 0.2761 - val_accuracy: 0.9163 - val_auc: 0.9549\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2625 - accuracy: 0.9137 - auc: 0.9612 - val_loss: 0.2783 - val_accuracy: 0.9214 - val_auc: 0.9549\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2651 - accuracy: 0.9159 - auc: 0.9596 - val_loss: 0.2774 - val_accuracy: 0.9174 - val_auc: 0.9551\n",
      "Epoch 41/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9149 - auc: 0.9593Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2662 - accuracy: 0.9149 - auc: 0.9595 - val_loss: 0.2782 - val_accuracy: 0.9178 - val_auc: 0.9552\n",
      "Epoch 00041: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 19us/sample - loss: 0.8071 - accuracy: 0.7987 - auc: 0.6999 - val_loss: 0.5328 - val_accuracy: 0.8555 - val_auc: 0.8626\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5486 - accuracy: 0.8189 - auc: 0.8361 - val_loss: 0.4462 - val_accuracy: 0.8772 - val_auc: 0.9082\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5109 - accuracy: 0.8573 - auc: 0.8667 - val_loss: 0.3961 - val_accuracy: 0.8933 - val_auc: 0.9270\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5060 - accuracy: 0.8685 - auc: 0.8845 - val_loss: 0.3539 - val_accuracy: 0.8962 - val_auc: 0.9344\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4287 - accuracy: 0.8819 - auc: 0.9033 - val_loss: 0.3282 - val_accuracy: 0.9000 - val_auc: 0.9417\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3857 - accuracy: 0.8892 - auc: 0.9211 - val_loss: 0.3131 - val_accuracy: 0.9016 - val_auc: 0.9463\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3837 - accuracy: 0.8893 - auc: 0.9187 - val_loss: 0.3061 - val_accuracy: 0.9058 - val_auc: 0.9480\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3704 - accuracy: 0.8953 - auc: 0.9235 - val_loss: 0.2956 - val_accuracy: 0.9063 - val_auc: 0.9499\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3362 - accuracy: 0.8960 - auc: 0.9358 - val_loss: 0.2900 - val_accuracy: 0.9058 - val_auc: 0.9512\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3389 - accuracy: 0.8982 - auc: 0.9355 - val_loss: 0.2863 - val_accuracy: 0.9086 - val_auc: 0.9525\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3297 - accuracy: 0.8975 - auc: 0.9388 - val_loss: 0.2861 - val_accuracy: 0.9076 - val_auc: 0.9528\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3143 - accuracy: 0.8998 - auc: 0.9438 - val_loss: 0.2855 - val_accuracy: 0.9061 - val_auc: 0.9524\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3180 - accuracy: 0.8973 - auc: 0.9426 - val_loss: 0.2845 - val_accuracy: 0.9068 - val_auc: 0.9533\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3148 - accuracy: 0.9001 - auc: 0.9434 - val_loss: 0.2844 - val_accuracy: 0.9080 - val_auc: 0.9532\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3101 - accuracy: 0.8992 - auc: 0.9454 - val_loss: 0.2836 - val_accuracy: 0.9100 - val_auc: 0.9537\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3128 - accuracy: 0.9017 - auc: 0.9435 - val_loss: 0.2826 - val_accuracy: 0.9084 - val_auc: 0.9537\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2916 - accuracy: 0.8983 - auc: 0.9512 - val_loss: 0.2832 - val_accuracy: 0.9086 - val_auc: 0.9537\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2871 - accuracy: 0.9003 - auc: 0.9518 - val_loss: 0.2845 - val_accuracy: 0.9092 - val_auc: 0.9537\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3029 - accuracy: 0.9010 - auc: 0.9471 - val_loss: 0.2876 - val_accuracy: 0.9085 - val_auc: 0.9529\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2902 - accuracy: 0.9014 - auc: 0.9509 - val_loss: 0.2907 - val_accuracy: 0.9087 - val_auc: 0.9520\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2996 - accuracy: 0.8993 - auc: 0.9473 - val_loss: 0.2874 - val_accuracy: 0.9050 - val_auc: 0.9534\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2817 - accuracy: 0.8976 - auc: 0.9529 - val_loss: 0.2919 - val_accuracy: 0.9072 - val_auc: 0.9531\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2644 - accuracy: 0.9002 - auc: 0.9583 - val_loss: 0.2957 - val_accuracy: 0.9084 - val_auc: 0.9520\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2847 - accuracy: 0.8824 - auc: 0.9522 - val_loss: 0.2981 - val_accuracy: 0.9059 - val_auc: 0.9518\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2754 - accuracy: 0.8579 - auc: 0.9548 - val_loss: 0.2977 - val_accuracy: 0.9050 - val_auc: 0.9520\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2738 - accuracy: 0.8601 - auc: 0.9551 - val_loss: 0.3011 - val_accuracy: 0.9047 - val_auc: 0.9507\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2759 - accuracy: 0.8575 - auc: 0.9540 - val_loss: 0.3030 - val_accuracy: 0.9050 - val_auc: 0.9508\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2748 - accuracy: 0.8571 - auc: 0.9542 - val_loss: 0.3030 - val_accuracy: 0.9022 - val_auc: 0.9509\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2681 - accuracy: 0.8562 - auc: 0.9570 - val_loss: 0.3069 - val_accuracy: 0.9045 - val_auc: 0.9506\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2631 - accuracy: 0.8560 - auc: 0.9581 - val_loss: 0.3099 - val_accuracy: 0.9031 - val_auc: 0.9503\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2628 - accuracy: 0.8573 - auc: 0.9580 - val_loss: 0.3127 - val_accuracy: 0.9028 - val_auc: 0.9503\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2717 - accuracy: 0.8548 - auc: 0.9561 - val_loss: 0.3172 - val_accuracy: 0.9030 - val_auc: 0.9496\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2497 - accuracy: 0.8563 - auc: 0.9620 - val_loss: 0.3210 - val_accuracy: 0.9050 - val_auc: 0.9486\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2734 - accuracy: 0.8550 - auc: 0.9548 - val_loss: 0.3246 - val_accuracy: 0.9026 - val_auc: 0.9490\n",
      "Epoch 35/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2523 - accuracy: 0.8553 - auc: 0.9605Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2525 - accuracy: 0.8552 - auc: 0.9604 - val_loss: 0.3299 - val_accuracy: 0.9050 - val_auc: 0.9493\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.8715 - accuracy: 0.3048 - auc: 0.7224 - val_loss: 0.4959 - val_accuracy: 0.5831 - val_auc: 0.9204\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.5209 - accuracy: 0.6275 - auc: 0.8843 - val_loss: 0.3786 - val_accuracy: 0.8146 - val_auc: 0.9384\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4153 - accuracy: 0.7520 - auc: 0.9173 - val_loss: 0.3259 - val_accuracy: 0.8645 - val_auc: 0.9458\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3754 - accuracy: 0.8043 - auc: 0.9259 - val_loss: 0.2972 - val_accuracy: 0.8829 - val_auc: 0.9506\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3433 - accuracy: 0.8326 - auc: 0.9373 - val_loss: 0.2839 - val_accuracy: 0.8884 - val_auc: 0.9534\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3081 - accuracy: 0.8464 - auc: 0.9474 - val_loss: 0.2720 - val_accuracy: 0.8994 - val_auc: 0.9558\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3110 - accuracy: 0.8547 - auc: 0.9452 - val_loss: 0.2640 - val_accuracy: 0.9026 - val_auc: 0.9586\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2998 - accuracy: 0.8621 - auc: 0.9490 - val_loss: 0.2594 - val_accuracy: 0.8992 - val_auc: 0.9596\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2806 - accuracy: 0.8618 - auc: 0.9545 - val_loss: 0.2574 - val_accuracy: 0.8974 - val_auc: 0.9600\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2866 - accuracy: 0.8681 - auc: 0.9541 - val_loss: 0.2542 - val_accuracy: 0.8995 - val_auc: 0.9606\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2719 - accuracy: 0.8676 - auc: 0.9575 - val_loss: 0.2550 - val_accuracy: 0.9069 - val_auc: 0.9604\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2607 - accuracy: 0.8730 - auc: 0.9604 - val_loss: 0.2548 - val_accuracy: 0.9073 - val_auc: 0.9605\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2640 - accuracy: 0.8767 - auc: 0.9594 - val_loss: 0.2555 - val_accuracy: 0.9069 - val_auc: 0.9605\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2559 - accuracy: 0.8815 - auc: 0.9615 - val_loss: 0.2587 - val_accuracy: 0.9073 - val_auc: 0.9593\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2536 - accuracy: 0.8781 - auc: 0.9621 - val_loss: 0.2612 - val_accuracy: 0.9091 - val_auc: 0.9588\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2495 - accuracy: 0.8805 - auc: 0.9638 - val_loss: 0.2610 - val_accuracy: 0.9097 - val_auc: 0.9590\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2522 - accuracy: 0.8816 - auc: 0.9629 - val_loss: 0.2611 - val_accuracy: 0.9082 - val_auc: 0.9592\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2453 - accuracy: 0.8893 - auc: 0.9643 - val_loss: 0.2630 - val_accuracy: 0.9088 - val_auc: 0.9589\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2419 - accuracy: 0.8878 - auc: 0.9651 - val_loss: 0.2642 - val_accuracy: 0.9098 - val_auc: 0.9588\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2383 - accuracy: 0.8926 - auc: 0.9661 - val_loss: 0.2656 - val_accuracy: 0.9096 - val_auc: 0.9585\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2473 - accuracy: 0.8887 - auc: 0.9637 - val_loss: 0.2655 - val_accuracy: 0.9142 - val_auc: 0.9591\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2353 - accuracy: 0.8943 - auc: 0.9669 - val_loss: 0.2655 - val_accuracy: 0.9124 - val_auc: 0.9592\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2407 - accuracy: 0.8939 - auc: 0.9654 - val_loss: 0.2688 - val_accuracy: 0.9098 - val_auc: 0.9585\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2336 - accuracy: 0.8923 - auc: 0.9673 - val_loss: 0.2726 - val_accuracy: 0.9126 - val_auc: 0.9579\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2423 - accuracy: 0.8933 - auc: 0.9650 - val_loss: 0.2729 - val_accuracy: 0.9116 - val_auc: 0.9580\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2281 - accuracy: 0.8956 - auc: 0.9684 - val_loss: 0.2710 - val_accuracy: 0.9131 - val_auc: 0.9589\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2287 - accuracy: 0.8942 - auc: 0.9685 - val_loss: 0.2744 - val_accuracy: 0.9142 - val_auc: 0.9575\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2287 - accuracy: 0.8991 - auc: 0.9684 - val_loss: 0.2808 - val_accuracy: 0.9174 - val_auc: 0.9568\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2251 - accuracy: 0.9000 - auc: 0.9690 - val_loss: 0.2813 - val_accuracy: 0.9160 - val_auc: 0.9570\n",
      "Epoch 30/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2280 - accuracy: 0.8987 - auc: 0.9682Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2278 - accuracy: 0.8987 - auc: 0.9682 - val_loss: 0.2826 - val_accuracy: 0.9133 - val_auc: 0.9565\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5925 - accuracy: 0.8304 - auc: 0.8039 - val_loss: 0.3761 - val_accuracy: 0.9017 - val_auc: 0.9241\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4219 - accuracy: 0.8761 - auc: 0.9022 - val_loss: 0.3284 - val_accuracy: 0.9119 - val_auc: 0.9403\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3906 - accuracy: 0.8905 - auc: 0.9157 - val_loss: 0.3084 - val_accuracy: 0.9095 - val_auc: 0.9466\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3415 - accuracy: 0.8970 - auc: 0.9356 - val_loss: 0.2946 - val_accuracy: 0.9135 - val_auc: 0.9523\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3202 - accuracy: 0.9003 - auc: 0.9421 - val_loss: 0.2842 - val_accuracy: 0.9151 - val_auc: 0.9544\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3225 - accuracy: 0.9052 - auc: 0.9405 - val_loss: 0.2785 - val_accuracy: 0.9130 - val_auc: 0.9555\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3094 - accuracy: 0.9054 - auc: 0.9474 - val_loss: 0.2776 - val_accuracy: 0.9184 - val_auc: 0.9556\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2986 - accuracy: 0.9086 - auc: 0.9502 - val_loss: 0.2771 - val_accuracy: 0.9166 - val_auc: 0.9547\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2810 - accuracy: 0.9119 - auc: 0.9566 - val_loss: 0.2749 - val_accuracy: 0.9198 - val_auc: 0.9551\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2849 - accuracy: 0.9122 - auc: 0.9549 - val_loss: 0.2733 - val_accuracy: 0.9200 - val_auc: 0.9555\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2756 - accuracy: 0.9137 - auc: 0.9583 - val_loss: 0.2728 - val_accuracy: 0.9188 - val_auc: 0.9560\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2743 - accuracy: 0.9125 - auc: 0.9588 - val_loss: 0.2729 - val_accuracy: 0.9239 - val_auc: 0.9560\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2671 - accuracy: 0.9166 - auc: 0.9595 - val_loss: 0.2727 - val_accuracy: 0.9212 - val_auc: 0.9557\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2623 - accuracy: 0.9104 - auc: 0.9617 - val_loss: 0.2719 - val_accuracy: 0.9226 - val_auc: 0.9559\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2590 - accuracy: 0.9173 - auc: 0.9632 - val_loss: 0.2743 - val_accuracy: 0.9215 - val_auc: 0.9556\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2570 - accuracy: 0.9176 - auc: 0.9636 - val_loss: 0.2739 - val_accuracy: 0.9181 - val_auc: 0.9555\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2597 - accuracy: 0.9164 - auc: 0.9621 - val_loss: 0.2744 - val_accuracy: 0.9217 - val_auc: 0.9554\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2558 - accuracy: 0.9157 - auc: 0.9631 - val_loss: 0.2744 - val_accuracy: 0.9231 - val_auc: 0.9560\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2483 - accuracy: 0.9182 - auc: 0.9653 - val_loss: 0.2741 - val_accuracy: 0.9236 - val_auc: 0.9556\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2464 - accuracy: 0.9198 - auc: 0.9661 - val_loss: 0.2768 - val_accuracy: 0.9210 - val_auc: 0.9555\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2488 - accuracy: 0.9193 - auc: 0.9654 - val_loss: 0.2761 - val_accuracy: 0.9195 - val_auc: 0.9554\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2428 - accuracy: 0.9181 - auc: 0.9663 - val_loss: 0.2778 - val_accuracy: 0.9213 - val_auc: 0.9554\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2467 - accuracy: 0.9159 - auc: 0.9654 - val_loss: 0.2814 - val_accuracy: 0.9239 - val_auc: 0.9547\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2423 - accuracy: 0.9199 - auc: 0.9671 - val_loss: 0.2799 - val_accuracy: 0.9196 - val_auc: 0.9550\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2325 - accuracy: 0.9169 - auc: 0.9685 - val_loss: 0.2853 - val_accuracy: 0.9253 - val_auc: 0.9540\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2396 - accuracy: 0.9210 - auc: 0.9672 - val_loss: 0.2854 - val_accuracy: 0.9238 - val_auc: 0.9541\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2342 - accuracy: 0.9195 - auc: 0.9687 - val_loss: 0.2892 - val_accuracy: 0.9249 - val_auc: 0.9534\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2328 - accuracy: 0.9208 - auc: 0.9689 - val_loss: 0.2909 - val_accuracy: 0.9247 - val_auc: 0.9531\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2300 - accuracy: 0.9210 - auc: 0.9692 - val_loss: 0.2958 - val_accuracy: 0.9244 - val_auc: 0.9522\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2265 - accuracy: 0.9202 - auc: 0.9702 - val_loss: 0.2991 - val_accuracy: 0.9248 - val_auc: 0.9518\n",
      "Epoch 31/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.9198 - auc: 0.9688Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2307 - accuracy: 0.9198 - auc: 0.9690 - val_loss: 0.3008 - val_accuracy: 0.9247 - val_auc: 0.9524\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.7427 - accuracy: 0.8304 - auc: 0.7097 - val_loss: 0.4157 - val_accuracy: 0.8766 - val_auc: 0.9082\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4934 - accuracy: 0.8410 - auc: 0.8653 - val_loss: 0.3471 - val_accuracy: 0.8822 - val_auc: 0.9334\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3918 - accuracy: 0.8663 - auc: 0.9128 - val_loss: 0.3175 - val_accuracy: 0.8970 - val_auc: 0.9452\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3562 - accuracy: 0.8857 - auc: 0.9317 - val_loss: 0.2992 - val_accuracy: 0.9026 - val_auc: 0.9506\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3566 - accuracy: 0.8858 - auc: 0.9283 - val_loss: 0.2841 - val_accuracy: 0.9068 - val_auc: 0.9560\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3239 - accuracy: 0.8945 - auc: 0.9415 - val_loss: 0.2749 - val_accuracy: 0.9079 - val_auc: 0.9584\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3114 - accuracy: 0.8997 - auc: 0.9465 - val_loss: 0.2693 - val_accuracy: 0.9089 - val_auc: 0.9589\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2994 - accuracy: 0.9006 - auc: 0.9488 - val_loss: 0.2673 - val_accuracy: 0.9144 - val_auc: 0.9589\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2980 - accuracy: 0.9060 - auc: 0.9489 - val_loss: 0.2646 - val_accuracy: 0.9143 - val_auc: 0.9590\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2813 - accuracy: 0.9021 - auc: 0.9555 - val_loss: 0.2621 - val_accuracy: 0.9161 - val_auc: 0.9598\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2714 - accuracy: 0.9098 - auc: 0.9581 - val_loss: 0.2624 - val_accuracy: 0.9169 - val_auc: 0.9593\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2741 - accuracy: 0.9105 - auc: 0.9561 - val_loss: 0.2635 - val_accuracy: 0.9178 - val_auc: 0.9593\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2665 - accuracy: 0.9108 - auc: 0.9585 - val_loss: 0.2626 - val_accuracy: 0.9171 - val_auc: 0.9587\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2623 - accuracy: 0.9123 - auc: 0.9607 - val_loss: 0.2637 - val_accuracy: 0.9168 - val_auc: 0.9589\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2562 - accuracy: 0.9123 - auc: 0.9616 - val_loss: 0.2646 - val_accuracy: 0.9167 - val_auc: 0.9581\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2641 - accuracy: 0.9106 - auc: 0.9585 - val_loss: 0.2665 - val_accuracy: 0.9152 - val_auc: 0.9571\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2570 - accuracy: 0.9118 - auc: 0.9618 - val_loss: 0.2679 - val_accuracy: 0.9155 - val_auc: 0.9570\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2593 - accuracy: 0.9107 - auc: 0.9603 - val_loss: 0.2712 - val_accuracy: 0.9168 - val_auc: 0.9565\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2526 - accuracy: 0.9094 - auc: 0.9623 - val_loss: 0.2730 - val_accuracy: 0.9175 - val_auc: 0.9556\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2537 - accuracy: 0.9131 - auc: 0.9618 - val_loss: 0.2740 - val_accuracy: 0.9171 - val_auc: 0.9558\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2485 - accuracy: 0.9112 - auc: 0.9639 - val_loss: 0.2749 - val_accuracy: 0.9184 - val_auc: 0.9562\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2443 - accuracy: 0.9127 - auc: 0.9647 - val_loss: 0.2744 - val_accuracy: 0.9171 - val_auc: 0.9559\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2375 - accuracy: 0.9138 - auc: 0.9662 - val_loss: 0.2808 - val_accuracy: 0.9204 - val_auc: 0.9551\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2461 - accuracy: 0.9127 - auc: 0.9638 - val_loss: 0.2793 - val_accuracy: 0.9174 - val_auc: 0.9554\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2420 - accuracy: 0.9128 - auc: 0.9650 - val_loss: 0.2782 - val_accuracy: 0.9183 - val_auc: 0.9554\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2445 - accuracy: 0.9104 - auc: 0.9640 - val_loss: 0.2830 - val_accuracy: 0.9196 - val_auc: 0.9544\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2399 - accuracy: 0.9144 - auc: 0.9657 - val_loss: 0.2867 - val_accuracy: 0.9201 - val_auc: 0.9541\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2335 - accuracy: 0.9144 - auc: 0.9674 - val_loss: 0.2915 - val_accuracy: 0.9198 - val_auc: 0.9533\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2329 - accuracy: 0.9158 - auc: 0.9676 - val_loss: 0.2930 - val_accuracy: 0.9219 - val_auc: 0.9534\n",
      "Epoch 30/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9153 - auc: 0.9685 ERestoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2270 - accuracy: 0.9153 - auc: 0.9689 - val_loss: 0.2971 - val_accuracy: 0.9221 - val_auc: 0.9529\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.6727 - accuracy: 0.4388 - auc: 0.7797 - val_loss: 0.4388 - val_accuracy: 0.7161 - val_auc: 0.9126\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4979 - accuracy: 0.7039 - auc: 0.8790 - val_loss: 0.3517 - val_accuracy: 0.8624 - val_auc: 0.9350\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4030 - accuracy: 0.8042 - auc: 0.9093 - val_loss: 0.3170 - val_accuracy: 0.8838 - val_auc: 0.9432\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3694 - accuracy: 0.8319 - auc: 0.9202 - val_loss: 0.2975 - val_accuracy: 0.8921 - val_auc: 0.9479\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3374 - accuracy: 0.8471 - auc: 0.9342 - val_loss: 0.2861 - val_accuracy: 0.8967 - val_auc: 0.9505\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3092 - accuracy: 0.8573 - auc: 0.9438 - val_loss: 0.2770 - val_accuracy: 0.8994 - val_auc: 0.9531\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3032 - accuracy: 0.8639 - auc: 0.9454 - val_loss: 0.2721 - val_accuracy: 0.9020 - val_auc: 0.9549\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3011 - accuracy: 0.8712 - auc: 0.9456 - val_loss: 0.2691 - val_accuracy: 0.9019 - val_auc: 0.9555\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2719 - accuracy: 0.8772 - auc: 0.9558 - val_loss: 0.2692 - val_accuracy: 0.9093 - val_auc: 0.9559\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2671 - accuracy: 0.8787 - auc: 0.9574 - val_loss: 0.2676 - val_accuracy: 0.9067 - val_auc: 0.9562\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2696 - accuracy: 0.8781 - auc: 0.9561 - val_loss: 0.2659 - val_accuracy: 0.9063 - val_auc: 0.9571\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2637 - accuracy: 0.8819 - auc: 0.9580 - val_loss: 0.2662 - val_accuracy: 0.9038 - val_auc: 0.9564\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2669 - accuracy: 0.8852 - auc: 0.9570 - val_loss: 0.2647 - val_accuracy: 0.9075 - val_auc: 0.9571\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.2638 - accuracy: 0.8835 - auc: 0.9585 - val_loss: 0.2642 - val_accuracy: 0.9054 - val_auc: 0.9572\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 0.2561 - accuracy: 0.8823 - auc: 0.9603 - val_loss: 0.2636 - val_accuracy: 0.9074 - val_auc: 0.9576\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.2471 - accuracy: 0.8886 - auc: 0.9630 - val_loss: 0.2650 - val_accuracy: 0.9126 - val_auc: 0.9582\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2540 - accuracy: 0.8886 - auc: 0.9613 - val_loss: 0.2659 - val_accuracy: 0.9110 - val_auc: 0.9575\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2400 - accuracy: 0.8900 - auc: 0.9649 - val_loss: 0.2692 - val_accuracy: 0.9111 - val_auc: 0.9572\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2404 - accuracy: 0.8908 - auc: 0.9650 - val_loss: 0.2733 - val_accuracy: 0.9116 - val_auc: 0.9564\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2372 - accuracy: 0.8935 - auc: 0.9657 - val_loss: 0.2725 - val_accuracy: 0.9115 - val_auc: 0.9562\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2392 - accuracy: 0.8892 - auc: 0.9651 - val_loss: 0.2724 - val_accuracy: 0.9101 - val_auc: 0.9572\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2333 - accuracy: 0.8915 - auc: 0.9664 - val_loss: 0.2779 - val_accuracy: 0.9104 - val_auc: 0.9552\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2250 - accuracy: 0.8936 - auc: 0.9690 - val_loss: 0.2848 - val_accuracy: 0.9135 - val_auc: 0.9536\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2344 - accuracy: 0.8937 - auc: 0.9663 - val_loss: 0.2877 - val_accuracy: 0.9140 - val_auc: 0.9526\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2278 - accuracy: 0.8944 - auc: 0.9679 - val_loss: 0.2886 - val_accuracy: 0.9112 - val_auc: 0.9527\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2268 - accuracy: 0.8893 - auc: 0.9684 - val_loss: 0.2887 - val_accuracy: 0.9141 - val_auc: 0.9533\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2255 - accuracy: 0.8961 - auc: 0.9687 - val_loss: 0.2908 - val_accuracy: 0.9104 - val_auc: 0.9527\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2268 - accuracy: 0.8920 - auc: 0.9683 - val_loss: 0.2910 - val_accuracy: 0.9082 - val_auc: 0.9528\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2231 - accuracy: 0.8920 - auc: 0.9693 - val_loss: 0.3006 - val_accuracy: 0.9144 - val_auc: 0.9520\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2223 - accuracy: 0.8917 - auc: 0.9695 - val_loss: 0.2990 - val_accuracy: 0.9139 - val_auc: 0.9526\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2220 - accuracy: 0.8953 - auc: 0.9698 - val_loss: 0.3024 - val_accuracy: 0.9171 - val_auc: 0.9526\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2184 - accuracy: 0.8966 - auc: 0.9703 - val_loss: 0.3046 - val_accuracy: 0.9171 - val_auc: 0.9516\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2134 - accuracy: 0.8969 - auc: 0.9720 - val_loss: 0.3057 - val_accuracy: 0.9144 - val_auc: 0.9523\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2192 - accuracy: 0.8940 - auc: 0.9701 - val_loss: 0.3111 - val_accuracy: 0.9122 - val_auc: 0.9505\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2149 - accuracy: 0.8916 - auc: 0.9713 - val_loss: 0.3165 - val_accuracy: 0.9169 - val_auc: 0.9505\n",
      "Epoch 36/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.8964 - auc: 0.9700Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2196 - accuracy: 0.8963 - auc: 0.9703 - val_loss: 0.3200 - val_accuracy: 0.9141 - val_auc: 0.9502\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 19us/sample - loss: 1.0123 - accuracy: 0.8584 - auc: 0.6235 - val_loss: 0.5122 - val_accuracy: 0.8848 - val_auc: 0.8664\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5478 - accuracy: 0.8396 - auc: 0.8312 - val_loss: 0.4303 - val_accuracy: 0.8773 - val_auc: 0.9152\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4813 - accuracy: 0.8615 - auc: 0.8827 - val_loss: 0.3877 - val_accuracy: 0.8929 - val_auc: 0.9286\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4175 - accuracy: 0.8872 - auc: 0.9152 - val_loss: 0.3557 - val_accuracy: 0.9048 - val_auc: 0.9347\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3874 - accuracy: 0.8946 - auc: 0.9256 - val_loss: 0.3334 - val_accuracy: 0.9128 - val_auc: 0.9391\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3849 - accuracy: 0.9014 - auc: 0.9260 - val_loss: 0.3196 - val_accuracy: 0.9100 - val_auc: 0.9444\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3518 - accuracy: 0.9029 - auc: 0.9370 - val_loss: 0.3008 - val_accuracy: 0.9124 - val_auc: 0.9497\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3154 - accuracy: 0.9066 - auc: 0.9452 - val_loss: 0.2926 - val_accuracy: 0.9142 - val_auc: 0.9510\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3077 - accuracy: 0.9084 - auc: 0.9467 - val_loss: 0.2869 - val_accuracy: 0.9109 - val_auc: 0.9518\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3013 - accuracy: 0.9064 - auc: 0.9484 - val_loss: 0.2843 - val_accuracy: 0.9133 - val_auc: 0.9520\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2883 - accuracy: 0.9073 - auc: 0.9553 - val_loss: 0.2823 - val_accuracy: 0.9153 - val_auc: 0.9520\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2844 - accuracy: 0.9109 - auc: 0.9549 - val_loss: 0.2846 - val_accuracy: 0.9171 - val_auc: 0.9518\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2735 - accuracy: 0.9115 - auc: 0.9575 - val_loss: 0.2849 - val_accuracy: 0.9181 - val_auc: 0.9514\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2664 - accuracy: 0.9106 - auc: 0.9599 - val_loss: 0.2833 - val_accuracy: 0.9165 - val_auc: 0.9515\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2737 - accuracy: 0.9097 - auc: 0.9579 - val_loss: 0.2830 - val_accuracy: 0.9165 - val_auc: 0.9521\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2745 - accuracy: 0.9129 - auc: 0.9579 - val_loss: 0.2844 - val_accuracy: 0.9136 - val_auc: 0.9522\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2702 - accuracy: 0.9106 - auc: 0.9590 - val_loss: 0.2868 - val_accuracy: 0.9132 - val_auc: 0.9520\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2600 - accuracy: 0.9106 - auc: 0.9618 - val_loss: 0.2873 - val_accuracy: 0.9164 - val_auc: 0.9519\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2615 - accuracy: 0.9133 - auc: 0.9614 - val_loss: 0.2910 - val_accuracy: 0.9138 - val_auc: 0.9510\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2538 - accuracy: 0.9117 - auc: 0.9627 - val_loss: 0.2941 - val_accuracy: 0.9155 - val_auc: 0.9507\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2422 - accuracy: 0.9143 - auc: 0.9661 - val_loss: 0.2975 - val_accuracy: 0.9188 - val_auc: 0.9500\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2431 - accuracy: 0.9144 - auc: 0.9656 - val_loss: 0.3010 - val_accuracy: 0.9203 - val_auc: 0.9498\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2578 - accuracy: 0.9134 - auc: 0.9625 - val_loss: 0.3000 - val_accuracy: 0.9159 - val_auc: 0.9504\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2421 - accuracy: 0.9144 - auc: 0.9659 - val_loss: 0.3047 - val_accuracy: 0.9209 - val_auc: 0.9501\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2377 - accuracy: 0.9132 - auc: 0.9668 - val_loss: 0.3096 - val_accuracy: 0.9185 - val_auc: 0.9489\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2387 - accuracy: 0.9147 - auc: 0.9666 - val_loss: 0.3152 - val_accuracy: 0.9190 - val_auc: 0.9487\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2329 - accuracy: 0.9150 - auc: 0.9680 - val_loss: 0.3192 - val_accuracy: 0.9183 - val_auc: 0.9486\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2234 - accuracy: 0.9146 - auc: 0.9704 - val_loss: 0.3208 - val_accuracy: 0.9196 - val_auc: 0.9483\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2317 - accuracy: 0.9128 - auc: 0.9679 - val_loss: 0.3255 - val_accuracy: 0.9171 - val_auc: 0.9477\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2240 - accuracy: 0.9127 - auc: 0.9697 - val_loss: 0.3307 - val_accuracy: 0.9193 - val_auc: 0.9474\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2180 - accuracy: 0.9145 - auc: 0.9712 - val_loss: 0.3333 - val_accuracy: 0.9198 - val_auc: 0.9469\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2205 - accuracy: 0.9145 - auc: 0.9701 - val_loss: 0.3399 - val_accuracy: 0.9228 - val_auc: 0.9447\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2264 - accuracy: 0.9155 - auc: 0.9695 - val_loss: 0.3431 - val_accuracy: 0.9216 - val_auc: 0.9446\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2227 - accuracy: 0.9142 - auc: 0.9699 - val_loss: 0.3476 - val_accuracy: 0.9204 - val_auc: 0.9444\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2176 - accuracy: 0.9142 - auc: 0.9711 - val_loss: 0.3526 - val_accuracy: 0.9196 - val_auc: 0.9448\n",
      "Epoch 36/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9122 - auc: 0.9712 ETA: 0s - loss: 0.2101 - accuracy: Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2165 - accuracy: 0.9124 - auc: 0.9710 - val_loss: 0.3579 - val_accuracy: 0.9207 - val_auc: 0.9444\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.7573 - accuracy: 0.8539 - auc: 0.7142 - val_loss: 0.3922 - val_accuracy: 0.8954 - val_auc: 0.9082\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4307 - accuracy: 0.8550 - auc: 0.9015 - val_loss: 0.3367 - val_accuracy: 0.8983 - val_auc: 0.9328\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3913 - accuracy: 0.8785 - auc: 0.9133 - val_loss: 0.3162 - val_accuracy: 0.8948 - val_auc: 0.9425\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 0.3521 - accuracy: 0.8847 - auc: 0.9338 - val_loss: 0.2969 - val_accuracy: 0.9013 - val_auc: 0.9483\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3223 - accuracy: 0.8915 - auc: 0.9425 - val_loss: 0.2835 - val_accuracy: 0.9077 - val_auc: 0.9525\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3022 - accuracy: 0.9004 - auc: 0.9482 - val_loss: 0.2808 - val_accuracy: 0.9115 - val_auc: 0.9521\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2914 - accuracy: 0.9021 - auc: 0.9536 - val_loss: 0.2749 - val_accuracy: 0.9109 - val_auc: 0.9552\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2891 - accuracy: 0.9019 - auc: 0.9520 - val_loss: 0.2701 - val_accuracy: 0.9131 - val_auc: 0.9565\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2787 - accuracy: 0.9041 - auc: 0.9574 - val_loss: 0.2682 - val_accuracy: 0.9159 - val_auc: 0.9570\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2762 - accuracy: 0.9076 - auc: 0.9564 - val_loss: 0.2705 - val_accuracy: 0.9119 - val_auc: 0.9565\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2681 - accuracy: 0.9076 - auc: 0.9585 - val_loss: 0.2684 - val_accuracy: 0.9126 - val_auc: 0.9566\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2608 - accuracy: 0.9087 - auc: 0.9614 - val_loss: 0.2673 - val_accuracy: 0.9137 - val_auc: 0.9574\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2612 - accuracy: 0.9067 - auc: 0.9608 - val_loss: 0.2658 - val_accuracy: 0.9148 - val_auc: 0.9579\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2552 - accuracy: 0.9108 - auc: 0.9619 - val_loss: 0.2640 - val_accuracy: 0.9136 - val_auc: 0.9579\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2586 - accuracy: 0.9086 - auc: 0.9610 - val_loss: 0.2672 - val_accuracy: 0.9191 - val_auc: 0.9574\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2507 - accuracy: 0.9121 - auc: 0.9635 - val_loss: 0.2678 - val_accuracy: 0.9184 - val_auc: 0.9574\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2489 - accuracy: 0.9094 - auc: 0.9638 - val_loss: 0.2687 - val_accuracy: 0.9182 - val_auc: 0.9571\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2481 - accuracy: 0.9119 - auc: 0.9640 - val_loss: 0.2671 - val_accuracy: 0.9163 - val_auc: 0.9579\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2347 - accuracy: 0.9121 - auc: 0.9676 - val_loss: 0.2730 - val_accuracy: 0.9232 - val_auc: 0.9570\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2510 - accuracy: 0.9151 - auc: 0.9631 - val_loss: 0.2671 - val_accuracy: 0.9167 - val_auc: 0.9574\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2383 - accuracy: 0.9119 - auc: 0.9663 - val_loss: 0.2695 - val_accuracy: 0.9181 - val_auc: 0.9573\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2416 - accuracy: 0.9127 - auc: 0.9654 - val_loss: 0.2669 - val_accuracy: 0.9163 - val_auc: 0.9581\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2357 - accuracy: 0.9116 - auc: 0.9672 - val_loss: 0.2709 - val_accuracy: 0.9180 - val_auc: 0.9571\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2312 - accuracy: 0.9149 - auc: 0.9681 - val_loss: 0.2702 - val_accuracy: 0.9215 - val_auc: 0.9579\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2298 - accuracy: 0.9150 - auc: 0.9686 - val_loss: 0.2745 - val_accuracy: 0.9204 - val_auc: 0.9568\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2268 - accuracy: 0.9152 - auc: 0.9692 - val_loss: 0.2770 - val_accuracy: 0.9180 - val_auc: 0.9567\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2248 - accuracy: 0.9144 - auc: 0.9694 - val_loss: 0.2790 - val_accuracy: 0.9220 - val_auc: 0.9562\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2254 - accuracy: 0.9157 - auc: 0.9695 - val_loss: 0.2794 - val_accuracy: 0.9216 - val_auc: 0.9567\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2226 - accuracy: 0.9154 - auc: 0.9703 - val_loss: 0.2837 - val_accuracy: 0.9200 - val_auc: 0.9555\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2210 - accuracy: 0.9140 - auc: 0.9704 - val_loss: 0.2896 - val_accuracy: 0.9207 - val_auc: 0.9544\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2182 - accuracy: 0.9180 - auc: 0.9708 - val_loss: 0.2921 - val_accuracy: 0.9217 - val_auc: 0.9532\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2139 - accuracy: 0.9185 - auc: 0.9721 - val_loss: 0.2942 - val_accuracy: 0.9223 - val_auc: 0.9538\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2186 - accuracy: 0.9172 - auc: 0.9708 - val_loss: 0.2987 - val_accuracy: 0.9225 - val_auc: 0.9526\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2187 - accuracy: 0.9177 - auc: 0.9708 - val_loss: 0.2966 - val_accuracy: 0.9225 - val_auc: 0.9540\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2195 - accuracy: 0.9163 - auc: 0.9707 - val_loss: 0.2974 - val_accuracy: 0.9234 - val_auc: 0.9544\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2137 - accuracy: 0.9178 - auc: 0.9720 - val_loss: 0.3023 - val_accuracy: 0.9220 - val_auc: 0.9533\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2113 - accuracy: 0.9171 - auc: 0.9724 - val_loss: 0.3115 - val_accuracy: 0.9222 - val_auc: 0.9512\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2128 - accuracy: 0.9188 - auc: 0.9724 - val_loss: 0.3149 - val_accuracy: 0.9227 - val_auc: 0.9513\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2086 - accuracy: 0.9194 - auc: 0.9732 - val_loss: 0.3205 - val_accuracy: 0.9222 - val_auc: 0.9493\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2100 - accuracy: 0.9179 - auc: 0.9727 - val_loss: 0.3249 - val_accuracy: 0.9236 - val_auc: 0.9499\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2061 - accuracy: 0.9193 - auc: 0.9736 - val_loss: 0.3274 - val_accuracy: 0.9259 - val_auc: 0.9491\n",
      "Epoch 42/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2098 - accuracy: 0.9204 - auc: 0.9728Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2091 - accuracy: 0.9205 - auc: 0.9730 - val_loss: 0.3340 - val_accuracy: 0.9261 - val_auc: 0.9492\n",
      "Epoch 00042: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.6379 - accuracy: 0.7638 - auc: 0.7715 - val_loss: 0.3787 - val_accuracy: 0.8742 - val_auc: 0.9233\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4081 - accuracy: 0.8546 - auc: 0.9094 - val_loss: 0.3240 - val_accuracy: 0.9049 - val_auc: 0.9469\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3501 - accuracy: 0.8838 - auc: 0.9307 - val_loss: 0.2973 - val_accuracy: 0.9074 - val_auc: 0.9538\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3227 - accuracy: 0.8888 - auc: 0.9423 - val_loss: 0.2847 - val_accuracy: 0.9139 - val_auc: 0.9564\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3171 - accuracy: 0.8943 - auc: 0.9431 - val_loss: 0.2788 - val_accuracy: 0.9104 - val_auc: 0.9570\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3043 - accuracy: 0.9014 - auc: 0.9485 - val_loss: 0.2728 - val_accuracy: 0.9106 - val_auc: 0.9582\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2797 - accuracy: 0.9031 - auc: 0.9562 - val_loss: 0.2715 - val_accuracy: 0.9149 - val_auc: 0.9579\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2786 - accuracy: 0.9047 - auc: 0.9543 - val_loss: 0.2710 - val_accuracy: 0.9149 - val_auc: 0.9574\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2659 - accuracy: 0.9073 - auc: 0.9596 - val_loss: 0.2698 - val_accuracy: 0.9160 - val_auc: 0.9577\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2730 - accuracy: 0.9081 - auc: 0.9576 - val_loss: 0.2674 - val_accuracy: 0.9140 - val_auc: 0.9587\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2582 - accuracy: 0.9088 - auc: 0.9615 - val_loss: 0.2670 - val_accuracy: 0.9189 - val_auc: 0.9586\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2465 - accuracy: 0.9087 - auc: 0.9651 - val_loss: 0.2686 - val_accuracy: 0.9247 - val_auc: 0.9581\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2528 - accuracy: 0.9160 - auc: 0.9633 - val_loss: 0.2665 - val_accuracy: 0.9219 - val_auc: 0.9582\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2523 - accuracy: 0.9131 - auc: 0.9637 - val_loss: 0.2706 - val_accuracy: 0.9232 - val_auc: 0.9568\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2519 - accuracy: 0.9126 - auc: 0.9646 - val_loss: 0.2694 - val_accuracy: 0.9208 - val_auc: 0.9571\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2387 - accuracy: 0.9155 - auc: 0.9671 - val_loss: 0.2712 - val_accuracy: 0.9199 - val_auc: 0.9568\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2371 - accuracy: 0.9137 - auc: 0.9671 - val_loss: 0.2740 - val_accuracy: 0.9235 - val_auc: 0.9558\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2343 - accuracy: 0.9164 - auc: 0.9679 - val_loss: 0.2814 - val_accuracy: 0.9245 - val_auc: 0.9547\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2385 - accuracy: 0.9165 - auc: 0.9666 - val_loss: 0.2817 - val_accuracy: 0.9239 - val_auc: 0.9546\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2405 - accuracy: 0.9149 - auc: 0.9669 - val_loss: 0.2801 - val_accuracy: 0.9238 - val_auc: 0.9547\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2281 - accuracy: 0.9177 - auc: 0.9694 - val_loss: 0.2808 - val_accuracy: 0.9214 - val_auc: 0.9546\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2244 - accuracy: 0.9184 - auc: 0.9704 - val_loss: 0.2844 - val_accuracy: 0.9247 - val_auc: 0.9539\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2303 - accuracy: 0.9187 - auc: 0.9691 - val_loss: 0.2882 - val_accuracy: 0.9234 - val_auc: 0.9531\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2316 - accuracy: 0.9170 - auc: 0.9684 - val_loss: 0.2886 - val_accuracy: 0.9244 - val_auc: 0.9534\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2295 - accuracy: 0.9163 - auc: 0.9685 - val_loss: 0.2897 - val_accuracy: 0.9266 - val_auc: 0.9534\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2269 - accuracy: 0.9214 - auc: 0.9693 - val_loss: 0.2899 - val_accuracy: 0.9228 - val_auc: 0.9537\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2210 - accuracy: 0.9185 - auc: 0.9710 - val_loss: 0.2974 - val_accuracy: 0.9265 - val_auc: 0.9516\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2225 - accuracy: 0.9201 - auc: 0.9705 - val_loss: 0.2976 - val_accuracy: 0.9254 - val_auc: 0.9514\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2236 - accuracy: 0.9200 - auc: 0.9703 - val_loss: 0.2990 - val_accuracy: 0.9274 - val_auc: 0.9520\n",
      "Epoch 30/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9252 - auc: 0.9730Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2113 - accuracy: 0.9251 - auc: 0.9731 - val_loss: 0.3006 - val_accuracy: 0.9245 - val_auc: 0.9518\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.7033 - accuracy: 0.4121 - auc: 0.7765 - val_loss: 0.3974 - val_accuracy: 0.7547 - val_auc: 0.9330\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4338 - accuracy: 0.7333 - auc: 0.8976 - val_loss: 0.3155 - val_accuracy: 0.8533 - val_auc: 0.9461\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3811 - accuracy: 0.8073 - auc: 0.9193 - val_loss: 0.2911 - val_accuracy: 0.8790 - val_auc: 0.9492\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3343 - accuracy: 0.8293 - auc: 0.9360 - val_loss: 0.2819 - val_accuracy: 0.8895 - val_auc: 0.9521\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3088 - accuracy: 0.8443 - auc: 0.9446 - val_loss: 0.2771 - val_accuracy: 0.9009 - val_auc: 0.9543\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2984 - accuracy: 0.8572 - auc: 0.9469 - val_loss: 0.2760 - val_accuracy: 0.8943 - val_auc: 0.9556\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2784 - accuracy: 0.8615 - auc: 0.9532 - val_loss: 0.2635 - val_accuracy: 0.9044 - val_auc: 0.9575\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2728 - accuracy: 0.8666 - auc: 0.9549 - val_loss: 0.2691 - val_accuracy: 0.9069 - val_auc: 0.9558\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2714 - accuracy: 0.8744 - auc: 0.9561 - val_loss: 0.2633 - val_accuracy: 0.9092 - val_auc: 0.9584\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2563 - accuracy: 0.8764 - auc: 0.9594 - val_loss: 0.2657 - val_accuracy: 0.9088 - val_auc: 0.9576\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2530 - accuracy: 0.8778 - auc: 0.9604 - val_loss: 0.2701 - val_accuracy: 0.9081 - val_auc: 0.9564\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2504 - accuracy: 0.8807 - auc: 0.9614 - val_loss: 0.2723 - val_accuracy: 0.9067 - val_auc: 0.9559\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2454 - accuracy: 0.8794 - auc: 0.9624 - val_loss: 0.2713 - val_accuracy: 0.9056 - val_auc: 0.9559\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2386 - accuracy: 0.8816 - auc: 0.9644 - val_loss: 0.2695 - val_accuracy: 0.9037 - val_auc: 0.9569\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2366 - accuracy: 0.8820 - auc: 0.9652 - val_loss: 0.2726 - val_accuracy: 0.9076 - val_auc: 0.9559\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2318 - accuracy: 0.8851 - auc: 0.9666 - val_loss: 0.2799 - val_accuracy: 0.9102 - val_auc: 0.9539\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2301 - accuracy: 0.8875 - auc: 0.9668 - val_loss: 0.2792 - val_accuracy: 0.9135 - val_auc: 0.9548\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2345 - accuracy: 0.8866 - auc: 0.9657 - val_loss: 0.2816 - val_accuracy: 0.9075 - val_auc: 0.9540\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2328 - accuracy: 0.8832 - auc: 0.9659 - val_loss: 0.2774 - val_accuracy: 0.9053 - val_auc: 0.9553\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2228 - accuracy: 0.8877 - auc: 0.9689 - val_loss: 0.2844 - val_accuracy: 0.9116 - val_auc: 0.9547\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2202 - accuracy: 0.8910 - auc: 0.9692 - val_loss: 0.2889 - val_accuracy: 0.9136 - val_auc: 0.9546\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2140 - accuracy: 0.8931 - auc: 0.9705 - val_loss: 0.2965 - val_accuracy: 0.9149 - val_auc: 0.9538\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2199 - accuracy: 0.8891 - auc: 0.9693 - val_loss: 0.2913 - val_accuracy: 0.9126 - val_auc: 0.9548\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2104 - accuracy: 0.8919 - auc: 0.9714 - val_loss: 0.2972 - val_accuracy: 0.9144 - val_auc: 0.9541\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2192 - accuracy: 0.8915 - auc: 0.9695 - val_loss: 0.2947 - val_accuracy: 0.9135 - val_auc: 0.9549\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2115 - accuracy: 0.8944 - auc: 0.9714 - val_loss: 0.3021 - val_accuracy: 0.9143 - val_auc: 0.9540\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2043 - accuracy: 0.8933 - auc: 0.9731 - val_loss: 0.3046 - val_accuracy: 0.9148 - val_auc: 0.9543\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2071 - accuracy: 0.8970 - auc: 0.9722 - val_loss: 0.3055 - val_accuracy: 0.9156 - val_auc: 0.9545\n",
      "Epoch 29/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.8972 - auc: 0.9729Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2055 - accuracy: 0.8972 - auc: 0.9728 - val_loss: 0.3103 - val_accuracy: 0.9156 - val_auc: 0.9541\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 25us/sample - loss: 0.6739 - accuracy: 0.5495 - auc: 0.7903 - val_loss: 0.4162 - val_accuracy: 0.7967 - val_auc: 0.9273\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4706 - accuracy: 0.7937 - auc: 0.8902 - val_loss: 0.3599 - val_accuracy: 0.8861 - val_auc: 0.9405\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3825 - accuracy: 0.8571 - auc: 0.9221 - val_loss: 0.3187 - val_accuracy: 0.8980 - val_auc: 0.9475\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3340 - accuracy: 0.8793 - auc: 0.9398 - val_loss: 0.2962 - val_accuracy: 0.9117 - val_auc: 0.9530\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3194 - accuracy: 0.8878 - auc: 0.9412 - val_loss: 0.2856 - val_accuracy: 0.9032 - val_auc: 0.9553\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3056 - accuracy: 0.8832 - auc: 0.9472 - val_loss: 0.2741 - val_accuracy: 0.9115 - val_auc: 0.9569\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2878 - accuracy: 0.8961 - auc: 0.9509 - val_loss: 0.2704 - val_accuracy: 0.9091 - val_auc: 0.9573\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2859 - accuracy: 0.8912 - auc: 0.9517 - val_loss: 0.2682 - val_accuracy: 0.9095 - val_auc: 0.9573\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2656 - accuracy: 0.8977 - auc: 0.9585 - val_loss: 0.2672 - val_accuracy: 0.9141 - val_auc: 0.9573\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2680 - accuracy: 0.8976 - auc: 0.9567 - val_loss: 0.2684 - val_accuracy: 0.9111 - val_auc: 0.9565\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2585 - accuracy: 0.8996 - auc: 0.9603 - val_loss: 0.2674 - val_accuracy: 0.9128 - val_auc: 0.9565\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2549 - accuracy: 0.8989 - auc: 0.9608 - val_loss: 0.2662 - val_accuracy: 0.9147 - val_auc: 0.9569\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2529 - accuracy: 0.9031 - auc: 0.9614 - val_loss: 0.2673 - val_accuracy: 0.9122 - val_auc: 0.9564\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2376 - accuracy: 0.9009 - auc: 0.9663 - val_loss: 0.2694 - val_accuracy: 0.9180 - val_auc: 0.9562\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2376 - accuracy: 0.9065 - auc: 0.9659 - val_loss: 0.2686 - val_accuracy: 0.9154 - val_auc: 0.9560\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2298 - accuracy: 0.9048 - auc: 0.9682 - val_loss: 0.2701 - val_accuracy: 0.9197 - val_auc: 0.9568\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2402 - accuracy: 0.9082 - auc: 0.9649 - val_loss: 0.2701 - val_accuracy: 0.9162 - val_auc: 0.9561\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2348 - accuracy: 0.9032 - auc: 0.9663 - val_loss: 0.2726 - val_accuracy: 0.9170 - val_auc: 0.9556\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2315 - accuracy: 0.9063 - auc: 0.9674 - val_loss: 0.2760 - val_accuracy: 0.9184 - val_auc: 0.9546\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2215 - accuracy: 0.9061 - auc: 0.9703 - val_loss: 0.2790 - val_accuracy: 0.9157 - val_auc: 0.9540\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2255 - accuracy: 0.9073 - auc: 0.9688 - val_loss: 0.2813 - val_accuracy: 0.9196 - val_auc: 0.9539\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2283 - accuracy: 0.9078 - auc: 0.9679 - val_loss: 0.2847 - val_accuracy: 0.9187 - val_auc: 0.9522\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2240 - accuracy: 0.9093 - auc: 0.9693 - val_loss: 0.2874 - val_accuracy: 0.9190 - val_auc: 0.9521\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2147 - accuracy: 0.9084 - auc: 0.9717 - val_loss: 0.2907 - val_accuracy: 0.9187 - val_auc: 0.9522\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2162 - accuracy: 0.9109 - auc: 0.9712 - val_loss: 0.2921 - val_accuracy: 0.9218 - val_auc: 0.9525\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2150 - accuracy: 0.9090 - auc: 0.9715 - val_loss: 0.2972 - val_accuracy: 0.9216 - val_auc: 0.9510\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2087 - accuracy: 0.9130 - auc: 0.9730 - val_loss: 0.3005 - val_accuracy: 0.9199 - val_auc: 0.9510\n",
      "Epoch 28/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9099 - auc: 0.9706Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2176 - accuracy: 0.9098 - auc: 0.9706 - val_loss: 0.3048 - val_accuracy: 0.9228 - val_auc: 0.9502\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 19us/sample - loss: 0.6952 - accuracy: 0.8091 - auc: 0.7770 - val_loss: 0.3954 - val_accuracy: 0.8829 - val_auc: 0.9250\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4689 - accuracy: 0.8564 - auc: 0.8908 - val_loss: 0.3483 - val_accuracy: 0.9030 - val_auc: 0.9374\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3860 - accuracy: 0.8862 - auc: 0.9247 - val_loss: 0.3232 - val_accuracy: 0.9105 - val_auc: 0.9425\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3469 - accuracy: 0.8920 - auc: 0.9335 - val_loss: 0.3074 - val_accuracy: 0.9124 - val_auc: 0.9450\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3226 - accuracy: 0.8968 - auc: 0.9443 - val_loss: 0.2952 - val_accuracy: 0.9155 - val_auc: 0.9486\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2996 - accuracy: 0.9060 - auc: 0.9495 - val_loss: 0.2874 - val_accuracy: 0.9196 - val_auc: 0.9506\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2900 - accuracy: 0.9065 - auc: 0.9543 - val_loss: 0.2839 - val_accuracy: 0.9185 - val_auc: 0.9529\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2835 - accuracy: 0.9075 - auc: 0.9564 - val_loss: 0.2813 - val_accuracy: 0.9189 - val_auc: 0.9532\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2840 - accuracy: 0.9082 - auc: 0.9551 - val_loss: 0.2791 - val_accuracy: 0.9211 - val_auc: 0.9544\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2789 - accuracy: 0.9102 - auc: 0.9572 - val_loss: 0.2761 - val_accuracy: 0.9141 - val_auc: 0.9551\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2705 - accuracy: 0.9099 - auc: 0.9590 - val_loss: 0.2784 - val_accuracy: 0.9176 - val_auc: 0.9545\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2615 - accuracy: 0.9125 - auc: 0.9620 - val_loss: 0.2781 - val_accuracy: 0.9194 - val_auc: 0.9546\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2585 - accuracy: 0.9156 - auc: 0.9627 - val_loss: 0.2797 - val_accuracy: 0.9204 - val_auc: 0.9539\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2595 - accuracy: 0.9134 - auc: 0.9614 - val_loss: 0.2772 - val_accuracy: 0.9169 - val_auc: 0.9550\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2559 - accuracy: 0.9137 - auc: 0.9626 - val_loss: 0.2777 - val_accuracy: 0.9193 - val_auc: 0.9549\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2512 - accuracy: 0.9142 - auc: 0.9643 - val_loss: 0.2748 - val_accuracy: 0.9179 - val_auc: 0.9560\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2402 - accuracy: 0.9161 - auc: 0.9669 - val_loss: 0.2758 - val_accuracy: 0.9199 - val_auc: 0.9558\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2368 - accuracy: 0.9146 - auc: 0.9674 - val_loss: 0.2795 - val_accuracy: 0.9231 - val_auc: 0.9550\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2385 - accuracy: 0.9169 - auc: 0.9672 - val_loss: 0.2806 - val_accuracy: 0.9223 - val_auc: 0.9553\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2313 - accuracy: 0.9207 - auc: 0.9696 - val_loss: 0.2837 - val_accuracy: 0.9224 - val_auc: 0.9549\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2358 - accuracy: 0.9190 - auc: 0.9683 - val_loss: 0.2897 - val_accuracy: 0.9241 - val_auc: 0.9540\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2356 - accuracy: 0.9167 - auc: 0.9680 - val_loss: 0.2909 - val_accuracy: 0.9233 - val_auc: 0.9532\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2305 - accuracy: 0.9160 - auc: 0.9691 - val_loss: 0.2948 - val_accuracy: 0.9263 - val_auc: 0.9531\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2354 - accuracy: 0.9187 - auc: 0.9685 - val_loss: 0.2963 - val_accuracy: 0.9235 - val_auc: 0.9523\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2295 - accuracy: 0.9168 - auc: 0.9692 - val_loss: 0.3001 - val_accuracy: 0.9238 - val_auc: 0.9522\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2241 - accuracy: 0.9193 - auc: 0.9707 - val_loss: 0.3022 - val_accuracy: 0.9245 - val_auc: 0.9514\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2294 - accuracy: 0.9189 - auc: 0.9691 - val_loss: 0.3053 - val_accuracy: 0.9229 - val_auc: 0.9513\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2263 - accuracy: 0.9189 - auc: 0.9697 - val_loss: 0.3140 - val_accuracy: 0.9245 - val_auc: 0.9497\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2226 - accuracy: 0.9181 - auc: 0.9707 - val_loss: 0.3200 - val_accuracy: 0.9249 - val_auc: 0.9481\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2153 - accuracy: 0.9189 - auc: 0.9721 - val_loss: 0.3244 - val_accuracy: 0.9252 - val_auc: 0.9481\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2219 - accuracy: 0.9208 - auc: 0.9711 - val_loss: 0.3319 - val_accuracy: 0.9269 - val_auc: 0.9473\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2154 - accuracy: 0.9214 - auc: 0.9722 - val_loss: 0.3313 - val_accuracy: 0.9257 - val_auc: 0.9479\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2178 - accuracy: 0.9204 - auc: 0.9715 - val_loss: 0.3300 - val_accuracy: 0.9261 - val_auc: 0.9478\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2166 - accuracy: 0.9205 - auc: 0.9718 - val_loss: 0.3396 - val_accuracy: 0.9278 - val_auc: 0.9469\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2092 - accuracy: 0.9231 - auc: 0.9734 - val_loss: 0.3415 - val_accuracy: 0.9260 - val_auc: 0.9466\n",
      "Epoch 36/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.9209 - auc: 0.9726 ETA: 1s -Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2099 - accuracy: 0.9209 - auc: 0.9727 - val_loss: 0.3459 - val_accuracy: 0.9263 - val_auc: 0.9463\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6440 - accuracy: 0.8713 - auc: 0.8063 - val_loss: 0.3937 - val_accuracy: 0.9047 - val_auc: 0.9254\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5567 - accuracy: 0.8968 - auc: 0.8373 - val_loss: 0.4459 - val_accuracy: 0.8139 - val_auc: 0.9037\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5297 - accuracy: 0.8988 - auc: 0.8444 - val_loss: 0.3727 - val_accuracy: 0.8174 - val_auc: 0.9370\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4453 - accuracy: 0.8953 - auc: 0.8769 - val_loss: 0.2931 - val_accuracy: 0.8757 - val_auc: 0.9543\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4382 - accuracy: 0.9014 - auc: 0.8840 - val_loss: 0.3049 - val_accuracy: 0.8764 - val_auc: 0.9508\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4396 - accuracy: 0.9140 - auc: 0.8728 - val_loss: 0.3103 - val_accuracy: 0.9073 - val_auc: 0.9460\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4147 - accuracy: 0.9060 - auc: 0.8862 - val_loss: 0.3102 - val_accuracy: 0.8823 - val_auc: 0.9495\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3849 - accuracy: 0.9128 - auc: 0.9050 - val_loss: 0.3218 - val_accuracy: 0.8903 - val_auc: 0.9438\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3816 - accuracy: 0.9113 - auc: 0.9003 - val_loss: 0.2986 - val_accuracy: 0.9049 - val_auc: 0.9501\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3906 - accuracy: 0.9197 - auc: 0.9135 - val_loss: 0.3320 - val_accuracy: 0.9269 - val_auc: 0.9468\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4133 - accuracy: 0.9147 - auc: 0.8995 - val_loss: 0.4226 - val_accuracy: 0.8858 - val_auc: 0.9483\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3943 - accuracy: 0.9176 - auc: 0.9012 - val_loss: 0.3114 - val_accuracy: 0.9061 - val_auc: 0.9495\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4332 - accuracy: 0.9070 - auc: 0.8961 - val_loss: 0.3358 - val_accuracy: 0.8957 - val_auc: 0.9528\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4067 - accuracy: 0.9288 - auc: 0.9013 - val_loss: 0.3638 - val_accuracy: 0.8851 - val_auc: 0.9439\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3995 - accuracy: 0.9289 - auc: 0.8991 - val_loss: 0.3181 - val_accuracy: 0.8758 - val_auc: 0.9518\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4155 - accuracy: 0.9178 - auc: 0.9069 - val_loss: 0.3917 - val_accuracy: 0.9104 - val_auc: 0.9462\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5428 - accuracy: 0.8469 - auc: 0.8772 - val_loss: 0.5538 - val_accuracy: 0.6875 - val_auc: 0.9141\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4956 - accuracy: 0.4732 - auc: 0.8137 - val_loss: 0.3965 - val_accuracy: 0.7052 - val_auc: 0.9329\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4376 - accuracy: 0.7050 - auc: 0.8517 - val_loss: 0.3652 - val_accuracy: 0.8953 - val_auc: 0.9495\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4555 - accuracy: 0.7657 - auc: 0.8652 - val_loss: 0.3888 - val_accuracy: 0.6884 - val_auc: 0.9340\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4332 - accuracy: 0.5987 - auc: 0.8327 - val_loss: 0.4073 - val_accuracy: 0.7146 - val_auc: 0.9386\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4209 - accuracy: 0.5046 - auc: 0.8454 - val_loss: 0.4227 - val_accuracy: 0.7307 - val_auc: 0.9397\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4224 - accuracy: 0.5167 - auc: 0.8501 - val_loss: 0.3618 - val_accuracy: 0.7346 - val_auc: 0.9376\n",
      "Epoch 24/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.4293 - accuracy: 0.5109 - auc: 0.8466Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4286 - accuracy: 0.5108 - auc: 0.8472 - val_loss: 0.3820 - val_accuracy: 0.7333 - val_auc: 0.9451\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6425 - accuracy: 0.6632 - auc: 0.7894 - val_loss: 0.4345 - val_accuracy: 0.9339 - val_auc: 0.9123\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5166 - accuracy: 0.7328 - auc: 0.8540 - val_loss: 0.3581 - val_accuracy: 0.8559 - val_auc: 0.9350\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5140 - accuracy: 0.8335 - auc: 0.8599 - val_loss: 0.3595 - val_accuracy: 0.8894 - val_auc: 0.9395\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4743 - accuracy: 0.8856 - auc: 0.8674 - val_loss: 0.3437 - val_accuracy: 0.7604 - val_auc: 0.9416\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4680 - accuracy: 0.7850 - auc: 0.8799 - val_loss: 0.3749 - val_accuracy: 0.7413 - val_auc: 0.9383\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4206 - accuracy: 0.7629 - auc: 0.8843 - val_loss: 0.3486 - val_accuracy: 0.8692 - val_auc: 0.9442\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4271 - accuracy: 0.6905 - auc: 0.8832 - val_loss: 0.4140 - val_accuracy: 0.9288 - val_auc: 0.9389\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4075 - accuracy: 0.7633 - auc: 0.8944 - val_loss: 0.3451 - val_accuracy: 0.9012 - val_auc: 0.9414\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3763 - accuracy: 0.8747 - auc: 0.9026 - val_loss: 0.4482 - val_accuracy: 0.7747 - val_auc: 0.9420\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4122 - accuracy: 0.8190 - auc: 0.8995 - val_loss: 0.4232 - val_accuracy: 0.7492 - val_auc: 0.9450\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3788 - accuracy: 0.7704 - auc: 0.8995 - val_loss: 0.4504 - val_accuracy: 0.7525 - val_auc: 0.9436\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3585 - accuracy: 0.8703 - auc: 0.9163 - val_loss: 0.4082 - val_accuracy: 0.8860 - val_auc: 0.9433\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4252 - accuracy: 0.6820 - auc: 0.8924 - val_loss: 0.4807 - val_accuracy: 0.7422 - val_auc: 0.9096\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3883 - accuracy: 0.6045 - auc: 0.8864 - val_loss: 0.4283 - val_accuracy: 0.7638 - val_auc: 0.9410\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3977 - accuracy: 0.6144 - auc: 0.8865 - val_loss: 0.4691 - val_accuracy: 0.7785 - val_auc: 0.9418\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3942 - accuracy: 0.6172 - auc: 0.8881 - val_loss: 0.4606 - val_accuracy: 0.7770 - val_auc: 0.9394\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3585 - accuracy: 0.6191 - auc: 0.8949 - val_loss: 0.4829 - val_accuracy: 0.7758 - val_auc: 0.9394\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3619 - accuracy: 0.6251 - auc: 0.8927 - val_loss: 0.5263 - val_accuracy: 0.7739 - val_auc: 0.9394\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3640 - accuracy: 0.6294 - auc: 0.8942 - val_loss: 0.4098 - val_accuracy: 0.7681 - val_auc: 0.9450\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3638 - accuracy: 0.6312 - auc: 0.8947 - val_loss: 0.4231 - val_accuracy: 0.7919 - val_auc: 0.9435\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3586 - accuracy: 0.6341 - auc: 0.8977 - val_loss: 0.4326 - val_accuracy: 0.7866 - val_auc: 0.9425\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3621 - accuracy: 0.6327 - auc: 0.8953 - val_loss: 0.5179 - val_accuracy: 0.7953 - val_auc: 0.9410\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3643 - accuracy: 0.6373 - auc: 0.8999 - val_loss: 0.4983 - val_accuracy: 0.7834 - val_auc: 0.9404\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3719 - accuracy: 0.6327 - auc: 0.8943 - val_loss: 0.4023 - val_accuracy: 0.7612 - val_auc: 0.9443\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3701 - accuracy: 0.6261 - auc: 0.8960 - val_loss: 0.3985 - val_accuracy: 0.7804 - val_auc: 0.9431\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3725 - accuracy: 0.6308 - auc: 0.8987 - val_loss: 0.5317 - val_accuracy: 0.7960 - val_auc: 0.9363\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3643 - accuracy: 0.6364 - auc: 0.8982 - val_loss: 0.4126 - val_accuracy: 0.7490 - val_auc: 0.9422\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3673 - accuracy: 0.6800 - auc: 0.8977 - val_loss: 0.4374 - val_accuracy: 0.7555 - val_auc: 0.9454\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4028 - accuracy: 0.6178 - auc: 0.8826 - val_loss: 0.8631 - val_accuracy: 0.7813 - val_auc: 0.9338\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3885 - accuracy: 0.6132 - auc: 0.8855 - val_loss: 0.4216 - val_accuracy: 0.7191 - val_auc: 0.9354\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3794 - accuracy: 0.6127 - auc: 0.8892 - val_loss: 0.6816 - val_accuracy: 0.7678 - val_auc: 0.9311\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3585 - accuracy: 0.6202 - auc: 0.8972 - val_loss: 0.7296 - val_accuracy: 0.7931 - val_auc: 0.9347\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3558 - accuracy: 0.6310 - auc: 0.9023 - val_loss: 0.6259 - val_accuracy: 0.7810 - val_auc: 0.9342\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3961 - accuracy: 0.6193 - auc: 0.8772 - val_loss: 0.6726 - val_accuracy: 0.7554 - val_auc: 0.9319\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3711 - accuracy: 0.6214 - auc: 0.8785 - val_loss: 0.7750 - val_accuracy: 0.7607 - val_auc: 0.9330\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3943 - accuracy: 0.6255 - auc: 0.8699 - val_loss: 0.6204 - val_accuracy: 0.7203 - val_auc: 0.9325\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3807 - accuracy: 0.6260 - auc: 0.8814 - val_loss: 0.7407 - val_accuracy: 0.7617 - val_auc: 0.9401\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3710 - accuracy: 0.6207 - auc: 0.8814 - val_loss: 0.9603 - val_accuracy: 0.7673 - val_auc: 0.9305\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3907 - accuracy: 0.6286 - auc: 0.8739 - val_loss: 0.7052 - val_accuracy: 0.7854 - val_auc: 0.9343\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3803 - accuracy: 0.6255 - auc: 0.8834 - val_loss: 0.6901 - val_accuracy: 0.7808 - val_auc: 0.9369\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3827 - accuracy: 0.6323 - auc: 0.8792 - val_loss: 0.6700 - val_accuracy: 0.7651 - val_auc: 0.9358\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3622 - accuracy: 0.6271 - auc: 0.8808 - val_loss: 0.8543 - val_accuracy: 0.7858 - val_auc: 0.9331\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3636 - accuracy: 0.6352 - auc: 0.8847 - val_loss: 0.6877 - val_accuracy: 0.7835 - val_auc: 0.9362\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3944 - accuracy: 0.6312 - auc: 0.8664 - val_loss: 0.6706 - val_accuracy: 0.7547 - val_auc: 0.9301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3734 - accuracy: 0.6325 - auc: 0.8774 - val_loss: 0.7855 - val_accuracy: 0.7900 - val_auc: 0.9309\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3620 - accuracy: 0.6349 - auc: 0.8807 - val_loss: 0.8936 - val_accuracy: 0.7954 - val_auc: 0.9304\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3581 - accuracy: 0.6377 - auc: 0.8865 - val_loss: 0.9953 - val_accuracy: 0.8036 - val_auc: 0.9308\n",
      "Epoch 48/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3762 - accuracy: 0.6386 - auc: 0.8754Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3762 - accuracy: 0.6387 - auc: 0.8754 - val_loss: 0.8932 - val_accuracy: 0.7950 - val_auc: 0.9298\n",
      "Epoch 00048: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5635 - accuracy: 0.7220 - auc: 0.8108 - val_loss: 0.3834 - val_accuracy: 0.8408 - val_auc: 0.9347\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4938 - accuracy: 0.8120 - auc: 0.8687 - val_loss: 0.3297 - val_accuracy: 0.9533 - val_auc: 0.9512\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4999 - accuracy: 0.8781 - auc: 0.8698 - val_loss: 0.3696 - val_accuracy: 0.9610 - val_auc: 0.9458\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5001 - accuracy: 0.8810 - auc: 0.8680 - val_loss: 0.4236 - val_accuracy: 0.8655 - val_auc: 0.9408\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4329 - accuracy: 0.6193 - auc: 0.8682 - val_loss: 0.4119 - val_accuracy: 0.8753 - val_auc: 0.9441\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5008 - accuracy: 0.7109 - auc: 0.8596 - val_loss: 0.3818 - val_accuracy: 0.8554 - val_auc: 0.9479\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6715 - accuracy: 0.7272 - auc: 0.8265 - val_loss: 0.7883 - val_accuracy: 0.7088 - val_auc: 0.8956\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5082 - accuracy: 0.5524 - auc: 0.8488 - val_loss: 0.3747 - val_accuracy: 0.7054 - val_auc: 0.9291\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7143 - accuracy: 0.7129 - auc: 0.8258 - val_loss: 1.0264 - val_accuracy: 0.6941 - val_auc: 0.8475\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5888 - accuracy: 0.5437 - auc: 0.7699 - val_loss: 0.6497 - val_accuracy: 0.7031 - val_auc: 0.8536\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4541 - accuracy: 0.5633 - auc: 0.8363 - val_loss: 0.5499 - val_accuracy: 0.6986 - val_auc: 0.9291\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4537 - accuracy: 0.5560 - auc: 0.8415 - val_loss: 0.4930 - val_accuracy: 0.7236 - val_auc: 0.9477\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4171 - accuracy: 0.5772 - auc: 0.8640 - val_loss: 0.4026 - val_accuracy: 0.7253 - val_auc: 0.9440\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4114 - accuracy: 0.5792 - auc: 0.8499 - val_loss: 0.4359 - val_accuracy: 0.7247 - val_auc: 0.9373\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3965 - accuracy: 0.5835 - auc: 0.8680 - val_loss: 0.3901 - val_accuracy: 0.7406 - val_auc: 0.9514\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3893 - accuracy: 0.5987 - auc: 0.8582 - val_loss: 0.4180 - val_accuracy: 0.7485 - val_auc: 0.9445\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3899 - accuracy: 0.6028 - auc: 0.8694 - val_loss: 0.4043 - val_accuracy: 0.7548 - val_auc: 0.9479\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3783 - accuracy: 0.6088 - auc: 0.8692 - val_loss: 0.4168 - val_accuracy: 0.7640 - val_auc: 0.9465\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3999 - accuracy: 0.6110 - auc: 0.8672 - val_loss: 0.4465 - val_accuracy: 0.7284 - val_auc: 0.9429\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3881 - accuracy: 0.6058 - auc: 0.8690 - val_loss: 0.4628 - val_accuracy: 0.7495 - val_auc: 0.9441\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4034 - accuracy: 0.6086 - auc: 0.8692 - val_loss: 0.4170 - val_accuracy: 0.7594 - val_auc: 0.9397\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3742 - accuracy: 0.6217 - auc: 0.8763 - val_loss: 0.4546 - val_accuracy: 0.7828 - val_auc: 0.9416\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3894 - accuracy: 0.6234 - auc: 0.8647 - val_loss: 0.4196 - val_accuracy: 0.7651 - val_auc: 0.9466\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3666 - accuracy: 0.6259 - auc: 0.8818 - val_loss: 0.4780 - val_accuracy: 0.7695 - val_auc: 0.9381\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3737 - accuracy: 0.6336 - auc: 0.8791 - val_loss: 0.4288 - val_accuracy: 0.7664 - val_auc: 0.9452\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3632 - accuracy: 0.6330 - auc: 0.8866 - val_loss: 0.4150 - val_accuracy: 0.7867 - val_auc: 0.9484\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3798 - accuracy: 0.6312 - auc: 0.8754 - val_loss: 0.4491 - val_accuracy: 0.7911 - val_auc: 0.9333\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3965 - accuracy: 0.6308 - auc: 0.8626 - val_loss: 0.4540 - val_accuracy: 0.7813 - val_auc: 0.9345\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3778 - accuracy: 0.6329 - auc: 0.8802 - val_loss: 0.4368 - val_accuracy: 0.7669 - val_auc: 0.9453\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3831 - accuracy: 0.6287 - auc: 0.8773 - val_loss: 0.4792 - val_accuracy: 0.7804 - val_auc: 0.9368\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3847 - accuracy: 0.6246 - auc: 0.8675 - val_loss: 0.5266 - val_accuracy: 0.7611 - val_auc: 0.9442\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3842 - accuracy: 0.6227 - auc: 0.8695 - val_loss: 0.5655 - val_accuracy: 0.7651 - val_auc: 0.9254\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3654 - accuracy: 0.6310 - auc: 0.8777 - val_loss: 0.6589 - val_accuracy: 0.7877 - val_auc: 0.9410\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3963 - accuracy: 0.6290 - auc: 0.8684 - val_loss: 0.4907 - val_accuracy: 0.7778 - val_auc: 0.9432\n",
      "Epoch 35/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3793 - accuracy: 0.6257 - auc: 0.8706Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3795 - accuracy: 0.6255 - auc: 0.8714 - val_loss: 0.5971 - val_accuracy: 0.7760 - val_auc: 0.9331\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.5639 - accuracy: 0.7136 - auc: 0.8230 - val_loss: 0.3111 - val_accuracy: 0.9107 - val_auc: 0.9448\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4819 - accuracy: 0.8982 - auc: 0.8601 - val_loss: 0.3440 - val_accuracy: 0.8709 - val_auc: 0.9436\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4619 - accuracy: 0.9010 - auc: 0.8915 - val_loss: 0.3151 - val_accuracy: 0.9014 - val_auc: 0.9531\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5393 - accuracy: 0.8877 - auc: 0.8561 - val_loss: 0.3841 - val_accuracy: 0.9605 - val_auc: 0.9433\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4713 - accuracy: 0.9148 - auc: 0.8568 - val_loss: 0.3298 - val_accuracy: 0.9067 - val_auc: 0.9545\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4269 - accuracy: 0.9211 - auc: 0.8778 - val_loss: 0.3290 - val_accuracy: 0.8943 - val_auc: 0.9512\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4450 - accuracy: 0.8237 - auc: 0.8714 - val_loss: 0.3937 - val_accuracy: 0.9648 - val_auc: 0.9450\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4297 - accuracy: 0.8718 - auc: 0.8707 - val_loss: 0.3316 - val_accuracy: 0.9059 - val_auc: 0.9492\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4085 - accuracy: 0.9187 - auc: 0.8736 - val_loss: 0.3276 - val_accuracy: 0.8636 - val_auc: 0.9527\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4066 - accuracy: 0.9226 - auc: 0.8867 - val_loss: 0.3347 - val_accuracy: 0.8902 - val_auc: 0.9490\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3777 - accuracy: 0.9307 - auc: 0.8939 - val_loss: 0.3690 - val_accuracy: 0.9042 - val_auc: 0.9527\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3881 - accuracy: 0.9203 - auc: 0.8941 - val_loss: 0.3218 - val_accuracy: 0.8854 - val_auc: 0.9488\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4017 - accuracy: 0.9201 - auc: 0.8821 - val_loss: 0.3485 - val_accuracy: 0.8851 - val_auc: 0.9515\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5225 - accuracy: 0.8513 - auc: 0.8706 - val_loss: 0.4639 - val_accuracy: 0.9548 - val_auc: 0.9254\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4593 - accuracy: 0.5410 - auc: 0.8280 - val_loss: 0.7299 - val_accuracy: 0.6994 - val_auc: 0.9321\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4452 - accuracy: 0.5152 - auc: 0.8281 - val_loss: 0.5941 - val_accuracy: 0.7075 - val_auc: 0.9366\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4356 - accuracy: 0.4952 - auc: 0.8341 - val_loss: 0.4615 - val_accuracy: 0.7067 - val_auc: 0.9368\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4183 - accuracy: 0.6361 - auc: 0.8618 - val_loss: 0.4231 - val_accuracy: 0.7125 - val_auc: 0.9364\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4041 - accuracy: 0.6966 - auc: 0.8656 - val_loss: 0.4486 - val_accuracy: 0.7325 - val_auc: 0.9404\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4164 - accuracy: 0.8082 - auc: 0.8684 - val_loss: 0.5873 - val_accuracy: 0.9105 - val_auc: 0.9408\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4872 - accuracy: 0.5417 - auc: 0.8231 - val_loss: 0.6453 - val_accuracy: 0.6632 - val_auc: 0.9094\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4736 - accuracy: 0.5329 - auc: 0.8046 - val_loss: 0.5273 - val_accuracy: 0.7174 - val_auc: 0.9062\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4579 - accuracy: 0.4954 - auc: 0.8084 - val_loss: 0.4662 - val_accuracy: 0.7220 - val_auc: 0.9123\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4663 - accuracy: 0.4994 - auc: 0.8059 - val_loss: 0.4649 - val_accuracy: 0.7179 - val_auc: 0.9073\n",
      "Epoch 25/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.4575 - accuracy: 0.5037 - auc: 0.8077Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4581 - accuracy: 0.5036 - auc: 0.8071 - val_loss: 0.4776 - val_accuracy: 0.7143 - val_auc: 0.9115\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 0.6727 - accuracy: 0.7894 - auc: 0.7332 - val_loss: 0.4953 - val_accuracy: 0.9309 - val_auc: 0.9200\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5293 - accuracy: 0.8730 - auc: 0.8448 - val_loss: 0.3789 - val_accuracy: 0.8793 - val_auc: 0.9262\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6594 - accuracy: 0.8363 - auc: 0.8191 - val_loss: 0.4062 - val_accuracy: 0.9196 - val_auc: 0.9284\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4847 - accuracy: 0.9120 - auc: 0.8609 - val_loss: 0.3869 - val_accuracy: 0.9214 - val_auc: 0.9411\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4560 - accuracy: 0.9131 - auc: 0.8706 - val_loss: 0.3745 - val_accuracy: 0.8734 - val_auc: 0.9408\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4258 - accuracy: 0.9132 - auc: 0.8864 - val_loss: 0.3445 - val_accuracy: 0.9377 - val_auc: 0.9426\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4208 - accuracy: 0.9123 - auc: 0.8861 - val_loss: 0.3110 - val_accuracy: 0.9128 - val_auc: 0.9473\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3891 - accuracy: 0.9134 - auc: 0.8866 - val_loss: 0.3225 - val_accuracy: 0.8770 - val_auc: 0.9497\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4067 - accuracy: 0.9173 - auc: 0.8948 - val_loss: 0.3265 - val_accuracy: 0.9014 - val_auc: 0.9446\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3918 - accuracy: 0.9155 - auc: 0.8915 - val_loss: 0.3609 - val_accuracy: 0.9045 - val_auc: 0.9387\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3886 - accuracy: 0.9213 - auc: 0.8984 - val_loss: 0.3414 - val_accuracy: 0.9035 - val_auc: 0.9442\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4530 - accuracy: 0.8534 - auc: 0.8683 - val_loss: 0.4769 - val_accuracy: 0.7273 - val_auc: 0.8895\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4885 - accuracy: 0.5165 - auc: 0.7991 - val_loss: 0.4450 - val_accuracy: 0.7362 - val_auc: 0.9229\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4500 - accuracy: 0.5214 - auc: 0.8283 - val_loss: 0.5105 - val_accuracy: 0.7598 - val_auc: 0.9258\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4399 - accuracy: 0.5251 - auc: 0.8358 - val_loss: 0.5131 - val_accuracy: 0.7464 - val_auc: 0.9251\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4674 - accuracy: 0.5957 - auc: 0.8482 - val_loss: 0.4706 - val_accuracy: 0.7515 - val_auc: 0.9422\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4221 - accuracy: 0.5846 - auc: 0.8627 - val_loss: 0.3425 - val_accuracy: 0.7280 - val_auc: 0.9464\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4170 - accuracy: 0.6768 - auc: 0.8699 - val_loss: 0.3453 - val_accuracy: 0.7526 - val_auc: 0.9461\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3968 - accuracy: 0.7265 - auc: 0.8820 - val_loss: 0.3740 - val_accuracy: 0.7393 - val_auc: 0.9446\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4137 - accuracy: 0.8905 - auc: 0.8898 - val_loss: 0.4446 - val_accuracy: 0.9105 - val_auc: 0.9404\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4180 - accuracy: 0.8140 - auc: 0.8752 - val_loss: 0.4749 - val_accuracy: 0.7649 - val_auc: 0.9373\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3813 - accuracy: 0.7147 - auc: 0.8894 - val_loss: 0.4479 - val_accuracy: 0.9170 - val_auc: 0.9453\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3945 - accuracy: 0.9217 - auc: 0.8907 - val_loss: 0.5841 - val_accuracy: 0.7506 - val_auc: 0.9431\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3808 - accuracy: 0.8565 - auc: 0.8978 - val_loss: 0.4011 - val_accuracy: 0.9314 - val_auc: 0.9394\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3952 - accuracy: 0.9466 - auc: 0.8940 - val_loss: 0.4417 - val_accuracy: 0.9231 - val_auc: 0.9413\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3918 - accuracy: 0.8267 - auc: 0.8836 - val_loss: 0.4502 - val_accuracy: 0.9172 - val_auc: 0.9446\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3802 - accuracy: 0.8552 - auc: 0.8893 - val_loss: 0.5210 - val_accuracy: 0.7388 - val_auc: 0.9418\n",
      "Epoch 28/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3938 - accuracy: 0.7969 - auc: 0.8869 ETA: 0s - loss: 0.3938 - accuracy: 0.7715 - auc: Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3957 - accuracy: 0.8021 - auc: 0.8856 - val_loss: 0.4951 - val_accuracy: 0.9617 - val_auc: 0.9419\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8559 - accuracy: 0.7759 - auc: 0.7729 - val_loss: 0.7272 - val_accuracy: 0.7420 - val_auc: 0.8571\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7760 - accuracy: 0.8503 - auc: 0.8420 - val_loss: 0.4654 - val_accuracy: 0.8451 - val_auc: 0.9380\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6398 - accuracy: 0.8735 - auc: 0.8609 - val_loss: 0.4482 - val_accuracy: 0.8995 - val_auc: 0.9364\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6337 - accuracy: 0.8697 - auc: 0.8868 - val_loss: 0.5171 - val_accuracy: 0.8252 - val_auc: 0.9288\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5382 - accuracy: 0.8726 - auc: 0.8888 - val_loss: 0.3894 - val_accuracy: 0.9225 - val_auc: 0.9396\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4919 - accuracy: 0.7770 - auc: 0.8972 - val_loss: 0.3977 - val_accuracy: 0.9191 - val_auc: 0.9403\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5167 - accuracy: 0.6857 - auc: 0.8831 - val_loss: 0.3618 - val_accuracy: 0.7628 - val_auc: 0.9506\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4539 - accuracy: 0.6471 - auc: 0.8940 - val_loss: 0.4166 - val_accuracy: 0.7818 - val_auc: 0.9444\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8162 - accuracy: 0.6495 - auc: 0.8869 - val_loss: 0.5737 - val_accuracy: 0.9080 - val_auc: 0.9211\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8103 - accuracy: 0.6426 - auc: 0.8181 - val_loss: 0.6517 - val_accuracy: 0.7096 - val_auc: 0.9146\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4829 - accuracy: 0.6186 - auc: 0.8450 - val_loss: 0.6701 - val_accuracy: 0.7296 - val_auc: 0.8936\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4482 - accuracy: 0.6332 - auc: 0.8679 - val_loss: 0.5941 - val_accuracy: 0.7525 - val_auc: 0.9147\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4308 - accuracy: 0.6538 - auc: 0.8717 - val_loss: 0.4286 - val_accuracy: 0.7544 - val_auc: 0.9401\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4194 - accuracy: 0.6665 - auc: 0.8896 - val_loss: 0.4352 - val_accuracy: 0.7722 - val_auc: 0.9468\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3773 - accuracy: 0.6666 - auc: 0.8900 - val_loss: 0.5261 - val_accuracy: 0.7792 - val_auc: 0.9424\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3870 - accuracy: 0.6782 - auc: 0.8955 - val_loss: 0.4543 - val_accuracy: 0.7677 - val_auc: 0.9441\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3814 - accuracy: 0.6811 - auc: 0.9020 - val_loss: 0.3987 - val_accuracy: 0.7706 - val_auc: 0.9470\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3579 - accuracy: 0.6844 - auc: 0.9079 - val_loss: 0.4187 - val_accuracy: 0.8092 - val_auc: 0.9489\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3473 - accuracy: 0.6988 - auc: 0.9046 - val_loss: 0.4600 - val_accuracy: 0.8094 - val_auc: 0.9481\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3422 - accuracy: 0.7065 - auc: 0.9135 - val_loss: 0.5068 - val_accuracy: 0.8197 - val_auc: 0.9450\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3347 - accuracy: 0.7106 - auc: 0.9153 - val_loss: 0.5415 - val_accuracy: 0.8315 - val_auc: 0.9440\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3464 - accuracy: 0.7169 - auc: 0.9135 - val_loss: 0.4130 - val_accuracy: 0.7996 - val_auc: 0.9488\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3413 - accuracy: 0.7139 - auc: 0.9125 - val_loss: 0.4516 - val_accuracy: 0.8041 - val_auc: 0.9460\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3482 - accuracy: 0.7112 - auc: 0.9153 - val_loss: 0.4589 - val_accuracy: 0.8158 - val_auc: 0.9438\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3453 - accuracy: 0.7135 - auc: 0.9168 - val_loss: 0.4942 - val_accuracy: 0.8159 - val_auc: 0.9457\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3306 - accuracy: 0.7233 - auc: 0.9126 - val_loss: 0.5597 - val_accuracy: 0.8315 - val_auc: 0.9469\n",
      "Epoch 27/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.7243 - auc: 0.9182Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3319 - accuracy: 0.7242 - auc: 0.9184 - val_loss: 0.4859 - val_accuracy: 0.8147 - val_auc: 0.9460\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5712 - accuracy: 0.8290 - auc: 0.8426 - val_loss: 0.4053 - val_accuracy: 0.9267 - val_auc: 0.9288\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5916 - accuracy: 0.8770 - auc: 0.8669 - val_loss: 0.4452 - val_accuracy: 0.8558 - val_auc: 0.9373\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5682 - accuracy: 0.8818 - auc: 0.8731 - val_loss: 0.3317 - val_accuracy: 0.9153 - val_auc: 0.9414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4874 - accuracy: 0.8789 - auc: 0.8885 - val_loss: 0.4116 - val_accuracy: 0.9189 - val_auc: 0.9364\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4864 - accuracy: 0.8981 - auc: 0.8942 - val_loss: 0.4898 - val_accuracy: 0.9098 - val_auc: 0.9386\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4958 - accuracy: 0.9124 - auc: 0.8975 - val_loss: 0.4505 - val_accuracy: 0.8975 - val_auc: 0.9427\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4363 - accuracy: 0.8990 - auc: 0.8942 - val_loss: 0.4537 - val_accuracy: 0.8541 - val_auc: 0.9374\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4603 - accuracy: 0.9178 - auc: 0.8873 - val_loss: 0.6139 - val_accuracy: 0.8770 - val_auc: 0.9407\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5529 - accuracy: 0.8442 - auc: 0.8807 - val_loss: 0.9484 - val_accuracy: 0.6880 - val_auc: 0.9393\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5300 - accuracy: 0.8428 - auc: 0.8805 - val_loss: 1.3620 - val_accuracy: 0.9095 - val_auc: 0.9321\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9747 - accuracy: 0.8010 - auc: 0.8703 - val_loss: 1.0867 - val_accuracy: 0.9219 - val_auc: 0.9304\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4656 - accuracy: 0.7215 - auc: 0.8761 - val_loss: 0.9253 - val_accuracy: 0.6983 - val_auc: 0.9335\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4002 - accuracy: 0.8227 - auc: 0.8946 - val_loss: 0.7606 - val_accuracy: 0.8950 - val_auc: 0.9384\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4139 - accuracy: 0.8382 - auc: 0.8967 - val_loss: 0.6312 - val_accuracy: 0.9093 - val_auc: 0.9310\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3727 - accuracy: 0.9273 - auc: 0.9153 - val_loss: 0.5705 - val_accuracy: 0.9259 - val_auc: 0.9362\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3910 - accuracy: 0.8411 - auc: 0.8979 - val_loss: 0.5671 - val_accuracy: 0.8889 - val_auc: 0.9384\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3784 - accuracy: 0.6101 - auc: 0.8934 - val_loss: 0.6133 - val_accuracy: 0.8874 - val_auc: 0.9353\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4148 - accuracy: 0.8016 - auc: 0.8981 - val_loss: 0.7440 - val_accuracy: 0.9394 - val_auc: 0.9257\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4367 - accuracy: 0.6207 - auc: 0.8862 - val_loss: 1.0194 - val_accuracy: 0.7437 - val_auc: 0.9324\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3907 - accuracy: 0.6855 - auc: 0.9001 - val_loss: 0.9351 - val_accuracy: 0.7256 - val_auc: 0.9355\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3835 - accuracy: 0.6034 - auc: 0.8963 - val_loss: 0.7458 - val_accuracy: 0.9146 - val_auc: 0.9382\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3797 - accuracy: 0.7152 - auc: 0.9017 - val_loss: 0.6865 - val_accuracy: 0.7367 - val_auc: 0.9406\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4036 - accuracy: 0.7176 - auc: 0.8941 - val_loss: 0.8314 - val_accuracy: 0.7258 - val_auc: 0.9355\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3845 - accuracy: 0.6133 - auc: 0.8806 - val_loss: 0.9588 - val_accuracy: 0.7315 - val_auc: 0.9336\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3787 - accuracy: 0.6525 - auc: 0.8901 - val_loss: 0.9271 - val_accuracy: 0.7541 - val_auc: 0.9390\n",
      "Epoch 26/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3965 - accuracy: 0.6217 - auc: 0.8879Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3963 - accuracy: 0.6217 - auc: 0.8885 - val_loss: 1.0298 - val_accuracy: 0.7465 - val_auc: 0.9292\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7739 - accuracy: 0.7327 - auc: 0.7794 - val_loss: 0.4016 - val_accuracy: 0.8803 - val_auc: 0.9151\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6245 - accuracy: 0.8784 - auc: 0.8652 - val_loss: 0.3845 - val_accuracy: 0.9160 - val_auc: 0.9247\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6090 - accuracy: 0.8613 - auc: 0.8644 - val_loss: 0.4381 - val_accuracy: 0.8464 - val_auc: 0.9297\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8057 - accuracy: 0.7479 - auc: 0.8425 - val_loss: 0.6751 - val_accuracy: 0.9178 - val_auc: 0.9190\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6426 - accuracy: 0.8070 - auc: 0.8427 - val_loss: 0.8699 - val_accuracy: 0.7325 - val_auc: 0.9176\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9507 - accuracy: 0.5996 - auc: 0.8078 - val_loss: 0.5955 - val_accuracy: 0.7032 - val_auc: 0.9264\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7543 - accuracy: 0.5929 - auc: 0.8595 - val_loss: 0.6164 - val_accuracy: 0.9104 - val_auc: 0.9466\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5625 - accuracy: 0.6677 - auc: 0.8831 - val_loss: 0.6209 - val_accuracy: 0.6894 - val_auc: 0.9445\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6965 - accuracy: 0.5789 - auc: 0.8268 - val_loss: 0.8470 - val_accuracy: 0.7073 - val_auc: 0.8744\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6928 - accuracy: 0.6112 - auc: 0.8195 - val_loss: 0.5914 - val_accuracy: 0.6553 - val_auc: 0.8450\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7969 - accuracy: 0.5883 - auc: 0.8070 - val_loss: 1.3244 - val_accuracy: 0.6713 - val_auc: 0.8965\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8476 - accuracy: 0.6625 - auc: 0.8503 - val_loss: 3.6362 - val_accuracy: 0.6955 - val_auc: 0.9307\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8584 - accuracy: 0.5510 - auc: 0.8394 - val_loss: 3.1646 - val_accuracy: 0.6396 - val_auc: 0.9137\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5592 - accuracy: 0.5380 - auc: 0.8419 - val_loss: 2.8462 - val_accuracy: 0.6575 - val_auc: 0.9312\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7044 - accuracy: 0.5556 - auc: 0.8540 - val_loss: 2.0981 - val_accuracy: 0.6594 - val_auc: 0.6892\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4644 - accuracy: 0.5721 - auc: 0.8540 - val_loss: 1.8813 - val_accuracy: 0.6853 - val_auc: 0.9328\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4228 - accuracy: 0.5848 - auc: 0.8697 - val_loss: 2.0190 - val_accuracy: 0.6934 - val_auc: 0.9361\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4352 - accuracy: 0.5911 - auc: 0.8633 - val_loss: 1.6688 - val_accuracy: 0.7019 - val_auc: 0.9417\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4391 - accuracy: 0.5875 - auc: 0.8604 - val_loss: 1.7717 - val_accuracy: 0.7057 - val_auc: 0.9409\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9533 - accuracy: 0.5841 - auc: 0.8528 - val_loss: 1.2867 - val_accuracy: 0.6811 - val_auc: 0.8851\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4425 - accuracy: 0.6018 - auc: 0.8371 - val_loss: 3.2795 - val_accuracy: 0.7057 - val_auc: 0.9022\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4033 - accuracy: 0.6030 - auc: 0.8536 - val_loss: 3.1807 - val_accuracy: 0.6908 - val_auc: 0.9109\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4181 - accuracy: 0.6023 - auc: 0.8479 - val_loss: 3.2247 - val_accuracy: 0.6992 - val_auc: 0.9195\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4055 - accuracy: 0.6061 - auc: 0.8518 - val_loss: 3.1323 - val_accuracy: 0.7107 - val_auc: 0.9226\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4055 - accuracy: 0.6122 - auc: 0.8628 - val_loss: 3.0251 - val_accuracy: 0.7202 - val_auc: 0.9223\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3873 - accuracy: 0.6218 - auc: 0.8617 - val_loss: 2.9751 - val_accuracy: 0.7252 - val_auc: 0.9241\n",
      "Epoch 27/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.6192 - auc: 0.8641Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3899 - accuracy: 0.6192 - auc: 0.8623 - val_loss: 3.2212 - val_accuracy: 0.7221 - val_auc: 0.9143\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.6558 - accuracy: 0.8555 - auc: 0.8023 - val_loss: 0.4060 - val_accuracy: 0.8575 - val_auc: 0.9185\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5307 - accuracy: 0.8827 - auc: 0.8735 - val_loss: 0.5142 - val_accuracy: 0.8919 - val_auc: 0.9231\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6909 - accuracy: 0.8572 - auc: 0.8690 - val_loss: 0.7107 - val_accuracy: 0.9416 - val_auc: 0.9268\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6256 - accuracy: 0.8927 - auc: 0.8583 - val_loss: 0.4171 - val_accuracy: 0.8934 - val_auc: 0.9351\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8452 - accuracy: 0.8242 - auc: 0.8351 - val_loss: 0.5621 - val_accuracy: 0.6448 - val_auc: 0.8676\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8170 - accuracy: 0.5888 - auc: 0.8023 - val_loss: 0.6289 - val_accuracy: 0.6829 - val_auc: 0.9063\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6635 - accuracy: 0.5705 - auc: 0.8588 - val_loss: 0.7076 - val_accuracy: 0.7143 - val_auc: 0.9321\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5968 - accuracy: 0.6908 - auc: 0.8803 - val_loss: 0.5146 - val_accuracy: 0.8845 - val_auc: 0.9371\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5212 - accuracy: 0.7070 - auc: 0.8566 - val_loss: 1.0192 - val_accuracy: 0.6850 - val_auc: 0.8514\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4804 - accuracy: 0.5897 - auc: 0.8122 - val_loss: 1.1410 - val_accuracy: 0.7013 - val_auc: 0.8604\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6238 - accuracy: 0.5924 - auc: 0.8198 - val_loss: 0.7026 - val_accuracy: 0.6973 - val_auc: 0.8714\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4280 - accuracy: 0.6219 - auc: 0.8356 - val_loss: 0.7489 - val_accuracy: 0.7439 - val_auc: 0.8880\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4993 - accuracy: 0.6207 - auc: 0.8350 - val_loss: 0.6320 - val_accuracy: 0.6983 - val_auc: 0.8774\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4333 - accuracy: 0.6433 - auc: 0.8443 - val_loss: 0.8780 - val_accuracy: 0.7446 - val_auc: 0.8871\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4101 - accuracy: 0.6572 - auc: 0.8464 - val_loss: 0.9501 - val_accuracy: 0.7530 - val_auc: 0.8881\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4043 - accuracy: 0.6550 - auc: 0.8552 - val_loss: 0.8978 - val_accuracy: 0.7700 - val_auc: 0.9001\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3846 - accuracy: 0.6696 - auc: 0.8674 - val_loss: 0.8357 - val_accuracy: 0.7746 - val_auc: 0.9158\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3972 - accuracy: 0.6730 - auc: 0.8749 - val_loss: 0.6236 - val_accuracy: 0.7621 - val_auc: 0.9221\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3713 - accuracy: 0.6789 - auc: 0.8804 - val_loss: 0.6919 - val_accuracy: 0.7926 - val_auc: 0.9202\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3761 - accuracy: 0.6785 - auc: 0.8779 - val_loss: 0.5961 - val_accuracy: 0.7674 - val_auc: 0.9205\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3539 - accuracy: 0.6877 - auc: 0.8867 - val_loss: 0.7000 - val_accuracy: 0.7965 - val_auc: 0.9224\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3719 - accuracy: 0.6853 - auc: 0.8866 - val_loss: 0.5795 - val_accuracy: 0.7736 - val_auc: 0.9215\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3664 - accuracy: 0.6884 - auc: 0.8763 - val_loss: 0.5576 - val_accuracy: 0.7790 - val_auc: 0.9242\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3376 - accuracy: 0.6981 - auc: 0.8907 - val_loss: 0.5810 - val_accuracy: 0.8068 - val_auc: 0.9254\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3386 - accuracy: 0.6998 - auc: 0.8887 - val_loss: 0.7309 - val_accuracy: 0.7948 - val_auc: 0.9213\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3663 - accuracy: 0.6928 - auc: 0.8905 - val_loss: 0.6168 - val_accuracy: 0.7941 - val_auc: 0.9226\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3560 - accuracy: 0.6957 - auc: 0.8933 - val_loss: 0.5831 - val_accuracy: 0.7934 - val_auc: 0.9408\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3344 - accuracy: 0.7039 - auc: 0.9141 - val_loss: 0.6116 - val_accuracy: 0.8154 - val_auc: 0.9422\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3261 - accuracy: 0.7114 - auc: 0.9230 - val_loss: 0.5091 - val_accuracy: 0.8070 - val_auc: 0.9440\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3086 - accuracy: 0.7135 - auc: 0.9292 - val_loss: 0.6598 - val_accuracy: 0.8144 - val_auc: 0.9418\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3316 - accuracy: 0.7083 - auc: 0.9195 - val_loss: 0.7040 - val_accuracy: 0.8077 - val_auc: 0.9369\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3179 - accuracy: 0.7086 - auc: 0.9227 - val_loss: 0.6354 - val_accuracy: 0.8180 - val_auc: 0.9428\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3315 - accuracy: 0.7025 - auc: 0.9218 - val_loss: 0.6736 - val_accuracy: 0.8134 - val_auc: 0.9413\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3107 - accuracy: 0.7052 - auc: 0.9285 - val_loss: 0.6382 - val_accuracy: 0.8051 - val_auc: 0.9435\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3415 - accuracy: 0.6995 - auc: 0.9232 - val_loss: 0.8781 - val_accuracy: 0.8162 - val_auc: 0.9059\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3709 - accuracy: 0.6991 - auc: 0.9014 - val_loss: 1.3455 - val_accuracy: 0.8045 - val_auc: 0.9337\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3551 - accuracy: 0.6907 - auc: 0.8935 - val_loss: 1.2098 - val_accuracy: 0.8049 - val_auc: 0.9334\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3470 - accuracy: 0.6955 - auc: 0.9004 - val_loss: 1.1490 - val_accuracy: 0.8082 - val_auc: 0.9343\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4421 - accuracy: 0.6812 - auc: 0.8847 - val_loss: 1.3540 - val_accuracy: 0.7913 - val_auc: 0.9300\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3931 - accuracy: 0.6712 - auc: 0.8818 - val_loss: 1.1163 - val_accuracy: 0.7952 - val_auc: 0.9338\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3518 - accuracy: 0.6798 - auc: 0.8935 - val_loss: 1.2492 - val_accuracy: 0.7917 - val_auc: 0.9389\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3999 - accuracy: 0.6801 - auc: 0.8865 - val_loss: 1.4051 - val_accuracy: 0.8102 - val_auc: 0.9298\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3925 - accuracy: 0.6813 - auc: 0.8885 - val_loss: 1.3316 - val_accuracy: 0.7867 - val_auc: 0.9339\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3430 - accuracy: 0.6802 - auc: 0.8932 - val_loss: 1.1862 - val_accuracy: 0.7991 - val_auc: 0.9328\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3349 - accuracy: 0.6909 - auc: 0.8914 - val_loss: 1.2805 - val_accuracy: 0.8109 - val_auc: 0.9304\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3467 - accuracy: 0.6888 - auc: 0.8916 - val_loss: 1.2907 - val_accuracy: 0.8075 - val_auc: 0.9308\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3370 - accuracy: 0.6918 - auc: 0.8990 - val_loss: 1.2441 - val_accuracy: 0.7994 - val_auc: 0.9282\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3417 - accuracy: 0.6914 - auc: 0.8947 - val_loss: 1.2097 - val_accuracy: 0.7926 - val_auc: 0.9150\n",
      "Epoch 49/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3483 - accuracy: 0.6861 - auc: 0.8908Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3469 - accuracy: 0.6861 - auc: 0.8910 - val_loss: 1.1928 - val_accuracy: 0.7988 - val_auc: 0.9301\n",
      "Epoch 00049: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 7s 27us/sample - loss: 0.8170 - accuracy: 0.7902 - auc: 0.7990 - val_loss: 0.4109 - val_accuracy: 0.9025 - val_auc: 0.9400\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6115 - accuracy: 0.8809 - auc: 0.8729 - val_loss: 0.4226 - val_accuracy: 0.8812 - val_auc: 0.9343\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7263 - accuracy: 0.8545 - auc: 0.8721 - val_loss: 0.4655 - val_accuracy: 0.9418 - val_auc: 0.9441\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6587 - accuracy: 0.8904 - auc: 0.8905 - val_loss: 0.4431 - val_accuracy: 0.8911 - val_auc: 0.9309\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5596 - accuracy: 0.8920 - auc: 0.9055 - val_loss: 0.4867 - val_accuracy: 0.8633 - val_auc: 0.9325\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4741 - accuracy: 0.9004 - auc: 0.9055 - val_loss: 0.5942 - val_accuracy: 0.8922 - val_auc: 0.9311\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4901 - accuracy: 0.8967 - auc: 0.9068 - val_loss: 0.3749 - val_accuracy: 0.9191 - val_auc: 0.9454\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3888 - accuracy: 0.8529 - auc: 0.9089 - val_loss: 0.5200 - val_accuracy: 0.9176 - val_auc: 0.9495\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5887 - accuracy: 0.8361 - auc: 0.8917 - val_loss: 0.5062 - val_accuracy: 0.7509 - val_auc: 0.9449\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4526 - accuracy: 0.6124 - auc: 0.8824 - val_loss: 0.4636 - val_accuracy: 0.7582 - val_auc: 0.9446\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4111 - accuracy: 0.6282 - auc: 0.8867 - val_loss: 0.5329 - val_accuracy: 0.7768 - val_auc: 0.8793\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3913 - accuracy: 0.6479 - auc: 0.8946 - val_loss: 0.4588 - val_accuracy: 0.7794 - val_auc: 0.9478\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3904 - accuracy: 0.6435 - auc: 0.8924 - val_loss: 0.4874 - val_accuracy: 0.8118 - val_auc: 0.9490\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4175 - accuracy: 0.6580 - auc: 0.8954 - val_loss: 0.4156 - val_accuracy: 0.7761 - val_auc: 0.9447\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4314 - accuracy: 0.6525 - auc: 0.8586 - val_loss: 0.5178 - val_accuracy: 0.7874 - val_auc: 0.9148\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4573 - accuracy: 0.6532 - auc: 0.8575 - val_loss: 0.5966 - val_accuracy: 0.7902 - val_auc: 0.9112\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4796 - accuracy: 0.6466 - auc: 0.8415 - val_loss: 0.5497 - val_accuracy: 0.7857 - val_auc: 0.9163\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4015 - accuracy: 0.6573 - auc: 0.8588 - val_loss: 0.7733 - val_accuracy: 0.7675 - val_auc: 0.9125\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3984 - accuracy: 0.6574 - auc: 0.8698 - val_loss: 0.7776 - val_accuracy: 0.7730 - val_auc: 0.9163\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4116 - accuracy: 0.6538 - auc: 0.8677 - val_loss: 0.7789 - val_accuracy: 0.7460 - val_auc: 0.9197\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4153 - accuracy: 0.6490 - auc: 0.8706 - val_loss: 0.6812 - val_accuracy: 0.7926 - val_auc: 0.9168\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4019 - accuracy: 0.6548 - auc: 0.8725 - val_loss: 0.5978 - val_accuracy: 0.7921 - val_auc: 0.9446\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3713 - accuracy: 0.6528 - auc: 0.8944 - val_loss: 0.7141 - val_accuracy: 0.7730 - val_auc: 0.9426\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3572 - accuracy: 0.6589 - auc: 0.9002 - val_loss: 0.6470 - val_accuracy: 0.7914 - val_auc: 0.9433\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3501 - accuracy: 0.6643 - auc: 0.9107 - val_loss: 0.6734 - val_accuracy: 0.8047 - val_auc: 0.9436\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3536 - accuracy: 0.6856 - auc: 0.9129 - val_loss: 0.6173 - val_accuracy: 0.7827 - val_auc: 0.9430\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3578 - accuracy: 0.6686 - auc: 0.9089 - val_loss: 0.7889 - val_accuracy: 0.8007 - val_auc: 0.9413\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3578 - accuracy: 0.6700 - auc: 0.9109Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3579 - accuracy: 0.6698 - auc: 0.9111 - val_loss: 0.5729 - val_accuracy: 0.7871 - val_auc: 0.9435\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.7860 - accuracy: 0.7260 - auc: 0.8311 - val_loss: 0.7057 - val_accuracy: 0.8446 - val_auc: 0.9212\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0743 - accuracy: 0.8019 - auc: 0.8425 - val_loss: 0.9225 - val_accuracy: 0.8513 - val_auc: 0.9330\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9868 - accuracy: 0.8322 - auc: 0.8643 - val_loss: 0.7360 - val_accuracy: 0.9093 - val_auc: 0.9283\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1032 - accuracy: 0.7921 - auc: 0.8594 - val_loss: 0.7980 - val_accuracy: 0.9157 - val_auc: 0.9214\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5642 - accuracy: 0.7471 - auc: 0.8393 - val_loss: 2.1981 - val_accuracy: 0.8999 - val_auc: 0.8883\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2359 - accuracy: 0.6312 - auc: 0.8291 - val_loss: 1.8382 - val_accuracy: 0.7557 - val_auc: 0.9055\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8270 - accuracy: 0.6292 - auc: 0.8431 - val_loss: 0.9124 - val_accuracy: 0.7577 - val_auc: 0.9128\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7957 - accuracy: 0.6619 - auc: 0.8563 - val_loss: 1.0473 - val_accuracy: 0.6638 - val_auc: 0.8539\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9038 - accuracy: 0.6606 - auc: 0.8469 - val_loss: 2.0392 - val_accuracy: 0.7367 - val_auc: 0.8706\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0637 - accuracy: 0.6216 - auc: 0.8411 - val_loss: 2.1263 - val_accuracy: 0.7664 - val_auc: 0.9248\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6701 - accuracy: 0.6649 - auc: 0.8899 - val_loss: 1.3537 - val_accuracy: 0.7201 - val_auc: 0.9184\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8501 - accuracy: 0.6418 - auc: 0.8644 - val_loss: 2.8133 - val_accuracy: 0.7232 - val_auc: 0.9154\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2561 - accuracy: 0.6324 - auc: 0.8573 - val_loss: 1.3780 - val_accuracy: 0.6824 - val_auc: 0.8847\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3383 - accuracy: 0.6181 - auc: 0.8368 - val_loss: 4.3614 - val_accuracy: 0.7244 - val_auc: 0.8910\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3706 - accuracy: 0.5985 - auc: 0.8248 - val_loss: 1.4300 - val_accuracy: 0.6712 - val_auc: 0.8378\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6313 - accuracy: 0.5995 - auc: 0.8162 - val_loss: 1.6106 - val_accuracy: 0.6702 - val_auc: 0.8626\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5122 - accuracy: 0.6171 - auc: 0.8320 - val_loss: 1.7657 - val_accuracy: 0.6926 - val_auc: 0.8735\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5409 - accuracy: 0.6285 - auc: 0.8368 - val_loss: 1.2905 - val_accuracy: 0.6974 - val_auc: 0.8830\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4930 - accuracy: 0.6290 - auc: 0.8320 - val_loss: 1.4987 - val_accuracy: 0.7197 - val_auc: 0.8634\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4740 - accuracy: 0.6181 - auc: 0.8062 - val_loss: 3.3107 - val_accuracy: 0.7198 - val_auc: 0.8603\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6750 - accuracy: 0.6315 - auc: 0.8241 - val_loss: 3.9947 - val_accuracy: 0.7062 - val_auc: 0.8579\n",
      "Epoch 22/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 1.9695 - accuracy: 0.6232 - auc: 0.8231Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.9669 - accuracy: 0.6231 - auc: 0.8231 - val_loss: 2.7302 - val_accuracy: 0.6860 - val_auc: 0.8544\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.8129 - accuracy: 0.7404 - auc: 0.8353 - val_loss: 0.4219 - val_accuracy: 0.8992 - val_auc: 0.9133\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2378 - accuracy: 0.8052 - auc: 0.8501 - val_loss: 0.8311 - val_accuracy: 0.8092 - val_auc: 0.9168\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2367 - accuracy: 0.8064 - auc: 0.8396 - val_loss: 0.9193 - val_accuracy: 0.9301 - val_auc: 0.9042\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0069 - accuracy: 0.8465 - auc: 0.8608 - val_loss: 0.7837 - val_accuracy: 0.8761 - val_auc: 0.9296\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0823 - accuracy: 0.8539 - auc: 0.8480 - val_loss: 0.8106 - val_accuracy: 0.8972 - val_auc: 0.9055\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7700 - accuracy: 0.8864 - auc: 0.8750 - val_loss: 0.9216 - val_accuracy: 0.9231 - val_auc: 0.9434\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7526 - accuracy: 0.8949 - auc: 0.8849 - val_loss: 0.9645 - val_accuracy: 0.9371 - val_auc: 0.9299\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6944 - accuracy: 0.7163 - auc: 0.8692 - val_loss: 1.2011 - val_accuracy: 0.7044 - val_auc: 0.9339\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5860 - accuracy: 0.5957 - auc: 0.8572 - val_loss: 1.1418 - val_accuracy: 0.6930 - val_auc: 0.9014\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5068 - accuracy: 0.6583 - auc: 0.8850 - val_loss: 0.8267 - val_accuracy: 0.7070 - val_auc: 0.9358\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5659 - accuracy: 0.7071 - auc: 0.8852 - val_loss: 1.3665 - val_accuracy: 0.7268 - val_auc: 0.9349\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4590 - accuracy: 0.6828 - auc: 0.8956 - val_loss: 1.1571 - val_accuracy: 0.7096 - val_auc: 0.9409\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3949 - accuracy: 0.8269 - auc: 0.9121 - val_loss: 1.1179 - val_accuracy: 0.9045 - val_auc: 0.9431\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4241 - accuracy: 0.6728 - auc: 0.9025 - val_loss: 1.0276 - val_accuracy: 0.7140 - val_auc: 0.9273\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3997 - accuracy: 0.6909 - auc: 0.8999 - val_loss: 1.3871 - val_accuracy: 0.7405 - val_auc: 0.9362\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4030 - accuracy: 0.6519 - auc: 0.9041 - val_loss: 1.2090 - val_accuracy: 0.7440 - val_auc: 0.9057\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3557 - accuracy: 0.6925 - auc: 0.9233 - val_loss: 1.0945 - val_accuracy: 0.9051 - val_auc: 0.9402\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3384 - accuracy: 0.9116 - auc: 0.9289 - val_loss: 1.0778 - val_accuracy: 0.7563 - val_auc: 0.9385\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4331 - accuracy: 0.6981 - auc: 0.8998 - val_loss: 1.9380 - val_accuracy: 0.7526 - val_auc: 0.9310\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4064 - accuracy: 0.6296 - auc: 0.8936 - val_loss: 1.9591 - val_accuracy: 0.7265 - val_auc: 0.9291\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3930 - accuracy: 0.6932 - auc: 0.9135 - val_loss: 1.3313 - val_accuracy: 0.8973 - val_auc: 0.9399\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4397 - accuracy: 0.6880 - auc: 0.9100 - val_loss: 1.1335 - val_accuracy: 0.7278 - val_auc: 0.9387\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3275 - accuracy: 0.7243 - auc: 0.9261 - val_loss: 1.0506 - val_accuracy: 0.7436 - val_auc: 0.9477\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3515 - accuracy: 0.8309 - auc: 0.9311 - val_loss: 0.9848 - val_accuracy: 0.9188 - val_auc: 0.9421\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3690 - accuracy: 0.8418 - auc: 0.9241 - val_loss: 1.3497 - val_accuracy: 0.7518 - val_auc: 0.9351\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3306 - accuracy: 0.6541 - auc: 0.9184 - val_loss: 1.3966 - val_accuracy: 0.7573 - val_auc: 0.9366\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3248 - accuracy: 0.7525 - auc: 0.9307 - val_loss: 1.4177 - val_accuracy: 0.7653 - val_auc: 0.9250\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3492 - accuracy: 0.6566 - auc: 0.9140 - val_loss: 1.3369 - val_accuracy: 0.7627 - val_auc: 0.9327\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3332 - accuracy: 0.6604 - auc: 0.9172 - val_loss: 1.2088 - val_accuracy: 0.7599 - val_auc: 0.9357\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3195 - accuracy: 0.6656 - auc: 0.9229 - val_loss: 1.2998 - val_accuracy: 0.7719 - val_auc: 0.9360\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3437 - accuracy: 0.6672 - auc: 0.9192 - val_loss: 1.2663 - val_accuracy: 0.7560 - val_auc: 0.9353\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3163 - accuracy: 0.6687 - auc: 0.9256 - val_loss: 1.3720 - val_accuracy: 0.7739 - val_auc: 0.9375\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3155 - accuracy: 0.6773 - auc: 0.9255 - val_loss: 1.4242 - val_accuracy: 0.7804 - val_auc: 0.9312\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3649 - accuracy: 0.6818 - auc: 0.9139 - val_loss: 1.3553 - val_accuracy: 0.7691 - val_auc: 0.9328\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3336 - accuracy: 0.6871 - auc: 0.9120 - val_loss: 1.7373 - val_accuracy: 0.7707 - val_auc: 0.9349\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3192 - accuracy: 0.6713 - auc: 0.9208 - val_loss: 1.6132 - val_accuracy: 0.7685 - val_auc: 0.9346\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3521 - accuracy: 0.6792 - auc: 0.9178 - val_loss: 1.5027 - val_accuracy: 0.7818 - val_auc: 0.9318\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3642 - accuracy: 0.6807 - auc: 0.9070 - val_loss: 1.8744 - val_accuracy: 0.7777 - val_auc: 0.9241\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3472 - accuracy: 0.6832 - auc: 0.9017 - val_loss: 1.9120 - val_accuracy: 0.7873 - val_auc: 0.9235\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3838 - accuracy: 0.6762 - auc: 0.9001 - val_loss: 2.2516 - val_accuracy: 0.7957 - val_auc: 0.9214\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3474 - accuracy: 0.6851 - auc: 0.9048 - val_loss: 2.0700 - val_accuracy: 0.7705 - val_auc: 0.9255\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3789 - accuracy: 0.6763 - auc: 0.9085 - val_loss: 1.6244 - val_accuracy: 0.7769 - val_auc: 0.9282\n",
      "Epoch 43/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.6790 - auc: 0.9142Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3238 - accuracy: 0.6789 - auc: 0.9142 - val_loss: 1.6617 - val_accuracy: 0.7848 - val_auc: 0.9268\n",
      "Epoch 00043: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.9365 - accuracy: 0.7671 - auc: 0.8311 - val_loss: 0.5993 - val_accuracy: 0.8758 - val_auc: 0.9137\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9673 - accuracy: 0.8113 - auc: 0.8457 - val_loss: 0.5020 - val_accuracy: 0.8967 - val_auc: 0.9279\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2233 - accuracy: 0.8256 - auc: 0.8546 - val_loss: 0.7599 - val_accuracy: 0.8844 - val_auc: 0.9297\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1197 - accuracy: 0.8177 - auc: 0.8370 - val_loss: 0.8403 - val_accuracy: 0.8672 - val_auc: 0.9336\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0784 - accuracy: 0.8536 - auc: 0.8501 - val_loss: 0.8957 - val_accuracy: 0.7179 - val_auc: 0.9354\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9332 - accuracy: 0.8206 - auc: 0.8567 - val_loss: 0.6070 - val_accuracy: 0.9195 - val_auc: 0.9301\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2427 - accuracy: 0.8634 - auc: 0.8621 - val_loss: 1.2203 - val_accuracy: 0.9280 - val_auc: 0.9360\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.0146 - accuracy: 0.7295 - auc: 0.8243 - val_loss: 1.6214 - val_accuracy: 0.9410 - val_auc: 0.8955\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4660 - accuracy: 0.7465 - auc: 0.8236 - val_loss: 1.5419 - val_accuracy: 0.7011 - val_auc: 0.9123\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9717 - accuracy: 0.5991 - auc: 0.8439 - val_loss: 1.0320 - val_accuracy: 0.6913 - val_auc: 0.9177\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6703 - accuracy: 0.5821 - auc: 0.8406 - val_loss: 1.7153 - val_accuracy: 0.6832 - val_auc: 0.8945\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8753 - accuracy: 0.5988 - auc: 0.8236 - val_loss: 1.3413 - val_accuracy: 0.6518 - val_auc: 0.8958\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8079 - accuracy: 0.5595 - auc: 0.8482 - val_loss: 1.4786 - val_accuracy: 0.6685 - val_auc: 0.9029\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5713 - accuracy: 0.5790 - auc: 0.8532 - val_loss: 1.1365 - val_accuracy: 0.6665 - val_auc: 0.9030\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4393 - accuracy: 0.5902 - auc: 0.8520 - val_loss: 1.2294 - val_accuracy: 0.6821 - val_auc: 0.9042\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5112 - accuracy: 0.5914 - auc: 0.8507 - val_loss: 0.9989 - val_accuracy: 0.6958 - val_auc: 0.9018\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4276 - accuracy: 0.6123 - auc: 0.8632 - val_loss: 1.1616 - val_accuracy: 0.7105 - val_auc: 0.9039\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4306 - accuracy: 0.6160 - auc: 0.8739 - val_loss: 1.1577 - val_accuracy: 0.6963 - val_auc: 0.9087\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4939 - accuracy: 0.6247 - auc: 0.8766 - val_loss: 1.1400 - val_accuracy: 0.7210 - val_auc: 0.9090\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3844 - accuracy: 0.6366 - auc: 0.8890 - val_loss: 1.1569 - val_accuracy: 0.7261 - val_auc: 0.9109\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3757 - accuracy: 0.6469 - auc: 0.8818 - val_loss: 1.1714 - val_accuracy: 0.7427 - val_auc: 0.9120\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3975 - accuracy: 0.6510 - auc: 0.8843 - val_loss: 1.1878 - val_accuracy: 0.7315 - val_auc: 0.9086\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3668 - accuracy: 0.6541 - auc: 0.8856 - val_loss: 1.0471 - val_accuracy: 0.7406 - val_auc: 0.9069\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3947 - accuracy: 0.6583 - auc: 0.8935 - val_loss: 1.0103 - val_accuracy: 0.7679 - val_auc: 0.9095\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3446 - accuracy: 0.6800 - auc: 0.8971 - val_loss: 1.0768 - val_accuracy: 0.7698 - val_auc: 0.9106\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3767 - accuracy: 0.6847 - auc: 0.9000 - val_loss: 0.8953 - val_accuracy: 0.7603 - val_auc: 0.9069\n",
      "Epoch 27/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3436 - accuracy: 0.6868 - auc: 0.8964Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3419 - accuracy: 0.6872 - auc: 0.8979 - val_loss: 1.0632 - val_accuracy: 0.7745 - val_auc: 0.9128\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.8650 - accuracy: 0.7778 - auc: 0.8178 - val_loss: 0.4263 - val_accuracy: 0.8885 - val_auc: 0.9360\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8560 - accuracy: 0.8297 - auc: 0.8624 - val_loss: 0.7659 - val_accuracy: 0.8686 - val_auc: 0.9171\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3660 - accuracy: 0.8235 - auc: 0.8550 - val_loss: 0.6092 - val_accuracy: 0.9002 - val_auc: 0.9375\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0447 - accuracy: 0.8649 - auc: 0.8759 - val_loss: 0.6760 - val_accuracy: 0.9224 - val_auc: 0.9286\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2577 - accuracy: 0.8513 - auc: 0.8732 - val_loss: 0.7193 - val_accuracy: 0.8801 - val_auc: 0.9300\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9001 - accuracy: 0.8555 - auc: 0.8717 - val_loss: 0.9934 - val_accuracy: 0.8423 - val_auc: 0.9270\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4854 - accuracy: 0.8689 - auc: 0.8414 - val_loss: 1.0794 - val_accuracy: 0.8891 - val_auc: 0.9397\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9278 - accuracy: 0.8828 - auc: 0.8586 - val_loss: 1.0360 - val_accuracy: 0.8754 - val_auc: 0.9390\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9612 - accuracy: 0.8581 - auc: 0.8812 - val_loss: 1.1498 - val_accuracy: 0.9219 - val_auc: 0.9361\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6840 - accuracy: 0.9197 - auc: 0.9079 - val_loss: 0.7488 - val_accuracy: 0.9383 - val_auc: 0.9419\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6041 - accuracy: 0.9260 - auc: 0.9102 - val_loss: 0.7094 - val_accuracy: 0.9078 - val_auc: 0.9423\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7046 - accuracy: 0.9027 - auc: 0.9040 - val_loss: 0.8315 - val_accuracy: 0.8934 - val_auc: 0.9359\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5523 - accuracy: 0.9187 - auc: 0.9073 - val_loss: 2.0823 - val_accuracy: 0.9242 - val_auc: 0.9381\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4959 - accuracy: 0.9326 - auc: 0.9207 - val_loss: 1.6928 - val_accuracy: 0.9275 - val_auc: 0.9429\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5150 - accuracy: 0.9275 - auc: 0.9143 - val_loss: 0.8999 - val_accuracy: 0.9496 - val_auc: 0.9087\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5072 - accuracy: 0.6631 - auc: 0.8549 - val_loss: 0.9755 - val_accuracy: 0.6697 - val_auc: 0.9180\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5487 - accuracy: 0.5584 - auc: 0.8700 - val_loss: 0.9788 - val_accuracy: 0.6770 - val_auc: 0.9117\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5609 - accuracy: 0.5709 - auc: 0.8585 - val_loss: 1.0449 - val_accuracy: 0.6999 - val_auc: 0.9218\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5448 - accuracy: 0.6460 - auc: 0.8876 - val_loss: 1.2848 - val_accuracy: 0.7017 - val_auc: 0.9372\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3989 - accuracy: 0.7025 - auc: 0.8996 - val_loss: 1.1862 - val_accuracy: 0.6851 - val_auc: 0.9326\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4430 - accuracy: 0.8714 - auc: 0.9041 - val_loss: 1.1723 - val_accuracy: 0.9120 - val_auc: 0.9377\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6264 - accuracy: 0.9122 - auc: 0.8901 - val_loss: 1.6475 - val_accuracy: 0.6974 - val_auc: 0.9284\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4028 - accuracy: 0.6988 - auc: 0.9004 - val_loss: 1.7679 - val_accuracy: 0.8980 - val_auc: 0.9306\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5207 - accuracy: 0.6826 - auc: 0.8794 - val_loss: 1.8504 - val_accuracy: 0.7001 - val_auc: 0.9333\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4349 - accuracy: 0.5941 - auc: 0.8836 - val_loss: 1.7646 - val_accuracy: 0.7112 - val_auc: 0.9242\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4336 - accuracy: 0.6065 - auc: 0.8806 - val_loss: 1.7109 - val_accuracy: 0.7204 - val_auc: 0.9229\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4464 - accuracy: 0.6050 - auc: 0.8630 - val_loss: 1.6543 - val_accuracy: 0.7217 - val_auc: 0.9305\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3708 - accuracy: 0.6122 - auc: 0.8810 - val_loss: 1.6414 - val_accuracy: 0.7362 - val_auc: 0.9335\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4753 - accuracy: 0.6103 - auc: 0.8741 - val_loss: 1.6047 - val_accuracy: 0.7123 - val_auc: 0.9316\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4190 - accuracy: 0.6179 - auc: 0.8923 - val_loss: 1.4352 - val_accuracy: 0.7232 - val_auc: 0.9313\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4579 - accuracy: 0.6218 - auc: 0.8767 - val_loss: 1.2990 - val_accuracy: 0.7284 - val_auc: 0.9185\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4090 - accuracy: 0.6305 - auc: 0.8659 - val_loss: 1.3657 - val_accuracy: 0.7413 - val_auc: 0.8967\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3727 - accuracy: 0.6377 - auc: 0.8721 - val_loss: 1.2983 - val_accuracy: 0.7491 - val_auc: 0.9281\n",
      "Epoch 34/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.3731 - accuracy: 0.6371 - auc: 0.8878Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3731 - accuracy: 0.6371 - auc: 0.8876 - val_loss: 1.1768 - val_accuracy: 0.7559 - val_auc: 0.9304\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.9214 - accuracy: 0.7728 - auc: 0.8372 - val_loss: 0.4453 - val_accuracy: 0.8917 - val_auc: 0.9126\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2337 - accuracy: 0.8106 - auc: 0.8439 - val_loss: 0.5268 - val_accuracy: 0.8990 - val_auc: 0.9261\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0519 - accuracy: 0.8350 - auc: 0.8604 - val_loss: 0.5152 - val_accuracy: 0.8925 - val_auc: 0.9418\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7613 - accuracy: 0.8671 - auc: 0.8863 - val_loss: 0.5482 - val_accuracy: 0.8795 - val_auc: 0.9205\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8705 - accuracy: 0.8776 - auc: 0.8780 - val_loss: 0.5448 - val_accuracy: 0.8579 - val_auc: 0.8982\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8379 - accuracy: 0.8799 - auc: 0.8697 - val_loss: 0.5158 - val_accuracy: 0.8502 - val_auc: 0.9402\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6310 - accuracy: 0.8871 - auc: 0.8774 - val_loss: 0.6604 - val_accuracy: 0.8778 - val_auc: 0.9318\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7825 - accuracy: 0.8859 - auc: 0.8547 - val_loss: 0.5231 - val_accuracy: 0.9325 - val_auc: 0.9418\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6267 - accuracy: 0.9125 - auc: 0.8620 - val_loss: 0.5382 - val_accuracy: 0.8732 - val_auc: 0.9421\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5420 - accuracy: 0.9123 - auc: 0.8737 - val_loss: 0.4582 - val_accuracy: 0.8804 - val_auc: 0.9512\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5164 - accuracy: 0.9166 - auc: 0.8795 - val_loss: 0.4413 - val_accuracy: 0.8493 - val_auc: 0.9463\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4688 - accuracy: 0.9086 - auc: 0.8671 - val_loss: 0.4574 - val_accuracy: 0.8752 - val_auc: 0.9372\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4113 - accuracy: 0.9160 - auc: 0.8920 - val_loss: 0.4287 - val_accuracy: 0.8928 - val_auc: 0.9543\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4216 - accuracy: 0.9184 - auc: 0.8935 - val_loss: 0.3604 - val_accuracy: 0.9165 - val_auc: 0.9528\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4023 - accuracy: 0.9141 - auc: 0.9014 - val_loss: 0.3774 - val_accuracy: 0.9150 - val_auc: 0.9581\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4263 - accuracy: 0.9183 - auc: 0.8998 - val_loss: 0.3750 - val_accuracy: 0.8945 - val_auc: 0.9482\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3814 - accuracy: 0.9199 - auc: 0.8990 - val_loss: 0.4014 - val_accuracy: 0.8712 - val_auc: 0.9513\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4011 - accuracy: 0.8367 - auc: 0.8988 - val_loss: 0.3810 - val_accuracy: 0.9080 - val_auc: 0.9514\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3958 - accuracy: 0.8201 - auc: 0.8924 - val_loss: 0.3789 - val_accuracy: 0.8824 - val_auc: 0.9540\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4617 - accuracy: 0.9184 - auc: 0.9085 - val_loss: 0.6358 - val_accuracy: 0.9197 - val_auc: 0.9435\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4886 - accuracy: 0.8642 - auc: 0.9070 - val_loss: 0.4342 - val_accuracy: 0.9100 - val_auc: 0.9451\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3867 - accuracy: 0.8227 - auc: 0.9041 - val_loss: 0.4824 - val_accuracy: 0.9094 - val_auc: 0.9458\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3880 - accuracy: 0.8558 - auc: 0.9071 - val_loss: 0.4594 - val_accuracy: 0.7261 - val_auc: 0.9426\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3989 - accuracy: 0.7133 - auc: 0.9010 - val_loss: 0.5099 - val_accuracy: 0.9045 - val_auc: 0.9391\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3798 - accuracy: 0.6981 - auc: 0.8933 - val_loss: 0.5260 - val_accuracy: 0.7549 - val_auc: 0.9430\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3816 - accuracy: 0.6485 - auc: 0.8880 - val_loss: 0.4823 - val_accuracy: 0.7524 - val_auc: 0.9470\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3777 - accuracy: 0.6019 - auc: 0.8871 - val_loss: 0.4901 - val_accuracy: 0.7600 - val_auc: 0.9415\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3700 - accuracy: 0.6082 - auc: 0.8900 - val_loss: 0.5521 - val_accuracy: 0.7695 - val_auc: 0.9388\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4147 - accuracy: 0.6128 - auc: 0.8818 - val_loss: 0.4286 - val_accuracy: 0.7564 - val_auc: 0.9394\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3715 - accuracy: 0.6416 - auc: 0.8986 - val_loss: 0.5300 - val_accuracy: 0.7619 - val_auc: 0.9339\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3761 - accuracy: 0.6614 - auc: 0.8985 - val_loss: 0.5698 - val_accuracy: 0.7868 - val_auc: 0.9283\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3811 - accuracy: 0.6387 - auc: 0.9004 - val_loss: 0.4758 - val_accuracy: 0.7579 - val_auc: 0.9367\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3783 - accuracy: 0.6622 - auc: 0.9029 - val_loss: 0.5270 - val_accuracy: 0.7768 - val_auc: 0.9413\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3817 - accuracy: 0.6617 - auc: 0.8967 - val_loss: 0.4150 - val_accuracy: 0.7508 - val_auc: 0.9400\n",
      "Epoch 35/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.3518 - accuracy: 0.6478 - auc: 0.9129Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3519 - accuracy: 0.6478 - auc: 0.9129 - val_loss: 0.5005 - val_accuracy: 0.7820 - val_auc: 0.9411\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 1.4075 - accuracy: 0.7432 - auc: 0.8105 - val_loss: 0.7766 - val_accuracy: 0.9217 - val_auc: 0.8950\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0420 - accuracy: 0.8263 - auc: 0.8447 - val_loss: 0.7984 - val_accuracy: 0.8972 - val_auc: 0.9158\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1743 - accuracy: 0.8216 - auc: 0.8551 - val_loss: 0.7431 - val_accuracy: 0.8194 - val_auc: 0.8744\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5762 - accuracy: 0.8300 - auc: 0.8577 - val_loss: 1.0098 - val_accuracy: 0.8706 - val_auc: 0.9302\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2764 - accuracy: 0.8370 - auc: 0.8720 - val_loss: 3.0610 - val_accuracy: 0.9227 - val_auc: 0.9312\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.1020 - accuracy: 0.8648 - auc: 0.8540 - val_loss: 1.2587 - val_accuracy: 0.8668 - val_auc: 0.9212\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7660 - accuracy: 0.8622 - auc: 0.8565 - val_loss: 2.4929 - val_accuracy: 0.8831 - val_auc: 0.9241\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1245 - accuracy: 0.8823 - auc: 0.8946 - val_loss: 1.2653 - val_accuracy: 0.8987 - val_auc: 0.9370\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8237 - accuracy: 0.9026 - auc: 0.9017 - val_loss: 2.1652 - val_accuracy: 0.9651 - val_auc: 0.9342\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7664 - accuracy: 0.8194 - auc: 0.8861 - val_loss: 1.7273 - val_accuracy: 0.6656 - val_auc: 0.9332\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7499 - accuracy: 0.6702 - auc: 0.8672 - val_loss: 1.9753 - val_accuracy: 0.6976 - val_auc: 0.9360\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4611 - accuracy: 0.6420 - auc: 0.8367 - val_loss: 2.1597 - val_accuracy: 0.6939 - val_auc: 0.8880\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8705 - accuracy: 0.5984 - auc: 0.8417 - val_loss: 1.6151 - val_accuracy: 0.6920 - val_auc: 0.8817\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4966 - accuracy: 0.5732 - auc: 0.8191 - val_loss: 2.2558 - val_accuracy: 0.7119 - val_auc: 0.8828\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6800 - accuracy: 0.5809 - auc: 0.8412 - val_loss: 4.0055 - val_accuracy: 0.6663 - val_auc: 0.8742\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9618 - accuracy: 0.5541 - auc: 0.8378 - val_loss: 2.6997 - val_accuracy: 0.6165 - val_auc: 0.8649\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8361 - accuracy: 0.5450 - auc: 0.8153 - val_loss: 2.6396 - val_accuracy: 0.6744 - val_auc: 0.8689\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8436 - accuracy: 0.5369 - auc: 0.7912 - val_loss: 2.9775 - val_accuracy: 0.6557 - val_auc: 0.8699\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.9362 - accuracy: 0.5624 - auc: 0.8335 - val_loss: 2.4259 - val_accuracy: 0.6787 - val_auc: 0.9121\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6506 - accuracy: 0.5658 - auc: 0.8569 - val_loss: 2.2608 - val_accuracy: 0.6374 - val_auc: 0.9112\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5297 - accuracy: 0.5587 - auc: 0.8523 - val_loss: 1.9224 - val_accuracy: 0.6647 - val_auc: 0.9102\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4411 - accuracy: 0.5737 - auc: 0.8660 - val_loss: 2.3529 - val_accuracy: 0.6886 - val_auc: 0.9194\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5846 - accuracy: 0.5842 - auc: 0.8595 - val_loss: 2.5283 - val_accuracy: 0.7028 - val_auc: 0.8901\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5998 - accuracy: 0.5871 - auc: 0.8593 - val_loss: 2.3242 - val_accuracy: 0.7042 - val_auc: 0.9390\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5247 - accuracy: 0.6017 - auc: 0.8902 - val_loss: 2.6893 - val_accuracy: 0.7173 - val_auc: 0.9027\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4639 - accuracy: 0.5999 - auc: 0.8445 - val_loss: 2.7533 - val_accuracy: 0.7122 - val_auc: 0.8875\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5052 - accuracy: 0.6040 - auc: 0.8392 - val_loss: 2.8795 - val_accuracy: 0.7071 - val_auc: 0.8789\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4640 - accuracy: 0.6056 - auc: 0.8415 - val_loss: 3.0633 - val_accuracy: 0.7131 - val_auc: 0.8842\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4346 - accuracy: 0.6107 - auc: 0.8463 - val_loss: 3.1302 - val_accuracy: 0.7179 - val_auc: 0.8841\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4551 - accuracy: 0.6116 - auc: 0.8426 - val_loss: 2.1184 - val_accuracy: 0.7200 - val_auc: 0.8847\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6442 - accuracy: 0.6129 - auc: 0.8773 - val_loss: 1.4952 - val_accuracy: 0.7387 - val_auc: 0.9366\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3983 - accuracy: 0.6174 - auc: 0.8920 - val_loss: 1.6314 - val_accuracy: 0.7265 - val_auc: 0.9381\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3614 - accuracy: 0.6158 - auc: 0.9063 - val_loss: 1.7223 - val_accuracy: 0.7345 - val_auc: 0.9362\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4005 - accuracy: 0.6141 - auc: 0.8886 - val_loss: 1.7882 - val_accuracy: 0.7263 - val_auc: 0.9370\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3800 - accuracy: 0.6149 - auc: 0.8878 - val_loss: 1.7658 - val_accuracy: 0.7240 - val_auc: 0.9448\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4282 - accuracy: 0.6211 - auc: 0.8805 - val_loss: 1.3730 - val_accuracy: 0.7295 - val_auc: 0.8905\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4054 - accuracy: 0.6222 - auc: 0.8475 - val_loss: 1.6547 - val_accuracy: 0.7408 - val_auc: 0.9003\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4044 - accuracy: 0.6281 - auc: 0.8585 - val_loss: 1.4839 - val_accuracy: 0.7259 - val_auc: 0.8969\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4153 - accuracy: 0.6252 - auc: 0.8591 - val_loss: 1.5328 - val_accuracy: 0.7267 - val_auc: 0.8970\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3820 - accuracy: 0.6330 - auc: 0.8581 - val_loss: 1.6214 - val_accuracy: 0.7413 - val_auc: 0.8989\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3977 - accuracy: 0.6339 - auc: 0.8474 - val_loss: 1.5953 - val_accuracy: 0.7340 - val_auc: 0.8853\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4106 - accuracy: 0.6378 - auc: 0.8626 - val_loss: 1.4522 - val_accuracy: 0.7423 - val_auc: 0.8916\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4135 - accuracy: 0.6414 - auc: 0.8615 - val_loss: 1.2114 - val_accuracy: 0.7463 - val_auc: 0.8986\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4572 - accuracy: 0.6464 - auc: 0.8638 - val_loss: 1.0831 - val_accuracy: 0.7516 - val_auc: 0.9011\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4039 - accuracy: 0.6443 - auc: 0.8642 - val_loss: 1.5707 - val_accuracy: 0.7494 - val_auc: 0.8998\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4004 - accuracy: 0.6416 - auc: 0.8714 - val_loss: 1.7694 - val_accuracy: 0.7434 - val_auc: 0.8944\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3855 - accuracy: 0.6467 - auc: 0.8622 - val_loss: 1.7857 - val_accuracy: 0.7465 - val_auc: 0.8968\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3903 - accuracy: 0.6438 - auc: 0.8662 - val_loss: 1.4277 - val_accuracy: 0.7467 - val_auc: 0.8962\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3785 - accuracy: 0.6461 - auc: 0.8702 - val_loss: 1.5662 - val_accuracy: 0.7507 - val_auc: 0.8985\n",
      "Epoch 50/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3791 - accuracy: 0.6379 - auc: 0.8703 - val_loss: 1.5776 - val_accuracy: 0.7421 - val_auc: 0.8961\n",
      "Epoch 51/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3951 - accuracy: 0.6456 - auc: 0.8681 - val_loss: 1.2252 - val_accuracy: 0.7490 - val_auc: 0.8966\n",
      "Epoch 52/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3978 - accuracy: 0.6498 - auc: 0.8663 - val_loss: 1.9899 - val_accuracy: 0.7599 - val_auc: 0.8961\n",
      "Epoch 53/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3856 - accuracy: 0.6479 - auc: 0.8676 - val_loss: 2.2349 - val_accuracy: 0.7552 - val_auc: 0.8987\n",
      "Epoch 54/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3902 - accuracy: 0.6476 - auc: 0.8652 - val_loss: 2.2353 - val_accuracy: 0.7530 - val_auc: 0.8926\n",
      "Epoch 55/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3714 - accuracy: 0.6508 - auc: 0.8646Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3716 - accuracy: 0.6509 - auc: 0.8646 - val_loss: 2.2179 - val_accuracy: 0.7579 - val_auc: 0.8953\n",
      "Epoch 00055: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.2036 - accuracy: 0.7303 - auc: 0.8181 - val_loss: 0.6712 - val_accuracy: 0.8972 - val_auc: 0.9130\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.2397 - accuracy: 0.8235 - auc: 0.8601 - val_loss: 0.7454 - val_accuracy: 0.8349 - val_auc: 0.9251\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.8204 - accuracy: 0.7870 - auc: 0.8432 - val_loss: 1.2092 - val_accuracy: 0.9089 - val_auc: 0.9072\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.6795 - accuracy: 0.7978 - auc: 0.8428 - val_loss: 1.9995 - val_accuracy: 0.8474 - val_auc: 0.9012\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.8021 - accuracy: 0.8597 - auc: 0.8702 - val_loss: 1.7081 - val_accuracy: 0.9283 - val_auc: 0.9218\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.4071 - accuracy: 0.8347 - auc: 0.8365 - val_loss: 5.2432 - val_accuracy: 0.8909 - val_auc: 0.9123\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.1397 - accuracy: 0.8624 - auc: 0.8512 - val_loss: 1.8941 - val_accuracy: 0.9043 - val_auc: 0.9244\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.0411 - accuracy: 0.8100 - auc: 0.8329 - val_loss: 3.2227 - val_accuracy: 0.8958 - val_auc: 0.9067\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.1907 - accuracy: 0.8952 - auc: 0.8605 - val_loss: 2.4030 - val_accuracy: 0.8666 - val_auc: 0.9062\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7294 - accuracy: 0.8773 - auc: 0.8455 - val_loss: 7.1613 - val_accuracy: 0.9000 - val_auc: 0.9123\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3552 - accuracy: 0.7552 - auc: 0.8732 - val_loss: 4.8558 - val_accuracy: 0.9169 - val_auc: 0.9237\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0299 - accuracy: 0.7360 - auc: 0.8741 - val_loss: 3.2020 - val_accuracy: 0.6461 - val_auc: 0.9283\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3211 - accuracy: 0.8826 - auc: 0.8847 - val_loss: 3.9592 - val_accuracy: 0.9092 - val_auc: 0.9327\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8115 - accuracy: 0.9106 - auc: 0.8917 - val_loss: 2.8132 - val_accuracy: 0.9362 - val_auc: 0.9354\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6493 - accuracy: 0.9307 - auc: 0.9076 - val_loss: 3.1978 - val_accuracy: 0.8942 - val_auc: 0.9365\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6290 - accuracy: 0.8222 - auc: 0.9001 - val_loss: 2.8006 - val_accuracy: 0.6787 - val_auc: 0.9334\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5597 - accuracy: 0.6094 - auc: 0.8997 - val_loss: 3.0506 - val_accuracy: 0.7150 - val_auc: 0.9337\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0479 - accuracy: 0.8162 - auc: 0.9060 - val_loss: 3.0330 - val_accuracy: 0.9114 - val_auc: 0.9297\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5619 - accuracy: 0.8606 - auc: 0.9094 - val_loss: 3.8225 - val_accuracy: 0.6904 - val_auc: 0.9245\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4514 - accuracy: 0.6556 - auc: 0.9068 - val_loss: 4.1342 - val_accuracy: 0.7089 - val_auc: 0.9305\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5502 - accuracy: 0.6769 - auc: 0.9010 - val_loss: 3.8939 - val_accuracy: 0.7068 - val_auc: 0.9301\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5268 - accuracy: 0.6160 - auc: 0.8746 - val_loss: 2.8531 - val_accuracy: 0.7109 - val_auc: 0.9174\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5777 - accuracy: 0.6147 - auc: 0.8709 - val_loss: 2.6607 - val_accuracy: 0.7041 - val_auc: 0.9167\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5119 - accuracy: 0.6254 - auc: 0.8815 - val_loss: 2.8802 - val_accuracy: 0.7264 - val_auc: 0.9286\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5015 - accuracy: 0.6258 - auc: 0.8855 - val_loss: 2.7474 - val_accuracy: 0.7409 - val_auc: 0.8922\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4207 - accuracy: 0.6655 - auc: 0.8669 - val_loss: 3.4231 - val_accuracy: 0.7275 - val_auc: 0.8934\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4605 - accuracy: 0.6412 - auc: 0.8823 - val_loss: 3.6419 - val_accuracy: 0.7415 - val_auc: 0.9344\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4889 - accuracy: 0.6448 - auc: 0.8928 - val_loss: 3.2695 - val_accuracy: 0.7398 - val_auc: 0.9293\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4345 - accuracy: 0.6416 - auc: 0.8905 - val_loss: 3.7599 - val_accuracy: 0.7382 - val_auc: 0.9344\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4075 - accuracy: 0.6476 - auc: 0.9045 - val_loss: 4.0083 - val_accuracy: 0.7476 - val_auc: 0.9338\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3853 - accuracy: 0.6521 - auc: 0.8914 - val_loss: 3.7295 - val_accuracy: 0.7417 - val_auc: 0.9349\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3790 - accuracy: 0.6551 - auc: 0.8917 - val_loss: 3.8011 - val_accuracy: 0.7492 - val_auc: 0.9298\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6881 - accuracy: 0.6591 - auc: 0.8887 - val_loss: 5.6504 - val_accuracy: 0.7622 - val_auc: 0.9295\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5991 - accuracy: 0.6665 - auc: 0.8803 - val_loss: 5.7574 - val_accuracy: 0.7455 - val_auc: 0.8835\n",
      "Epoch 35/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.5761 - accuracy: 0.6648 - auc: 0.8500 ETA: 0s - loss: 0.6Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5731 - accuracy: 0.6647 - auc: 0.8500 - val_loss: 5.5257 - val_accuracy: 0.7466 - val_auc: 0.8860\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 1.3986 - accuracy: 0.7487 - auc: 0.8086 - val_loss: 0.6965 - val_accuracy: 0.8820 - val_auc: 0.9268\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5900 - accuracy: 0.8062 - auc: 0.8476 - val_loss: 1.1868 - val_accuracy: 0.9054 - val_auc: 0.9237\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.4127 - accuracy: 0.8211 - auc: 0.8575 - val_loss: 1.3922 - val_accuracy: 0.8045 - val_auc: 0.9193\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 2.0701 - accuracy: 0.8249 - auc: 0.8583 - val_loss: 1.3108 - val_accuracy: 0.9097 - val_auc: 0.9133\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5758 - accuracy: 0.8369 - auc: 0.8586 - val_loss: 1.2971 - val_accuracy: 0.8649 - val_auc: 0.9104\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.7595 - accuracy: 0.8396 - auc: 0.8575 - val_loss: 1.1650 - val_accuracy: 0.7922 - val_auc: 0.9062\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.0526 - accuracy: 0.8724 - auc: 0.8740 - val_loss: 0.9977 - val_accuracy: 0.8653 - val_auc: 0.9098\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8390 - accuracy: 0.8810 - auc: 0.8703 - val_loss: 1.2752 - val_accuracy: 0.8502 - val_auc: 0.9277\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3267 - accuracy: 0.8639 - auc: 0.8718 - val_loss: 1.0057 - val_accuracy: 0.8677 - val_auc: 0.9196\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.8721 - accuracy: 0.9037 - auc: 0.8929 - val_loss: 1.1176 - val_accuracy: 0.8746 - val_auc: 0.9208\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.3156 - accuracy: 0.8765 - auc: 0.8638 - val_loss: 1.7843 - val_accuracy: 0.9156 - val_auc: 0.9259\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6333 - accuracy: 0.9173 - auc: 0.8931 - val_loss: 2.5441 - val_accuracy: 0.9225 - val_auc: 0.9231\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7473 - accuracy: 0.9220 - auc: 0.9107 - val_loss: 1.3345 - val_accuracy: 0.9068 - val_auc: 0.9304\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5580 - accuracy: 0.9235 - auc: 0.8892 - val_loss: 1.4846 - val_accuracy: 0.8816 - val_auc: 0.9353\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5625 - accuracy: 0.9214 - auc: 0.9113 - val_loss: 1.2793 - val_accuracy: 0.9007 - val_auc: 0.9340\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5150 - accuracy: 0.9063 - auc: 0.9057 - val_loss: 1.7326 - val_accuracy: 0.9359 - val_auc: 0.9398\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4152 - accuracy: 0.9033 - auc: 0.9201 - val_loss: 1.9150 - val_accuracy: 0.6520 - val_auc: 0.9398\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5524 - accuracy: 0.7654 - auc: 0.8942 - val_loss: 1.9915 - val_accuracy: 0.6532 - val_auc: 0.9367\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4866 - accuracy: 0.6638 - auc: 0.8839 - val_loss: 1.5517 - val_accuracy: 0.6609 - val_auc: 0.9404\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4808 - accuracy: 0.7783 - auc: 0.8841 - val_loss: 1.6223 - val_accuracy: 0.8966 - val_auc: 0.9397\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4550 - accuracy: 0.6985 - auc: 0.8896 - val_loss: 1.6091 - val_accuracy: 0.6620 - val_auc: 0.9403\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4098 - accuracy: 0.6342 - auc: 0.9002 - val_loss: 1.5163 - val_accuracy: 0.6884 - val_auc: 0.9383\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4203 - accuracy: 0.6723 - auc: 0.9014 - val_loss: 1.0964 - val_accuracy: 0.6993 - val_auc: 0.9400\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3774 - accuracy: 0.7426 - auc: 0.9049 - val_loss: 1.4051 - val_accuracy: 0.7001 - val_auc: 0.9398\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3972 - accuracy: 0.7334 - auc: 0.9032 - val_loss: 1.3865 - val_accuracy: 0.7103 - val_auc: 0.9405\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3454 - accuracy: 0.6423 - auc: 0.9080 - val_loss: 1.5033 - val_accuracy: 0.7236 - val_auc: 0.9448\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3305 - accuracy: 0.7079 - auc: 0.9177 - val_loss: 1.5710 - val_accuracy: 0.7430 - val_auc: 0.9455\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4346 - accuracy: 0.6658 - auc: 0.9091 - val_loss: 1.0897 - val_accuracy: 0.9030 - val_auc: 0.9490\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3974 - accuracy: 0.7169 - auc: 0.9069 - val_loss: 1.3281 - val_accuracy: 0.9246 - val_auc: 0.9437\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3667 - accuracy: 0.6693 - auc: 0.9123 - val_loss: 1.6838 - val_accuracy: 0.7311 - val_auc: 0.9418\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3562 - accuracy: 0.6459 - auc: 0.9132 - val_loss: 1.8220 - val_accuracy: 0.7221 - val_auc: 0.9428\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3499 - accuracy: 0.6521 - auc: 0.9035 - val_loss: 1.8276 - val_accuracy: 0.7361 - val_auc: 0.9411\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3284 - accuracy: 0.6748 - auc: 0.9195 - val_loss: 2.2341 - val_accuracy: 0.9260 - val_auc: 0.9350\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3627 - accuracy: 0.6827 - auc: 0.9124 - val_loss: 2.1499 - val_accuracy: 0.7521 - val_auc: 0.9327\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3398 - accuracy: 0.6698 - auc: 0.9078 - val_loss: 1.4848 - val_accuracy: 0.7682 - val_auc: 0.9353\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3442 - accuracy: 0.6763 - auc: 0.9149 - val_loss: 1.4584 - val_accuracy: 0.7603 - val_auc: 0.9380\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3574 - accuracy: 0.6716 - auc: 0.9145 - val_loss: 1.2978 - val_accuracy: 0.7336 - val_auc: 0.9351\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4355 - accuracy: 0.6669 - auc: 0.9072 - val_loss: 1.6628 - val_accuracy: 0.7633 - val_auc: 0.9366\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3613 - accuracy: 0.6796 - auc: 0.9108 - val_loss: 1.7865 - val_accuracy: 0.7492 - val_auc: 0.9349\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3653 - accuracy: 0.6709 - auc: 0.9122 - val_loss: 1.1273 - val_accuracy: 0.7457 - val_auc: 0.9393\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3184 - accuracy: 0.6739 - auc: 0.9182 - val_loss: 1.2803 - val_accuracy: 0.7680 - val_auc: 0.9399\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3251 - accuracy: 0.7004 - auc: 0.9223 - val_loss: 1.1686 - val_accuracy: 0.7629 - val_auc: 0.9380\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3222 - accuracy: 0.6848 - auc: 0.9245 - val_loss: 1.3270 - val_accuracy: 0.7815 - val_auc: 0.9304\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3419 - accuracy: 0.6882 - auc: 0.9181 - val_loss: 1.3258 - val_accuracy: 0.7761 - val_auc: 0.9350\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3294 - accuracy: 0.6892 - auc: 0.9180 - val_loss: 1.3054 - val_accuracy: 0.7752 - val_auc: 0.9401\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3171 - accuracy: 0.6917 - auc: 0.9152 - val_loss: 1.2990 - val_accuracy: 0.7769 - val_auc: 0.9377\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3076 - accuracy: 0.6962 - auc: 0.9208 - val_loss: 1.3728 - val_accuracy: 0.7871 - val_auc: 0.9349\n",
      "Epoch 48/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3136 - accuracy: 0.7059 - auc: 0.9236Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3126 - accuracy: 0.7060 - auc: 0.9235 - val_loss: 1.4057 - val_accuracy: 0.7916 - val_auc: 0.9333\n",
      "Epoch 00048: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 1.2813 - accuracy: 0.7359 - auc: 0.8053 - val_loss: 0.7561 - val_accuracy: 0.9079 - val_auc: 0.9094\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2126 - accuracy: 0.8319 - auc: 0.8614 - val_loss: 0.7232 - val_accuracy: 0.8776 - val_auc: 0.9312\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.9405 - accuracy: 0.8017 - auc: 0.8480 - val_loss: 1.5780 - val_accuracy: 0.8276 - val_auc: 0.9188\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.4393 - accuracy: 0.8348 - auc: 0.8540 - val_loss: 0.8807 - val_accuracy: 0.8455 - val_auc: 0.9303\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.1023 - accuracy: 0.8183 - auc: 0.8573 - val_loss: 1.3318 - val_accuracy: 0.8119 - val_auc: 0.9171\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.3553 - accuracy: 0.8389 - auc: 0.8455 - val_loss: 2.0307 - val_accuracy: 0.8124 - val_auc: 0.9176\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.0291 - accuracy: 0.8667 - auc: 0.8795 - val_loss: 2.3261 - val_accuracy: 0.9213 - val_auc: 0.9150\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9841 - accuracy: 0.9115 - auc: 0.8977 - val_loss: 2.1517 - val_accuracy: 0.8973 - val_auc: 0.9193\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.7782 - accuracy: 0.8638 - auc: 0.8793 - val_loss: 1.2500 - val_accuracy: 0.9254 - val_auc: 0.9400\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9691 - accuracy: 0.9121 - auc: 0.8928 - val_loss: 1.2983 - val_accuracy: 0.9045 - val_auc: 0.9317\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6042 - accuracy: 0.9274 - auc: 0.9108 - val_loss: 1.7723 - val_accuracy: 0.9470 - val_auc: 0.9290\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2322 - accuracy: 0.8951 - auc: 0.8847 - val_loss: 2.1770 - val_accuracy: 0.9411 - val_auc: 0.9333\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8760 - accuracy: 0.9114 - auc: 0.9127 - val_loss: 1.6931 - val_accuracy: 0.9232 - val_auc: 0.9354\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9266 - accuracy: 0.9185 - auc: 0.9010 - val_loss: 2.4057 - val_accuracy: 0.8987 - val_auc: 0.9282\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5799 - accuracy: 0.8410 - auc: 0.8951 - val_loss: 2.6695 - val_accuracy: 0.8984 - val_auc: 0.9343\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.5991 - accuracy: 0.8899 - auc: 0.8786 - val_loss: 1.7819 - val_accuracy: 0.8929 - val_auc: 0.9219\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.6016 - accuracy: 0.9103 - auc: 0.8940 - val_loss: 3.1028 - val_accuracy: 0.9155 - val_auc: 0.9338\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7182 - accuracy: 0.9274 - auc: 0.8983 - val_loss: 3.2793 - val_accuracy: 0.8795 - val_auc: 0.9414\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7241 - accuracy: 0.9192 - auc: 0.8983 - val_loss: 2.5498 - val_accuracy: 0.8986 - val_auc: 0.9324\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9995 - accuracy: 0.9158 - auc: 0.8986 - val_loss: 2.3042 - val_accuracy: 0.9579 - val_auc: 0.9338\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7711 - accuracy: 0.9409 - auc: 0.8717 - val_loss: 2.0605 - val_accuracy: 0.9408 - val_auc: 0.9204\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6064 - accuracy: 0.8069 - auc: 0.8704 - val_loss: 1.9101 - val_accuracy: 0.9303 - val_auc: 0.9369\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5318 - accuracy: 0.9369 - auc: 0.8739 - val_loss: 2.2776 - val_accuracy: 0.9250 - val_auc: 0.9418\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9358 - accuracy: 0.9112 - auc: 0.8733 - val_loss: 3.6495 - val_accuracy: 0.6078 - val_auc: 0.9333\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7492 - accuracy: 0.7619 - auc: 0.8628 - val_loss: 4.0030 - val_accuracy: 0.9167 - val_auc: 0.9105\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7753 - accuracy: 0.7789 - auc: 0.8509 - val_loss: 3.0539 - val_accuracy: 0.9201 - val_auc: 0.9348\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9274 - accuracy: 0.8170 - auc: 0.8613 - val_loss: 2.6367 - val_accuracy: 0.9263 - val_auc: 0.9378\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5849 - accuracy: 0.8635 - auc: 0.8620 - val_loss: 3.2241 - val_accuracy: 0.9079 - val_auc: 0.9344\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4982 - accuracy: 0.9416 - auc: 0.8694 - val_loss: 3.4949 - val_accuracy: 0.9104 - val_auc: 0.9196\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5183 - accuracy: 0.7995 - auc: 0.8696 - val_loss: 2.7670 - val_accuracy: 0.9139 - val_auc: 0.9348\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7403 - accuracy: 0.6810 - auc: 0.8404 - val_loss: 1.7500 - val_accuracy: 0.6163 - val_auc: 0.8751\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5156 - accuracy: 0.4788 - auc: 0.8238 - val_loss: 1.9843 - val_accuracy: 0.6213 - val_auc: 0.8697\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 3s 11us/sample - loss: 0.4825 - accuracy: 0.5470 - auc: 0.8367 - val_loss: 2.1032 - val_accuracy: 0.6298 - val_auc: 0.8797\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.5646 - accuracy: 0.4828 - auc: 0.8188 - val_loss: 1.9974 - val_accuracy: 0.6305 - val_auc: 0.8748\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4915 - accuracy: 0.4917 - auc: 0.8183 - val_loss: 2.3239 - val_accuracy: 0.6465 - val_auc: 0.8783\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4806 - accuracy: 0.5027 - auc: 0.8264 - val_loss: 2.3364 - val_accuracy: 0.6560 - val_auc: 0.8802\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5129 - accuracy: 0.5075 - auc: 0.8210 - val_loss: 2.4118 - val_accuracy: 0.6594 - val_auc: 0.8945\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4553 - accuracy: 0.5157 - auc: 0.8495 - val_loss: 2.3535 - val_accuracy: 0.9178 - val_auc: 0.9332\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5833 - accuracy: 0.7275 - auc: 0.8660 - val_loss: 2.0882 - val_accuracy: 0.6648 - val_auc: 0.9308\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5436 - accuracy: 0.6389 - auc: 0.8421 - val_loss: 2.7448 - val_accuracy: 0.6615 - val_auc: 0.8813\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5208 - accuracy: 0.5096 - auc: 0.8225 - val_loss: 2.5190 - val_accuracy: 0.6450 - val_auc: 0.8761\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4861 - accuracy: 0.5040 - auc: 0.8241 - val_loss: 2.7550 - val_accuracy: 0.6462 - val_auc: 0.8709\n",
      "Epoch 43/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.5085 - auc: 0.8317Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4911 - accuracy: 0.5085 - auc: 0.8318 - val_loss: 2.8016 - val_accuracy: 0.6516 - val_auc: 0.8791\n",
      "Epoch 00043: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 1.4664 - accuracy: 0.7057 - auc: 0.8356 - val_loss: 0.7668 - val_accuracy: 0.7583 - val_auc: 0.9103\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3131 - accuracy: 0.7811 - auc: 0.8425 - val_loss: 0.8968 - val_accuracy: 0.8878 - val_auc: 0.9240\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0325 - accuracy: 0.8494 - auc: 0.8872 - val_loss: 0.5778 - val_accuracy: 0.9003 - val_auc: 0.9332\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4478 - accuracy: 0.8261 - auc: 0.8533 - val_loss: 1.5980 - val_accuracy: 0.9070 - val_auc: 0.8986\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4274 - accuracy: 0.8503 - auc: 0.8772 - val_loss: 2.2498 - val_accuracy: 0.9052 - val_auc: 0.9070\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.8060 - accuracy: 0.8493 - auc: 0.8642 - val_loss: 1.4322 - val_accuracy: 0.5783 - val_auc: 0.8389\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.3280 - accuracy: 0.8644 - auc: 0.8727 - val_loss: 2.7696 - val_accuracy: 0.8444 - val_auc: 0.9246\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.8914 - accuracy: 0.8291 - auc: 0.8269 - val_loss: 2.5300 - val_accuracy: 0.8459 - val_auc: 0.9130\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.9216 - accuracy: 0.8148 - auc: 0.8449 - val_loss: 1.3033 - val_accuracy: 0.6588 - val_auc: 0.9137\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9459 - accuracy: 0.7056 - auc: 0.8697 - val_loss: 1.5109 - val_accuracy: 0.6214 - val_auc: 0.9241\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5729 - accuracy: 0.8448 - auc: 0.9023 - val_loss: 1.7135 - val_accuracy: 0.9144 - val_auc: 0.9350\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8028 - accuracy: 0.8581 - auc: 0.8791 - val_loss: 4.0713 - val_accuracy: 0.9466 - val_auc: 0.9259\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9074 - accuracy: 0.7089 - auc: 0.8697 - val_loss: 3.1458 - val_accuracy: 0.8951 - val_auc: 0.9258\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7158 - accuracy: 0.6520 - auc: 0.8466 - val_loss: 3.3663 - val_accuracy: 0.6843 - val_auc: 0.8931\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.8383 - accuracy: 0.5813 - auc: 0.8240 - val_loss: 3.4587 - val_accuracy: 0.7002 - val_auc: 0.8960\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2548 - accuracy: 0.6014 - auc: 0.8474 - val_loss: 5.0070 - val_accuracy: 0.7006 - val_auc: 0.8946\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7505 - accuracy: 0.5821 - auc: 0.8398 - val_loss: 4.4999 - val_accuracy: 0.6616 - val_auc: 0.8740\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7135 - accuracy: 0.5729 - auc: 0.8511 - val_loss: 3.8032 - val_accuracy: 0.6596 - val_auc: 0.8867\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6296 - accuracy: 0.5846 - auc: 0.8456 - val_loss: 3.3265 - val_accuracy: 0.6689 - val_auc: 0.8640\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2712 - accuracy: 0.5855 - auc: 0.8319 - val_loss: 3.7750 - val_accuracy: 0.6728 - val_auc: 0.8679\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6301 - accuracy: 0.5949 - auc: 0.8427 - val_loss: 3.6916 - val_accuracy: 0.6807 - val_auc: 0.8788\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5336 - accuracy: 0.6001 - auc: 0.8765 - val_loss: 4.0772 - val_accuracy: 0.6929 - val_auc: 0.9218\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5087 - accuracy: 0.6034 - auc: 0.8701 - val_loss: 3.7830 - val_accuracy: 0.7008 - val_auc: 0.8884\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6834 - accuracy: 0.6099 - auc: 0.8859 - val_loss: 2.5858 - val_accuracy: 0.7089 - val_auc: 0.9289\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4056 - accuracy: 0.6183 - auc: 0.9023 - val_loss: 2.7762 - val_accuracy: 0.7199 - val_auc: 0.9248\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3968 - accuracy: 0.6274 - auc: 0.9032 - val_loss: 2.5571 - val_accuracy: 0.7286 - val_auc: 0.9356\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3794 - accuracy: 0.6370 - auc: 0.9116 - val_loss: 2.6245 - val_accuracy: 0.7234 - val_auc: 0.9279\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4057 - accuracy: 0.6503 - auc: 0.9077 - val_loss: 1.9680 - val_accuracy: 0.7238 - val_auc: 0.9364\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3762 - accuracy: 0.6319 - auc: 0.9036 - val_loss: 1.9835 - val_accuracy: 0.7271 - val_auc: 0.9368\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3988 - accuracy: 0.6346 - auc: 0.9061 - val_loss: 2.1799 - val_accuracy: 0.7278 - val_auc: 0.9353\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3784 - accuracy: 0.6636 - auc: 0.9080 - val_loss: 2.1450 - val_accuracy: 0.7366 - val_auc: 0.9401\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3774 - accuracy: 0.6442 - auc: 0.9081 - val_loss: 2.0589 - val_accuracy: 0.7365 - val_auc: 0.9393\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3730 - accuracy: 0.6479 - auc: 0.9050 - val_loss: 2.1365 - val_accuracy: 0.7410 - val_auc: 0.9319\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3545 - accuracy: 0.6564 - auc: 0.9106 - val_loss: 2.0377 - val_accuracy: 0.7487 - val_auc: 0.9258\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3620 - accuracy: 0.6630 - auc: 0.9126 - val_loss: 1.8918 - val_accuracy: 0.7536 - val_auc: 0.9398\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3533 - accuracy: 0.6882 - auc: 0.9200 - val_loss: 2.0328 - val_accuracy: 0.7517 - val_auc: 0.9381\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3528 - accuracy: 0.6718 - auc: 0.9125 - val_loss: 1.7913 - val_accuracy: 0.7618 - val_auc: 0.9294\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3654 - accuracy: 0.6648 - auc: 0.9040 - val_loss: 1.9639 - val_accuracy: 0.7591 - val_auc: 0.9373\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3568 - accuracy: 0.6677 - auc: 0.9045 - val_loss: 1.7689 - val_accuracy: 0.7466 - val_auc: 0.9410\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3720 - accuracy: 0.6644 - auc: 0.9001 - val_loss: 1.2589 - val_accuracy: 0.7543 - val_auc: 0.9383\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3560 - accuracy: 0.6697 - auc: 0.9071 - val_loss: 1.3497 - val_accuracy: 0.7681 - val_auc: 0.9378\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3437 - accuracy: 0.6777 - auc: 0.9067 - val_loss: 1.7986 - val_accuracy: 0.7615 - val_auc: 0.9284\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3401 - accuracy: 0.6815 - auc: 0.9087 - val_loss: 1.7642 - val_accuracy: 0.7721 - val_auc: 0.9292\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3230 - accuracy: 0.6880 - auc: 0.9096 - val_loss: 1.7168 - val_accuracy: 0.7780 - val_auc: 0.9339\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3359 - accuracy: 0.6913 - auc: 0.9121 - val_loss: 1.9591 - val_accuracy: 0.7720 - val_auc: 0.9328\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3494 - accuracy: 0.6933 - auc: 0.9077 - val_loss: 1.7699 - val_accuracy: 0.7726 - val_auc: 0.9305\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3488 - accuracy: 0.6859 - auc: 0.8968 - val_loss: 1.7060 - val_accuracy: 0.7756 - val_auc: 0.9330\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3306 - accuracy: 0.6979 - auc: 0.8981 - val_loss: 1.7902 - val_accuracy: 0.7828 - val_auc: 0.9347\n",
      "Epoch 49/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3394 - accuracy: 0.6978 - auc: 0.8966 - val_loss: 1.6879 - val_accuracy: 0.7870 - val_auc: 0.9309\n",
      "Epoch 50/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3405 - accuracy: 0.7002 - auc: 0.9029 - val_loss: 1.6382 - val_accuracy: 0.7918 - val_auc: 0.9350\n",
      "Epoch 51/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3399 - accuracy: 0.7073 - auc: 0.8970 - val_loss: 1.5344 - val_accuracy: 0.7721 - val_auc: 0.9332\n",
      "Epoch 52/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3281 - accuracy: 0.7081 - auc: 0.9054 - val_loss: 1.6035 - val_accuracy: 0.7934 - val_auc: 0.9328\n",
      "Epoch 53/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3330 - accuracy: 0.7093 - auc: 0.9070 - val_loss: 1.4633 - val_accuracy: 0.7922 - val_auc: 0.9315\n",
      "Epoch 54/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3351 - accuracy: 0.7085 - auc: 0.9003 - val_loss: 1.4157 - val_accuracy: 0.7936 - val_auc: 0.9338\n",
      "Epoch 55/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3119 - accuracy: 0.7167 - auc: 0.9056 - val_loss: 1.7817 - val_accuracy: 0.8024 - val_auc: 0.9359\n",
      "Epoch 56/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3407 - accuracy: 0.7164 - auc: 0.8990 - val_loss: 1.6470 - val_accuracy: 0.7973 - val_auc: 0.9125\n",
      "Epoch 57/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3516 - accuracy: 0.7166 - auc: 0.8702 - val_loss: 2.0538 - val_accuracy: 0.8032 - val_auc: 0.8888\n",
      "Epoch 58/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3339 - accuracy: 0.7239 - auc: 0.8802 - val_loss: 2.0939 - val_accuracy: 0.8121 - val_auc: 0.9020\n",
      "Epoch 59/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.3331 - accuracy: 0.7245 - auc: 0.8903Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3328 - accuracy: 0.7245 - auc: 0.8905 - val_loss: 2.2402 - val_accuracy: 0.8203 - val_auc: 0.9043\n",
      "Epoch 00059: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 0.5087 - accuracy: 0.8752 - auc: 0.8211 - val_loss: 0.3542 - val_accuracy: 0.9177 - val_auc: 0.9474\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4246 - accuracy: 0.9125 - auc: 0.8879 - val_loss: 0.3257 - val_accuracy: 0.9183 - val_auc: 0.9555\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3884 - accuracy: 0.9165 - auc: 0.9116 - val_loss: 0.3046 - val_accuracy: 0.9102 - val_auc: 0.9545\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3668 - accuracy: 0.9142 - auc: 0.9185 - val_loss: 0.2994 - val_accuracy: 0.9282 - val_auc: 0.9526\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3691 - accuracy: 0.9177 - auc: 0.9167 - val_loss: 0.2815 - val_accuracy: 0.9248 - val_auc: 0.9565\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3586 - accuracy: 0.9187 - auc: 0.9249 - val_loss: 0.2743 - val_accuracy: 0.9226 - val_auc: 0.9560\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3575 - accuracy: 0.9190 - auc: 0.9219 - val_loss: 0.2802 - val_accuracy: 0.9032 - val_auc: 0.9550\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3516 - accuracy: 0.9181 - auc: 0.9288 - val_loss: 0.2781 - val_accuracy: 0.9035 - val_auc: 0.9548\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3484 - accuracy: 0.9186 - auc: 0.9246 - val_loss: 0.2742 - val_accuracy: 0.9132 - val_auc: 0.9570\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3402 - accuracy: 0.9171 - auc: 0.9277 - val_loss: 0.2740 - val_accuracy: 0.9197 - val_auc: 0.9543\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3440 - accuracy: 0.9201 - auc: 0.9234 - val_loss: 0.2687 - val_accuracy: 0.9195 - val_auc: 0.9579\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3276 - accuracy: 0.9188 - auc: 0.9366 - val_loss: 0.2673 - val_accuracy: 0.9185 - val_auc: 0.9586\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3259 - accuracy: 0.9191 - auc: 0.9349 - val_loss: 0.2686 - val_accuracy: 0.9235 - val_auc: 0.9575\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3323 - accuracy: 0.9255 - auc: 0.9334 - val_loss: 0.2697 - val_accuracy: 0.9165 - val_auc: 0.9560\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3376 - accuracy: 0.9239 - auc: 0.9306 - val_loss: 0.2651 - val_accuracy: 0.9126 - val_auc: 0.9585\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3328 - accuracy: 0.9194 - auc: 0.9320 - val_loss: 0.2685 - val_accuracy: 0.9230 - val_auc: 0.9572\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3363 - accuracy: 0.9247 - auc: 0.9294 - val_loss: 0.2773 - val_accuracy: 0.9103 - val_auc: 0.9545\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3267 - accuracy: 0.9214 - auc: 0.9387 - val_loss: 0.2739 - val_accuracy: 0.9144 - val_auc: 0.9552\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3249 - accuracy: 0.9221 - auc: 0.9330 - val_loss: 0.2759 - val_accuracy: 0.9230 - val_auc: 0.9546\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3377 - accuracy: 0.9214 - auc: 0.9320 - val_loss: 0.2727 - val_accuracy: 0.9202 - val_auc: 0.9553\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3290 - accuracy: 0.9223 - auc: 0.9333 - val_loss: 0.2733 - val_accuracy: 0.9127 - val_auc: 0.9551\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3230 - accuracy: 0.9222 - auc: 0.9373 - val_loss: 0.2815 - val_accuracy: 0.9143 - val_auc: 0.9524\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3323 - accuracy: 0.9209 - auc: 0.9319 - val_loss: 0.2827 - val_accuracy: 0.9217 - val_auc: 0.9526\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3291 - accuracy: 0.9226 - auc: 0.9340 - val_loss: 0.2775 - val_accuracy: 0.9207 - val_auc: 0.9538\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3279 - accuracy: 0.9230 - auc: 0.9344 - val_loss: 0.2813 - val_accuracy: 0.9211 - val_auc: 0.9534\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3382 - accuracy: 0.9231 - auc: 0.9290 - val_loss: 0.2832 - val_accuracy: 0.9162 - val_auc: 0.9523\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3162 - accuracy: 0.9261 - auc: 0.9394 - val_loss: 0.2819 - val_accuracy: 0.9186 - val_auc: 0.9538\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3282 - accuracy: 0.9234 - auc: 0.9327 - val_loss: 0.2839 - val_accuracy: 0.9298 - val_auc: 0.9528\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3361 - accuracy: 0.9284 - auc: 0.9318 - val_loss: 0.2864 - val_accuracy: 0.9151 - val_auc: 0.9522\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3291 - accuracy: 0.9231 - auc: 0.9352 - val_loss: 0.2919 - val_accuracy: 0.9262 - val_auc: 0.9505\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3313 - accuracy: 0.9241 - auc: 0.9327 - val_loss: 0.2881 - val_accuracy: 0.9204 - val_auc: 0.9523\n",
      "Epoch 32/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3168 - accuracy: 0.9255 - auc: 0.9407Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3151 - accuracy: 0.9254 - auc: 0.9421 - val_loss: 0.2843 - val_accuracy: 0.9153 - val_auc: 0.9537\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6386 - accuracy: 0.7091 - auc: 0.7829 - val_loss: 0.3619 - val_accuracy: 0.8687 - val_auc: 0.9344\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4513 - accuracy: 0.8816 - auc: 0.8702 - val_loss: 0.3126 - val_accuracy: 0.8832 - val_auc: 0.9506\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4048 - accuracy: 0.8954 - auc: 0.8941 - val_loss: 0.2889 - val_accuracy: 0.8933 - val_auc: 0.9558\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3975 - accuracy: 0.9029 - auc: 0.8964 - val_loss: 0.2865 - val_accuracy: 0.8739 - val_auc: 0.9549\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3830 - accuracy: 0.8962 - auc: 0.9021 - val_loss: 0.2880 - val_accuracy: 0.8949 - val_auc: 0.9557\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3685 - accuracy: 0.9040 - auc: 0.9124 - val_loss: 0.2725 - val_accuracy: 0.8828 - val_auc: 0.9572\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3403 - accuracy: 0.8955 - auc: 0.9212 - val_loss: 0.2651 - val_accuracy: 0.8790 - val_auc: 0.9594\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3415 - accuracy: 0.8716 - auc: 0.9191 - val_loss: 0.2656 - val_accuracy: 0.8691 - val_auc: 0.9605\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3434 - accuracy: 0.7043 - auc: 0.9155 - val_loss: 0.2808 - val_accuracy: 0.8644 - val_auc: 0.9561\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3399 - accuracy: 0.7066 - auc: 0.9219 - val_loss: 0.2727 - val_accuracy: 0.8563 - val_auc: 0.9590\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3286 - accuracy: 0.7056 - auc: 0.9217 - val_loss: 0.2805 - val_accuracy: 0.8638 - val_auc: 0.9561\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3241 - accuracy: 0.7147 - auc: 0.9248 - val_loss: 0.2876 - val_accuracy: 0.8538 - val_auc: 0.9542\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3330 - accuracy: 0.7033 - auc: 0.9260 - val_loss: 0.2985 - val_accuracy: 0.8587 - val_auc: 0.9515\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3183 - accuracy: 0.7082 - auc: 0.9294 - val_loss: 0.3019 - val_accuracy: 0.8591 - val_auc: 0.9528\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3335 - accuracy: 0.6967 - auc: 0.9237 - val_loss: 0.3189 - val_accuracy: 0.8477 - val_auc: 0.9510\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3410 - accuracy: 0.6922 - auc: 0.9195 - val_loss: 0.3114 - val_accuracy: 0.8634 - val_auc: 0.9496\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3364 - accuracy: 0.7072 - auc: 0.9216 - val_loss: 0.3127 - val_accuracy: 0.8620 - val_auc: 0.9496\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3265 - accuracy: 0.7034 - auc: 0.9208 - val_loss: 0.3212 - val_accuracy: 0.8567 - val_auc: 0.9499\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3300 - accuracy: 0.6971 - auc: 0.9226 - val_loss: 0.3219 - val_accuracy: 0.8501 - val_auc: 0.9507\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3297 - accuracy: 0.6986 - auc: 0.9199 - val_loss: 0.3280 - val_accuracy: 0.8518 - val_auc: 0.9500\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3192 - accuracy: 0.6995 - auc: 0.9258 - val_loss: 0.3226 - val_accuracy: 0.8511 - val_auc: 0.9503\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3213 - accuracy: 0.7007 - auc: 0.9222 - val_loss: 0.3352 - val_accuracy: 0.8565 - val_auc: 0.9499\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3192 - accuracy: 0.7020 - auc: 0.9268 - val_loss: 0.3319 - val_accuracy: 0.8568 - val_auc: 0.9512\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3209 - accuracy: 0.7029 - auc: 0.9232 - val_loss: 0.3421 - val_accuracy: 0.8629 - val_auc: 0.9490\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3184 - accuracy: 0.7064 - auc: 0.9269 - val_loss: 0.3444 - val_accuracy: 0.8605 - val_auc: 0.9489\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3162 - accuracy: 0.6981 - auc: 0.9240 - val_loss: 0.3547 - val_accuracy: 0.8646 - val_auc: 0.9482\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3162 - accuracy: 0.7059 - auc: 0.9268 - val_loss: 0.3496 - val_accuracy: 0.8558 - val_auc: 0.9476\n",
      "Epoch 28/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3120 - accuracy: 0.7024 - auc: 0.9275Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3120 - accuracy: 0.7023 - auc: 0.9277 - val_loss: 0.3361 - val_accuracy: 0.8583 - val_auc: 0.9503\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7056 - accuracy: 0.6086 - auc: 0.7354 - val_loss: 0.4033 - val_accuracy: 0.8777 - val_auc: 0.9239\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4934 - accuracy: 0.7341 - auc: 0.8422 - val_loss: 0.3163 - val_accuracy: 0.8576 - val_auc: 0.9470\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4288 - accuracy: 0.7929 - auc: 0.8758 - val_loss: 0.3009 - val_accuracy: 0.8659 - val_auc: 0.9523\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3922 - accuracy: 0.8806 - auc: 0.8974 - val_loss: 0.2902 - val_accuracy: 0.8837 - val_auc: 0.9536\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3748 - accuracy: 0.8881 - auc: 0.9029 - val_loss: 0.2864 - val_accuracy: 0.8807 - val_auc: 0.9523\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3708 - accuracy: 0.8924 - auc: 0.9015 - val_loss: 0.2913 - val_accuracy: 0.8910 - val_auc: 0.9521\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3704 - accuracy: 0.9000 - auc: 0.9115 - val_loss: 0.2828 - val_accuracy: 0.8867 - val_auc: 0.9528\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3664 - accuracy: 0.8928 - auc: 0.9066 - val_loss: 0.2830 - val_accuracy: 0.8908 - val_auc: 0.9530\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3514 - accuracy: 0.8959 - auc: 0.9122 - val_loss: 0.2831 - val_accuracy: 0.8800 - val_auc: 0.9531\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3546 - accuracy: 0.7014 - auc: 0.9105 - val_loss: 0.2850 - val_accuracy: 0.8627 - val_auc: 0.9532\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3550 - accuracy: 0.6868 - auc: 0.9124 - val_loss: 0.2804 - val_accuracy: 0.8564 - val_auc: 0.9541\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3470 - accuracy: 0.6991 - auc: 0.9137 - val_loss: 0.2945 - val_accuracy: 0.8615 - val_auc: 0.9524\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3407 - accuracy: 0.7011 - auc: 0.9171 - val_loss: 0.2958 - val_accuracy: 0.8604 - val_auc: 0.9520\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3373 - accuracy: 0.6986 - auc: 0.9163 - val_loss: 0.2993 - val_accuracy: 0.8541 - val_auc: 0.9515\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3284 - accuracy: 0.7011 - auc: 0.9226 - val_loss: 0.2971 - val_accuracy: 0.8522 - val_auc: 0.9530\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3282 - accuracy: 0.7021 - auc: 0.9226 - val_loss: 0.3008 - val_accuracy: 0.8540 - val_auc: 0.9533\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3347 - accuracy: 0.7038 - auc: 0.9203 - val_loss: 0.2899 - val_accuracy: 0.8602 - val_auc: 0.9554\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3158 - accuracy: 0.7067 - auc: 0.9275 - val_loss: 0.2935 - val_accuracy: 0.8696 - val_auc: 0.9551\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3295 - accuracy: 0.7107 - auc: 0.9213 - val_loss: 0.2876 - val_accuracy: 0.8608 - val_auc: 0.9561\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3192 - accuracy: 0.6986 - auc: 0.9292 - val_loss: 0.3008 - val_accuracy: 0.8660 - val_auc: 0.9535\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3311 - accuracy: 0.6996 - auc: 0.9174 - val_loss: 0.3030 - val_accuracy: 0.8585 - val_auc: 0.9520\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3226 - accuracy: 0.7053 - auc: 0.9227 - val_loss: 0.3126 - val_accuracy: 0.8563 - val_auc: 0.9513\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3298 - accuracy: 0.6941 - auc: 0.9181 - val_loss: 0.3158 - val_accuracy: 0.8530 - val_auc: 0.9511\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3171 - accuracy: 0.7012 - auc: 0.9243 - val_loss: 0.3191 - val_accuracy: 0.8568 - val_auc: 0.9507\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3123 - accuracy: 0.7015 - auc: 0.9283 - val_loss: 0.3157 - val_accuracy: 0.8559 - val_auc: 0.9529\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3097 - accuracy: 0.6978 - auc: 0.9277 - val_loss: 0.3280 - val_accuracy: 0.8584 - val_auc: 0.9538\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3252 - accuracy: 0.7074 - auc: 0.9213 - val_loss: 0.3240 - val_accuracy: 0.8540 - val_auc: 0.9520\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3192 - accuracy: 0.6975 - auc: 0.9240 - val_loss: 0.3170 - val_accuracy: 0.8562 - val_auc: 0.9554\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3184 - accuracy: 0.6983 - auc: 0.9265 - val_loss: 0.3260 - val_accuracy: 0.8609 - val_auc: 0.9529\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3169 - accuracy: 0.7018 - auc: 0.9239 - val_loss: 0.3254 - val_accuracy: 0.8600 - val_auc: 0.9533\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3115 - accuracy: 0.7088 - auc: 0.9267 - val_loss: 0.3231 - val_accuracy: 0.8578 - val_auc: 0.9548\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3062 - accuracy: 0.7014 - auc: 0.9319 - val_loss: 0.3311 - val_accuracy: 0.8591 - val_auc: 0.9541\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3160 - accuracy: 0.7042 - auc: 0.9232 - val_loss: 0.3325 - val_accuracy: 0.8585 - val_auc: 0.9541\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3145 - accuracy: 0.6970 - auc: 0.9222 - val_loss: 0.3354 - val_accuracy: 0.8599 - val_auc: 0.9542\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3058 - accuracy: 0.7059 - auc: 0.9282 - val_loss: 0.3212 - val_accuracy: 0.8626 - val_auc: 0.9559\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3069 - accuracy: 0.7031 - auc: 0.9252 - val_loss: 0.3295 - val_accuracy: 0.8632 - val_auc: 0.9545\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3087 - accuracy: 0.7032 - auc: 0.9271 - val_loss: 0.3336 - val_accuracy: 0.8608 - val_auc: 0.9553\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3181 - accuracy: 0.7012 - auc: 0.9272 - val_loss: 0.3346 - val_accuracy: 0.8564 - val_auc: 0.9546\n",
      "Epoch 39/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.6933 - auc: 0.9210Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3219 - accuracy: 0.6933 - auc: 0.9210 - val_loss: 0.3461 - val_accuracy: 0.8476 - val_auc: 0.9532\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.6264 - accuracy: 0.5022 - auc: 0.7942 - val_loss: 0.3632 - val_accuracy: 0.7866 - val_auc: 0.9377\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4249 - accuracy: 0.7801 - auc: 0.8814 - val_loss: 0.3110 - val_accuracy: 0.8912 - val_auc: 0.9480\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3963 - accuracy: 0.8892 - auc: 0.8934 - val_loss: 0.2947 - val_accuracy: 0.8776 - val_auc: 0.9499\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3775 - accuracy: 0.8898 - auc: 0.9042 - val_loss: 0.2827 - val_accuracy: 0.8916 - val_auc: 0.9540\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3748 - accuracy: 0.8880 - auc: 0.9001 - val_loss: 0.2763 - val_accuracy: 0.8801 - val_auc: 0.9561\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3584 - accuracy: 0.8013 - auc: 0.9073 - val_loss: 0.2715 - val_accuracy: 0.8792 - val_auc: 0.9578\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3627 - accuracy: 0.7189 - auc: 0.9076 - val_loss: 0.2830 - val_accuracy: 0.8557 - val_auc: 0.9541\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3451 - accuracy: 0.6993 - auc: 0.9165 - val_loss: 0.2818 - val_accuracy: 0.8636 - val_auc: 0.9548\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3480 - accuracy: 0.7060 - auc: 0.9136 - val_loss: 0.2844 - val_accuracy: 0.8601 - val_auc: 0.9538\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3338 - accuracy: 0.7064 - auc: 0.9213 - val_loss: 0.2896 - val_accuracy: 0.8740 - val_auc: 0.9530\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3275 - accuracy: 0.7148 - auc: 0.9256 - val_loss: 0.2891 - val_accuracy: 0.8823 - val_auc: 0.9537\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3466 - accuracy: 0.7167 - auc: 0.9171 - val_loss: 0.2968 - val_accuracy: 0.8549 - val_auc: 0.9525\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3202 - accuracy: 0.7129 - auc: 0.9276 - val_loss: 0.2861 - val_accuracy: 0.8653 - val_auc: 0.9543\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3348 - accuracy: 0.7128 - auc: 0.9214 - val_loss: 0.2969 - val_accuracy: 0.8671 - val_auc: 0.9524\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3269 - accuracy: 0.7131 - auc: 0.9252 - val_loss: 0.2878 - val_accuracy: 0.8611 - val_auc: 0.9553\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3214 - accuracy: 0.7108 - auc: 0.9243 - val_loss: 0.2976 - val_accuracy: 0.8644 - val_auc: 0.9533\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3199 - accuracy: 0.7184 - auc: 0.9269 - val_loss: 0.2994 - val_accuracy: 0.8641 - val_auc: 0.9538\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3221 - accuracy: 0.7092 - auc: 0.9245 - val_loss: 0.3063 - val_accuracy: 0.8637 - val_auc: 0.9525\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3296 - accuracy: 0.7123 - auc: 0.9247 - val_loss: 0.2978 - val_accuracy: 0.8661 - val_auc: 0.9537\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3190 - accuracy: 0.7134 - auc: 0.9267 - val_loss: 0.2995 - val_accuracy: 0.8680 - val_auc: 0.9555\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3279 - accuracy: 0.7156 - auc: 0.9240 - val_loss: 0.3108 - val_accuracy: 0.8754 - val_auc: 0.9528\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3252 - accuracy: 0.7213 - auc: 0.9254 - val_loss: 0.2977 - val_accuracy: 0.8637 - val_auc: 0.9543\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3254 - accuracy: 0.7120 - auc: 0.9241 - val_loss: 0.3043 - val_accuracy: 0.8614 - val_auc: 0.9553\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3157 - accuracy: 0.7133 - auc: 0.9291 - val_loss: 0.3096 - val_accuracy: 0.8670 - val_auc: 0.9522\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3236 - accuracy: 0.7168 - auc: 0.9238 - val_loss: 0.3112 - val_accuracy: 0.8642 - val_auc: 0.9522\n",
      "Epoch 26/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3232 - accuracy: 0.7085 - auc: 0.9258Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3201 - accuracy: 0.7087 - auc: 0.9278 - val_loss: 0.3122 - val_accuracy: 0.8632 - val_auc: 0.9537\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.5370 - accuracy: 0.4247 - auc: 0.8567 - val_loss: 0.3266 - val_accuracy: 0.8668 - val_auc: 0.9415\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4029 - accuracy: 0.8508 - auc: 0.9023 - val_loss: 0.2958 - val_accuracy: 0.8993 - val_auc: 0.9515\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3578 - accuracy: 0.8820 - auc: 0.9217 - val_loss: 0.2748 - val_accuracy: 0.9080 - val_auc: 0.9541\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3740 - accuracy: 0.8893 - auc: 0.9113 - val_loss: 0.2789 - val_accuracy: 0.8914 - val_auc: 0.9550\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3501 - accuracy: 0.8976 - auc: 0.9223 - val_loss: 0.2740 - val_accuracy: 0.9007 - val_auc: 0.9548\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3409 - accuracy: 0.9019 - auc: 0.9265 - val_loss: 0.2803 - val_accuracy: 0.8834 - val_auc: 0.9538\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3373 - accuracy: 0.9010 - auc: 0.9268 - val_loss: 0.2803 - val_accuracy: 0.9019 - val_auc: 0.9543\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3496 - accuracy: 0.9028 - auc: 0.9198 - val_loss: 0.2851 - val_accuracy: 0.9117 - val_auc: 0.9535\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3504 - accuracy: 0.9039 - auc: 0.9202 - val_loss: 0.2878 - val_accuracy: 0.9022 - val_auc: 0.9531\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3357 - accuracy: 0.9059 - auc: 0.9276 - val_loss: 0.2921 - val_accuracy: 0.9110 - val_auc: 0.9527\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3375 - accuracy: 0.9039 - auc: 0.9244 - val_loss: 0.2990 - val_accuracy: 0.9041 - val_auc: 0.9497\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3397 - accuracy: 0.9133 - auc: 0.9250 - val_loss: 0.3024 - val_accuracy: 0.8998 - val_auc: 0.9511\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3379 - accuracy: 0.9034 - auc: 0.9269 - val_loss: 0.3056 - val_accuracy: 0.9071 - val_auc: 0.9500\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3359 - accuracy: 0.9010 - auc: 0.9266 - val_loss: 0.3044 - val_accuracy: 0.9023 - val_auc: 0.9514\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3469 - accuracy: 0.9034 - auc: 0.9226 - val_loss: 0.3008 - val_accuracy: 0.9052 - val_auc: 0.9499\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3277 - accuracy: 0.9105 - auc: 0.9266 - val_loss: 0.2998 - val_accuracy: 0.9019 - val_auc: 0.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3206 - accuracy: 0.9106 - auc: 0.9315 - val_loss: 0.3090 - val_accuracy: 0.9080 - val_auc: 0.9500\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3270 - accuracy: 0.9107 - auc: 0.9276 - val_loss: 0.3081 - val_accuracy: 0.9043 - val_auc: 0.9513\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3393 - accuracy: 0.9124 - auc: 0.9239 - val_loss: 0.3085 - val_accuracy: 0.9029 - val_auc: 0.9501\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3204 - accuracy: 0.9059 - auc: 0.9332 - val_loss: 0.3152 - val_accuracy: 0.9106 - val_auc: 0.9507\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3148 - accuracy: 0.9100 - auc: 0.9368 - val_loss: 0.3110 - val_accuracy: 0.9137 - val_auc: 0.9509\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3279 - accuracy: 0.9181 - auc: 0.9290 - val_loss: 0.3131 - val_accuracy: 0.9085 - val_auc: 0.9497\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3164 - accuracy: 0.9132 - auc: 0.9329 - val_loss: 0.3178 - val_accuracy: 0.9120 - val_auc: 0.9506\n",
      "Epoch 24/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3068 - accuracy: 0.9173 - auc: 0.9387Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3106 - accuracy: 0.9175 - auc: 0.9372 - val_loss: 0.3240 - val_accuracy: 0.9174 - val_auc: 0.9511\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 22us/sample - loss: 0.7739 - accuracy: 0.9220 - auc: 0.7041 - val_loss: 0.4136 - val_accuracy: 0.8959 - val_auc: 0.9283\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4500 - accuracy: 0.9102 - auc: 0.8862 - val_loss: 0.3327 - val_accuracy: 0.8995 - val_auc: 0.9402\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3989 - accuracy: 0.8918 - auc: 0.9072 - val_loss: 0.3040 - val_accuracy: 0.9012 - val_auc: 0.9492\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3747 - accuracy: 0.8943 - auc: 0.9166 - val_loss: 0.2942 - val_accuracy: 0.8897 - val_auc: 0.9495\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3472 - accuracy: 0.8974 - auc: 0.9301 - val_loss: 0.2729 - val_accuracy: 0.8947 - val_auc: 0.9558\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3447 - accuracy: 0.8344 - auc: 0.9300 - val_loss: 0.2779 - val_accuracy: 0.8867 - val_auc: 0.9557\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3311 - accuracy: 0.8233 - auc: 0.9327 - val_loss: 0.2873 - val_accuracy: 0.8925 - val_auc: 0.9532\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3204 - accuracy: 0.8246 - auc: 0.9351 - val_loss: 0.2712 - val_accuracy: 0.8732 - val_auc: 0.9568\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3109 - accuracy: 0.8279 - auc: 0.9420 - val_loss: 0.2806 - val_accuracy: 0.8796 - val_auc: 0.9549\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2974 - accuracy: 0.8252 - auc: 0.9459 - val_loss: 0.2769 - val_accuracy: 0.8837 - val_auc: 0.9557\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2902 - accuracy: 0.8331 - auc: 0.9463 - val_loss: 0.2842 - val_accuracy: 0.8854 - val_auc: 0.9539\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2892 - accuracy: 0.8365 - auc: 0.9478 - val_loss: 0.2884 - val_accuracy: 0.8717 - val_auc: 0.9539\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2807 - accuracy: 0.8330 - auc: 0.9500 - val_loss: 0.3161 - val_accuracy: 0.8892 - val_auc: 0.9497\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2807 - accuracy: 0.8328 - auc: 0.9503 - val_loss: 0.3010 - val_accuracy: 0.8801 - val_auc: 0.9524\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2782 - accuracy: 0.8357 - auc: 0.9517 - val_loss: 0.3244 - val_accuracy: 0.8912 - val_auc: 0.9488\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2776 - accuracy: 0.8367 - auc: 0.9517 - val_loss: 0.3184 - val_accuracy: 0.8772 - val_auc: 0.9484\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2698 - accuracy: 0.8315 - auc: 0.9520 - val_loss: 0.3309 - val_accuracy: 0.8867 - val_auc: 0.9504\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2597 - accuracy: 0.8387 - auc: 0.9539 - val_loss: 0.3496 - val_accuracy: 0.8886 - val_auc: 0.9463\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2685 - accuracy: 0.8408 - auc: 0.9543 - val_loss: 0.3515 - val_accuracy: 0.8739 - val_auc: 0.9489\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2639 - accuracy: 0.8329 - auc: 0.9528 - val_loss: 0.3580 - val_accuracy: 0.8890 - val_auc: 0.9505\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2635 - accuracy: 0.8415 - auc: 0.9521 - val_loss: 0.3770 - val_accuracy: 0.8913 - val_auc: 0.9450\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2523 - accuracy: 0.8438 - auc: 0.9562 - val_loss: 0.3785 - val_accuracy: 0.8966 - val_auc: 0.9461\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2466 - accuracy: 0.8503 - auc: 0.9572 - val_loss: 0.3670 - val_accuracy: 0.8943 - val_auc: 0.9482\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2589 - accuracy: 0.8498 - auc: 0.9555 - val_loss: 0.3681 - val_accuracy: 0.8837 - val_auc: 0.9479\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2587 - accuracy: 0.8410 - auc: 0.9550 - val_loss: 0.3806 - val_accuracy: 0.8906 - val_auc: 0.9459\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2623 - accuracy: 0.8416 - auc: 0.9553 - val_loss: 0.3828 - val_accuracy: 0.8899 - val_auc: 0.9438\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2517 - accuracy: 0.8412 - auc: 0.9567 - val_loss: 0.3902 - val_accuracy: 0.8943 - val_auc: 0.9436\n",
      "Epoch 28/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2455 - accuracy: 0.8498 - auc: 0.9584Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2445 - accuracy: 0.8500 - auc: 0.9587 - val_loss: 0.4063 - val_accuracy: 0.8998 - val_auc: 0.9451\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.5673 - accuracy: 0.8392 - auc: 0.8364 - val_loss: 0.3433 - val_accuracy: 0.9046 - val_auc: 0.9407\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3852 - accuracy: 0.9052 - auc: 0.9168 - val_loss: 0.2972 - val_accuracy: 0.9128 - val_auc: 0.9474\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3546 - accuracy: 0.9025 - auc: 0.9292 - val_loss: 0.2803 - val_accuracy: 0.9036 - val_auc: 0.9544\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3289 - accuracy: 0.9046 - auc: 0.9388 - val_loss: 0.2838 - val_accuracy: 0.9069 - val_auc: 0.9514\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3069 - accuracy: 0.9117 - auc: 0.9471 - val_loss: 0.2752 - val_accuracy: 0.8953 - val_auc: 0.9552\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3093 - accuracy: 0.9012 - auc: 0.9455 - val_loss: 0.2767 - val_accuracy: 0.9097 - val_auc: 0.9549\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2938 - accuracy: 0.9045 - auc: 0.9498 - val_loss: 0.2841 - val_accuracy: 0.9040 - val_auc: 0.9534\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3013 - accuracy: 0.8997 - auc: 0.9464 - val_loss: 0.2929 - val_accuracy: 0.9054 - val_auc: 0.9502\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2841 - accuracy: 0.9050 - auc: 0.9531 - val_loss: 0.2931 - val_accuracy: 0.9068 - val_auc: 0.9532\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2753 - accuracy: 0.8989 - auc: 0.9551 - val_loss: 0.3062 - val_accuracy: 0.9040 - val_auc: 0.9532\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2751 - accuracy: 0.8956 - auc: 0.9549 - val_loss: 0.3085 - val_accuracy: 0.8997 - val_auc: 0.9495\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2698 - accuracy: 0.8981 - auc: 0.9570 - val_loss: 0.3144 - val_accuracy: 0.9030 - val_auc: 0.9474\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2578 - accuracy: 0.8946 - auc: 0.9597 - val_loss: 0.3244 - val_accuracy: 0.9111 - val_auc: 0.9483\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2669 - accuracy: 0.8960 - auc: 0.9577 - val_loss: 0.3376 - val_accuracy: 0.9060 - val_auc: 0.9443\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2656 - accuracy: 0.8857 - auc: 0.9572 - val_loss: 0.3418 - val_accuracy: 0.9016 - val_auc: 0.9466\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2541 - accuracy: 0.8854 - auc: 0.9602 - val_loss: 0.3537 - val_accuracy: 0.8926 - val_auc: 0.9453\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2536 - accuracy: 0.8248 - auc: 0.9608 - val_loss: 0.3533 - val_accuracy: 0.8973 - val_auc: 0.9457\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2563 - accuracy: 0.8302 - auc: 0.9604 - val_loss: 0.3482 - val_accuracy: 0.8872 - val_auc: 0.9445\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2599 - accuracy: 0.8136 - auc: 0.9581 - val_loss: 0.3580 - val_accuracy: 0.8854 - val_auc: 0.9459\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2456 - accuracy: 0.8184 - auc: 0.9622 - val_loss: 0.3712 - val_accuracy: 0.8883 - val_auc: 0.9452\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2578 - accuracy: 0.8157 - auc: 0.9591 - val_loss: 0.3795 - val_accuracy: 0.8868 - val_auc: 0.9452\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2513 - accuracy: 0.8173 - auc: 0.9614 - val_loss: 0.3871 - val_accuracy: 0.8886 - val_auc: 0.9433\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2468 - accuracy: 0.8145 - auc: 0.9616 - val_loss: 0.3840 - val_accuracy: 0.8869 - val_auc: 0.9436\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2466 - accuracy: 0.8149 - auc: 0.9614 - val_loss: 0.4017 - val_accuracy: 0.8887 - val_auc: 0.9418\n",
      "Epoch 25/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2435 - accuracy: 0.8153 - auc: 0.9622Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2462 - accuracy: 0.8151 - auc: 0.9615 - val_loss: 0.4197 - val_accuracy: 0.8870 - val_auc: 0.9450\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.6731 - accuracy: 0.8843 - auc: 0.8093 - val_loss: 0.3461 - val_accuracy: 0.9036 - val_auc: 0.9401\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4123 - accuracy: 0.8989 - auc: 0.9079 - val_loss: 0.3175 - val_accuracy: 0.9234 - val_auc: 0.9459\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3700 - accuracy: 0.9141 - auc: 0.9269 - val_loss: 0.3002 - val_accuracy: 0.9043 - val_auc: 0.9517\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3484 - accuracy: 0.9052 - auc: 0.9326 - val_loss: 0.2897 - val_accuracy: 0.9163 - val_auc: 0.9526\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3309 - accuracy: 0.9145 - auc: 0.9387 - val_loss: 0.2843 - val_accuracy: 0.9068 - val_auc: 0.9531\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3256 - accuracy: 0.9097 - auc: 0.9402 - val_loss: 0.2830 - val_accuracy: 0.9132 - val_auc: 0.9522\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3199 - accuracy: 0.9103 - auc: 0.9413 - val_loss: 0.2827 - val_accuracy: 0.9245 - val_auc: 0.9533\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3061 - accuracy: 0.9113 - auc: 0.9458 - val_loss: 0.2759 - val_accuracy: 0.9144 - val_auc: 0.9553\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3065 - accuracy: 0.9115 - auc: 0.9458 - val_loss: 0.2776 - val_accuracy: 0.9056 - val_auc: 0.9550\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3069 - accuracy: 0.9048 - auc: 0.9453 - val_loss: 0.2892 - val_accuracy: 0.9079 - val_auc: 0.9530\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2833 - accuracy: 0.9061 - auc: 0.9537 - val_loss: 0.2872 - val_accuracy: 0.9121 - val_auc: 0.9532\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2785 - accuracy: 0.9069 - auc: 0.9536 - val_loss: 0.2800 - val_accuracy: 0.9146 - val_auc: 0.9569\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2734 - accuracy: 0.9080 - auc: 0.9557 - val_loss: 0.2871 - val_accuracy: 0.9084 - val_auc: 0.9563\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2795 - accuracy: 0.9056 - auc: 0.9543 - val_loss: 0.2875 - val_accuracy: 0.9091 - val_auc: 0.9566\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2858 - accuracy: 0.9009 - auc: 0.9515 - val_loss: 0.2955 - val_accuracy: 0.9151 - val_auc: 0.9557\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2690 - accuracy: 0.9039 - auc: 0.9567 - val_loss: 0.3052 - val_accuracy: 0.9091 - val_auc: 0.9528\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2656 - accuracy: 0.9054 - auc: 0.9566 - val_loss: 0.3044 - val_accuracy: 0.9148 - val_auc: 0.9545\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2641 - accuracy: 0.9074 - auc: 0.9586 - val_loss: 0.3359 - val_accuracy: 0.9168 - val_auc: 0.9512\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2649 - accuracy: 0.9114 - auc: 0.9574 - val_loss: 0.3433 - val_accuracy: 0.9137 - val_auc: 0.9511\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2602 - accuracy: 0.9014 - auc: 0.9595 - val_loss: 0.3420 - val_accuracy: 0.9102 - val_auc: 0.9522\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2570 - accuracy: 0.9060 - auc: 0.9607 - val_loss: 0.3469 - val_accuracy: 0.9179 - val_auc: 0.9511\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2516 - accuracy: 0.9087 - auc: 0.9620 - val_loss: 0.3637 - val_accuracy: 0.9197 - val_auc: 0.9509\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2670 - accuracy: 0.9094 - auc: 0.9574 - val_loss: 0.3686 - val_accuracy: 0.9080 - val_auc: 0.9502\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2566 - accuracy: 0.9105 - auc: 0.9613 - val_loss: 0.3791 - val_accuracy: 0.9140 - val_auc: 0.9503\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2574 - accuracy: 0.9097 - auc: 0.9612 - val_loss: 0.3915 - val_accuracy: 0.9179 - val_auc: 0.9482\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2555 - accuracy: 0.9078 - auc: 0.9608 - val_loss: 0.4087 - val_accuracy: 0.9146 - val_auc: 0.9471\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2527 - accuracy: 0.9082 - auc: 0.9620 - val_loss: 0.4202 - val_accuracy: 0.9131 - val_auc: 0.9465\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2530 - accuracy: 0.9111 - auc: 0.9617 - val_loss: 0.4209 - val_accuracy: 0.9206 - val_auc: 0.9477\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2496 - accuracy: 0.9113 - auc: 0.9617 - val_loss: 0.4125 - val_accuracy: 0.9178 - val_auc: 0.9509\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2451 - accuracy: 0.9119 - auc: 0.9639 - val_loss: 0.4299 - val_accuracy: 0.9170 - val_auc: 0.9457\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2501 - accuracy: 0.9093 - auc: 0.9614 - val_loss: 0.3965 - val_accuracy: 0.9210 - val_auc: 0.9495\n",
      "Epoch 32/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2517 - accuracy: 0.9118 - auc: 0.9621Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2522 - accuracy: 0.9119 - auc: 0.9615 - val_loss: 0.3852 - val_accuracy: 0.9202 - val_auc: 0.9507\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 18us/sample - loss: 0.5302 - accuracy: 0.6834 - auc: 0.8543 - val_loss: 0.3422 - val_accuracy: 0.8857 - val_auc: 0.9319\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3691 - accuracy: 0.8283 - auc: 0.9248 - val_loss: 0.3062 - val_accuracy: 0.8829 - val_auc: 0.9440\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3330 - accuracy: 0.8670 - auc: 0.9343 - val_loss: 0.3034 - val_accuracy: 0.8858 - val_auc: 0.9466\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3066 - accuracy: 0.8801 - auc: 0.9455 - val_loss: 0.2992 - val_accuracy: 0.8936 - val_auc: 0.9490\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2972 - accuracy: 0.8830 - auc: 0.9466 - val_loss: 0.3052 - val_accuracy: 0.9020 - val_auc: 0.9481\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2977 - accuracy: 0.8785 - auc: 0.9461 - val_loss: 0.2979 - val_accuracy: 0.9019 - val_auc: 0.9495\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2971 - accuracy: 0.8878 - auc: 0.9480 - val_loss: 0.2919 - val_accuracy: 0.8934 - val_auc: 0.9514\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2884 - accuracy: 0.8835 - auc: 0.9510 - val_loss: 0.2910 - val_accuracy: 0.8971 - val_auc: 0.9523\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2783 - accuracy: 0.8877 - auc: 0.9531 - val_loss: 0.3055 - val_accuracy: 0.8946 - val_auc: 0.9499\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2786 - accuracy: 0.8786 - auc: 0.9531 - val_loss: 0.3039 - val_accuracy: 0.8989 - val_auc: 0.9508\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2829 - accuracy: 0.8312 - auc: 0.9502 - val_loss: 0.3109 - val_accuracy: 0.8747 - val_auc: 0.9508\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2688 - accuracy: 0.8167 - auc: 0.9558 - val_loss: 0.3249 - val_accuracy: 0.8902 - val_auc: 0.9503\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2814 - accuracy: 0.8191 - auc: 0.9516 - val_loss: 0.3345 - val_accuracy: 0.8834 - val_auc: 0.9483\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2664 - accuracy: 0.8154 - auc: 0.9555 - val_loss: 0.3480 - val_accuracy: 0.8882 - val_auc: 0.9472\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2549 - accuracy: 0.8205 - auc: 0.9592 - val_loss: 0.3714 - val_accuracy: 0.8893 - val_auc: 0.9455\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2523 - accuracy: 0.8301 - auc: 0.9594 - val_loss: 0.3779 - val_accuracy: 0.8905 - val_auc: 0.9449\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2483 - accuracy: 0.8198 - auc: 0.9611 - val_loss: 0.3853 - val_accuracy: 0.8929 - val_auc: 0.9461\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2539 - accuracy: 0.8189 - auc: 0.9599 - val_loss: 0.3901 - val_accuracy: 0.8844 - val_auc: 0.9448\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2590 - accuracy: 0.8201 - auc: 0.9585 - val_loss: 0.3971 - val_accuracy: 0.8917 - val_auc: 0.9433\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2587 - accuracy: 0.8119 - auc: 0.9582 - val_loss: 0.3843 - val_accuracy: 0.8913 - val_auc: 0.9448\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2493 - accuracy: 0.8185 - auc: 0.9601 - val_loss: 0.3876 - val_accuracy: 0.8934 - val_auc: 0.9443\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2493 - accuracy: 0.8203 - auc: 0.9616 - val_loss: 0.4103 - val_accuracy: 0.8864 - val_auc: 0.9415\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2587 - accuracy: 0.8130 - auc: 0.9588 - val_loss: 0.4130 - val_accuracy: 0.8944 - val_auc: 0.9440\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2702 - accuracy: 0.8114 - auc: 0.9557 - val_loss: 0.4083 - val_accuracy: 0.8842 - val_auc: 0.9434\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2481 - accuracy: 0.8145 - auc: 0.9591 - val_loss: 0.4335 - val_accuracy: 0.8893 - val_auc: 0.9427\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2503 - accuracy: 0.8163 - auc: 0.9602 - val_loss: 0.4476 - val_accuracy: 0.8862 - val_auc: 0.9425\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2412 - accuracy: 0.8121 - auc: 0.9622 - val_loss: 0.4572 - val_accuracy: 0.8891 - val_auc: 0.9424\n",
      "Epoch 28/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2406 - accuracy: 0.8102 - auc: 0.9636Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2407 - accuracy: 0.8103 - auc: 0.9635 - val_loss: 0.4852 - val_accuracy: 0.8909 - val_auc: 0.9387\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.5520 - accuracy: 0.4578 - auc: 0.8747 - val_loss: 0.3210 - val_accuracy: 0.8302 - val_auc: 0.9495\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3742 - accuracy: 0.6897 - auc: 0.9328 - val_loss: 0.2782 - val_accuracy: 0.8751 - val_auc: 0.9549\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3310 - accuracy: 0.8472 - auc: 0.9405 - val_loss: 0.2675 - val_accuracy: 0.8780 - val_auc: 0.9575\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3030 - accuracy: 0.8706 - auc: 0.9509 - val_loss: 0.2627 - val_accuracy: 0.9089 - val_auc: 0.9588\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3027 - accuracy: 0.8865 - auc: 0.9511 - val_loss: 0.2695 - val_accuracy: 0.9076 - val_auc: 0.9561\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2910 - accuracy: 0.8983 - auc: 0.9512 - val_loss: 0.2786 - val_accuracy: 0.9036 - val_auc: 0.9537\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2735 - accuracy: 0.8999 - auc: 0.9587 - val_loss: 0.2810 - val_accuracy: 0.9104 - val_auc: 0.9541\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2871 - accuracy: 0.9001 - auc: 0.9540 - val_loss: 0.2828 - val_accuracy: 0.9069 - val_auc: 0.9533\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2796 - accuracy: 0.9046 - auc: 0.9567 - val_loss: 0.2836 - val_accuracy: 0.9073 - val_auc: 0.9526\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2746 - accuracy: 0.9053 - auc: 0.9577 - val_loss: 0.2937 - val_accuracy: 0.9023 - val_auc: 0.9521\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2727 - accuracy: 0.9058 - auc: 0.9568 - val_loss: 0.2917 - val_accuracy: 0.9071 - val_auc: 0.9516\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2633 - accuracy: 0.9083 - auc: 0.9602 - val_loss: 0.2924 - val_accuracy: 0.9100 - val_auc: 0.9523\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2718 - accuracy: 0.9099 - auc: 0.9585 - val_loss: 0.3037 - val_accuracy: 0.9135 - val_auc: 0.9509\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2609 - accuracy: 0.9099 - auc: 0.9610 - val_loss: 0.3152 - val_accuracy: 0.9262 - val_auc: 0.9498\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2667 - accuracy: 0.9157 - auc: 0.9595 - val_loss: 0.3111 - val_accuracy: 0.9097 - val_auc: 0.9495\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2770 - accuracy: 0.9086 - auc: 0.9579 - val_loss: 0.3129 - val_accuracy: 0.9036 - val_auc: 0.9492\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2713 - accuracy: 0.9075 - auc: 0.9587 - val_loss: 0.3157 - val_accuracy: 0.9141 - val_auc: 0.9483\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2660 - accuracy: 0.9151 - auc: 0.9604 - val_loss: 0.3287 - val_accuracy: 0.9169 - val_auc: 0.9483\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2578 - accuracy: 0.9130 - auc: 0.9608 - val_loss: 0.3421 - val_accuracy: 0.9102 - val_auc: 0.9471\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2693 - accuracy: 0.9164 - auc: 0.9586 - val_loss: 0.3362 - val_accuracy: 0.9169 - val_auc: 0.9476\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2631 - accuracy: 0.9138 - auc: 0.9599 - val_loss: 0.3439 - val_accuracy: 0.9224 - val_auc: 0.9461\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2665 - accuracy: 0.9153 - auc: 0.9594 - val_loss: 0.3463 - val_accuracy: 0.9141 - val_auc: 0.9480\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2582 - accuracy: 0.9146 - auc: 0.9618 - val_loss: 0.3643 - val_accuracy: 0.9303 - val_auc: 0.9470\n",
      "Epoch 24/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2574 - accuracy: 0.9156 - auc: 0.9613Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2581 - accuracy: 0.9160 - auc: 0.9607 - val_loss: 0.3599 - val_accuracy: 0.9258 - val_auc: 0.9478\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5672 - accuracy: 0.6333 - auc: 0.8737 - val_loss: 0.3462 - val_accuracy: 0.8572 - val_auc: 0.9411\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3661 - accuracy: 0.8046 - auc: 0.9313 - val_loss: 0.2848 - val_accuracy: 0.8768 - val_auc: 0.9512\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3081 - accuracy: 0.8355 - auc: 0.9467 - val_loss: 0.2763 - val_accuracy: 0.8896 - val_auc: 0.9545\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2992 - accuracy: 0.8484 - auc: 0.9498 - val_loss: 0.2681 - val_accuracy: 0.8862 - val_auc: 0.9564\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2654 - accuracy: 0.8622 - auc: 0.9591 - val_loss: 0.2713 - val_accuracy: 0.8957 - val_auc: 0.9564\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2773 - accuracy: 0.8677 - auc: 0.9555 - val_loss: 0.2798 - val_accuracy: 0.8937 - val_auc: 0.9542\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2641 - accuracy: 0.8728 - auc: 0.9587 - val_loss: 0.2734 - val_accuracy: 0.8977 - val_auc: 0.9565\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2537 - accuracy: 0.8818 - auc: 0.9615 - val_loss: 0.2870 - val_accuracy: 0.9114 - val_auc: 0.9559\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2458 - accuracy: 0.8913 - auc: 0.9636 - val_loss: 0.2837 - val_accuracy: 0.8888 - val_auc: 0.9565\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2415 - accuracy: 0.8901 - auc: 0.9647 - val_loss: 0.2958 - val_accuracy: 0.9042 - val_auc: 0.9548\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2526 - accuracy: 0.8828 - auc: 0.9622 - val_loss: 0.2944 - val_accuracy: 0.9057 - val_auc: 0.9526\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2416 - accuracy: 0.8923 - auc: 0.9652 - val_loss: 0.3052 - val_accuracy: 0.9117 - val_auc: 0.9523\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2385 - accuracy: 0.8974 - auc: 0.9660 - val_loss: 0.3044 - val_accuracy: 0.9103 - val_auc: 0.9538\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2355 - accuracy: 0.8952 - auc: 0.9664 - val_loss: 0.3129 - val_accuracy: 0.9081 - val_auc: 0.9541\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2332 - accuracy: 0.8978 - auc: 0.9669 - val_loss: 0.3324 - val_accuracy: 0.9135 - val_auc: 0.9510\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2315 - accuracy: 0.9016 - auc: 0.9673 - val_loss: 0.3416 - val_accuracy: 0.9134 - val_auc: 0.9511\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2309 - accuracy: 0.8934 - auc: 0.9676 - val_loss: 0.3290 - val_accuracy: 0.9134 - val_auc: 0.9532\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2362 - accuracy: 0.8981 - auc: 0.9669 - val_loss: 0.3241 - val_accuracy: 0.9116 - val_auc: 0.9535\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2342 - accuracy: 0.8931 - auc: 0.9670 - val_loss: 0.3432 - val_accuracy: 0.9212 - val_auc: 0.9513\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2219 - accuracy: 0.9010 - auc: 0.9695 - val_loss: 0.3571 - val_accuracy: 0.9117 - val_auc: 0.9511\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2282 - accuracy: 0.8990 - auc: 0.9685 - val_loss: 0.3749 - val_accuracy: 0.9205 - val_auc: 0.9501\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2350 - accuracy: 0.9028 - auc: 0.9669 - val_loss: 0.3678 - val_accuracy: 0.9008 - val_auc: 0.9497\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2234 - accuracy: 0.8994 - auc: 0.9704 - val_loss: 0.4003 - val_accuracy: 0.9225 - val_auc: 0.9484\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2176 - accuracy: 0.9047 - auc: 0.9707 - val_loss: 0.4286 - val_accuracy: 0.9207 - val_auc: 0.9452\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2261 - accuracy: 0.9007 - auc: 0.9692 - val_loss: 0.4305 - val_accuracy: 0.9224 - val_auc: 0.9451\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2190 - accuracy: 0.9066 - auc: 0.9710 - val_loss: 0.4363 - val_accuracy: 0.9253 - val_auc: 0.9472\n",
      "Epoch 27/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.9033 - auc: 0.9695Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2258 - accuracy: 0.9035 - auc: 0.9694 - val_loss: 0.4415 - val_accuracy: 0.9257 - val_auc: 0.9456\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 0.5309 - accuracy: 0.7132 - auc: 0.8715 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_auc: 0.9415\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3279 - accuracy: 0.8722 - auc: 0.9398 - val_loss: 0.2816 - val_accuracy: 0.9062 - val_auc: 0.9525\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2955 - accuracy: 0.8870 - auc: 0.9499 - val_loss: 0.2758 - val_accuracy: 0.9042 - val_auc: 0.9544\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2889 - accuracy: 0.8948 - auc: 0.9516 - val_loss: 0.2771 - val_accuracy: 0.9009 - val_auc: 0.9536\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2759 - accuracy: 0.8896 - auc: 0.9567 - val_loss: 0.2759 - val_accuracy: 0.9114 - val_auc: 0.9548\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2633 - accuracy: 0.9023 - auc: 0.9591 - val_loss: 0.2798 - val_accuracy: 0.9064 - val_auc: 0.9553\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2577 - accuracy: 0.9062 - auc: 0.9611 - val_loss: 0.2836 - val_accuracy: 0.9215 - val_auc: 0.9546\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2576 - accuracy: 0.9059 - auc: 0.9610 - val_loss: 0.2909 - val_accuracy: 0.9218 - val_auc: 0.9536\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2590 - accuracy: 0.9092 - auc: 0.9622 - val_loss: 0.3014 - val_accuracy: 0.9148 - val_auc: 0.9526\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2541 - accuracy: 0.9056 - auc: 0.9629 - val_loss: 0.3082 - val_accuracy: 0.9230 - val_auc: 0.9509\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2464 - accuracy: 0.9090 - auc: 0.9645 - val_loss: 0.3025 - val_accuracy: 0.9181 - val_auc: 0.9516\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2467 - accuracy: 0.9090 - auc: 0.9642 - val_loss: 0.3117 - val_accuracy: 0.9194 - val_auc: 0.9507\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2232 - accuracy: 0.9081 - auc: 0.9701 - val_loss: 0.3219 - val_accuracy: 0.9169 - val_auc: 0.9508\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2386 - accuracy: 0.9111 - auc: 0.9658 - val_loss: 0.3199 - val_accuracy: 0.9198 - val_auc: 0.9491\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2344 - accuracy: 0.9119 - auc: 0.9678 - val_loss: 0.3279 - val_accuracy: 0.9221 - val_auc: 0.9488\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2285 - accuracy: 0.9131 - auc: 0.9688 - val_loss: 0.3471 - val_accuracy: 0.9189 - val_auc: 0.9454\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2256 - accuracy: 0.9108 - auc: 0.9689 - val_loss: 0.3606 - val_accuracy: 0.9222 - val_auc: 0.9456\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2251 - accuracy: 0.9105 - auc: 0.9692 - val_loss: 0.3504 - val_accuracy: 0.9169 - val_auc: 0.9464\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2259 - accuracy: 0.9071 - auc: 0.9688 - val_loss: 0.3458 - val_accuracy: 0.9162 - val_auc: 0.9484\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2247 - accuracy: 0.9088 - auc: 0.9694 - val_loss: 0.3602 - val_accuracy: 0.9207 - val_auc: 0.9469\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2230 - accuracy: 0.9088 - auc: 0.9700 - val_loss: 0.3751 - val_accuracy: 0.9166 - val_auc: 0.9436\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2215 - accuracy: 0.9105 - auc: 0.9705 - val_loss: 0.3894 - val_accuracy: 0.9119 - val_auc: 0.9422\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2175 - accuracy: 0.9101 - auc: 0.9708 - val_loss: 0.4117 - val_accuracy: 0.9283 - val_auc: 0.9424\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2179 - accuracy: 0.9120 - auc: 0.9711 - val_loss: 0.4123 - val_accuracy: 0.9226 - val_auc: 0.9421\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2127 - accuracy: 0.9086 - auc: 0.9721 - val_loss: 0.4295 - val_accuracy: 0.9245 - val_auc: 0.9409\n",
      "Epoch 26/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2192 - accuracy: 0.9073 - auc: 0.9713Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2179 - accuracy: 0.9073 - auc: 0.9715 - val_loss: 0.4123 - val_accuracy: 0.9200 - val_auc: 0.9452\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6031 - accuracy: 0.6484 - auc: 0.8615 - val_loss: 0.3159 - val_accuracy: 0.8328 - val_auc: 0.9459\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3567 - accuracy: 0.8139 - auc: 0.9322 - val_loss: 0.2862 - val_accuracy: 0.8701 - val_auc: 0.9519\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3121 - accuracy: 0.8365 - auc: 0.9451 - val_loss: 0.2773 - val_accuracy: 0.8978 - val_auc: 0.9542\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3058 - accuracy: 0.8435 - auc: 0.9462 - val_loss: 0.2659 - val_accuracy: 0.8949 - val_auc: 0.9577\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2798 - accuracy: 0.8607 - auc: 0.9527 - val_loss: 0.2690 - val_accuracy: 0.8990 - val_auc: 0.9571\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2786 - accuracy: 0.8673 - auc: 0.9545 - val_loss: 0.2719 - val_accuracy: 0.8958 - val_auc: 0.9568\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2662 - accuracy: 0.8717 - auc: 0.9576 - val_loss: 0.2817 - val_accuracy: 0.8916 - val_auc: 0.9546\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2629 - accuracy: 0.8716 - auc: 0.9584 - val_loss: 0.2823 - val_accuracy: 0.8996 - val_auc: 0.9553\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2497 - accuracy: 0.8778 - auc: 0.9615 - val_loss: 0.2867 - val_accuracy: 0.9035 - val_auc: 0.9561\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2447 - accuracy: 0.8811 - auc: 0.9636 - val_loss: 0.2992 - val_accuracy: 0.9010 - val_auc: 0.9534\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2369 - accuracy: 0.8874 - auc: 0.9651 - val_loss: 0.3110 - val_accuracy: 0.9100 - val_auc: 0.9524\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2565 - accuracy: 0.8854 - auc: 0.9603 - val_loss: 0.3032 - val_accuracy: 0.8987 - val_auc: 0.9533\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2397 - accuracy: 0.8893 - auc: 0.9644 - val_loss: 0.3094 - val_accuracy: 0.9051 - val_auc: 0.9539\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2392 - accuracy: 0.8881 - auc: 0.9641 - val_loss: 0.3159 - val_accuracy: 0.8957 - val_auc: 0.9519\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2383 - accuracy: 0.8822 - auc: 0.9652 - val_loss: 0.3320 - val_accuracy: 0.9100 - val_auc: 0.9521\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2329 - accuracy: 0.8904 - auc: 0.9663 - val_loss: 0.3329 - val_accuracy: 0.9114 - val_auc: 0.9530\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2272 - accuracy: 0.8919 - auc: 0.9675 - val_loss: 0.3424 - val_accuracy: 0.9139 - val_auc: 0.9514\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2318 - accuracy: 0.8895 - auc: 0.9663 - val_loss: 0.3654 - val_accuracy: 0.9221 - val_auc: 0.9502\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2225 - accuracy: 0.8878 - auc: 0.9684 - val_loss: 0.3614 - val_accuracy: 0.9086 - val_auc: 0.9492\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2280 - accuracy: 0.8756 - auc: 0.9670 - val_loss: 0.3726 - val_accuracy: 0.9071 - val_auc: 0.9472\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2256 - accuracy: 0.8764 - auc: 0.9676 - val_loss: 0.3933 - val_accuracy: 0.9096 - val_auc: 0.9469\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2160 - accuracy: 0.8727 - auc: 0.9699 - val_loss: 0.3947 - val_accuracy: 0.9099 - val_auc: 0.9484\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2155 - accuracy: 0.8797 - auc: 0.9698 - val_loss: 0.4067 - val_accuracy: 0.9101 - val_auc: 0.9483\n",
      "Epoch 24/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2202 - accuracy: 0.8737 - auc: 0.9695Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2186 - accuracy: 0.8737 - auc: 0.9698 - val_loss: 0.4252 - val_accuracy: 0.9132 - val_auc: 0.9437\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.4836 - accuracy: 0.6958 - auc: 0.8866 - val_loss: 0.2991 - val_accuracy: 0.8659 - val_auc: 0.9468\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3432 - accuracy: 0.8261 - auc: 0.9336 - val_loss: 0.2824 - val_accuracy: 0.8712 - val_auc: 0.9528\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3059 - accuracy: 0.8538 - auc: 0.9461 - val_loss: 0.2667 - val_accuracy: 0.8963 - val_auc: 0.9570\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3004 - accuracy: 0.8631 - auc: 0.9473 - val_loss: 0.2618 - val_accuracy: 0.8821 - val_auc: 0.9589\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2724 - accuracy: 0.8874 - auc: 0.9562 - val_loss: 0.2691 - val_accuracy: 0.8974 - val_auc: 0.9561\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2651 - accuracy: 0.8890 - auc: 0.9585 - val_loss: 0.2772 - val_accuracy: 0.9110 - val_auc: 0.9556\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2775 - accuracy: 0.8919 - auc: 0.9553 - val_loss: 0.2763 - val_accuracy: 0.9031 - val_auc: 0.9552\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2644 - accuracy: 0.8949 - auc: 0.9581 - val_loss: 0.2820 - val_accuracy: 0.9037 - val_auc: 0.9545\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2658 - accuracy: 0.8956 - auc: 0.9592 - val_loss: 0.2888 - val_accuracy: 0.9124 - val_auc: 0.9528\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2528 - accuracy: 0.8983 - auc: 0.9617 - val_loss: 0.2866 - val_accuracy: 0.9120 - val_auc: 0.9553\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2492 - accuracy: 0.8942 - auc: 0.9626 - val_loss: 0.3017 - val_accuracy: 0.9112 - val_auc: 0.9528\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2393 - accuracy: 0.9023 - auc: 0.9654 - val_loss: 0.3121 - val_accuracy: 0.9091 - val_auc: 0.9506\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2569 - accuracy: 0.8999 - auc: 0.9634 - val_loss: 0.3023 - val_accuracy: 0.9132 - val_auc: 0.9518\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2345 - accuracy: 0.8984 - auc: 0.9667 - val_loss: 0.3126 - val_accuracy: 0.9110 - val_auc: 0.9515\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2338 - accuracy: 0.9036 - auc: 0.9665 - val_loss: 0.3159 - val_accuracy: 0.9110 - val_auc: 0.9511\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2300 - accuracy: 0.8988 - auc: 0.9669 - val_loss: 0.3360 - val_accuracy: 0.9164 - val_auc: 0.9501\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2265 - accuracy: 0.9037 - auc: 0.9684 - val_loss: 0.3438 - val_accuracy: 0.9161 - val_auc: 0.9494\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2305 - accuracy: 0.9009 - auc: 0.9677 - val_loss: 0.3419 - val_accuracy: 0.9092 - val_auc: 0.9505\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2222 - accuracy: 0.9002 - auc: 0.9693 - val_loss: 0.3636 - val_accuracy: 0.9177 - val_auc: 0.9470\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2272 - accuracy: 0.9021 - auc: 0.9684 - val_loss: 0.3619 - val_accuracy: 0.9144 - val_auc: 0.9467\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2216 - accuracy: 0.9050 - auc: 0.9701 - val_loss: 0.3823 - val_accuracy: 0.9261 - val_auc: 0.9446\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2228 - accuracy: 0.9059 - auc: 0.9693 - val_loss: 0.3617 - val_accuracy: 0.9164 - val_auc: 0.9491\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2180 - accuracy: 0.9024 - auc: 0.9698 - val_loss: 0.3852 - val_accuracy: 0.9161 - val_auc: 0.9477\n",
      "Epoch 24/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2146 - accuracy: 0.8990 - auc: 0.9710Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2162 - accuracy: 0.8992 - auc: 0.9706 - val_loss: 0.4132 - val_accuracy: 0.9205 - val_auc: 0.9445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.5394 - accuracy: 0.6909 - auc: 0.8702 - val_loss: 0.2864 - val_accuracy: 0.8887 - val_auc: 0.9505\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3441 - accuracy: 0.8381 - auc: 0.9380 - val_loss: 0.2731 - val_accuracy: 0.8849 - val_auc: 0.9562\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3074 - accuracy: 0.8485 - auc: 0.9476 - val_loss: 0.2738 - val_accuracy: 0.9032 - val_auc: 0.9561\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2819 - accuracy: 0.8699 - auc: 0.9541 - val_loss: 0.2744 - val_accuracy: 0.9018 - val_auc: 0.9561\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2856 - accuracy: 0.8811 - auc: 0.9548 - val_loss: 0.2800 - val_accuracy: 0.9006 - val_auc: 0.9559\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2580 - accuracy: 0.8846 - auc: 0.9608 - val_loss: 0.2881 - val_accuracy: 0.8976 - val_auc: 0.9541\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2615 - accuracy: 0.8891 - auc: 0.9597 - val_loss: 0.2889 - val_accuracy: 0.8954 - val_auc: 0.9541\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2523 - accuracy: 0.8902 - auc: 0.9624 - val_loss: 0.3042 - val_accuracy: 0.9062 - val_auc: 0.9527\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2548 - accuracy: 0.8897 - auc: 0.9616 - val_loss: 0.3152 - val_accuracy: 0.9053 - val_auc: 0.9518\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2470 - accuracy: 0.8941 - auc: 0.9638 - val_loss: 0.3082 - val_accuracy: 0.9078 - val_auc: 0.9522\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2522 - accuracy: 0.8941 - auc: 0.9630 - val_loss: 0.3166 - val_accuracy: 0.9073 - val_auc: 0.9501\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2384 - accuracy: 0.8997 - auc: 0.9659 - val_loss: 0.3294 - val_accuracy: 0.9007 - val_auc: 0.9480\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2309 - accuracy: 0.8991 - auc: 0.9678 - val_loss: 0.3421 - val_accuracy: 0.9174 - val_auc: 0.9505\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2356 - accuracy: 0.8998 - auc: 0.9671 - val_loss: 0.3518 - val_accuracy: 0.9127 - val_auc: 0.9485\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2394 - accuracy: 0.8963 - auc: 0.9657 - val_loss: 0.3660 - val_accuracy: 0.9137 - val_auc: 0.9474\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2287 - accuracy: 0.8984 - auc: 0.9680 - val_loss: 0.3883 - val_accuracy: 0.9177 - val_auc: 0.9451\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2303 - accuracy: 0.9001 - auc: 0.9677 - val_loss: 0.3798 - val_accuracy: 0.9143 - val_auc: 0.9452\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2208 - accuracy: 0.8987 - auc: 0.9701 - val_loss: 0.4046 - val_accuracy: 0.9165 - val_auc: 0.9456\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2296 - accuracy: 0.8986 - auc: 0.9676 - val_loss: 0.4065 - val_accuracy: 0.9147 - val_auc: 0.9463\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2250 - accuracy: 0.8993 - auc: 0.9691 - val_loss: 0.4216 - val_accuracy: 0.9141 - val_auc: 0.9437\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2114 - accuracy: 0.9004 - auc: 0.9720 - val_loss: 0.4408 - val_accuracy: 0.9147 - val_auc: 0.9441\n",
      "Epoch 22/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2181 - accuracy: 0.8996 - auc: 0.9710Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2178 - accuracy: 0.8995 - auc: 0.9711 - val_loss: 0.4690 - val_accuracy: 0.9157 - val_auc: 0.9416\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6099 - accuracy: 0.8465 - auc: 0.8589 - val_loss: 0.3266 - val_accuracy: 0.8891 - val_auc: 0.9432\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3475 - accuracy: 0.9003 - auc: 0.9371 - val_loss: 0.2986 - val_accuracy: 0.9011 - val_auc: 0.9577\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3134 - accuracy: 0.9056 - auc: 0.9501 - val_loss: 0.2855 - val_accuracy: 0.9137 - val_auc: 0.9582\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3022 - accuracy: 0.9086 - auc: 0.9533 - val_loss: 0.2747 - val_accuracy: 0.9113 - val_auc: 0.9595\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2896 - accuracy: 0.9123 - auc: 0.9566 - val_loss: 0.2731 - val_accuracy: 0.9026 - val_auc: 0.9585\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2796 - accuracy: 0.9119 - auc: 0.9582 - val_loss: 0.2779 - val_accuracy: 0.9132 - val_auc: 0.9553\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2792 - accuracy: 0.9133 - auc: 0.9578 - val_loss: 0.2706 - val_accuracy: 0.9299 - val_auc: 0.9590\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2726 - accuracy: 0.9178 - auc: 0.9602 - val_loss: 0.2715 - val_accuracy: 0.9006 - val_auc: 0.9585\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2711 - accuracy: 0.9126 - auc: 0.9598 - val_loss: 0.2768 - val_accuracy: 0.9136 - val_auc: 0.9571\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2664 - accuracy: 0.9152 - auc: 0.9616 - val_loss: 0.2686 - val_accuracy: 0.9125 - val_auc: 0.9574\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2657 - accuracy: 0.9163 - auc: 0.9604 - val_loss: 0.2725 - val_accuracy: 0.9092 - val_auc: 0.9566\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2542 - accuracy: 0.9138 - auc: 0.9642 - val_loss: 0.2813 - val_accuracy: 0.9193 - val_auc: 0.9546\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2534 - accuracy: 0.9147 - auc: 0.9633 - val_loss: 0.2850 - val_accuracy: 0.9236 - val_auc: 0.9539\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2521 - accuracy: 0.9128 - auc: 0.9640 - val_loss: 0.2790 - val_accuracy: 0.9147 - val_auc: 0.9553\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2672 - accuracy: 0.9157 - auc: 0.9616 - val_loss: 0.2908 - val_accuracy: 0.9292 - val_auc: 0.9545\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2552 - accuracy: 0.9143 - auc: 0.9632 - val_loss: 0.2807 - val_accuracy: 0.9192 - val_auc: 0.9552\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2447 - accuracy: 0.9168 - auc: 0.9660 - val_loss: 0.3000 - val_accuracy: 0.9121 - val_auc: 0.9507\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2421 - accuracy: 0.9146 - auc: 0.9659 - val_loss: 0.3243 - val_accuracy: 0.9202 - val_auc: 0.9466\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2343 - accuracy: 0.9179 - auc: 0.9684 - val_loss: 0.3222 - val_accuracy: 0.9184 - val_auc: 0.9483\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2376 - accuracy: 0.9144 - auc: 0.9675 - val_loss: 0.3327 - val_accuracy: 0.9213 - val_auc: 0.9475\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2279 - accuracy: 0.9165 - auc: 0.9701 - val_loss: 0.3648 - val_accuracy: 0.9269 - val_auc: 0.9458\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2420 - accuracy: 0.9184 - auc: 0.9669 - val_loss: 0.3519 - val_accuracy: 0.9093 - val_auc: 0.9485\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2267 - accuracy: 0.9117 - auc: 0.9695 - val_loss: 0.3698 - val_accuracy: 0.9261 - val_auc: 0.9441\n",
      "Epoch 24/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2273 - accuracy: 0.9164 - auc: 0.9693Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2276 - accuracy: 0.9163 - auc: 0.9694 - val_loss: 0.3864 - val_accuracy: 0.9253 - val_auc: 0.9439\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.5452 - accuracy: 0.7485 - auc: 0.8823 - val_loss: 0.3220 - val_accuracy: 0.8787 - val_auc: 0.9431\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3291 - accuracy: 0.8501 - auc: 0.9387 - val_loss: 0.2764 - val_accuracy: 0.8867 - val_auc: 0.9540\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3006 - accuracy: 0.8747 - auc: 0.9487 - val_loss: 0.2819 - val_accuracy: 0.8934 - val_auc: 0.9524\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2703 - accuracy: 0.8807 - auc: 0.9563 - val_loss: 0.2924 - val_accuracy: 0.9021 - val_auc: 0.9521\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2666 - accuracy: 0.8809 - auc: 0.9578 - val_loss: 0.2817 - val_accuracy: 0.9004 - val_auc: 0.9537\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2666 - accuracy: 0.8904 - auc: 0.9580 - val_loss: 0.2833 - val_accuracy: 0.8908 - val_auc: 0.9529\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2435 - accuracy: 0.8907 - auc: 0.9643 - val_loss: 0.3008 - val_accuracy: 0.9174 - val_auc: 0.9508\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2436 - accuracy: 0.8971 - auc: 0.9640 - val_loss: 0.3013 - val_accuracy: 0.9076 - val_auc: 0.9511\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2320 - accuracy: 0.8990 - auc: 0.9672 - val_loss: 0.3306 - val_accuracy: 0.9135 - val_auc: 0.9494\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2554 - accuracy: 0.8968 - auc: 0.9630 - val_loss: 0.3323 - val_accuracy: 0.8908 - val_auc: 0.9472\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2340 - accuracy: 0.8971 - auc: 0.9670 - val_loss: 0.3190 - val_accuracy: 0.9121 - val_auc: 0.9511\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2277 - accuracy: 0.9061 - auc: 0.9685 - val_loss: 0.3283 - val_accuracy: 0.9035 - val_auc: 0.9521\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2364 - accuracy: 0.8943 - auc: 0.9667 - val_loss: 0.3484 - val_accuracy: 0.9159 - val_auc: 0.9473\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2384 - accuracy: 0.9000 - auc: 0.9671 - val_loss: 0.3607 - val_accuracy: 0.9230 - val_auc: 0.9479\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2265 - accuracy: 0.9040 - auc: 0.9688 - val_loss: 0.3693 - val_accuracy: 0.9138 - val_auc: 0.9473\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2280 - accuracy: 0.8974 - auc: 0.9682 - val_loss: 0.3818 - val_accuracy: 0.9210 - val_auc: 0.9453\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2130 - accuracy: 0.9038 - auc: 0.9721 - val_loss: 0.3991 - val_accuracy: 0.9205 - val_auc: 0.9476\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2192 - accuracy: 0.9072 - auc: 0.9707 - val_loss: 0.3967 - val_accuracy: 0.9120 - val_auc: 0.9487\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2214 - accuracy: 0.8990 - auc: 0.9699 - val_loss: 0.4235 - val_accuracy: 0.9171 - val_auc: 0.9444\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2352 - accuracy: 0.9051 - auc: 0.9729 - val_loss: 0.4205 - val_accuracy: 0.9281 - val_auc: 0.9453\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2141 - accuracy: 0.9095 - auc: 0.9720 - val_loss: 0.4217 - val_accuracy: 0.9156 - val_auc: 0.9462\n",
      "Epoch 22/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9039 - auc: 0.9711Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2161 - accuracy: 0.9036 - auc: 0.9710 - val_loss: 0.4112 - val_accuracy: 0.9083 - val_auc: 0.9464\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 21us/sample - loss: 0.5314 - accuracy: 0.7034 - auc: 0.8654 - val_loss: 0.3140 - val_accuracy: 0.8318 - val_auc: 0.9464\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3358 - accuracy: 0.8234 - auc: 0.9370 - val_loss: 0.2714 - val_accuracy: 0.8774 - val_auc: 0.9561\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3210 - accuracy: 0.8441 - auc: 0.9413 - val_loss: 0.2664 - val_accuracy: 0.8927 - val_auc: 0.9568\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2789 - accuracy: 0.8647 - auc: 0.9532 - val_loss: 0.2770 - val_accuracy: 0.8985 - val_auc: 0.9543\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2774 - accuracy: 0.8736 - auc: 0.9543 - val_loss: 0.2737 - val_accuracy: 0.8992 - val_auc: 0.9556\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2640 - accuracy: 0.8715 - auc: 0.9572 - val_loss: 0.2881 - val_accuracy: 0.9003 - val_auc: 0.9534\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2534 - accuracy: 0.8796 - auc: 0.9611 - val_loss: 0.2847 - val_accuracy: 0.8950 - val_auc: 0.9537\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2461 - accuracy: 0.8832 - auc: 0.9625 - val_loss: 0.2866 - val_accuracy: 0.8930 - val_auc: 0.9539\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2343 - accuracy: 0.8871 - auc: 0.9657 - val_loss: 0.2986 - val_accuracy: 0.8950 - val_auc: 0.9524\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2316 - accuracy: 0.8879 - auc: 0.9664 - val_loss: 0.3246 - val_accuracy: 0.9092 - val_auc: 0.9511\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2319 - accuracy: 0.8878 - auc: 0.9664 - val_loss: 0.3179 - val_accuracy: 0.9127 - val_auc: 0.9524\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2211 - accuracy: 0.8954 - auc: 0.9693 - val_loss: 0.3293 - val_accuracy: 0.9129 - val_auc: 0.9514\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2232 - accuracy: 0.8982 - auc: 0.9683 - val_loss: 0.3385 - val_accuracy: 0.9003 - val_auc: 0.9484\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2192 - accuracy: 0.8946 - auc: 0.9695 - val_loss: 0.3584 - val_accuracy: 0.8966 - val_auc: 0.9498\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2321 - accuracy: 0.8915 - auc: 0.9665 - val_loss: 0.3537 - val_accuracy: 0.9114 - val_auc: 0.9505\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2188 - accuracy: 0.8982 - auc: 0.9700 - val_loss: 0.3853 - val_accuracy: 0.9148 - val_auc: 0.9454\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2176 - accuracy: 0.8961 - auc: 0.9698 - val_loss: 0.3897 - val_accuracy: 0.9105 - val_auc: 0.9493\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2100 - accuracy: 0.8964 - auc: 0.9717 - val_loss: 0.4205 - val_accuracy: 0.9144 - val_auc: 0.9475\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2001 - accuracy: 0.9010 - auc: 0.9732 - val_loss: 0.4385 - val_accuracy: 0.9152 - val_auc: 0.9400\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2051 - accuracy: 0.8980 - auc: 0.9722 - val_loss: 0.4326 - val_accuracy: 0.9107 - val_auc: 0.9422\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2176 - accuracy: 0.8927 - auc: 0.9707 - val_loss: 0.4385 - val_accuracy: 0.9194 - val_auc: 0.9397\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2168 - accuracy: 0.8970 - auc: 0.9700 - val_loss: 0.4620 - val_accuracy: 0.9189 - val_auc: 0.9424\n",
      "Epoch 23/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2121 - accuracy: 0.8937 - auc: 0.9712Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2120 - accuracy: 0.8937 - auc: 0.9713 - val_loss: 0.4707 - val_accuracy: 0.9173 - val_auc: 0.9422\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.4684 - accuracy: 0.8117 - auc: 0.8864 - val_loss: 0.3029 - val_accuracy: 0.8641 - val_auc: 0.9522\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3214 - accuracy: 0.8821 - auc: 0.9396 - val_loss: 0.2783 - val_accuracy: 0.8971 - val_auc: 0.9532\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3001 - accuracy: 0.8994 - auc: 0.9480 - val_loss: 0.2661 - val_accuracy: 0.8991 - val_auc: 0.9594\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2862 - accuracy: 0.9002 - auc: 0.9519 - val_loss: 0.2652 - val_accuracy: 0.8986 - val_auc: 0.9603\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2724 - accuracy: 0.9026 - auc: 0.9575 - val_loss: 0.2776 - val_accuracy: 0.9226 - val_auc: 0.9553\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2731 - accuracy: 0.9108 - auc: 0.9587 - val_loss: 0.2667 - val_accuracy: 0.9099 - val_auc: 0.9581\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2644 - accuracy: 0.9046 - auc: 0.9600 - val_loss: 0.2732 - val_accuracy: 0.9263 - val_auc: 0.9574\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2498 - accuracy: 0.9117 - auc: 0.9634 - val_loss: 0.2718 - val_accuracy: 0.9098 - val_auc: 0.9575\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2592 - accuracy: 0.9060 - auc: 0.9619 - val_loss: 0.2688 - val_accuracy: 0.9105 - val_auc: 0.9566\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2515 - accuracy: 0.9126 - auc: 0.9627 - val_loss: 0.2773 - val_accuracy: 0.9037 - val_auc: 0.9556\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2494 - accuracy: 0.9038 - auc: 0.9634 - val_loss: 0.2765 - val_accuracy: 0.9182 - val_auc: 0.9560\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2365 - accuracy: 0.9103 - auc: 0.9665 - val_loss: 0.2852 - val_accuracy: 0.9218 - val_auc: 0.9537\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2415 - accuracy: 0.9094 - auc: 0.9655 - val_loss: 0.3053 - val_accuracy: 0.9269 - val_auc: 0.9519\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2492 - accuracy: 0.9105 - auc: 0.9648 - val_loss: 0.2889 - val_accuracy: 0.9087 - val_auc: 0.9546\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2348 - accuracy: 0.9151 - auc: 0.9672 - val_loss: 0.3037 - val_accuracy: 0.9126 - val_auc: 0.9523\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2323 - accuracy: 0.9136 - auc: 0.9677 - val_loss: 0.3058 - val_accuracy: 0.9174 - val_auc: 0.9523\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2236 - accuracy: 0.9119 - auc: 0.9699 - val_loss: 0.2988 - val_accuracy: 0.9218 - val_auc: 0.9530\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2352 - accuracy: 0.9167 - auc: 0.9677 - val_loss: 0.3189 - val_accuracy: 0.9141 - val_auc: 0.9495\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2200 - accuracy: 0.9088 - auc: 0.9711 - val_loss: 0.3172 - val_accuracy: 0.9161 - val_auc: 0.9515\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2268 - accuracy: 0.9124 - auc: 0.9691 - val_loss: 0.3260 - val_accuracy: 0.9198 - val_auc: 0.9506\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2279 - accuracy: 0.9110 - auc: 0.9686 - val_loss: 0.3188 - val_accuracy: 0.9218 - val_auc: 0.9518\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2133 - accuracy: 0.9181 - auc: 0.9723 - val_loss: 0.3458 - val_accuracy: 0.9297 - val_auc: 0.9475\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2228 - accuracy: 0.9144 - auc: 0.9698 - val_loss: 0.3458 - val_accuracy: 0.9263 - val_auc: 0.9477\n",
      "Epoch 24/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2128 - accuracy: 0.9152 - auc: 0.9720 ETA: 0s - loss: 0.2168 - accuraRestoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2125 - accuracy: 0.9153 - auc: 0.9722 - val_loss: 0.3732 - val_accuracy: 0.9309 - val_auc: 0.9467\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.5074 - accuracy: 0.6998 - auc: 0.8910 - val_loss: 0.3072 - val_accuracy: 0.8672 - val_auc: 0.9451\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3213 - accuracy: 0.8311 - auc: 0.9441 - val_loss: 0.2787 - val_accuracy: 0.8783 - val_auc: 0.9538\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3083 - accuracy: 0.8583 - auc: 0.9482 - val_loss: 0.2732 - val_accuracy: 0.8861 - val_auc: 0.9547\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2744 - accuracy: 0.8656 - auc: 0.9565 - val_loss: 0.2797 - val_accuracy: 0.8946 - val_auc: 0.9523\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2582 - accuracy: 0.8783 - auc: 0.9608 - val_loss: 0.2861 - val_accuracy: 0.8996 - val_auc: 0.9533\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2509 - accuracy: 0.8886 - auc: 0.9627 - val_loss: 0.2924 - val_accuracy: 0.9023 - val_auc: 0.9530\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2465 - accuracy: 0.8876 - auc: 0.9639 - val_loss: 0.3032 - val_accuracy: 0.9138 - val_auc: 0.9503\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2384 - accuracy: 0.8952 - auc: 0.9657 - val_loss: 0.2944 - val_accuracy: 0.9030 - val_auc: 0.9539\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2341 - accuracy: 0.8940 - auc: 0.9668 - val_loss: 0.3030 - val_accuracy: 0.9006 - val_auc: 0.9520\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2335 - accuracy: 0.8934 - auc: 0.9671 - val_loss: 0.3071 - val_accuracy: 0.9085 - val_auc: 0.9528\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2425 - accuracy: 0.8975 - auc: 0.9664 - val_loss: 0.3073 - val_accuracy: 0.9005 - val_auc: 0.9504\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2259 - accuracy: 0.8990 - auc: 0.9689 - val_loss: 0.3330 - val_accuracy: 0.9148 - val_auc: 0.9502\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2288 - accuracy: 0.9011 - auc: 0.9681 - val_loss: 0.3380 - val_accuracy: 0.9139 - val_auc: 0.9491\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2211 - accuracy: 0.9038 - auc: 0.9701 - val_loss: 0.3371 - val_accuracy: 0.9064 - val_auc: 0.9517\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2349 - accuracy: 0.8998 - auc: 0.9667 - val_loss: 0.3420 - val_accuracy: 0.8950 - val_auc: 0.9490\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2258 - accuracy: 0.9009 - auc: 0.9690 - val_loss: 0.3712 - val_accuracy: 0.9188 - val_auc: 0.9450\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2077 - accuracy: 0.9055 - auc: 0.9728 - val_loss: 0.4077 - val_accuracy: 0.9241 - val_auc: 0.9444\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2248 - accuracy: 0.9072 - auc: 0.9691 - val_loss: 0.3972 - val_accuracy: 0.9217 - val_auc: 0.9470\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2233 - accuracy: 0.9032 - auc: 0.9695 - val_loss: 0.3793 - val_accuracy: 0.9124 - val_auc: 0.9470\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2186 - accuracy: 0.9008 - auc: 0.9707 - val_loss: 0.4071 - val_accuracy: 0.9179 - val_auc: 0.9465\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2068 - accuracy: 0.9081 - auc: 0.9731 - val_loss: 0.4221 - val_accuracy: 0.9175 - val_auc: 0.9453\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2067 - accuracy: 0.9044 - auc: 0.9730 - val_loss: 0.4606 - val_accuracy: 0.9179 - val_auc: 0.9416\n",
      "Epoch 23/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9051 - auc: 0.9712Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2172 - accuracy: 0.9051 - auc: 0.9710 - val_loss: 0.4304 - val_accuracy: 0.9146 - val_auc: 0.9450\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 1.1672 - accuracy: 0.2070 - auc: 0.5962 - val_loss: 0.7585 - val_accuracy: 0.1965 - val_auc: 0.7849\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8263 - accuracy: 0.2376 - auc: 0.7179 - val_loss: 0.6476 - val_accuracy: 0.2678 - val_auc: 0.8490\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7203 - accuracy: 0.3010 - auc: 0.7810 - val_loss: 0.5790 - val_accuracy: 0.3826 - val_auc: 0.8863\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6561 - accuracy: 0.3734 - auc: 0.8079 - val_loss: 0.5293 - val_accuracy: 0.5005 - val_auc: 0.9071\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5915 - accuracy: 0.4425 - auc: 0.8264 - val_loss: 0.4884 - val_accuracy: 0.6072 - val_auc: 0.9201\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5493 - accuracy: 0.5009 - auc: 0.8485 - val_loss: 0.4572 - val_accuracy: 0.6808 - val_auc: 0.9270\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5411 - accuracy: 0.5450 - auc: 0.8553 - val_loss: 0.4276 - val_accuracy: 0.7360 - val_auc: 0.9318\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5125 - accuracy: 0.5806 - auc: 0.8735 - val_loss: 0.3968 - val_accuracy: 0.7760 - val_auc: 0.9359\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4843 - accuracy: 0.6054 - auc: 0.8807 - val_loss: 0.3747 - val_accuracy: 0.8012 - val_auc: 0.9399\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4576 - accuracy: 0.6285 - auc: 0.8837 - val_loss: 0.3579 - val_accuracy: 0.8224 - val_auc: 0.9428\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4574 - accuracy: 0.6411 - auc: 0.8870 - val_loss: 0.3412 - val_accuracy: 0.8306 - val_auc: 0.9453\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4243 - accuracy: 0.6559 - auc: 0.9001 - val_loss: 0.3229 - val_accuracy: 0.8458 - val_auc: 0.9462\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4065 - accuracy: 0.6669 - auc: 0.9002 - val_loss: 0.3177 - val_accuracy: 0.8546 - val_auc: 0.9468\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4076 - accuracy: 0.6754 - auc: 0.9025 - val_loss: 0.3051 - val_accuracy: 0.8581 - val_auc: 0.9506\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3970 - accuracy: 0.6826 - auc: 0.9036 - val_loss: 0.2989 - val_accuracy: 0.8649 - val_auc: 0.9515\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3865 - accuracy: 0.6888 - auc: 0.9099 - val_loss: 0.2924 - val_accuracy: 0.8678 - val_auc: 0.9533\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3802 - accuracy: 0.6947 - auc: 0.9099 - val_loss: 0.2890 - val_accuracy: 0.8700 - val_auc: 0.9537\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3645 - accuracy: 0.7000 - auc: 0.9200 - val_loss: 0.2841 - val_accuracy: 0.8733 - val_auc: 0.9543\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3706 - accuracy: 0.7054 - auc: 0.9110 - val_loss: 0.2833 - val_accuracy: 0.8760 - val_auc: 0.9548\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3750 - accuracy: 0.7096 - auc: 0.9128 - val_loss: 0.2773 - val_accuracy: 0.8741 - val_auc: 0.9559\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3655 - accuracy: 0.7121 - auc: 0.9125 - val_loss: 0.2773 - val_accuracy: 0.8790 - val_auc: 0.9562\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3634 - accuracy: 0.7169 - auc: 0.9154 - val_loss: 0.2756 - val_accuracy: 0.8781 - val_auc: 0.9561\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3502 - accuracy: 0.7169 - auc: 0.9209 - val_loss: 0.2744 - val_accuracy: 0.8802 - val_auc: 0.9564\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3701 - accuracy: 0.7232 - auc: 0.9116 - val_loss: 0.2735 - val_accuracy: 0.8828 - val_auc: 0.9568\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3648 - accuracy: 0.7221 - auc: 0.9145 - val_loss: 0.2719 - val_accuracy: 0.8819 - val_auc: 0.9571\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3620 - accuracy: 0.7243 - auc: 0.9149 - val_loss: 0.2722 - val_accuracy: 0.8817 - val_auc: 0.9566\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3481 - accuracy: 0.7274 - auc: 0.9221 - val_loss: 0.2715 - val_accuracy: 0.8842 - val_auc: 0.9570\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3474 - accuracy: 0.7297 - auc: 0.9179 - val_loss: 0.2690 - val_accuracy: 0.8835 - val_auc: 0.9572\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3367 - accuracy: 0.7301 - auc: 0.9269 - val_loss: 0.2698 - val_accuracy: 0.8854 - val_auc: 0.9573\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3470 - accuracy: 0.7322 - auc: 0.9218 - val_loss: 0.2668 - val_accuracy: 0.8867 - val_auc: 0.9582\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3474 - accuracy: 0.7325 - auc: 0.9221 - val_loss: 0.2672 - val_accuracy: 0.8868 - val_auc: 0.9579\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3428 - accuracy: 0.7342 - auc: 0.9201 - val_loss: 0.2689 - val_accuracy: 0.8866 - val_auc: 0.9573\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3364 - accuracy: 0.7345 - auc: 0.9265 - val_loss: 0.2700 - val_accuracy: 0.8850 - val_auc: 0.9568\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3416 - accuracy: 0.7319 - auc: 0.9212 - val_loss: 0.2706 - val_accuracy: 0.8854 - val_auc: 0.9566\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3393 - accuracy: 0.7339 - auc: 0.9239 - val_loss: 0.2705 - val_accuracy: 0.8852 - val_auc: 0.9569\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3384 - accuracy: 0.7372 - auc: 0.9237 - val_loss: 0.2693 - val_accuracy: 0.8868 - val_auc: 0.9569\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3366 - accuracy: 0.7384 - auc: 0.9262 - val_loss: 0.2718 - val_accuracy: 0.8877 - val_auc: 0.9565\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3396 - accuracy: 0.7381 - auc: 0.9234 - val_loss: 0.2732 - val_accuracy: 0.8851 - val_auc: 0.9560\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3404 - accuracy: 0.7385 - auc: 0.9223 - val_loss: 0.2731 - val_accuracy: 0.8850 - val_auc: 0.9559\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3369 - accuracy: 0.7389 - auc: 0.9239 - val_loss: 0.2739 - val_accuracy: 0.8877 - val_auc: 0.9558\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3369 - accuracy: 0.7412 - auc: 0.9233 - val_loss: 0.2732 - val_accuracy: 0.8852 - val_auc: 0.9563\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3317 - accuracy: 0.7412 - auc: 0.9272 - val_loss: 0.2749 - val_accuracy: 0.8873 - val_auc: 0.9560\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3352 - accuracy: 0.7425 - auc: 0.9260 - val_loss: 0.2763 - val_accuracy: 0.8845 - val_auc: 0.9556\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3295 - accuracy: 0.7430 - auc: 0.9270 - val_loss: 0.2798 - val_accuracy: 0.8848 - val_auc: 0.9550\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3427 - accuracy: 0.7427 - auc: 0.9202 - val_loss: 0.2813 - val_accuracy: 0.8869 - val_auc: 0.9548\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3204 - accuracy: 0.7425 - auc: 0.9313 - val_loss: 0.2787 - val_accuracy: 0.8849 - val_auc: 0.9552\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3215 - accuracy: 0.7433 - auc: 0.9302 - val_loss: 0.2807 - val_accuracy: 0.8868 - val_auc: 0.9545\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3321 - accuracy: 0.7419 - auc: 0.9276 - val_loss: 0.2828 - val_accuracy: 0.8861 - val_auc: 0.9546\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3194 - accuracy: 0.7434 - auc: 0.9315 - val_loss: 0.2821 - val_accuracy: 0.8864 - val_auc: 0.9546\n",
      "Epoch 50/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3185 - accuracy: 0.7436 - auc: 0.9313Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3200 - accuracy: 0.7436 - auc: 0.9310 - val_loss: 0.2840 - val_accuracy: 0.8866 - val_auc: 0.9543\n",
      "Epoch 00050: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8296 - accuracy: 0.3096 - auc: 0.6351 - val_loss: 0.5527 - val_accuracy: 0.4397 - val_auc: 0.8655\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6599 - accuracy: 0.3744 - auc: 0.7341 - val_loss: 0.4645 - val_accuracy: 0.6007 - val_auc: 0.9184\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5587 - accuracy: 0.4560 - auc: 0.8131 - val_loss: 0.4233 - val_accuracy: 0.7189 - val_auc: 0.9279\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5153 - accuracy: 0.5230 - auc: 0.8439 - val_loss: 0.3929 - val_accuracy: 0.7886 - val_auc: 0.9348\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4916 - accuracy: 0.5857 - auc: 0.8563 - val_loss: 0.3661 - val_accuracy: 0.8219 - val_auc: 0.9432\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4615 - accuracy: 0.8091 - auc: 0.8662 - val_loss: 0.3460 - val_accuracy: 0.8671 - val_auc: 0.9490\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4514 - accuracy: 0.8635 - auc: 0.8725 - val_loss: 0.3297 - val_accuracy: 0.8747 - val_auc: 0.9530\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4179 - accuracy: 0.8690 - auc: 0.8987 - val_loss: 0.3191 - val_accuracy: 0.8820 - val_auc: 0.9542\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4167 - accuracy: 0.8748 - auc: 0.8896 - val_loss: 0.3083 - val_accuracy: 0.8871 - val_auc: 0.9557\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4190 - accuracy: 0.8813 - auc: 0.8935 - val_loss: 0.3011 - val_accuracy: 0.8915 - val_auc: 0.9569\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3932 - accuracy: 0.8866 - auc: 0.9050 - val_loss: 0.2948 - val_accuracy: 0.8958 - val_auc: 0.9575\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4017 - accuracy: 0.8890 - auc: 0.8966 - val_loss: 0.2890 - val_accuracy: 0.8973 - val_auc: 0.9579\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3904 - accuracy: 0.8942 - auc: 0.9004 - val_loss: 0.2863 - val_accuracy: 0.9014 - val_auc: 0.9585\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3906 - accuracy: 0.8977 - auc: 0.9034 - val_loss: 0.2824 - val_accuracy: 0.9018 - val_auc: 0.9583\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3835 - accuracy: 0.8960 - auc: 0.9054 - val_loss: 0.2808 - val_accuracy: 0.9012 - val_auc: 0.9583\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3806 - accuracy: 0.8971 - auc: 0.9089 - val_loss: 0.2807 - val_accuracy: 0.8998 - val_auc: 0.9572\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3770 - accuracy: 0.8976 - auc: 0.9078 - val_loss: 0.2779 - val_accuracy: 0.9019 - val_auc: 0.9582\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3641 - accuracy: 0.9001 - auc: 0.9130 - val_loss: 0.2755 - val_accuracy: 0.9040 - val_auc: 0.9579\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3563 - accuracy: 0.9026 - auc: 0.9177 - val_loss: 0.2762 - val_accuracy: 0.9039 - val_auc: 0.9575\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3490 - accuracy: 0.9018 - auc: 0.9211 - val_loss: 0.2755 - val_accuracy: 0.9039 - val_auc: 0.9574\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3536 - accuracy: 0.9057 - auc: 0.9194 - val_loss: 0.2743 - val_accuracy: 0.9048 - val_auc: 0.9573\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3398 - accuracy: 0.9038 - auc: 0.9237 - val_loss: 0.2721 - val_accuracy: 0.9052 - val_auc: 0.9578\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3515 - accuracy: 0.9067 - auc: 0.9186 - val_loss: 0.2716 - val_accuracy: 0.9069 - val_auc: 0.9579\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3589 - accuracy: 0.9073 - auc: 0.9173 - val_loss: 0.2728 - val_accuracy: 0.9065 - val_auc: 0.9574\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3397 - accuracy: 0.9065 - auc: 0.9232 - val_loss: 0.2716 - val_accuracy: 0.9064 - val_auc: 0.9579\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3457 - accuracy: 0.9067 - auc: 0.9203 - val_loss: 0.2732 - val_accuracy: 0.9044 - val_auc: 0.9573\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3438 - accuracy: 0.9059 - auc: 0.9203 - val_loss: 0.2730 - val_accuracy: 0.9032 - val_auc: 0.9572\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3330 - accuracy: 0.9052 - auc: 0.9237 - val_loss: 0.2746 - val_accuracy: 0.9041 - val_auc: 0.9569\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3336 - accuracy: 0.9075 - auc: 0.9269 - val_loss: 0.2746 - val_accuracy: 0.9035 - val_auc: 0.9569\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3385 - accuracy: 0.9060 - auc: 0.9239 - val_loss: 0.2759 - val_accuracy: 0.9029 - val_auc: 0.9560\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3388 - accuracy: 0.9067 - auc: 0.9254 - val_loss: 0.2754 - val_accuracy: 0.9031 - val_auc: 0.9566\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3326 - accuracy: 0.9085 - auc: 0.9238 - val_loss: 0.2770 - val_accuracy: 0.9025 - val_auc: 0.9561\n",
      "Epoch 33/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.9079 - auc: 0.9261Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3306 - accuracy: 0.9080 - auc: 0.9264 - val_loss: 0.2739 - val_accuracy: 0.9022 - val_auc: 0.9566\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6868 - accuracy: 0.7904 - auc: 0.6038 - val_loss: 0.4998 - val_accuracy: 0.8837 - val_auc: 0.8421\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5606 - accuracy: 0.8467 - auc: 0.7515 - val_loss: 0.4432 - val_accuracy: 0.9093 - val_auc: 0.9117\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5040 - accuracy: 0.8738 - auc: 0.8130 - val_loss: 0.4043 - val_accuracy: 0.9135 - val_auc: 0.9378\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4719 - accuracy: 0.8867 - auc: 0.8496 - val_loss: 0.3801 - val_accuracy: 0.9168 - val_auc: 0.9475\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4455 - accuracy: 0.8940 - auc: 0.8700 - val_loss: 0.3622 - val_accuracy: 0.9181 - val_auc: 0.9538\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4274 - accuracy: 0.8992 - auc: 0.8794 - val_loss: 0.3470 - val_accuracy: 0.9160 - val_auc: 0.9569\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4081 - accuracy: 0.9022 - auc: 0.9016 - val_loss: 0.3356 - val_accuracy: 0.9151 - val_auc: 0.9598\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4061 - accuracy: 0.9083 - auc: 0.8974 - val_loss: 0.3265 - val_accuracy: 0.9185 - val_auc: 0.9608\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3936 - accuracy: 0.9079 - auc: 0.9081 - val_loss: 0.3205 - val_accuracy: 0.9157 - val_auc: 0.9607\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3872 - accuracy: 0.9075 - auc: 0.9080 - val_loss: 0.3134 - val_accuracy: 0.9168 - val_auc: 0.9605\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3642 - accuracy: 0.9085 - auc: 0.9272 - val_loss: 0.3069 - val_accuracy: 0.9150 - val_auc: 0.9609\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3692 - accuracy: 0.9132 - auc: 0.9158 - val_loss: 0.3015 - val_accuracy: 0.9166 - val_auc: 0.9608\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3633 - accuracy: 0.9102 - auc: 0.9230 - val_loss: 0.2978 - val_accuracy: 0.9167 - val_auc: 0.9620\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3612 - accuracy: 0.9095 - auc: 0.9262 - val_loss: 0.2939 - val_accuracy: 0.9138 - val_auc: 0.9613\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3580 - accuracy: 0.9094 - auc: 0.9247 - val_loss: 0.2902 - val_accuracy: 0.9139 - val_auc: 0.9622\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3620 - accuracy: 0.9122 - auc: 0.9185 - val_loss: 0.2876 - val_accuracy: 0.9157 - val_auc: 0.9616\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3548 - accuracy: 0.9148 - auc: 0.9253 - val_loss: 0.2850 - val_accuracy: 0.9163 - val_auc: 0.9611\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3547 - accuracy: 0.9137 - auc: 0.9209 - val_loss: 0.2842 - val_accuracy: 0.9164 - val_auc: 0.9603\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3578 - accuracy: 0.9141 - auc: 0.9181 - val_loss: 0.2819 - val_accuracy: 0.9167 - val_auc: 0.9607\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3409 - accuracy: 0.9157 - auc: 0.9281 - val_loss: 0.2799 - val_accuracy: 0.9172 - val_auc: 0.9604\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3448 - accuracy: 0.9154 - auc: 0.9282 - val_loss: 0.2793 - val_accuracy: 0.9153 - val_auc: 0.9599\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3448 - accuracy: 0.9146 - auc: 0.9281 - val_loss: 0.2770 - val_accuracy: 0.9167 - val_auc: 0.9601\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3401 - accuracy: 0.9176 - auc: 0.9276 - val_loss: 0.2763 - val_accuracy: 0.9167 - val_auc: 0.9600\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3422 - accuracy: 0.9155 - auc: 0.9279 - val_loss: 0.2757 - val_accuracy: 0.9148 - val_auc: 0.9596\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3491 - accuracy: 0.9151 - auc: 0.9227 - val_loss: 0.2756 - val_accuracy: 0.9166 - val_auc: 0.9594\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3312 - accuracy: 0.9176 - auc: 0.9312 - val_loss: 0.2729 - val_accuracy: 0.9171 - val_auc: 0.9599\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.3451 - accuracy: 0.9162 - auc: 0.9257 - val_loss: 0.2742 - val_accuracy: 0.9177 - val_auc: 0.9587\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3332 - accuracy: 0.9193 - auc: 0.9315 - val_loss: 0.2731 - val_accuracy: 0.9186 - val_auc: 0.9592\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3420 - accuracy: 0.9179 - auc: 0.9269 - val_loss: 0.2727 - val_accuracy: 0.9178 - val_auc: 0.9586\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3342 - accuracy: 0.9191 - auc: 0.9320 - val_loss: 0.2721 - val_accuracy: 0.9195 - val_auc: 0.9588\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3414 - accuracy: 0.9204 - auc: 0.9269 - val_loss: 0.2732 - val_accuracy: 0.9194 - val_auc: 0.9578\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3200 - accuracy: 0.9198 - auc: 0.9370 - val_loss: 0.2718 - val_accuracy: 0.9197 - val_auc: 0.9580\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3221 - accuracy: 0.9203 - auc: 0.9356 - val_loss: 0.2695 - val_accuracy: 0.9196 - val_auc: 0.9587\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3334 - accuracy: 0.9192 - auc: 0.9314 - val_loss: 0.2691 - val_accuracy: 0.9189 - val_auc: 0.9584\n",
      "Epoch 35/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3412 - accuracy: 0.9209 - auc: 0.9260Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3409 - accuracy: 0.9209 - auc: 0.9260 - val_loss: 0.2689 - val_accuracy: 0.9206 - val_auc: 0.9583\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 18us/sample - loss: 0.9746 - accuracy: 0.2837 - auc: 0.5615 - val_loss: 0.6827 - val_accuracy: 0.3101 - val_auc: 0.7405\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7373 - accuracy: 0.3361 - auc: 0.7187 - val_loss: 0.5867 - val_accuracy: 0.4249 - val_auc: 0.8371\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6729 - accuracy: 0.4013 - auc: 0.7739 - val_loss: 0.5196 - val_accuracy: 0.5272 - val_auc: 0.8847\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6064 - accuracy: 0.4585 - auc: 0.8053 - val_loss: 0.4709 - val_accuracy: 0.6165 - val_auc: 0.9029\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5527 - accuracy: 0.5089 - auc: 0.8317 - val_loss: 0.4359 - val_accuracy: 0.6880 - val_auc: 0.9134\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5416 - accuracy: 0.5485 - auc: 0.8344 - val_loss: 0.4013 - val_accuracy: 0.7363 - val_auc: 0.9248\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5101 - accuracy: 0.5783 - auc: 0.8483 - val_loss: 0.3781 - val_accuracy: 0.7719 - val_auc: 0.9322\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4941 - accuracy: 0.6022 - auc: 0.8567 - val_loss: 0.3625 - val_accuracy: 0.7966 - val_auc: 0.9369\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4787 - accuracy: 0.6167 - auc: 0.8587 - val_loss: 0.3483 - val_accuracy: 0.8062 - val_auc: 0.9412\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4441 - accuracy: 0.6356 - auc: 0.8786 - val_loss: 0.3359 - val_accuracy: 0.8250 - val_auc: 0.9444\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4237 - accuracy: 0.6553 - auc: 0.8859 - val_loss: 0.3235 - val_accuracy: 0.8376 - val_auc: 0.9475\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4148 - accuracy: 0.6748 - auc: 0.8883 - val_loss: 0.3150 - val_accuracy: 0.8489 - val_auc: 0.9490\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4032 - accuracy: 0.6937 - auc: 0.8943 - val_loss: 0.3099 - val_accuracy: 0.8545 - val_auc: 0.9499\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3945 - accuracy: 0.7155 - auc: 0.8966 - val_loss: 0.3032 - val_accuracy: 0.8631 - val_auc: 0.9512\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3831 - accuracy: 0.7324 - auc: 0.9019 - val_loss: 0.3023 - val_accuracy: 0.8681 - val_auc: 0.9516\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3930 - accuracy: 0.7405 - auc: 0.9009 - val_loss: 0.2993 - val_accuracy: 0.8646 - val_auc: 0.9526\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3702 - accuracy: 0.7478 - auc: 0.9081 - val_loss: 0.2935 - val_accuracy: 0.8692 - val_auc: 0.9539\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3717 - accuracy: 0.7566 - auc: 0.9062 - val_loss: 0.2922 - val_accuracy: 0.8714 - val_auc: 0.9537\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3655 - accuracy: 0.7586 - auc: 0.9078 - val_loss: 0.2926 - val_accuracy: 0.8734 - val_auc: 0.9541\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3719 - accuracy: 0.7630 - auc: 0.9065 - val_loss: 0.2914 - val_accuracy: 0.8749 - val_auc: 0.9545\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3620 - accuracy: 0.7631 - auc: 0.9079 - val_loss: 0.2903 - val_accuracy: 0.8728 - val_auc: 0.9548\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3561 - accuracy: 0.7659 - auc: 0.9094 - val_loss: 0.2890 - val_accuracy: 0.8729 - val_auc: 0.9553\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3482 - accuracy: 0.7685 - auc: 0.9160 - val_loss: 0.2871 - val_accuracy: 0.8767 - val_auc: 0.9557\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3574 - accuracy: 0.7712 - auc: 0.9115 - val_loss: 0.2844 - val_accuracy: 0.8748 - val_auc: 0.9563\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3534 - accuracy: 0.7705 - auc: 0.9135 - val_loss: 0.2862 - val_accuracy: 0.8748 - val_auc: 0.9561\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3413 - accuracy: 0.7756 - auc: 0.9153 - val_loss: 0.2864 - val_accuracy: 0.8787 - val_auc: 0.9562\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3513 - accuracy: 0.7769 - auc: 0.9146 - val_loss: 0.2870 - val_accuracy: 0.8770 - val_auc: 0.9561\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3415 - accuracy: 0.7775 - auc: 0.9195 - val_loss: 0.2844 - val_accuracy: 0.8772 - val_auc: 0.9563\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3358 - accuracy: 0.7772 - auc: 0.9200 - val_loss: 0.2841 - val_accuracy: 0.8789 - val_auc: 0.9565\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3451 - accuracy: 0.7796 - auc: 0.9168 - val_loss: 0.2827 - val_accuracy: 0.8774 - val_auc: 0.9573\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3441 - accuracy: 0.7798 - auc: 0.9160 - val_loss: 0.2823 - val_accuracy: 0.8779 - val_auc: 0.9576\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3438 - accuracy: 0.7801 - auc: 0.9209 - val_loss: 0.2836 - val_accuracy: 0.8759 - val_auc: 0.9570\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3387 - accuracy: 0.7787 - auc: 0.9193 - val_loss: 0.2851 - val_accuracy: 0.8758 - val_auc: 0.9568\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3278 - accuracy: 0.7800 - auc: 0.9232 - val_loss: 0.2819 - val_accuracy: 0.8779 - val_auc: 0.9569\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3385 - accuracy: 0.7810 - auc: 0.9156 - val_loss: 0.2874 - val_accuracy: 0.8761 - val_auc: 0.9561\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3313 - accuracy: 0.7815 - auc: 0.9218 - val_loss: 0.2877 - val_accuracy: 0.8766 - val_auc: 0.9564\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3425 - accuracy: 0.7834 - auc: 0.9186 - val_loss: 0.2875 - val_accuracy: 0.8744 - val_auc: 0.9557\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3255 - accuracy: 0.7829 - auc: 0.9226 - val_loss: 0.2894 - val_accuracy: 0.8760 - val_auc: 0.9558\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3290 - accuracy: 0.7834 - auc: 0.9213 - val_loss: 0.2903 - val_accuracy: 0.8782 - val_auc: 0.9556\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.3325 - accuracy: 0.7838 - auc: 0.9217 - val_loss: 0.2881 - val_accuracy: 0.8776 - val_auc: 0.9560\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3200 - accuracy: 0.7860 - auc: 0.9270 - val_loss: 0.2876 - val_accuracy: 0.8793 - val_auc: 0.9564\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3284 - accuracy: 0.7857 - auc: 0.9236 - val_loss: 0.2865 - val_accuracy: 0.8778 - val_auc: 0.9563\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3263 - accuracy: 0.7862 - auc: 0.9231 - val_loss: 0.2912 - val_accuracy: 0.8787 - val_auc: 0.9553\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3229 - accuracy: 0.7859 - auc: 0.9241 - val_loss: 0.2919 - val_accuracy: 0.8773 - val_auc: 0.9554\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3227 - accuracy: 0.7871 - auc: 0.9240 - val_loss: 0.2927 - val_accuracy: 0.8787 - val_auc: 0.9557\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3308 - accuracy: 0.7854 - auc: 0.9200 - val_loss: 0.2931 - val_accuracy: 0.8745 - val_auc: 0.9551\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3262 - accuracy: 0.7844 - auc: 0.9236 - val_loss: 0.2946 - val_accuracy: 0.8726 - val_auc: 0.9550\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3217 - accuracy: 0.7802 - auc: 0.9243 - val_loss: 0.2953 - val_accuracy: 0.8714 - val_auc: 0.9534\n",
      "Epoch 49/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3236 - accuracy: 0.7807 - auc: 0.9257 - val_loss: 0.2966 - val_accuracy: 0.8717 - val_auc: 0.9543\n",
      "Epoch 50/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3144 - accuracy: 0.7808 - auc: 0.9271 - val_loss: 0.2925 - val_accuracy: 0.8719 - val_auc: 0.9551\n",
      "Epoch 51/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3151 - accuracy: 0.7854 - auc: 0.9273Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3170 - accuracy: 0.7852 - auc: 0.9270 - val_loss: 0.2955 - val_accuracy: 0.8747 - val_auc: 0.9547\n",
      "Epoch 00051: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.7115 - accuracy: 0.8683 - auc: 0.6642 - val_loss: 0.4750 - val_accuracy: 0.9180 - val_auc: 0.8729\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5480 - accuracy: 0.8770 - auc: 0.7922 - val_loss: 0.4026 - val_accuracy: 0.9136 - val_auc: 0.9183\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4944 - accuracy: 0.8840 - auc: 0.8309 - val_loss: 0.3627 - val_accuracy: 0.9131 - val_auc: 0.9389\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4492 - accuracy: 0.8883 - auc: 0.8657 - val_loss: 0.3404 - val_accuracy: 0.9140 - val_auc: 0.9477\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4290 - accuracy: 0.8960 - auc: 0.8859 - val_loss: 0.3278 - val_accuracy: 0.9133 - val_auc: 0.9523\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4155 - accuracy: 0.8983 - auc: 0.8959 - val_loss: 0.3175 - val_accuracy: 0.9118 - val_auc: 0.9551\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3858 - accuracy: 0.9011 - auc: 0.9093 - val_loss: 0.3112 - val_accuracy: 0.9144 - val_auc: 0.9562\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3757 - accuracy: 0.9076 - auc: 0.9154 - val_loss: 0.3074 - val_accuracy: 0.9183 - val_auc: 0.9570\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3831 - accuracy: 0.9097 - auc: 0.9088 - val_loss: 0.3055 - val_accuracy: 0.9184 - val_auc: 0.9576\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3722 - accuracy: 0.9124 - auc: 0.9163 - val_loss: 0.3033 - val_accuracy: 0.9179 - val_auc: 0.9581\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3593 - accuracy: 0.9138 - auc: 0.9283 - val_loss: 0.3023 - val_accuracy: 0.9208 - val_auc: 0.9583\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3649 - accuracy: 0.9149 - auc: 0.9209 - val_loss: 0.2989 - val_accuracy: 0.9200 - val_auc: 0.9589\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3575 - accuracy: 0.9142 - auc: 0.9239 - val_loss: 0.2969 - val_accuracy: 0.9192 - val_auc: 0.9591\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3656 - accuracy: 0.9142 - auc: 0.9217 - val_loss: 0.2965 - val_accuracy: 0.9198 - val_auc: 0.9589\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3488 - accuracy: 0.9153 - auc: 0.9325 - val_loss: 0.2962 - val_accuracy: 0.9175 - val_auc: 0.9586\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3529 - accuracy: 0.9147 - auc: 0.9286 - val_loss: 0.2956 - val_accuracy: 0.9195 - val_auc: 0.9586\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3501 - accuracy: 0.9162 - auc: 0.9294 - val_loss: 0.2943 - val_accuracy: 0.9200 - val_auc: 0.9590\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3439 - accuracy: 0.9158 - auc: 0.9350 - val_loss: 0.2939 - val_accuracy: 0.9192 - val_auc: 0.9577\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3609 - accuracy: 0.9182 - auc: 0.9213 - val_loss: 0.2944 - val_accuracy: 0.9218 - val_auc: 0.9576\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3447 - accuracy: 0.9187 - auc: 0.9327 - val_loss: 0.2943 - val_accuracy: 0.9190 - val_auc: 0.9587\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3467 - accuracy: 0.9181 - auc: 0.9297 - val_loss: 0.2928 - val_accuracy: 0.9202 - val_auc: 0.9590\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3573 - accuracy: 0.9192 - auc: 0.9250 - val_loss: 0.2927 - val_accuracy: 0.9199 - val_auc: 0.9589\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3445 - accuracy: 0.9174 - auc: 0.9329 - val_loss: 0.2932 - val_accuracy: 0.9193 - val_auc: 0.9587\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3429 - accuracy: 0.9184 - auc: 0.9320 - val_loss: 0.2924 - val_accuracy: 0.9196 - val_auc: 0.9577\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3384 - accuracy: 0.9189 - auc: 0.9327 - val_loss: 0.2906 - val_accuracy: 0.9214 - val_auc: 0.9589\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3488 - accuracy: 0.9225 - auc: 0.9266 - val_loss: 0.2912 - val_accuracy: 0.9222 - val_auc: 0.9580\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3447 - accuracy: 0.9200 - auc: 0.9292 - val_loss: 0.2925 - val_accuracy: 0.9207 - val_auc: 0.9563\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3392 - accuracy: 0.9188 - auc: 0.9383 - val_loss: 0.2915 - val_accuracy: 0.9200 - val_auc: 0.9561\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3286 - accuracy: 0.9201 - auc: 0.9410 - val_loss: 0.2908 - val_accuracy: 0.9223 - val_auc: 0.9569\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3437 - accuracy: 0.9226 - auc: 0.9332 - val_loss: 0.2905 - val_accuracy: 0.9207 - val_auc: 0.9591\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3393 - accuracy: 0.9216 - auc: 0.9326 - val_loss: 0.2906 - val_accuracy: 0.9228 - val_auc: 0.9579\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3298 - accuracy: 0.9213 - auc: 0.9379 - val_loss: 0.2893 - val_accuracy: 0.9215 - val_auc: 0.9581\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3349 - accuracy: 0.9211 - auc: 0.9355 - val_loss: 0.2876 - val_accuracy: 0.9214 - val_auc: 0.9571\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3373 - accuracy: 0.9201 - auc: 0.9330 - val_loss: 0.2885 - val_accuracy: 0.9218 - val_auc: 0.9570\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3265 - accuracy: 0.9237 - auc: 0.9373 - val_loss: 0.2894 - val_accuracy: 0.9233 - val_auc: 0.9579\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.3369 - accuracy: 0.9237 - auc: 0.9374 - val_loss: 0.2908 - val_accuracy: 0.9212 - val_auc: 0.9577\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3316 - accuracy: 0.9227 - auc: 0.9360 - val_loss: 0.2897 - val_accuracy: 0.9216 - val_auc: 0.9580\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3307 - accuracy: 0.9232 - auc: 0.9372 - val_loss: 0.2888 - val_accuracy: 0.9233 - val_auc: 0.9569\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3333 - accuracy: 0.9241 - auc: 0.9357 - val_loss: 0.2885 - val_accuracy: 0.9243 - val_auc: 0.9570\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3393 - accuracy: 0.9244 - auc: 0.9341 - val_loss: 0.2881 - val_accuracy: 0.9226 - val_auc: 0.9575\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3186 - accuracy: 0.9215 - auc: 0.9437 - val_loss: 0.2887 - val_accuracy: 0.9218 - val_auc: 0.9572\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3382 - accuracy: 0.9218 - auc: 0.9344 - val_loss: 0.2892 - val_accuracy: 0.9224 - val_auc: 0.9573\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3324 - accuracy: 0.9236 - auc: 0.9332 - val_loss: 0.2888 - val_accuracy: 0.9241 - val_auc: 0.9573\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3439 - accuracy: 0.9252 - auc: 0.9301 - val_loss: 0.2895 - val_accuracy: 0.9229 - val_auc: 0.9573\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3475 - accuracy: 0.9223 - auc: 0.9284 - val_loss: 0.2877 - val_accuracy: 0.9229 - val_auc: 0.9576\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3304 - accuracy: 0.9247 - auc: 0.9392 - val_loss: 0.2873 - val_accuracy: 0.9236 - val_auc: 0.9578\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3309 - accuracy: 0.9248 - auc: 0.9386 - val_loss: 0.2881 - val_accuracy: 0.9229 - val_auc: 0.9575\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3411 - accuracy: 0.9246 - auc: 0.9294 - val_loss: 0.2874 - val_accuracy: 0.9235 - val_auc: 0.9579\n",
      "Epoch 49/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3368 - accuracy: 0.9249 - auc: 0.9341 - val_loss: 0.2879 - val_accuracy: 0.9229 - val_auc: 0.9574\n",
      "Epoch 50/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3241 - accuracy: 0.9223 - auc: 0.9382Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3255 - accuracy: 0.9225 - auc: 0.9374 - val_loss: 0.2882 - val_accuracy: 0.9229 - val_auc: 0.9571\n",
      "Epoch 00050: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7068 - accuracy: 0.8289 - auc: 0.7208 - val_loss: 0.4002 - val_accuracy: 0.8864 - val_auc: 0.9073\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5403 - accuracy: 0.8552 - auc: 0.8257 - val_loss: 0.3507 - val_accuracy: 0.9025 - val_auc: 0.9331\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4620 - accuracy: 0.8714 - auc: 0.8749 - val_loss: 0.3295 - val_accuracy: 0.9094 - val_auc: 0.9417\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4216 - accuracy: 0.8837 - auc: 0.9004 - val_loss: 0.3161 - val_accuracy: 0.9081 - val_auc: 0.9456\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3830 - accuracy: 0.8899 - auc: 0.9167 - val_loss: 0.3066 - val_accuracy: 0.9119 - val_auc: 0.9495\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3667 - accuracy: 0.8946 - auc: 0.9280 - val_loss: 0.2989 - val_accuracy: 0.9131 - val_auc: 0.9516\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3525 - accuracy: 0.9010 - auc: 0.9299 - val_loss: 0.2910 - val_accuracy: 0.9155 - val_auc: 0.9542\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3359 - accuracy: 0.9050 - auc: 0.9380 - val_loss: 0.2819 - val_accuracy: 0.9199 - val_auc: 0.9573\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3400 - accuracy: 0.9079 - auc: 0.9358 - val_loss: 0.2806 - val_accuracy: 0.9164 - val_auc: 0.9574\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3377 - accuracy: 0.9066 - auc: 0.9372 - val_loss: 0.2779 - val_accuracy: 0.9178 - val_auc: 0.9576\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3305 - accuracy: 0.9089 - auc: 0.9405 - val_loss: 0.2725 - val_accuracy: 0.9186 - val_auc: 0.9591\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3142 - accuracy: 0.9115 - auc: 0.9447 - val_loss: 0.2712 - val_accuracy: 0.9213 - val_auc: 0.9590\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3183 - accuracy: 0.9127 - auc: 0.9459 - val_loss: 0.2702 - val_accuracy: 0.9180 - val_auc: 0.9590\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3070 - accuracy: 0.9103 - auc: 0.9484 - val_loss: 0.2696 - val_accuracy: 0.9188 - val_auc: 0.9590\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3043 - accuracy: 0.9121 - auc: 0.9495 - val_loss: 0.2681 - val_accuracy: 0.9192 - val_auc: 0.9595\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3027 - accuracy: 0.9131 - auc: 0.9495 - val_loss: 0.2684 - val_accuracy: 0.9199 - val_auc: 0.9591\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2993 - accuracy: 0.9147 - auc: 0.9513 - val_loss: 0.2660 - val_accuracy: 0.9179 - val_auc: 0.9593\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3094 - accuracy: 0.9129 - auc: 0.9465 - val_loss: 0.2652 - val_accuracy: 0.9171 - val_auc: 0.9594\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2858 - accuracy: 0.9123 - auc: 0.9554 - val_loss: 0.2658 - val_accuracy: 0.9198 - val_auc: 0.9591\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3014 - accuracy: 0.9160 - auc: 0.9504 - val_loss: 0.2656 - val_accuracy: 0.9187 - val_auc: 0.9589\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2926 - accuracy: 0.9146 - auc: 0.9532 - val_loss: 0.2648 - val_accuracy: 0.9186 - val_auc: 0.9591\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2903 - accuracy: 0.9141 - auc: 0.9533 - val_loss: 0.2660 - val_accuracy: 0.9191 - val_auc: 0.9588\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2868 - accuracy: 0.9163 - auc: 0.9548 - val_loss: 0.2678 - val_accuracy: 0.9197 - val_auc: 0.9585\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2828 - accuracy: 0.9173 - auc: 0.9559 - val_loss: 0.2670 - val_accuracy: 0.9206 - val_auc: 0.9586\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2785 - accuracy: 0.9165 - auc: 0.9567 - val_loss: 0.2668 - val_accuracy: 0.9210 - val_auc: 0.9585\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2898 - accuracy: 0.9172 - auc: 0.9541 - val_loss: 0.2661 - val_accuracy: 0.9210 - val_auc: 0.9587\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2771 - accuracy: 0.9175 - auc: 0.9576 - val_loss: 0.2676 - val_accuracy: 0.9207 - val_auc: 0.9584\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2887 - accuracy: 0.9150 - auc: 0.9538 - val_loss: 0.2698 - val_accuracy: 0.9179 - val_auc: 0.9576\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2937 - accuracy: 0.9117 - auc: 0.9519 - val_loss: 0.2701 - val_accuracy: 0.9166 - val_auc: 0.9571\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2875 - accuracy: 0.9147 - auc: 0.9541 - val_loss: 0.2710 - val_accuracy: 0.9191 - val_auc: 0.9568\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2765 - accuracy: 0.9150 - auc: 0.9571 - val_loss: 0.2718 - val_accuracy: 0.9180 - val_auc: 0.9566\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2753 - accuracy: 0.9141 - auc: 0.9575 - val_loss: 0.2720 - val_accuracy: 0.9189 - val_auc: 0.9567\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2729 - accuracy: 0.9152 - auc: 0.9589 - val_loss: 0.2710 - val_accuracy: 0.9186 - val_auc: 0.9569\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2754 - accuracy: 0.9129 - auc: 0.9572 - val_loss: 0.2702 - val_accuracy: 0.9180 - val_auc: 0.9572\n",
      "Epoch 35/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2742 - accuracy: 0.9133 - auc: 0.9579Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2712 - accuracy: 0.9135 - auc: 0.9587 - val_loss: 0.2715 - val_accuracy: 0.9180 - val_auc: 0.9569\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.9650 - accuracy: 0.3197 - auc: 0.5751 - val_loss: 0.6114 - val_accuracy: 0.3503 - val_auc: 0.8197\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6750 - accuracy: 0.4088 - auc: 0.7678 - val_loss: 0.4970 - val_accuracy: 0.5211 - val_auc: 0.8983\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5504 - accuracy: 0.5155 - auc: 0.8537 - val_loss: 0.4275 - val_accuracy: 0.6776 - val_auc: 0.9192\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4930 - accuracy: 0.6104 - auc: 0.8769 - val_loss: 0.3782 - val_accuracy: 0.7709 - val_auc: 0.9309\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4609 - accuracy: 0.6671 - auc: 0.8908 - val_loss: 0.3469 - val_accuracy: 0.8129 - val_auc: 0.9383\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4229 - accuracy: 0.7074 - auc: 0.9035 - val_loss: 0.3245 - val_accuracy: 0.8473 - val_auc: 0.9433\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3888 - accuracy: 0.7423 - auc: 0.9163 - val_loss: 0.3072 - val_accuracy: 0.8656 - val_auc: 0.9470\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3855 - accuracy: 0.7587 - auc: 0.9172 - val_loss: 0.2975 - val_accuracy: 0.8695 - val_auc: 0.9496\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3578 - accuracy: 0.7756 - auc: 0.9293 - val_loss: 0.2896 - val_accuracy: 0.8785 - val_auc: 0.9512\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3392 - accuracy: 0.7872 - auc: 0.9373 - val_loss: 0.2824 - val_accuracy: 0.8870 - val_auc: 0.9529\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3394 - accuracy: 0.8034 - auc: 0.9337 - val_loss: 0.2793 - val_accuracy: 0.8910 - val_auc: 0.9534\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3224 - accuracy: 0.8097 - auc: 0.9420 - val_loss: 0.2752 - val_accuracy: 0.8952 - val_auc: 0.9545\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3206 - accuracy: 0.8159 - auc: 0.9415 - val_loss: 0.2734 - val_accuracy: 0.8959 - val_auc: 0.9548\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3069 - accuracy: 0.8186 - auc: 0.9456 - val_loss: 0.2717 - val_accuracy: 0.8975 - val_auc: 0.9554\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3198 - accuracy: 0.8230 - auc: 0.9411 - val_loss: 0.2696 - val_accuracy: 0.8945 - val_auc: 0.9558\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3013 - accuracy: 0.8229 - auc: 0.9478 - val_loss: 0.2676 - val_accuracy: 0.8970 - val_auc: 0.9568\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2884 - accuracy: 0.8284 - auc: 0.9517 - val_loss: 0.2667 - val_accuracy: 0.8986 - val_auc: 0.9569\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2927 - accuracy: 0.8326 - auc: 0.9501 - val_loss: 0.2671 - val_accuracy: 0.8994 - val_auc: 0.9570\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2966 - accuracy: 0.8367 - auc: 0.9481 - val_loss: 0.2679 - val_accuracy: 0.9012 - val_auc: 0.9569\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2874 - accuracy: 0.8337 - auc: 0.9526 - val_loss: 0.2668 - val_accuracy: 0.8979 - val_auc: 0.9572\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2825 - accuracy: 0.8371 - auc: 0.9533 - val_loss: 0.2680 - val_accuracy: 0.8996 - val_auc: 0.9570\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2864 - accuracy: 0.8403 - auc: 0.9516 - val_loss: 0.2685 - val_accuracy: 0.9012 - val_auc: 0.9569\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2768 - accuracy: 0.8423 - auc: 0.9562 - val_loss: 0.2676 - val_accuracy: 0.9023 - val_auc: 0.9573\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2802 - accuracy: 0.8446 - auc: 0.9543 - val_loss: 0.2683 - val_accuracy: 0.9028 - val_auc: 0.9573\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2767 - accuracy: 0.8464 - auc: 0.9553 - val_loss: 0.2705 - val_accuracy: 0.9045 - val_auc: 0.9570\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2656 - accuracy: 0.8494 - auc: 0.9585 - val_loss: 0.2707 - val_accuracy: 0.9065 - val_auc: 0.9569\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2723 - accuracy: 0.8518 - auc: 0.9559 - val_loss: 0.2715 - val_accuracy: 0.9039 - val_auc: 0.9569\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2583 - accuracy: 0.8502 - auc: 0.9607 - val_loss: 0.2738 - val_accuracy: 0.9057 - val_auc: 0.9568\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2617 - accuracy: 0.8511 - auc: 0.9584 - val_loss: 0.2746 - val_accuracy: 0.9061 - val_auc: 0.9567\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2645 - accuracy: 0.8510 - auc: 0.9585 - val_loss: 0.2745 - val_accuracy: 0.9072 - val_auc: 0.9565\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2698 - accuracy: 0.8525 - auc: 0.9564 - val_loss: 0.2743 - val_accuracy: 0.9046 - val_auc: 0.9564\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2613 - accuracy: 0.8487 - auc: 0.9595 - val_loss: 0.2768 - val_accuracy: 0.9037 - val_auc: 0.9567\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2622 - accuracy: 0.8506 - auc: 0.9592 - val_loss: 0.2770 - val_accuracy: 0.9042 - val_auc: 0.9557\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2587 - accuracy: 0.8512 - auc: 0.9598 - val_loss: 0.2786 - val_accuracy: 0.9054 - val_auc: 0.9556\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2577 - accuracy: 0.8538 - auc: 0.9599 - val_loss: 0.2816 - val_accuracy: 0.9058 - val_auc: 0.9552\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2604 - accuracy: 0.8537 - auc: 0.9588 - val_loss: 0.2832 - val_accuracy: 0.9055 - val_auc: 0.9550\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2534 - accuracy: 0.8524 - auc: 0.9620 - val_loss: 0.2835 - val_accuracy: 0.9071 - val_auc: 0.9550\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2564 - accuracy: 0.8523 - auc: 0.9602 - val_loss: 0.2850 - val_accuracy: 0.9057 - val_auc: 0.9549\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2514 - accuracy: 0.8521 - auc: 0.9619 - val_loss: 0.2873 - val_accuracy: 0.9043 - val_auc: 0.9546\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2546 - accuracy: 0.8517 - auc: 0.9609 - val_loss: 0.2906 - val_accuracy: 0.9061 - val_auc: 0.9544\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2451 - accuracy: 0.8534 - auc: 0.9641 - val_loss: 0.2927 - val_accuracy: 0.9078 - val_auc: 0.9542\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2447 - accuracy: 0.8541 - auc: 0.9636 - val_loss: 0.2946 - val_accuracy: 0.9090 - val_auc: 0.9542\n",
      "Epoch 43/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2513 - accuracy: 0.8555 - auc: 0.9615Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2516 - accuracy: 0.8554 - auc: 0.9612 - val_loss: 0.2957 - val_accuracy: 0.9070 - val_auc: 0.9539\n",
      "Epoch 00043: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7396 - accuracy: 0.8249 - auc: 0.6555 - val_loss: 0.5321 - val_accuracy: 0.8961 - val_auc: 0.8277\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5348 - accuracy: 0.8477 - auc: 0.8233 - val_loss: 0.4319 - val_accuracy: 0.8961 - val_auc: 0.9169\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4772 - accuracy: 0.8649 - auc: 0.8641 - val_loss: 0.3889 - val_accuracy: 0.8997 - val_auc: 0.9320\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4239 - accuracy: 0.8763 - auc: 0.8985 - val_loss: 0.3589 - val_accuracy: 0.9005 - val_auc: 0.9410\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3967 - accuracy: 0.8838 - auc: 0.9136 - val_loss: 0.3412 - val_accuracy: 0.9032 - val_auc: 0.9459\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3749 - accuracy: 0.8886 - auc: 0.9248 - val_loss: 0.3288 - val_accuracy: 0.9068 - val_auc: 0.9486\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3694 - accuracy: 0.8953 - auc: 0.9298 - val_loss: 0.3190 - val_accuracy: 0.9095 - val_auc: 0.9505\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3600 - accuracy: 0.8985 - auc: 0.9319 - val_loss: 0.3110 - val_accuracy: 0.9082 - val_auc: 0.9517\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3404 - accuracy: 0.9018 - auc: 0.9406 - val_loss: 0.3055 - val_accuracy: 0.9108 - val_auc: 0.9525\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3373 - accuracy: 0.9026 - auc: 0.9434 - val_loss: 0.3017 - val_accuracy: 0.9121 - val_auc: 0.9532\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3325 - accuracy: 0.9056 - auc: 0.9388 - val_loss: 0.2977 - val_accuracy: 0.9151 - val_auc: 0.9538\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3223 - accuracy: 0.9085 - auc: 0.9478 - val_loss: 0.2934 - val_accuracy: 0.9145 - val_auc: 0.9546\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3264 - accuracy: 0.9072 - auc: 0.9435 - val_loss: 0.2897 - val_accuracy: 0.9146 - val_auc: 0.9553\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3137 - accuracy: 0.9089 - auc: 0.9488 - val_loss: 0.2854 - val_accuracy: 0.9145 - val_auc: 0.9561\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3053 - accuracy: 0.9085 - auc: 0.9511 - val_loss: 0.2837 - val_accuracy: 0.9131 - val_auc: 0.9566\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3177 - accuracy: 0.9085 - auc: 0.9457 - val_loss: 0.2814 - val_accuracy: 0.9117 - val_auc: 0.9570\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3134 - accuracy: 0.9098 - auc: 0.9476 - val_loss: 0.2780 - val_accuracy: 0.9147 - val_auc: 0.9578\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3136 - accuracy: 0.9128 - auc: 0.9486 - val_loss: 0.2764 - val_accuracy: 0.9144 - val_auc: 0.9579\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3126 - accuracy: 0.9084 - auc: 0.9498 - val_loss: 0.2770 - val_accuracy: 0.9124 - val_auc: 0.9572\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2945 - accuracy: 0.9118 - auc: 0.9550 - val_loss: 0.2743 - val_accuracy: 0.9141 - val_auc: 0.9590\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3031 - accuracy: 0.9127 - auc: 0.9497 - val_loss: 0.2729 - val_accuracy: 0.9153 - val_auc: 0.9588\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2871 - accuracy: 0.9142 - auc: 0.9575 - val_loss: 0.2723 - val_accuracy: 0.9154 - val_auc: 0.9585\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2982 - accuracy: 0.9133 - auc: 0.9527 - val_loss: 0.2720 - val_accuracy: 0.9139 - val_auc: 0.9579\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2885 - accuracy: 0.9144 - auc: 0.9565 - val_loss: 0.2729 - val_accuracy: 0.9164 - val_auc: 0.9573\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2883 - accuracy: 0.9165 - auc: 0.9563 - val_loss: 0.2729 - val_accuracy: 0.9177 - val_auc: 0.9573\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2901 - accuracy: 0.9150 - auc: 0.9551 - val_loss: 0.2699 - val_accuracy: 0.9171 - val_auc: 0.9579\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2828 - accuracy: 0.9177 - auc: 0.9565 - val_loss: 0.2703 - val_accuracy: 0.9169 - val_auc: 0.9575\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2873 - accuracy: 0.9151 - auc: 0.9547 - val_loss: 0.2703 - val_accuracy: 0.9152 - val_auc: 0.9569\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2888 - accuracy: 0.9146 - auc: 0.9554 - val_loss: 0.2712 - val_accuracy: 0.9150 - val_auc: 0.9571\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2840 - accuracy: 0.9146 - auc: 0.9567 - val_loss: 0.2698 - val_accuracy: 0.9153 - val_auc: 0.9568\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2730 - accuracy: 0.9162 - auc: 0.9603 - val_loss: 0.2699 - val_accuracy: 0.9177 - val_auc: 0.9568\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2833 - accuracy: 0.9157 - auc: 0.9558 - val_loss: 0.2704 - val_accuracy: 0.9163 - val_auc: 0.9565\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2817 - accuracy: 0.9164 - auc: 0.9578 - val_loss: 0.2732 - val_accuracy: 0.9148 - val_auc: 0.9551\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2853 - accuracy: 0.9154 - auc: 0.9558 - val_loss: 0.2712 - val_accuracy: 0.9156 - val_auc: 0.9559\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2797 - accuracy: 0.9176 - auc: 0.9569 - val_loss: 0.2727 - val_accuracy: 0.9179 - val_auc: 0.9552\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2746 - accuracy: 0.9169 - auc: 0.9587 - val_loss: 0.2736 - val_accuracy: 0.9176 - val_auc: 0.9550\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2701 - accuracy: 0.9166 - auc: 0.9599 - val_loss: 0.2721 - val_accuracy: 0.9182 - val_auc: 0.9554\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2825 - accuracy: 0.9158 - auc: 0.9559 - val_loss: 0.2718 - val_accuracy: 0.9180 - val_auc: 0.9556\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2651 - accuracy: 0.9196 - auc: 0.9621 - val_loss: 0.2737 - val_accuracy: 0.9201 - val_auc: 0.9550\n",
      "Epoch 40/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2785 - accuracy: 0.9169 - auc: 0.9576Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2791 - accuracy: 0.9170 - auc: 0.9574 - val_loss: 0.2729 - val_accuracy: 0.9169 - val_auc: 0.9549\n",
      "Epoch 00040: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.9130 - accuracy: 0.9031 - auc: 0.6405 - val_loss: 0.5077 - val_accuracy: 0.9178 - val_auc: 0.8254\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5906 - accuracy: 0.8765 - auc: 0.7998 - val_loss: 0.4046 - val_accuracy: 0.9000 - val_auc: 0.8984\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5036 - accuracy: 0.8771 - auc: 0.8552 - val_loss: 0.3583 - val_accuracy: 0.9006 - val_auc: 0.9258\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4687 - accuracy: 0.8841 - auc: 0.8749 - val_loss: 0.3391 - val_accuracy: 0.9050 - val_auc: 0.9363\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4375 - accuracy: 0.8892 - auc: 0.8909 - val_loss: 0.3252 - val_accuracy: 0.9105 - val_auc: 0.9417\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4123 - accuracy: 0.8959 - auc: 0.9031 - val_loss: 0.3146 - val_accuracy: 0.9101 - val_auc: 0.9462\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3986 - accuracy: 0.9033 - auc: 0.9171 - val_loss: 0.3081 - val_accuracy: 0.9157 - val_auc: 0.9484\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3742 - accuracy: 0.9050 - auc: 0.9212 - val_loss: 0.3006 - val_accuracy: 0.9175 - val_auc: 0.9502\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3666 - accuracy: 0.9043 - auc: 0.9268 - val_loss: 0.2972 - val_accuracy: 0.9155 - val_auc: 0.9510\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3575 - accuracy: 0.9066 - auc: 0.9314 - val_loss: 0.2922 - val_accuracy: 0.9171 - val_auc: 0.9520\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3533 - accuracy: 0.9076 - auc: 0.9338 - val_loss: 0.2880 - val_accuracy: 0.9188 - val_auc: 0.9527\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3421 - accuracy: 0.9130 - auc: 0.9359 - val_loss: 0.2847 - val_accuracy: 0.9207 - val_auc: 0.9532\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3512 - accuracy: 0.9121 - auc: 0.9338 - val_loss: 0.2829 - val_accuracy: 0.9180 - val_auc: 0.9538\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3464 - accuracy: 0.9114 - auc: 0.9345 - val_loss: 0.2805 - val_accuracy: 0.9182 - val_auc: 0.9542\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3256 - accuracy: 0.9148 - auc: 0.9416 - val_loss: 0.2764 - val_accuracy: 0.9207 - val_auc: 0.9550\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3295 - accuracy: 0.9146 - auc: 0.9397 - val_loss: 0.2758 - val_accuracy: 0.9190 - val_auc: 0.9548\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3275 - accuracy: 0.9134 - auc: 0.9412 - val_loss: 0.2748 - val_accuracy: 0.9182 - val_auc: 0.9550\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3108 - accuracy: 0.9135 - auc: 0.9451 - val_loss: 0.2723 - val_accuracy: 0.9186 - val_auc: 0.9555\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3067 - accuracy: 0.9147 - auc: 0.9480 - val_loss: 0.2733 - val_accuracy: 0.9196 - val_auc: 0.9552\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3082 - accuracy: 0.9165 - auc: 0.9482 - val_loss: 0.2737 - val_accuracy: 0.9201 - val_auc: 0.9551\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3046 - accuracy: 0.9128 - auc: 0.9485 - val_loss: 0.2720 - val_accuracy: 0.9184 - val_auc: 0.9555\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3011 - accuracy: 0.9150 - auc: 0.9506 - val_loss: 0.2708 - val_accuracy: 0.9193 - val_auc: 0.9557\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3019 - accuracy: 0.9147 - auc: 0.9498 - val_loss: 0.2721 - val_accuracy: 0.9194 - val_auc: 0.9552\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3057 - accuracy: 0.9163 - auc: 0.9473 - val_loss: 0.2724 - val_accuracy: 0.9193 - val_auc: 0.9547\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2968 - accuracy: 0.9157 - auc: 0.9503 - val_loss: 0.2697 - val_accuracy: 0.9191 - val_auc: 0.9559\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2937 - accuracy: 0.9153 - auc: 0.9510 - val_loss: 0.2698 - val_accuracy: 0.9186 - val_auc: 0.9556\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2823 - accuracy: 0.9163 - auc: 0.9560 - val_loss: 0.2702 - val_accuracy: 0.9192 - val_auc: 0.9557\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2835 - accuracy: 0.9147 - auc: 0.9544 - val_loss: 0.2699 - val_accuracy: 0.9191 - val_auc: 0.9559\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2940 - accuracy: 0.9175 - auc: 0.9517 - val_loss: 0.2706 - val_accuracy: 0.9181 - val_auc: 0.9560\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2908 - accuracy: 0.9157 - auc: 0.9532 - val_loss: 0.2710 - val_accuracy: 0.9200 - val_auc: 0.9559\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2908 - accuracy: 0.9169 - auc: 0.9523 - val_loss: 0.2712 - val_accuracy: 0.9182 - val_auc: 0.9553\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2830 - accuracy: 0.9148 - auc: 0.9544 - val_loss: 0.2712 - val_accuracy: 0.9196 - val_auc: 0.9558\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2769 - accuracy: 0.9181 - auc: 0.9566 - val_loss: 0.2721 - val_accuracy: 0.9193 - val_auc: 0.9556\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2725 - accuracy: 0.9160 - auc: 0.9578 - val_loss: 0.2728 - val_accuracy: 0.9184 - val_auc: 0.9550\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2897 - accuracy: 0.9172 - auc: 0.9520 - val_loss: 0.2745 - val_accuracy: 0.9169 - val_auc: 0.9547\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2851 - accuracy: 0.9146 - auc: 0.9543 - val_loss: 0.2757 - val_accuracy: 0.9185 - val_auc: 0.9547\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2730 - accuracy: 0.9177 - auc: 0.9572 - val_loss: 0.2761 - val_accuracy: 0.9199 - val_auc: 0.9552\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2777 - accuracy: 0.9189 - auc: 0.9564 - val_loss: 0.2772 - val_accuracy: 0.9200 - val_auc: 0.9548\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2735 - accuracy: 0.9160 - auc: 0.9575 - val_loss: 0.2789 - val_accuracy: 0.9186 - val_auc: 0.9542\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2677 - accuracy: 0.9170 - auc: 0.9592 - val_loss: 0.2795 - val_accuracy: 0.9173 - val_auc: 0.9541\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2677 - accuracy: 0.9165 - auc: 0.9588 - val_loss: 0.2805 - val_accuracy: 0.9189 - val_auc: 0.9537\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2631 - accuracy: 0.9159 - auc: 0.9599 - val_loss: 0.2821 - val_accuracy: 0.9188 - val_auc: 0.9536\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2617 - accuracy: 0.9180 - auc: 0.9604 - val_loss: 0.2838 - val_accuracy: 0.9204 - val_auc: 0.9530\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2721 - accuracy: 0.9155 - auc: 0.9575 - val_loss: 0.2816 - val_accuracy: 0.9174 - val_auc: 0.9540\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2740 - accuracy: 0.9168 - auc: 0.9567 - val_loss: 0.2833 - val_accuracy: 0.9185 - val_auc: 0.9541\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2583 - accuracy: 0.9153 - auc: 0.9611 - val_loss: 0.2831 - val_accuracy: 0.9172 - val_auc: 0.9533\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2603 - accuracy: 0.9151 - auc: 0.9609 - val_loss: 0.2840 - val_accuracy: 0.9173 - val_auc: 0.9533\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2589 - accuracy: 0.9143 - auc: 0.9607 - val_loss: 0.2864 - val_accuracy: 0.9181 - val_auc: 0.9529\n",
      "Epoch 49/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9156 - auc: 0.9579Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2667 - accuracy: 0.9156 - auc: 0.9580 - val_loss: 0.2873 - val_accuracy: 0.9192 - val_auc: 0.9530\n",
      "Epoch 00049: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 20us/sample - loss: 0.6879 - accuracy: 0.7887 - auc: 0.7105 - val_loss: 0.4508 - val_accuracy: 0.8524 - val_auc: 0.8840\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5306 - accuracy: 0.8194 - auc: 0.8237 - val_loss: 0.4081 - val_accuracy: 0.8732 - val_auc: 0.9112\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4725 - accuracy: 0.8419 - auc: 0.8760 - val_loss: 0.3840 - val_accuracy: 0.8843 - val_auc: 0.9242\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4181 - accuracy: 0.8660 - auc: 0.9023 - val_loss: 0.3617 - val_accuracy: 0.8981 - val_auc: 0.9339\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4003 - accuracy: 0.8801 - auc: 0.9119 - val_loss: 0.3454 - val_accuracy: 0.9004 - val_auc: 0.9393\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3854 - accuracy: 0.8873 - auc: 0.9238 - val_loss: 0.3322 - val_accuracy: 0.9024 - val_auc: 0.9428\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3765 - accuracy: 0.8851 - auc: 0.9235 - val_loss: 0.3204 - val_accuracy: 0.9027 - val_auc: 0.9460\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3557 - accuracy: 0.8908 - auc: 0.9287 - val_loss: 0.3141 - val_accuracy: 0.9064 - val_auc: 0.9478\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3429 - accuracy: 0.8959 - auc: 0.9347 - val_loss: 0.3059 - val_accuracy: 0.9098 - val_auc: 0.9491\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3339 - accuracy: 0.9012 - auc: 0.9395 - val_loss: 0.3015 - val_accuracy: 0.9096 - val_auc: 0.9498\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3400 - accuracy: 0.8996 - auc: 0.9368 - val_loss: 0.2948 - val_accuracy: 0.9080 - val_auc: 0.9509\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3179 - accuracy: 0.8992 - auc: 0.9466 - val_loss: 0.2918 - val_accuracy: 0.9093 - val_auc: 0.9510\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3215 - accuracy: 0.9024 - auc: 0.9431 - val_loss: 0.2879 - val_accuracy: 0.9101 - val_auc: 0.9522\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3145 - accuracy: 0.9046 - auc: 0.9461 - val_loss: 0.2849 - val_accuracy: 0.9126 - val_auc: 0.9527\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3113 - accuracy: 0.9056 - auc: 0.9476 - val_loss: 0.2826 - val_accuracy: 0.9118 - val_auc: 0.9529\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3082 - accuracy: 0.9040 - auc: 0.9474 - val_loss: 0.2804 - val_accuracy: 0.9097 - val_auc: 0.9534\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3030 - accuracy: 0.9056 - auc: 0.9491 - val_loss: 0.2805 - val_accuracy: 0.9114 - val_auc: 0.9533\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3050 - accuracy: 0.9040 - auc: 0.9480 - val_loss: 0.2786 - val_accuracy: 0.9097 - val_auc: 0.9537\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2934 - accuracy: 0.9049 - auc: 0.9534 - val_loss: 0.2784 - val_accuracy: 0.9119 - val_auc: 0.9534\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2954 - accuracy: 0.9085 - auc: 0.9523 - val_loss: 0.2776 - val_accuracy: 0.9135 - val_auc: 0.9535\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2900 - accuracy: 0.9061 - auc: 0.9545 - val_loss: 0.2785 - val_accuracy: 0.9117 - val_auc: 0.9531\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2909 - accuracy: 0.9086 - auc: 0.9531 - val_loss: 0.2776 - val_accuracy: 0.9140 - val_auc: 0.9532\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2829 - accuracy: 0.9092 - auc: 0.9563 - val_loss: 0.2767 - val_accuracy: 0.9146 - val_auc: 0.9535\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2810 - accuracy: 0.9118 - auc: 0.9568 - val_loss: 0.2751 - val_accuracy: 0.9159 - val_auc: 0.9539\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2923 - accuracy: 0.9109 - auc: 0.9521 - val_loss: 0.2751 - val_accuracy: 0.9135 - val_auc: 0.9541\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2762 - accuracy: 0.9079 - auc: 0.9585 - val_loss: 0.2761 - val_accuracy: 0.9143 - val_auc: 0.9539\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2814 - accuracy: 0.9098 - auc: 0.9563 - val_loss: 0.2781 - val_accuracy: 0.9135 - val_auc: 0.9532\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2844 - accuracy: 0.9098 - auc: 0.9541 - val_loss: 0.2788 - val_accuracy: 0.9143 - val_auc: 0.9533\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2840 - accuracy: 0.9094 - auc: 0.9545 - val_loss: 0.2805 - val_accuracy: 0.9135 - val_auc: 0.9529\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2742 - accuracy: 0.9117 - auc: 0.9571 - val_loss: 0.2816 - val_accuracy: 0.9146 - val_auc: 0.9528\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2806 - accuracy: 0.9109 - auc: 0.9556 - val_loss: 0.2824 - val_accuracy: 0.9139 - val_auc: 0.9527\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2728 - accuracy: 0.9087 - auc: 0.9580 - val_loss: 0.2840 - val_accuracy: 0.9137 - val_auc: 0.9526\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2711 - accuracy: 0.9117 - auc: 0.9588 - val_loss: 0.2852 - val_accuracy: 0.9151 - val_auc: 0.9525\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2623 - accuracy: 0.9143 - auc: 0.9615 - val_loss: 0.2872 - val_accuracy: 0.9164 - val_auc: 0.9526\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2674 - accuracy: 0.9127 - auc: 0.9602 - val_loss: 0.2863 - val_accuracy: 0.9157 - val_auc: 0.9525\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2730 - accuracy: 0.9128 - auc: 0.9575 - val_loss: 0.2883 - val_accuracy: 0.9170 - val_auc: 0.9521\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2717 - accuracy: 0.9131 - auc: 0.9578 - val_loss: 0.2909 - val_accuracy: 0.9162 - val_auc: 0.9513\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2607 - accuracy: 0.9165 - auc: 0.9614 - val_loss: 0.2934 - val_accuracy: 0.9185 - val_auc: 0.9513\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2569 - accuracy: 0.9167 - auc: 0.9627 - val_loss: 0.2940 - val_accuracy: 0.9183 - val_auc: 0.9514\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2587 - accuracy: 0.9144 - auc: 0.9629 - val_loss: 0.2959 - val_accuracy: 0.9161 - val_auc: 0.9512\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2661 - accuracy: 0.9125 - auc: 0.9594 - val_loss: 0.2973 - val_accuracy: 0.9171 - val_auc: 0.9512\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2640 - accuracy: 0.9129 - auc: 0.9610 - val_loss: 0.2985 - val_accuracy: 0.9180 - val_auc: 0.9509\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2674 - accuracy: 0.9164 - auc: 0.9593 - val_loss: 0.3007 - val_accuracy: 0.9161 - val_auc: 0.9507\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2613 - accuracy: 0.9127 - auc: 0.9612 - val_loss: 0.3027 - val_accuracy: 0.9149 - val_auc: 0.9505\n",
      "Epoch 45/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2635 - accuracy: 0.9126 - auc: 0.9604Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2635 - accuracy: 0.9126 - auc: 0.9604 - val_loss: 0.3043 - val_accuracy: 0.9174 - val_auc: 0.9505\n",
      "Epoch 00045: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.9107 - accuracy: 0.1610 - auc: 0.6996 - val_loss: 0.6293 - val_accuracy: 0.2126 - val_auc: 0.8884\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6405 - accuracy: 0.4017 - auc: 0.8422 - val_loss: 0.4618 - val_accuracy: 0.6010 - val_auc: 0.9175\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5016 - accuracy: 0.5974 - auc: 0.8824 - val_loss: 0.3801 - val_accuracy: 0.7699 - val_auc: 0.9290\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4402 - accuracy: 0.6934 - auc: 0.9028 - val_loss: 0.3341 - val_accuracy: 0.8278 - val_auc: 0.9404\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3785 - accuracy: 0.7459 - auc: 0.9269 - val_loss: 0.3083 - val_accuracy: 0.8634 - val_auc: 0.9447\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3586 - accuracy: 0.7831 - auc: 0.9310 - val_loss: 0.2924 - val_accuracy: 0.8787 - val_auc: 0.9495\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3444 - accuracy: 0.8021 - auc: 0.9348 - val_loss: 0.2828 - val_accuracy: 0.8794 - val_auc: 0.9522\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3253 - accuracy: 0.8097 - auc: 0.9414 - val_loss: 0.2774 - val_accuracy: 0.8824 - val_auc: 0.9534\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3143 - accuracy: 0.8211 - auc: 0.9436 - val_loss: 0.2704 - val_accuracy: 0.8878 - val_auc: 0.9555\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2971 - accuracy: 0.8314 - auc: 0.9494 - val_loss: 0.2684 - val_accuracy: 0.8914 - val_auc: 0.9558\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2912 - accuracy: 0.8366 - auc: 0.9511 - val_loss: 0.2688 - val_accuracy: 0.8928 - val_auc: 0.9558\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2853 - accuracy: 0.8408 - auc: 0.9529 - val_loss: 0.2692 - val_accuracy: 0.8951 - val_auc: 0.9558\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2799 - accuracy: 0.8452 - auc: 0.9543 - val_loss: 0.2703 - val_accuracy: 0.8964 - val_auc: 0.9554\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2666 - accuracy: 0.8486 - auc: 0.9584 - val_loss: 0.2709 - val_accuracy: 0.8984 - val_auc: 0.9559\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2699 - accuracy: 0.8528 - auc: 0.9570 - val_loss: 0.2736 - val_accuracy: 0.9008 - val_auc: 0.9548\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2715 - accuracy: 0.8537 - auc: 0.9570 - val_loss: 0.2736 - val_accuracy: 0.8978 - val_auc: 0.9551\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2582 - accuracy: 0.8566 - auc: 0.9609 - val_loss: 0.2764 - val_accuracy: 0.9022 - val_auc: 0.9548\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2593 - accuracy: 0.8554 - auc: 0.9607 - val_loss: 0.2747 - val_accuracy: 0.9012 - val_auc: 0.9553\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2628 - accuracy: 0.8601 - auc: 0.9594 - val_loss: 0.2754 - val_accuracy: 0.9005 - val_auc: 0.9553\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2523 - accuracy: 0.8612 - auc: 0.9625 - val_loss: 0.2761 - val_accuracy: 0.9030 - val_auc: 0.9555\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2530 - accuracy: 0.8651 - auc: 0.9621 - val_loss: 0.2794 - val_accuracy: 0.9037 - val_auc: 0.9552\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2520 - accuracy: 0.8663 - auc: 0.9622 - val_loss: 0.2812 - val_accuracy: 0.9051 - val_auc: 0.9550\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2485 - accuracy: 0.8670 - auc: 0.9642 - val_loss: 0.2802 - val_accuracy: 0.9038 - val_auc: 0.9553\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2393 - accuracy: 0.8682 - auc: 0.9654 - val_loss: 0.2835 - val_accuracy: 0.9061 - val_auc: 0.9551\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2470 - accuracy: 0.8681 - auc: 0.9635 - val_loss: 0.2828 - val_accuracy: 0.9039 - val_auc: 0.9553\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2390 - accuracy: 0.8694 - auc: 0.9655 - val_loss: 0.2871 - val_accuracy: 0.9055 - val_auc: 0.9549\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2329 - accuracy: 0.8710 - auc: 0.9672 - val_loss: 0.2863 - val_accuracy: 0.9059 - val_auc: 0.9553\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2332 - accuracy: 0.8721 - auc: 0.9674 - val_loss: 0.2895 - val_accuracy: 0.9070 - val_auc: 0.9553\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2336 - accuracy: 0.8750 - auc: 0.9663 - val_loss: 0.2912 - val_accuracy: 0.9061 - val_auc: 0.9539\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2408 - accuracy: 0.8730 - auc: 0.9651 - val_loss: 0.2923 - val_accuracy: 0.9047 - val_auc: 0.9536\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2323 - accuracy: 0.8723 - auc: 0.9673 - val_loss: 0.2951 - val_accuracy: 0.9058 - val_auc: 0.9536\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2262 - accuracy: 0.8768 - auc: 0.9685 - val_loss: 0.2974 - val_accuracy: 0.9088 - val_auc: 0.9538\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2362 - accuracy: 0.8762 - auc: 0.9665 - val_loss: 0.2991 - val_accuracy: 0.9079 - val_auc: 0.9534\n",
      "Epoch 34/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2348 - accuracy: 0.8764 - auc: 0.9666Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2347 - accuracy: 0.8763 - auc: 0.9666 - val_loss: 0.2984 - val_accuracy: 0.9075 - val_auc: 0.9527\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.1419 - accuracy: 0.9078 - auc: 0.5888 - val_loss: 0.5812 - val_accuracy: 0.9381 - val_auc: 0.8147\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6087 - accuracy: 0.8677 - auc: 0.8040 - val_loss: 0.4246 - val_accuracy: 0.9071 - val_auc: 0.9007\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4971 - accuracy: 0.8660 - auc: 0.8668 - val_loss: 0.3773 - val_accuracy: 0.9034 - val_auc: 0.9231\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4455 - accuracy: 0.8760 - auc: 0.8907 - val_loss: 0.3519 - val_accuracy: 0.9050 - val_auc: 0.9330\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4203 - accuracy: 0.8843 - auc: 0.9073 - val_loss: 0.3344 - val_accuracy: 0.9109 - val_auc: 0.9381\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4001 - accuracy: 0.8924 - auc: 0.9180 - val_loss: 0.3217 - val_accuracy: 0.9120 - val_auc: 0.9407\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3785 - accuracy: 0.8936 - auc: 0.9217 - val_loss: 0.3111 - val_accuracy: 0.9127 - val_auc: 0.9433\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3470 - accuracy: 0.8995 - auc: 0.9350 - val_loss: 0.3005 - val_accuracy: 0.9118 - val_auc: 0.9451\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3297 - accuracy: 0.8994 - auc: 0.9410 - val_loss: 0.2956 - val_accuracy: 0.9153 - val_auc: 0.9464\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3300 - accuracy: 0.9037 - auc: 0.9415 - val_loss: 0.2927 - val_accuracy: 0.9162 - val_auc: 0.9474\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3113 - accuracy: 0.9069 - auc: 0.9473 - val_loss: 0.2915 - val_accuracy: 0.9172 - val_auc: 0.9482\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3059 - accuracy: 0.9084 - auc: 0.9483 - val_loss: 0.2855 - val_accuracy: 0.9174 - val_auc: 0.9503\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3033 - accuracy: 0.9045 - auc: 0.9483 - val_loss: 0.2848 - val_accuracy: 0.9155 - val_auc: 0.9510\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2767 - accuracy: 0.9072 - auc: 0.9565 - val_loss: 0.2814 - val_accuracy: 0.9171 - val_auc: 0.9516\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2809 - accuracy: 0.9081 - auc: 0.9554 - val_loss: 0.2810 - val_accuracy: 0.9199 - val_auc: 0.9520\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2864 - accuracy: 0.9064 - auc: 0.9548 - val_loss: 0.2793 - val_accuracy: 0.9150 - val_auc: 0.9528\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2774 - accuracy: 0.9086 - auc: 0.9564 - val_loss: 0.2797 - val_accuracy: 0.9178 - val_auc: 0.9528\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2667 - accuracy: 0.9097 - auc: 0.9595 - val_loss: 0.2808 - val_accuracy: 0.9188 - val_auc: 0.9529\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2660 - accuracy: 0.9118 - auc: 0.9594 - val_loss: 0.2794 - val_accuracy: 0.9175 - val_auc: 0.9534\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2614 - accuracy: 0.9107 - auc: 0.9611 - val_loss: 0.2801 - val_accuracy: 0.9175 - val_auc: 0.9537\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2535 - accuracy: 0.9109 - auc: 0.9637 - val_loss: 0.2817 - val_accuracy: 0.9199 - val_auc: 0.9533\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2596 - accuracy: 0.9121 - auc: 0.9616 - val_loss: 0.2827 - val_accuracy: 0.9183 - val_auc: 0.9534\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2607 - accuracy: 0.9109 - auc: 0.9608 - val_loss: 0.2815 - val_accuracy: 0.9180 - val_auc: 0.9538\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2528 - accuracy: 0.9142 - auc: 0.9631 - val_loss: 0.2832 - val_accuracy: 0.9205 - val_auc: 0.9537\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2536 - accuracy: 0.9124 - auc: 0.9631 - val_loss: 0.2848 - val_accuracy: 0.9180 - val_auc: 0.9533\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2522 - accuracy: 0.9139 - auc: 0.9638 - val_loss: 0.2878 - val_accuracy: 0.9203 - val_auc: 0.9525\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2508 - accuracy: 0.9118 - auc: 0.9635 - val_loss: 0.2900 - val_accuracy: 0.9200 - val_auc: 0.9520\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2500 - accuracy: 0.9149 - auc: 0.9642 - val_loss: 0.2928 - val_accuracy: 0.9210 - val_auc: 0.9512\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2427 - accuracy: 0.9145 - auc: 0.9661 - val_loss: 0.2941 - val_accuracy: 0.9206 - val_auc: 0.9509\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2538 - accuracy: 0.9140 - auc: 0.9630 - val_loss: 0.2922 - val_accuracy: 0.9180 - val_auc: 0.9514\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2471 - accuracy: 0.9143 - auc: 0.9643 - val_loss: 0.2937 - val_accuracy: 0.9196 - val_auc: 0.9515\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2350 - accuracy: 0.9131 - auc: 0.9676 - val_loss: 0.2960 - val_accuracy: 0.9205 - val_auc: 0.9522\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2421 - accuracy: 0.9150 - auc: 0.9656 - val_loss: 0.2982 - val_accuracy: 0.9195 - val_auc: 0.9506\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2361 - accuracy: 0.9165 - auc: 0.9675 - val_loss: 0.3015 - val_accuracy: 0.9227 - val_auc: 0.9510\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2404 - accuracy: 0.9133 - auc: 0.9662 - val_loss: 0.3031 - val_accuracy: 0.9210 - val_auc: 0.9506\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2363 - accuracy: 0.9158 - auc: 0.9671 - val_loss: 0.3066 - val_accuracy: 0.9210 - val_auc: 0.9504\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2282 - accuracy: 0.9169 - auc: 0.9694 - val_loss: 0.3096 - val_accuracy: 0.9237 - val_auc: 0.9503\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2325 - accuracy: 0.9180 - auc: 0.9681 - val_loss: 0.3113 - val_accuracy: 0.9221 - val_auc: 0.9507\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2346 - accuracy: 0.9150 - auc: 0.9673 - val_loss: 0.3097 - val_accuracy: 0.9217 - val_auc: 0.9511\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2262 - accuracy: 0.9169 - auc: 0.9693 - val_loss: 0.3123 - val_accuracy: 0.9240 - val_auc: 0.9506\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2179 - accuracy: 0.9170 - auc: 0.9713 - val_loss: 0.3141 - val_accuracy: 0.9223 - val_auc: 0.9504\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2253 - accuracy: 0.9174 - auc: 0.9698 - val_loss: 0.3158 - val_accuracy: 0.9226 - val_auc: 0.9508\n",
      "Epoch 43/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2218 - accuracy: 0.9162 - auc: 0.9703Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2242 - accuracy: 0.9163 - auc: 0.9698 - val_loss: 0.3198 - val_accuracy: 0.9233 - val_auc: 0.9488\n",
      "Epoch 00043: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5733 - accuracy: 0.8629 - auc: 0.8091 - val_loss: 0.3861 - val_accuracy: 0.9064 - val_auc: 0.9134\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4653 - accuracy: 0.8605 - auc: 0.8789 - val_loss: 0.3536 - val_accuracy: 0.9026 - val_auc: 0.9307\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4232 - accuracy: 0.8765 - auc: 0.8988 - val_loss: 0.3324 - val_accuracy: 0.9057 - val_auc: 0.9389\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3801 - accuracy: 0.8838 - auc: 0.9181 - val_loss: 0.3141 - val_accuracy: 0.9093 - val_auc: 0.9457\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3506 - accuracy: 0.8940 - auc: 0.9283 - val_loss: 0.3045 - val_accuracy: 0.9152 - val_auc: 0.9477\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3535 - accuracy: 0.8972 - auc: 0.9285 - val_loss: 0.2989 - val_accuracy: 0.9124 - val_auc: 0.9491\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3392 - accuracy: 0.9009 - auc: 0.9337 - val_loss: 0.2924 - val_accuracy: 0.9128 - val_auc: 0.9511\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3079 - accuracy: 0.9034 - auc: 0.9456 - val_loss: 0.2892 - val_accuracy: 0.9159 - val_auc: 0.9517\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3095 - accuracy: 0.9045 - auc: 0.9472 - val_loss: 0.2882 - val_accuracy: 0.9153 - val_auc: 0.9517\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3055 - accuracy: 0.9058 - auc: 0.9478 - val_loss: 0.2792 - val_accuracy: 0.9153 - val_auc: 0.9543\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2928 - accuracy: 0.9047 - auc: 0.9515 - val_loss: 0.2781 - val_accuracy: 0.9150 - val_auc: 0.9539\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2958 - accuracy: 0.9072 - auc: 0.9502 - val_loss: 0.2762 - val_accuracy: 0.9175 - val_auc: 0.9546\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2896 - accuracy: 0.9110 - auc: 0.9517 - val_loss: 0.2752 - val_accuracy: 0.9162 - val_auc: 0.9550\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2855 - accuracy: 0.9071 - auc: 0.9537 - val_loss: 0.2755 - val_accuracy: 0.9171 - val_auc: 0.9551\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2808 - accuracy: 0.9130 - auc: 0.9545 - val_loss: 0.2722 - val_accuracy: 0.9162 - val_auc: 0.9558\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2738 - accuracy: 0.9097 - auc: 0.9567 - val_loss: 0.2719 - val_accuracy: 0.9176 - val_auc: 0.9558\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2679 - accuracy: 0.9120 - auc: 0.9597 - val_loss: 0.2733 - val_accuracy: 0.9192 - val_auc: 0.9555\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2757 - accuracy: 0.9117 - auc: 0.9562 - val_loss: 0.2730 - val_accuracy: 0.9197 - val_auc: 0.9554\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2682 - accuracy: 0.9146 - auc: 0.9586 - val_loss: 0.2744 - val_accuracy: 0.9188 - val_auc: 0.9549\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2623 - accuracy: 0.9061 - auc: 0.9600 - val_loss: 0.2740 - val_accuracy: 0.9169 - val_auc: 0.9550\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2517 - accuracy: 0.9138 - auc: 0.9637 - val_loss: 0.2749 - val_accuracy: 0.9195 - val_auc: 0.9547\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2550 - accuracy: 0.9148 - auc: 0.9619 - val_loss: 0.2748 - val_accuracy: 0.9203 - val_auc: 0.9550\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2590 - accuracy: 0.9160 - auc: 0.9608 - val_loss: 0.2744 - val_accuracy: 0.9195 - val_auc: 0.9551\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2586 - accuracy: 0.9144 - auc: 0.9606 - val_loss: 0.2767 - val_accuracy: 0.9202 - val_auc: 0.9542\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2484 - accuracy: 0.9162 - auc: 0.9640 - val_loss: 0.2770 - val_accuracy: 0.9208 - val_auc: 0.9547\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2520 - accuracy: 0.9148 - auc: 0.9625 - val_loss: 0.2737 - val_accuracy: 0.9185 - val_auc: 0.9553\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2561 - accuracy: 0.9128 - auc: 0.9615 - val_loss: 0.2713 - val_accuracy: 0.9191 - val_auc: 0.9561\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2595 - accuracy: 0.9145 - auc: 0.9604 - val_loss: 0.2724 - val_accuracy: 0.9211 - val_auc: 0.9558\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2504 - accuracy: 0.9151 - auc: 0.9637 - val_loss: 0.2725 - val_accuracy: 0.9218 - val_auc: 0.9558\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2399 - accuracy: 0.9171 - auc: 0.9663 - val_loss: 0.2745 - val_accuracy: 0.9216 - val_auc: 0.9557\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2507 - accuracy: 0.9165 - auc: 0.9634 - val_loss: 0.2769 - val_accuracy: 0.9220 - val_auc: 0.9550\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2388 - accuracy: 0.9161 - auc: 0.9666 - val_loss: 0.2773 - val_accuracy: 0.9211 - val_auc: 0.9550\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2399 - accuracy: 0.9163 - auc: 0.9664 - val_loss: 0.2786 - val_accuracy: 0.9202 - val_auc: 0.9542\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2445 - accuracy: 0.9140 - auc: 0.9646 - val_loss: 0.2783 - val_accuracy: 0.9189 - val_auc: 0.9541\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2476 - accuracy: 0.9135 - auc: 0.9640 - val_loss: 0.2785 - val_accuracy: 0.9211 - val_auc: 0.9541\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2348 - accuracy: 0.9151 - auc: 0.9675 - val_loss: 0.2832 - val_accuracy: 0.9225 - val_auc: 0.9533\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2357 - accuracy: 0.9155 - auc: 0.9671 - val_loss: 0.2828 - val_accuracy: 0.9230 - val_auc: 0.9538\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2351 - accuracy: 0.9173 - auc: 0.9669 - val_loss: 0.2840 - val_accuracy: 0.9235 - val_auc: 0.9540\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2450 - accuracy: 0.9179 - auc: 0.9646 - val_loss: 0.2873 - val_accuracy: 0.9230 - val_auc: 0.9532\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2292 - accuracy: 0.9163 - auc: 0.9684 - val_loss: 0.2860 - val_accuracy: 0.9222 - val_auc: 0.9537\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2358 - accuracy: 0.9160 - auc: 0.9666 - val_loss: 0.2876 - val_accuracy: 0.9223 - val_auc: 0.9539\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2298 - accuracy: 0.9181 - auc: 0.9684 - val_loss: 0.2859 - val_accuracy: 0.9225 - val_auc: 0.9540\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2320 - accuracy: 0.9156 - auc: 0.9676 - val_loss: 0.2835 - val_accuracy: 0.9226 - val_auc: 0.9552\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2351 - accuracy: 0.9170 - auc: 0.9669 - val_loss: 0.2881 - val_accuracy: 0.9245 - val_auc: 0.9545\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2297 - accuracy: 0.9172 - auc: 0.9682 - val_loss: 0.2888 - val_accuracy: 0.9247 - val_auc: 0.9545\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2303 - accuracy: 0.9175 - auc: 0.9680 - val_loss: 0.2908 - val_accuracy: 0.9238 - val_auc: 0.9542\n",
      "Epoch 47/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9166 - auc: 0.9691Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2254 - accuracy: 0.9166 - auc: 0.9690 - val_loss: 0.2944 - val_accuracy: 0.9240 - val_auc: 0.9537\n",
      "Epoch 00047: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 1.0513 - accuracy: 0.9290 - auc: 0.6201 - val_loss: 0.5064 - val_accuracy: 0.9605 - val_auc: 0.8681\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5721 - accuracy: 0.8953 - auc: 0.8224 - val_loss: 0.3946 - val_accuracy: 0.9334 - val_auc: 0.9130\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4605 - accuracy: 0.8855 - auc: 0.8786 - val_loss: 0.3603 - val_accuracy: 0.9199 - val_auc: 0.9272\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4279 - accuracy: 0.8873 - auc: 0.8948 - val_loss: 0.3397 - val_accuracy: 0.9180 - val_auc: 0.9360\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4061 - accuracy: 0.8927 - auc: 0.9108 - val_loss: 0.3230 - val_accuracy: 0.9147 - val_auc: 0.9422\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3883 - accuracy: 0.8954 - auc: 0.9140 - val_loss: 0.3119 - val_accuracy: 0.9159 - val_auc: 0.9452\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3716 - accuracy: 0.8958 - auc: 0.9236 - val_loss: 0.3023 - val_accuracy: 0.9136 - val_auc: 0.9479\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3361 - accuracy: 0.8979 - auc: 0.9366 - val_loss: 0.2965 - val_accuracy: 0.9148 - val_auc: 0.9489\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3342 - accuracy: 0.9003 - auc: 0.9377 - val_loss: 0.2937 - val_accuracy: 0.9168 - val_auc: 0.9496\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3224 - accuracy: 0.9013 - auc: 0.9421 - val_loss: 0.2884 - val_accuracy: 0.9168 - val_auc: 0.9506\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3129 - accuracy: 0.9045 - auc: 0.9444 - val_loss: 0.2846 - val_accuracy: 0.9164 - val_auc: 0.9517\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3187 - accuracy: 0.9046 - auc: 0.9433 - val_loss: 0.2809 - val_accuracy: 0.9172 - val_auc: 0.9534\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2957 - accuracy: 0.9094 - auc: 0.9505 - val_loss: 0.2799 - val_accuracy: 0.9204 - val_auc: 0.9534\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3034 - accuracy: 0.9104 - auc: 0.9513 - val_loss: 0.2759 - val_accuracy: 0.9202 - val_auc: 0.9549\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2875 - accuracy: 0.9110 - auc: 0.9532 - val_loss: 0.2781 - val_accuracy: 0.9172 - val_auc: 0.9542\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2914 - accuracy: 0.9060 - auc: 0.9517 - val_loss: 0.2768 - val_accuracy: 0.9167 - val_auc: 0.9546\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2774 - accuracy: 0.9099 - auc: 0.9557 - val_loss: 0.2766 - val_accuracy: 0.9185 - val_auc: 0.9542\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2735 - accuracy: 0.9120 - auc: 0.9579 - val_loss: 0.2758 - val_accuracy: 0.9201 - val_auc: 0.9547\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2720 - accuracy: 0.9104 - auc: 0.9583 - val_loss: 0.2748 - val_accuracy: 0.9187 - val_auc: 0.9551\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2678 - accuracy: 0.9121 - auc: 0.9598 - val_loss: 0.2750 - val_accuracy: 0.9211 - val_auc: 0.9551\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2693 - accuracy: 0.9129 - auc: 0.9587 - val_loss: 0.2748 - val_accuracy: 0.9189 - val_auc: 0.9551\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2678 - accuracy: 0.9129 - auc: 0.9585 - val_loss: 0.2753 - val_accuracy: 0.9180 - val_auc: 0.9553\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2596 - accuracy: 0.9119 - auc: 0.9612 - val_loss: 0.2765 - val_accuracy: 0.9202 - val_auc: 0.9550\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2635 - accuracy: 0.9134 - auc: 0.9595 - val_loss: 0.2759 - val_accuracy: 0.9202 - val_auc: 0.9555\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2642 - accuracy: 0.9108 - auc: 0.9595 - val_loss: 0.2757 - val_accuracy: 0.9169 - val_auc: 0.9551\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2674 - accuracy: 0.9112 - auc: 0.9595 - val_loss: 0.2758 - val_accuracy: 0.9188 - val_auc: 0.9552\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2518 - accuracy: 0.9132 - auc: 0.9625 - val_loss: 0.2771 - val_accuracy: 0.9187 - val_auc: 0.9551\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2622 - accuracy: 0.9118 - auc: 0.9607 - val_loss: 0.2759 - val_accuracy: 0.9193 - val_auc: 0.9557\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2519 - accuracy: 0.9135 - auc: 0.9627 - val_loss: 0.2776 - val_accuracy: 0.9206 - val_auc: 0.9555\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2549 - accuracy: 0.9151 - auc: 0.9630 - val_loss: 0.2770 - val_accuracy: 0.9206 - val_auc: 0.9556\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2426 - accuracy: 0.9137 - auc: 0.9657 - val_loss: 0.2780 - val_accuracy: 0.9213 - val_auc: 0.9559\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2449 - accuracy: 0.9175 - auc: 0.9652 - val_loss: 0.2801 - val_accuracy: 0.9225 - val_auc: 0.9556\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2454 - accuracy: 0.9142 - auc: 0.9646 - val_loss: 0.2808 - val_accuracy: 0.9188 - val_auc: 0.9552\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2449 - accuracy: 0.9142 - auc: 0.9645 - val_loss: 0.2812 - val_accuracy: 0.9202 - val_auc: 0.9553\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2389 - accuracy: 0.9141 - auc: 0.9662 - val_loss: 0.2822 - val_accuracy: 0.9215 - val_auc: 0.9554\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2434 - accuracy: 0.9162 - auc: 0.9648 - val_loss: 0.2844 - val_accuracy: 0.9223 - val_auc: 0.9546\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2429 - accuracy: 0.9163 - auc: 0.9650 - val_loss: 0.2839 - val_accuracy: 0.9215 - val_auc: 0.9546\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2403 - accuracy: 0.9149 - auc: 0.9658 - val_loss: 0.2863 - val_accuracy: 0.9236 - val_auc: 0.9543\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2321 - accuracy: 0.9172 - auc: 0.9681 - val_loss: 0.2873 - val_accuracy: 0.9229 - val_auc: 0.9541\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2373 - accuracy: 0.9147 - auc: 0.9667 - val_loss: 0.2848 - val_accuracy: 0.9224 - val_auc: 0.9549\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2304 - accuracy: 0.9159 - auc: 0.9685 - val_loss: 0.2860 - val_accuracy: 0.9220 - val_auc: 0.9547\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2207 - accuracy: 0.9173 - auc: 0.9708 - val_loss: 0.2902 - val_accuracy: 0.9238 - val_auc: 0.9543\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2252 - accuracy: 0.9166 - auc: 0.9693 - val_loss: 0.2928 - val_accuracy: 0.9227 - val_auc: 0.9540\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2350 - accuracy: 0.9149 - auc: 0.9670 - val_loss: 0.2952 - val_accuracy: 0.9228 - val_auc: 0.9536\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2268 - accuracy: 0.9164 - auc: 0.9689 - val_loss: 0.2972 - val_accuracy: 0.9222 - val_auc: 0.9535\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2356 - accuracy: 0.9139 - auc: 0.9669 - val_loss: 0.2984 - val_accuracy: 0.9212 - val_auc: 0.9529\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2264 - accuracy: 0.9144 - auc: 0.9691 - val_loss: 0.3006 - val_accuracy: 0.9234 - val_auc: 0.9528\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2238 - accuracy: 0.9177 - auc: 0.9700 - val_loss: 0.3028 - val_accuracy: 0.9233 - val_auc: 0.9528\n",
      "Epoch 49/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2204 - accuracy: 0.9170 - auc: 0.9706 - val_loss: 0.3047 - val_accuracy: 0.9238 - val_auc: 0.9526\n",
      "Epoch 50/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2248 - accuracy: 0.9159 - auc: 0.9691 - val_loss: 0.3090 - val_accuracy: 0.9225 - val_auc: 0.9519\n",
      "Epoch 51/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2236 - accuracy: 0.9166 - auc: 0.9697Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2235 - accuracy: 0.9166 - auc: 0.9698 - val_loss: 0.3138 - val_accuracy: 0.9237 - val_auc: 0.9516\n",
      "Epoch 00051: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 6s 23us/sample - loss: 0.7482 - accuracy: 0.5042 - auc: 0.7523 - val_loss: 0.4799 - val_accuracy: 0.6675 - val_auc: 0.9180\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5193 - accuracy: 0.7144 - auc: 0.8785 - val_loss: 0.3836 - val_accuracy: 0.8228 - val_auc: 0.9431\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4407 - accuracy: 0.8107 - auc: 0.9050 - val_loss: 0.3386 - val_accuracy: 0.8718 - val_auc: 0.9517\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3893 - accuracy: 0.8433 - auc: 0.9220 - val_loss: 0.3134 - val_accuracy: 0.8826 - val_auc: 0.9549\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3609 - accuracy: 0.8639 - auc: 0.9314 - val_loss: 0.3006 - val_accuracy: 0.8888 - val_auc: 0.9568\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3424 - accuracy: 0.8776 - auc: 0.9392 - val_loss: 0.2856 - val_accuracy: 0.8992 - val_auc: 0.9586\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3231 - accuracy: 0.8853 - auc: 0.9436 - val_loss: 0.2766 - val_accuracy: 0.9024 - val_auc: 0.9592\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3146 - accuracy: 0.8844 - auc: 0.9463 - val_loss: 0.2705 - val_accuracy: 0.9030 - val_auc: 0.9596\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2997 - accuracy: 0.8932 - auc: 0.9511 - val_loss: 0.2656 - val_accuracy: 0.9093 - val_auc: 0.9600\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2837 - accuracy: 0.8995 - auc: 0.9564 - val_loss: 0.2602 - val_accuracy: 0.9132 - val_auc: 0.9605\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2906 - accuracy: 0.8979 - auc: 0.9525 - val_loss: 0.2578 - val_accuracy: 0.9092 - val_auc: 0.9608\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2781 - accuracy: 0.9008 - auc: 0.9565 - val_loss: 0.2567 - val_accuracy: 0.9134 - val_auc: 0.9609\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2771 - accuracy: 0.9034 - auc: 0.9564 - val_loss: 0.2554 - val_accuracy: 0.9107 - val_auc: 0.9606\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.2729 - accuracy: 0.9015 - auc: 0.9579 - val_loss: 0.2555 - val_accuracy: 0.9125 - val_auc: 0.9605\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2699 - accuracy: 0.9034 - auc: 0.9583 - val_loss: 0.2554 - val_accuracy: 0.9119 - val_auc: 0.9606\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2689 - accuracy: 0.9047 - auc: 0.9593 - val_loss: 0.2554 - val_accuracy: 0.9123 - val_auc: 0.9598\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2663 - accuracy: 0.9044 - auc: 0.9596 - val_loss: 0.2547 - val_accuracy: 0.9135 - val_auc: 0.9599\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2576 - accuracy: 0.9070 - auc: 0.9617 - val_loss: 0.2556 - val_accuracy: 0.9164 - val_auc: 0.9594\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2485 - accuracy: 0.9110 - auc: 0.9648 - val_loss: 0.2551 - val_accuracy: 0.9152 - val_auc: 0.9598\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2464 - accuracy: 0.9062 - auc: 0.9654 - val_loss: 0.2549 - val_accuracy: 0.9142 - val_auc: 0.9594\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2481 - accuracy: 0.9089 - auc: 0.9646 - val_loss: 0.2573 - val_accuracy: 0.9158 - val_auc: 0.9591\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2479 - accuracy: 0.9080 - auc: 0.9641 - val_loss: 0.2587 - val_accuracy: 0.9181 - val_auc: 0.9589\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2460 - accuracy: 0.9112 - auc: 0.9650 - val_loss: 0.2582 - val_accuracy: 0.9161 - val_auc: 0.9592\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2366 - accuracy: 0.9105 - auc: 0.9678 - val_loss: 0.2583 - val_accuracy: 0.9174 - val_auc: 0.9593\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2387 - accuracy: 0.9126 - auc: 0.9667 - val_loss: 0.2586 - val_accuracy: 0.9174 - val_auc: 0.9585\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2482 - accuracy: 0.9087 - auc: 0.9640 - val_loss: 0.2600 - val_accuracy: 0.9152 - val_auc: 0.9583\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2366 - accuracy: 0.9105 - auc: 0.9671 - val_loss: 0.2604 - val_accuracy: 0.9168 - val_auc: 0.9585\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2362 - accuracy: 0.9104 - auc: 0.9669 - val_loss: 0.2627 - val_accuracy: 0.9187 - val_auc: 0.9582\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2385 - accuracy: 0.9107 - auc: 0.9669 - val_loss: 0.2635 - val_accuracy: 0.9173 - val_auc: 0.9583\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2360 - accuracy: 0.9112 - auc: 0.9674 - val_loss: 0.2635 - val_accuracy: 0.9172 - val_auc: 0.9582\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2331 - accuracy: 0.9105 - auc: 0.9679 - val_loss: 0.2661 - val_accuracy: 0.9187 - val_auc: 0.9572\n",
      "Epoch 32/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2307 - accuracy: 0.9123 - auc: 0.9685Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2298 - accuracy: 0.9124 - auc: 0.9689 - val_loss: 0.2689 - val_accuracy: 0.9194 - val_auc: 0.9561\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.8008 - accuracy: 0.3411 - auc: 0.7388 - val_loss: 0.5066 - val_accuracy: 0.5251 - val_auc: 0.8995\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5292 - accuracy: 0.5948 - auc: 0.8709 - val_loss: 0.3953 - val_accuracy: 0.7921 - val_auc: 0.9300\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4407 - accuracy: 0.7341 - auc: 0.8997 - val_loss: 0.3417 - val_accuracy: 0.8521 - val_auc: 0.9411\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3767 - accuracy: 0.8030 - auc: 0.9242 - val_loss: 0.3102 - val_accuracy: 0.8843 - val_auc: 0.9453\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3414 - accuracy: 0.8385 - auc: 0.9364 - val_loss: 0.2880 - val_accuracy: 0.8908 - val_auc: 0.9515\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3313 - accuracy: 0.8488 - auc: 0.9397 - val_loss: 0.2806 - val_accuracy: 0.8912 - val_auc: 0.9535\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3084 - accuracy: 0.8551 - auc: 0.9464 - val_loss: 0.2766 - val_accuracy: 0.8971 - val_auc: 0.9541\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2884 - accuracy: 0.8638 - auc: 0.9514 - val_loss: 0.2729 - val_accuracy: 0.9003 - val_auc: 0.9552\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2934 - accuracy: 0.8695 - auc: 0.9501 - val_loss: 0.2703 - val_accuracy: 0.9011 - val_auc: 0.9561\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2762 - accuracy: 0.8690 - auc: 0.9553 - val_loss: 0.2708 - val_accuracy: 0.9027 - val_auc: 0.9560\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2821 - accuracy: 0.8717 - auc: 0.9527 - val_loss: 0.2691 - val_accuracy: 0.9010 - val_auc: 0.9564\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2681 - accuracy: 0.8763 - auc: 0.9570 - val_loss: 0.2672 - val_accuracy: 0.9038 - val_auc: 0.9573\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2511 - accuracy: 0.8761 - auc: 0.9622 - val_loss: 0.2680 - val_accuracy: 0.9054 - val_auc: 0.9573\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2502 - accuracy: 0.8840 - auc: 0.9623 - val_loss: 0.2683 - val_accuracy: 0.9061 - val_auc: 0.9571\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2550 - accuracy: 0.8820 - auc: 0.9614 - val_loss: 0.2686 - val_accuracy: 0.9069 - val_auc: 0.9571\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2482 - accuracy: 0.8804 - auc: 0.9626 - val_loss: 0.2669 - val_accuracy: 0.9050 - val_auc: 0.9579\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2485 - accuracy: 0.8827 - auc: 0.9628 - val_loss: 0.2683 - val_accuracy: 0.9077 - val_auc: 0.9578\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2527 - accuracy: 0.8828 - auc: 0.9613 - val_loss: 0.2674 - val_accuracy: 0.9059 - val_auc: 0.9577\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2421 - accuracy: 0.8852 - auc: 0.9642 - val_loss: 0.2692 - val_accuracy: 0.9069 - val_auc: 0.9576\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2465 - accuracy: 0.8835 - auc: 0.9631 - val_loss: 0.2695 - val_accuracy: 0.9072 - val_auc: 0.9574\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2305 - accuracy: 0.8875 - auc: 0.9676 - val_loss: 0.2724 - val_accuracy: 0.9098 - val_auc: 0.9572\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2335 - accuracy: 0.8901 - auc: 0.9665 - val_loss: 0.2714 - val_accuracy: 0.9110 - val_auc: 0.9577\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2295 - accuracy: 0.8898 - auc: 0.9676 - val_loss: 0.2744 - val_accuracy: 0.9093 - val_auc: 0.9571\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2268 - accuracy: 0.8904 - auc: 0.9683 - val_loss: 0.2767 - val_accuracy: 0.9125 - val_auc: 0.9572\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2368 - accuracy: 0.8896 - auc: 0.9657 - val_loss: 0.2759 - val_accuracy: 0.9068 - val_auc: 0.9566\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2164 - accuracy: 0.8879 - auc: 0.9710 - val_loss: 0.2808 - val_accuracy: 0.9127 - val_auc: 0.9558\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2292 - accuracy: 0.8889 - auc: 0.9676 - val_loss: 0.2821 - val_accuracy: 0.9123 - val_auc: 0.9558\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2221 - accuracy: 0.8908 - auc: 0.9695 - val_loss: 0.2850 - val_accuracy: 0.9124 - val_auc: 0.9553\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2240 - accuracy: 0.8921 - auc: 0.9689 - val_loss: 0.2873 - val_accuracy: 0.9122 - val_auc: 0.9551\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2232 - accuracy: 0.8943 - auc: 0.9689 - val_loss: 0.2864 - val_accuracy: 0.9123 - val_auc: 0.9548\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2203 - accuracy: 0.8939 - auc: 0.9697 - val_loss: 0.2905 - val_accuracy: 0.9121 - val_auc: 0.9538\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2133 - accuracy: 0.8932 - auc: 0.9716 - val_loss: 0.2942 - val_accuracy: 0.9146 - val_auc: 0.9538\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2124 - accuracy: 0.8942 - auc: 0.9718 - val_loss: 0.2957 - val_accuracy: 0.9154 - val_auc: 0.9538\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2154 - accuracy: 0.8942 - auc: 0.9709 - val_loss: 0.2955 - val_accuracy: 0.9148 - val_auc: 0.9543\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2203 - accuracy: 0.8969 - auc: 0.9697 - val_loss: 0.2927 - val_accuracy: 0.9137 - val_auc: 0.9537\n",
      "Epoch 36/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.8918 - auc: 0.9715Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2131 - accuracy: 0.8918 - auc: 0.9715 - val_loss: 0.2954 - val_accuracy: 0.9130 - val_auc: 0.9533\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 1.0273 - accuracy: 0.1107 - auc: 0.7578 - val_loss: 0.6740 - val_accuracy: 0.1285 - val_auc: 0.8930\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6700 - accuracy: 0.3756 - auc: 0.8465 - val_loss: 0.4689 - val_accuracy: 0.6107 - val_auc: 0.9255\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5086 - accuracy: 0.5888 - auc: 0.8975 - val_loss: 0.3859 - val_accuracy: 0.7911 - val_auc: 0.9369\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4454 - accuracy: 0.7092 - auc: 0.9049 - val_loss: 0.3391 - val_accuracy: 0.8462 - val_auc: 0.9450\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4056 - accuracy: 0.7606 - auc: 0.9233 - val_loss: 0.3130 - val_accuracy: 0.8684 - val_auc: 0.9488\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3726 - accuracy: 0.7989 - auc: 0.9280 - val_loss: 0.2947 - val_accuracy: 0.8821 - val_auc: 0.9520\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3487 - accuracy: 0.8186 - auc: 0.9364 - val_loss: 0.2876 - val_accuracy: 0.8930 - val_auc: 0.9517\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3396 - accuracy: 0.8317 - auc: 0.9366 - val_loss: 0.2810 - val_accuracy: 0.8909 - val_auc: 0.9538\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3077 - accuracy: 0.8451 - auc: 0.9463 - val_loss: 0.2764 - val_accuracy: 0.8961 - val_auc: 0.9547\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3021 - accuracy: 0.8525 - auc: 0.9471 - val_loss: 0.2754 - val_accuracy: 0.9006 - val_auc: 0.9546\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2973 - accuracy: 0.8580 - auc: 0.9495 - val_loss: 0.2755 - val_accuracy: 0.9004 - val_auc: 0.9542\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2767 - accuracy: 0.8612 - auc: 0.9561 - val_loss: 0.2768 - val_accuracy: 0.9057 - val_auc: 0.9538\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2663 - accuracy: 0.8699 - auc: 0.9583 - val_loss: 0.2770 - val_accuracy: 0.9101 - val_auc: 0.9542\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2786 - accuracy: 0.8742 - auc: 0.9556 - val_loss: 0.2762 - val_accuracy: 0.9063 - val_auc: 0.9541\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2588 - accuracy: 0.8750 - auc: 0.9601 - val_loss: 0.2788 - val_accuracy: 0.9070 - val_auc: 0.9538\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2528 - accuracy: 0.8786 - auc: 0.9618 - val_loss: 0.2802 - val_accuracy: 0.9101 - val_auc: 0.9539\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2628 - accuracy: 0.8812 - auc: 0.9598 - val_loss: 0.2796 - val_accuracy: 0.9095 - val_auc: 0.9543\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2528 - accuracy: 0.8823 - auc: 0.9625 - val_loss: 0.2810 - val_accuracy: 0.9135 - val_auc: 0.9545\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2461 - accuracy: 0.8791 - auc: 0.9637 - val_loss: 0.2806 - val_accuracy: 0.9094 - val_auc: 0.9543\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2462 - accuracy: 0.8835 - auc: 0.9633 - val_loss: 0.2791 - val_accuracy: 0.9109 - val_auc: 0.9551\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2418 - accuracy: 0.8835 - auc: 0.9646 - val_loss: 0.2794 - val_accuracy: 0.9113 - val_auc: 0.9554\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2447 - accuracy: 0.8878 - auc: 0.9636 - val_loss: 0.2806 - val_accuracy: 0.9119 - val_auc: 0.9546\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2429 - accuracy: 0.8865 - auc: 0.9640 - val_loss: 0.2787 - val_accuracy: 0.9109 - val_auc: 0.9551\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2375 - accuracy: 0.8865 - auc: 0.9672 - val_loss: 0.2815 - val_accuracy: 0.9125 - val_auc: 0.9549\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2354 - accuracy: 0.8862 - auc: 0.9661 - val_loss: 0.2829 - val_accuracy: 0.9101 - val_auc: 0.9547\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2344 - accuracy: 0.8873 - auc: 0.9670 - val_loss: 0.2860 - val_accuracy: 0.9130 - val_auc: 0.9544\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2337 - accuracy: 0.8915 - auc: 0.9665 - val_loss: 0.2866 - val_accuracy: 0.9134 - val_auc: 0.9544\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2322 - accuracy: 0.8885 - auc: 0.9671 - val_loss: 0.2864 - val_accuracy: 0.9112 - val_auc: 0.9544\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2249 - accuracy: 0.8932 - auc: 0.9689 - val_loss: 0.2885 - val_accuracy: 0.9146 - val_auc: 0.9547\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2206 - accuracy: 0.8921 - auc: 0.9700 - val_loss: 0.2894 - val_accuracy: 0.9151 - val_auc: 0.9549\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2195 - accuracy: 0.8925 - auc: 0.9701 - val_loss: 0.2930 - val_accuracy: 0.9147 - val_auc: 0.9539\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2196 - accuracy: 0.8936 - auc: 0.9703 - val_loss: 0.2940 - val_accuracy: 0.9160 - val_auc: 0.9545\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2145 - accuracy: 0.8942 - auc: 0.9715 - val_loss: 0.2975 - val_accuracy: 0.9169 - val_auc: 0.9541\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2180 - accuracy: 0.8961 - auc: 0.9706 - val_loss: 0.2988 - val_accuracy: 0.9180 - val_auc: 0.9542\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2159 - accuracy: 0.8981 - auc: 0.9711 - val_loss: 0.3003 - val_accuracy: 0.9188 - val_auc: 0.9542\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2156 - accuracy: 0.8965 - auc: 0.9713 - val_loss: 0.3023 - val_accuracy: 0.9171 - val_auc: 0.9539\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2134 - accuracy: 0.8986 - auc: 0.9719 - val_loss: 0.3060 - val_accuracy: 0.9194 - val_auc: 0.9537\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2098 - accuracy: 0.8983 - auc: 0.9724 - val_loss: 0.3070 - val_accuracy: 0.9195 - val_auc: 0.9530\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2100 - accuracy: 0.8980 - auc: 0.9724 - val_loss: 0.3061 - val_accuracy: 0.9201 - val_auc: 0.9531\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2077 - accuracy: 0.9010 - auc: 0.9730 - val_loss: 0.3121 - val_accuracy: 0.9213 - val_auc: 0.9527\n",
      "Epoch 41/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2080 - accuracy: 0.9018 - auc: 0.9729Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2079 - accuracy: 0.9018 - auc: 0.9729 - val_loss: 0.3127 - val_accuracy: 0.9223 - val_auc: 0.9528\n",
      "Epoch 00041: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.7002 - accuracy: 0.5108 - auc: 0.7408 - val_loss: 0.4557 - val_accuracy: 0.7350 - val_auc: 0.9139\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4993 - accuracy: 0.7078 - auc: 0.8627 - val_loss: 0.3757 - val_accuracy: 0.8368 - val_auc: 0.9345\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4214 - accuracy: 0.7910 - auc: 0.9020 - val_loss: 0.3393 - val_accuracy: 0.8706 - val_auc: 0.9404\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3791 - accuracy: 0.8270 - auc: 0.9190 - val_loss: 0.3143 - val_accuracy: 0.8794 - val_auc: 0.9461\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3398 - accuracy: 0.8492 - auc: 0.9343 - val_loss: 0.3022 - val_accuracy: 0.8913 - val_auc: 0.9484\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3185 - accuracy: 0.8625 - auc: 0.9430 - val_loss: 0.2888 - val_accuracy: 0.8998 - val_auc: 0.9508\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3073 - accuracy: 0.8723 - auc: 0.9439 - val_loss: 0.2740 - val_accuracy: 0.8979 - val_auc: 0.9558\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2885 - accuracy: 0.8759 - auc: 0.9502 - val_loss: 0.2712 - val_accuracy: 0.9056 - val_auc: 0.9559\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2792 - accuracy: 0.8831 - auc: 0.9538 - val_loss: 0.2690 - val_accuracy: 0.9084 - val_auc: 0.9563\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2694 - accuracy: 0.8855 - auc: 0.9565 - val_loss: 0.2699 - val_accuracy: 0.9124 - val_auc: 0.9560\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2662 - accuracy: 0.8922 - auc: 0.9566 - val_loss: 0.2664 - val_accuracy: 0.9085 - val_auc: 0.9569\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2619 - accuracy: 0.8894 - auc: 0.9580 - val_loss: 0.2666 - val_accuracy: 0.9094 - val_auc: 0.9566\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2621 - accuracy: 0.8912 - auc: 0.9578 - val_loss: 0.2674 - val_accuracy: 0.9110 - val_auc: 0.9565\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2550 - accuracy: 0.8937 - auc: 0.9607 - val_loss: 0.2675 - val_accuracy: 0.9102 - val_auc: 0.9564\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2542 - accuracy: 0.8964 - auc: 0.9603 - val_loss: 0.2676 - val_accuracy: 0.9125 - val_auc: 0.9567\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2395 - accuracy: 0.8957 - auc: 0.9649 - val_loss: 0.2687 - val_accuracy: 0.9132 - val_auc: 0.9564\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2487 - accuracy: 0.8968 - auc: 0.9620 - val_loss: 0.2696 - val_accuracy: 0.9119 - val_auc: 0.9562\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2451 - accuracy: 0.8984 - auc: 0.9628 - val_loss: 0.2726 - val_accuracy: 0.9131 - val_auc: 0.9557\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2383 - accuracy: 0.8986 - auc: 0.9649 - val_loss: 0.2760 - val_accuracy: 0.9144 - val_auc: 0.9545\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2305 - accuracy: 0.8996 - auc: 0.9671 - val_loss: 0.2791 - val_accuracy: 0.9172 - val_auc: 0.9543oss: 0.2315 - accuracy: 0.8990 -\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2379 - accuracy: 0.9028 - auc: 0.9647 - val_loss: 0.2773 - val_accuracy: 0.9152 - val_auc: 0.9543\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2296 - accuracy: 0.8981 - auc: 0.9674 - val_loss: 0.2822 - val_accuracy: 0.9153 - val_auc: 0.9528\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2237 - accuracy: 0.9021 - auc: 0.9689 - val_loss: 0.2849 - val_accuracy: 0.9185 - val_auc: 0.9533\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2347 - accuracy: 0.9014 - auc: 0.9658 - val_loss: 0.2865 - val_accuracy: 0.9156 - val_auc: 0.9524\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2303 - accuracy: 0.9018 - auc: 0.9669 - val_loss: 0.2851 - val_accuracy: 0.9139 - val_auc: 0.9530\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2263 - accuracy: 0.9008 - auc: 0.9680 - val_loss: 0.2879 - val_accuracy: 0.9171 - val_auc: 0.9529\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2298 - accuracy: 0.9008 - auc: 0.9671 - val_loss: 0.2876 - val_accuracy: 0.9150 - val_auc: 0.9525\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2253 - accuracy: 0.9019 - auc: 0.9682 - val_loss: 0.2879 - val_accuracy: 0.9150 - val_auc: 0.9528\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2197 - accuracy: 0.9030 - auc: 0.9697 - val_loss: 0.2910 - val_accuracy: 0.9169 - val_auc: 0.9524\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2196 - accuracy: 0.9017 - auc: 0.9697 - val_loss: 0.2910 - val_accuracy: 0.9156 - val_auc: 0.9527\n",
      "Epoch 31/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2139 - accuracy: 0.9040 - auc: 0.9708Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2153 - accuracy: 0.9039 - auc: 0.9708 - val_loss: 0.2949 - val_accuracy: 0.9180 - val_auc: 0.9524\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.7301 - accuracy: 0.6514 - auc: 0.7232 - val_loss: 0.4476 - val_accuracy: 0.7834 - val_auc: 0.8890\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5198 - accuracy: 0.7581 - auc: 0.8588 - val_loss: 0.3723 - val_accuracy: 0.8549 - val_auc: 0.9236\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4291 - accuracy: 0.8233 - auc: 0.8975 - val_loss: 0.3336 - val_accuracy: 0.8812 - val_auc: 0.9384\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3803 - accuracy: 0.8488 - auc: 0.9215 - val_loss: 0.3126 - val_accuracy: 0.8947 - val_auc: 0.9436\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3580 - accuracy: 0.8684 - auc: 0.9292 - val_loss: 0.3009 - val_accuracy: 0.9006 - val_auc: 0.9464\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3281 - accuracy: 0.8730 - auc: 0.9392 - val_loss: 0.2920 - val_accuracy: 0.9033 - val_auc: 0.9486\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3209 - accuracy: 0.8754 - auc: 0.9404 - val_loss: 0.2856 - val_accuracy: 0.9007 - val_auc: 0.9510\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3093 - accuracy: 0.8815 - auc: 0.9458 - val_loss: 0.2800 - val_accuracy: 0.9051 - val_auc: 0.9527\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2953 - accuracy: 0.8885 - auc: 0.9483 - val_loss: 0.2769 - val_accuracy: 0.9092 - val_auc: 0.9536\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2894 - accuracy: 0.8875 - auc: 0.9510 - val_loss: 0.2763 - val_accuracy: 0.9070 - val_auc: 0.9535\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2758 - accuracy: 0.8919 - auc: 0.9549 - val_loss: 0.2747 - val_accuracy: 0.9096 - val_auc: 0.9541\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2593 - accuracy: 0.8966 - auc: 0.9606 - val_loss: 0.2761 - val_accuracy: 0.9163 - val_auc: 0.9540\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2762 - accuracy: 0.8984 - auc: 0.9542 - val_loss: 0.2761 - val_accuracy: 0.9103 - val_auc: 0.9537\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2589 - accuracy: 0.8975 - auc: 0.9598 - val_loss: 0.2751 - val_accuracy: 0.9099 - val_auc: 0.9541\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2638 - accuracy: 0.8973 - auc: 0.9597 - val_loss: 0.2750 - val_accuracy: 0.9125 - val_auc: 0.9544\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2561 - accuracy: 0.8976 - auc: 0.9607 - val_loss: 0.2741 - val_accuracy: 0.9105 - val_auc: 0.9548\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2535 - accuracy: 0.8986 - auc: 0.9614 - val_loss: 0.2725 - val_accuracy: 0.9112 - val_auc: 0.9555\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2521 - accuracy: 0.8984 - auc: 0.9619 - val_loss: 0.2720 - val_accuracy: 0.9107 - val_auc: 0.9559\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2415 - accuracy: 0.8994 - auc: 0.9651 - val_loss: 0.2713 - val_accuracy: 0.9136 - val_auc: 0.9564\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2491 - accuracy: 0.8981 - auc: 0.9627 - val_loss: 0.2720 - val_accuracy: 0.9097 - val_auc: 0.9559\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2326 - accuracy: 0.9014 - auc: 0.9677 - val_loss: 0.2740 - val_accuracy: 0.9148 - val_auc: 0.9554\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2364 - accuracy: 0.9058 - auc: 0.9660 - val_loss: 0.2744 - val_accuracy: 0.9168 - val_auc: 0.9559\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2310 - accuracy: 0.9057 - auc: 0.9676 - val_loss: 0.2787 - val_accuracy: 0.9188 - val_auc: 0.9550\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2337 - accuracy: 0.9062 - auc: 0.9669 - val_loss: 0.2772 - val_accuracy: 0.9154 - val_auc: 0.9552\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2307 - accuracy: 0.9050 - auc: 0.9677 - val_loss: 0.2795 - val_accuracy: 0.9166 - val_auc: 0.9551\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2311 - accuracy: 0.9054 - auc: 0.9672 - val_loss: 0.2799 - val_accuracy: 0.9157 - val_auc: 0.9547\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2233 - accuracy: 0.9072 - auc: 0.9695 - val_loss: 0.2833 - val_accuracy: 0.9194 - val_auc: 0.9547\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2198 - accuracy: 0.9096 - auc: 0.9704 - val_loss: 0.2861 - val_accuracy: 0.9193 - val_auc: 0.9542\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2262 - accuracy: 0.9090 - auc: 0.9687 - val_loss: 0.2877 - val_accuracy: 0.9171 - val_auc: 0.9539\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2238 - accuracy: 0.9055 - auc: 0.9692 - val_loss: 0.2884 - val_accuracy: 0.9167 - val_auc: 0.9536\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2214 - accuracy: 0.9090 - auc: 0.9697 - val_loss: 0.2916 - val_accuracy: 0.9189 - val_auc: 0.9535\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2208 - accuracy: 0.9081 - auc: 0.9700 - val_loss: 0.2933 - val_accuracy: 0.9187 - val_auc: 0.9530\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2110 - accuracy: 0.9107 - auc: 0.9723 - val_loss: 0.2936 - val_accuracy: 0.9209 - val_auc: 0.9537\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2188 - accuracy: 0.9103 - auc: 0.9704 - val_loss: 0.2949 - val_accuracy: 0.9175 - val_auc: 0.9531\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2113 - accuracy: 0.9073 - auc: 0.9721 - val_loss: 0.2996 - val_accuracy: 0.9191 - val_auc: 0.9524\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2218 - accuracy: 0.9074 - auc: 0.9697 - val_loss: 0.2970 - val_accuracy: 0.9175 - val_auc: 0.9532\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2194 - accuracy: 0.9070 - auc: 0.9700 - val_loss: 0.2992 - val_accuracy: 0.9187 - val_auc: 0.9528\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2100 - accuracy: 0.9120 - auc: 0.9725 - val_loss: 0.3059 - val_accuracy: 0.9221 - val_auc: 0.9510\n",
      "Epoch 39/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9104 - auc: 0.9716Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2130 - accuracy: 0.9104 - auc: 0.9717 - val_loss: 0.3074 - val_accuracy: 0.9223 - val_auc: 0.9513\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.9055 - accuracy: 0.8058 - auc: 0.6573 - val_loss: 0.4088 - val_accuracy: 0.8529 - val_auc: 0.9126\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4914 - accuracy: 0.8177 - auc: 0.8704 - val_loss: 0.3652 - val_accuracy: 0.8790 - val_auc: 0.9329\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4387 - accuracy: 0.8523 - auc: 0.9034 - val_loss: 0.3375 - val_accuracy: 0.8949 - val_auc: 0.9420\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3935 - accuracy: 0.8699 - auc: 0.9182 - val_loss: 0.3235 - val_accuracy: 0.9010 - val_auc: 0.9451\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3676 - accuracy: 0.8797 - auc: 0.9298 - val_loss: 0.3123 - val_accuracy: 0.9028 - val_auc: 0.9477\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3407 - accuracy: 0.8884 - auc: 0.9362 - val_loss: 0.3039 - val_accuracy: 0.9086 - val_auc: 0.9483\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3253 - accuracy: 0.8956 - auc: 0.9417 - val_loss: 0.2967 - val_accuracy: 0.9106 - val_auc: 0.9496\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3161 - accuracy: 0.8966 - auc: 0.9435 - val_loss: 0.2907 - val_accuracy: 0.9103 - val_auc: 0.9515\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2964 - accuracy: 0.8998 - auc: 0.9517 - val_loss: 0.2906 - val_accuracy: 0.9130 - val_auc: 0.9510\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2934 - accuracy: 0.9000 - auc: 0.9513 - val_loss: 0.2891 - val_accuracy: 0.9144 - val_auc: 0.9513\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2722 - accuracy: 0.9037 - auc: 0.9578 - val_loss: 0.2868 - val_accuracy: 0.9154 - val_auc: 0.9519\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2781 - accuracy: 0.9028 - auc: 0.9554 - val_loss: 0.2875 - val_accuracy: 0.9150 - val_auc: 0.9517\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2702 - accuracy: 0.9055 - auc: 0.9581 - val_loss: 0.2866 - val_accuracy: 0.9135 - val_auc: 0.9511\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2706 - accuracy: 0.9048 - auc: 0.9572 - val_loss: 0.2884 - val_accuracy: 0.9155 - val_auc: 0.9507\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2642 - accuracy: 0.9081 - auc: 0.9594 - val_loss: 0.2857 - val_accuracy: 0.9136 - val_auc: 0.9508\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2452 - accuracy: 0.9079 - auc: 0.9652 - val_loss: 0.2892 - val_accuracy: 0.9177 - val_auc: 0.9505\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2565 - accuracy: 0.9105 - auc: 0.9612 - val_loss: 0.2887 - val_accuracy: 0.9163 - val_auc: 0.9504\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2553 - accuracy: 0.9088 - auc: 0.9623 - val_loss: 0.2871 - val_accuracy: 0.9179 - val_auc: 0.9508\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2461 - accuracy: 0.9095 - auc: 0.9645 - val_loss: 0.2889 - val_accuracy: 0.9188 - val_auc: 0.9510\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2424 - accuracy: 0.9100 - auc: 0.9650 - val_loss: 0.2938 - val_accuracy: 0.9190 - val_auc: 0.9503\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2434 - accuracy: 0.9117 - auc: 0.9645 - val_loss: 0.2957 - val_accuracy: 0.9184 - val_auc: 0.9498\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2447 - accuracy: 0.9118 - auc: 0.9649 - val_loss: 0.2967 - val_accuracy: 0.9188 - val_auc: 0.9495\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2328 - accuracy: 0.9072 - auc: 0.9679 - val_loss: 0.2978 - val_accuracy: 0.9196 - val_auc: 0.9490\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2312 - accuracy: 0.9119 - auc: 0.9684 - val_loss: 0.3019 - val_accuracy: 0.9232 - val_auc: 0.9486\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2295 - accuracy: 0.9144 - auc: 0.9687 - val_loss: 0.3021 - val_accuracy: 0.9206 - val_auc: 0.9491\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2321 - accuracy: 0.9125 - auc: 0.9679 - val_loss: 0.3021 - val_accuracy: 0.9193 - val_auc: 0.9496\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2275 - accuracy: 0.9128 - auc: 0.9686 - val_loss: 0.3056 - val_accuracy: 0.9199 - val_auc: 0.9499\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2251 - accuracy: 0.9118 - auc: 0.9695 - val_loss: 0.3099 - val_accuracy: 0.9220 - val_auc: 0.9486\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2215 - accuracy: 0.9135 - auc: 0.9703 - val_loss: 0.3137 - val_accuracy: 0.9209 - val_auc: 0.9486\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2275 - accuracy: 0.9127 - auc: 0.9688 - val_loss: 0.3171 - val_accuracy: 0.9199 - val_auc: 0.9486\n",
      "Epoch 31/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9123 - auc: 0.9679Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2332 - accuracy: 0.9123 - auc: 0.9673 - val_loss: 0.3209 - val_accuracy: 0.9199 - val_auc: 0.9483\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 312863 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "312863/312863 [==============================] - 4s 12us/sample - loss: 0.6322 - accuracy: 0.8858 - auc: 0.8355 - val_loss: 0.3218 - val_accuracy: 0.9203 - val_auc: 0.9517\n",
      "Epoch 2/100\n",
      "312863/312863 [==============================] - 2s 7us/sample - loss: 0.3702 - accuracy: 0.9101 - auc: 0.9260 - val_loss: 0.3051 - val_accuracy: 0.9181 - val_auc: 0.9516\n",
      "Epoch 3/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3510 - accuracy: 0.9153 - auc: 0.9340 - val_loss: 0.2955 - val_accuracy: 0.9191 - val_auc: 0.9535\n",
      "Epoch 4/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3403 - accuracy: 0.9120 - auc: 0.9377 - val_loss: 0.2988 - val_accuracy: 0.9120 - val_auc: 0.9518\n",
      "Epoch 5/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3338 - accuracy: 0.9131 - auc: 0.9411 - val_loss: 0.2914 - val_accuracy: 0.9338 - val_auc: 0.9508\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3232 - accuracy: 0.9158 - auc: 0.9462 - val_loss: 0.2769 - val_accuracy: 0.9133 - val_auc: 0.9543\n",
      "Epoch 7/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3158 - accuracy: 0.9155 - auc: 0.9459 - val_loss: 0.2732 - val_accuracy: 0.9207 - val_auc: 0.9562\n",
      "Epoch 8/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3150 - accuracy: 0.9140 - auc: 0.9459 - val_loss: 0.2801 - val_accuracy: 0.9213 - val_auc: 0.9547\n",
      "Epoch 9/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3113 - accuracy: 0.9171 - auc: 0.9467 - val_loss: 0.2776 - val_accuracy: 0.9097 - val_auc: 0.9546\n",
      "Epoch 10/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3041 - accuracy: 0.9168 - auc: 0.9480 - val_loss: 0.2794 - val_accuracy: 0.9097 - val_auc: 0.9532\n",
      "Epoch 11/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3066 - accuracy: 0.9159 - auc: 0.9486 - val_loss: 0.3052 - val_accuracy: 0.9027 - val_auc: 0.9504\n",
      "Epoch 12/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2995 - accuracy: 0.9149 - auc: 0.9506 - val_loss: 0.3152 - val_accuracy: 0.9146 - val_auc: 0.9506\n",
      "Epoch 13/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.3027 - accuracy: 0.9169 - auc: 0.9492 - val_loss: 0.3201 - val_accuracy: 0.9038 - val_auc: 0.9527\n",
      "Epoch 14/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2913 - accuracy: 0.9152 - auc: 0.9538 - val_loss: 0.3276 - val_accuracy: 0.9242 - val_auc: 0.9507\n",
      "Epoch 15/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2881 - accuracy: 0.9183 - auc: 0.9558 - val_loss: 0.3149 - val_accuracy: 0.9202 - val_auc: 0.9522\n",
      "Epoch 16/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2922 - accuracy: 0.9155 - auc: 0.9516 - val_loss: 0.3211 - val_accuracy: 0.9186 - val_auc: 0.9508\n",
      "Epoch 17/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2772 - accuracy: 0.9188 - auc: 0.9572 - val_loss: 0.3448 - val_accuracy: 0.9347 - val_auc: 0.9502\n",
      "Epoch 18/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2796 - accuracy: 0.9168 - auc: 0.9569 - val_loss: 0.3503 - val_accuracy: 0.9289 - val_auc: 0.9516\n",
      "Epoch 19/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2829 - accuracy: 0.9196 - auc: 0.9556 - val_loss: 0.3511 - val_accuracy: 0.9161 - val_auc: 0.9482\n",
      "Epoch 20/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2840 - accuracy: 0.9175 - auc: 0.9567 - val_loss: 0.3508 - val_accuracy: 0.9203 - val_auc: 0.9525\n",
      "Epoch 21/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2839 - accuracy: 0.9176 - auc: 0.9557 - val_loss: 0.3526 - val_accuracy: 0.9319 - val_auc: 0.9509\n",
      "Epoch 22/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2867 - accuracy: 0.9178 - auc: 0.9546 - val_loss: 0.3330 - val_accuracy: 0.9112 - val_auc: 0.9507\n",
      "Epoch 23/100\n",
      "312863/312863 [==============================] - 3s 8us/sample - loss: 0.2859 - accuracy: 0.9186 - auc: 0.9565 - val_loss: 0.3570 - val_accuracy: 0.9059 - val_auc: 0.9517\n",
      "Epoch 24/100\n",
      "312863/312863 [==============================] - 3s 8us/sample - loss: 0.2877 - accuracy: 0.9164 - auc: 0.9539 - val_loss: 0.3234 - val_accuracy: 0.9200 - val_auc: 0.9506\n",
      "Epoch 25/100\n",
      "312863/312863 [==============================] - 2s 8us/sample - loss: 0.2746 - accuracy: 0.9216 - auc: 0.9576 - val_loss: 0.3222 - val_accuracy: 0.9166 - val_auc: 0.9514\n",
      "Epoch 26/100\n",
      "312863/312863 [==============================] - 3s 8us/sample - loss: 0.2762 - accuracy: 0.9229 - auc: 0.9562 - val_loss: 0.3629 - val_accuracy: 0.9112 - val_auc: 0.9514\n",
      "Epoch 27/100\n",
      "306176/312863 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.9194 - auc: 0.9568Restoring model weights from the end of the best epoch.\n",
      "312863/312863 [==============================] - 3s 8us/sample - loss: 0.2810 - accuracy: 0.9194 - auc: 0.9569 - val_loss: 0.3655 - val_accuracy: 0.9344 - val_auc: 0.9534\n",
      "Epoch 00027: early stopping\n",
      "204.0366351524989\n"
     ]
    }
   ],
   "source": [
    "model= KerasClassifier(build_fn = create_model)\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_options,\n",
    "                    scoring='balanced_accuracy')\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train,\n",
    "                       callbacks=[es],\n",
    "                       epochs=100,\n",
    "                       class_weight=class_weight,\n",
    "                       validation_data = (X_val,y_val),verbose = 1)\n",
    "end_time=time.time()\n",
    "\n",
    "print((end_time-start_time)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T00:47:00.047503Z",
     "start_time": "2020-05-22T00:46:56.904333Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "J_IMch4MjhLO"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(grid_result.cv_results_).to_excel('GS_weights_3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "VCA-ID-Tuning for weight.ipynb",
   "provenance": [
    {
     "file_id": "1feXHQjiqioLl47_p65uRpdSv6vX9EnAr",
     "timestamp": 1589212555597
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
