{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:44:40.812597Z",
     "start_time": "2020-05-21T20:44:39.241218Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1QxOQkOlJ1S_"
   },
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cq34ehtsJ1Th"
   },
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:44:50.234934Z",
     "start_time": "2020-05-21T20:44:40.816085Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10148,
     "status": "ok",
     "timestamp": 1589212832817,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "_v04MZq4J1To",
    "outputId": "0dd4542d-a365-47ce-8669-1d559fef6985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488849, 151)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prsn_Injry_Sev_ID</th>\n",
       "      <th>Unit_Nbr</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Toll_Road_Fl</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Constr_Zone_Fl</th>\n",
       "      <th>Road_Constr_Zone_Wrkr_Fl</th>\n",
       "      <th>At_Intrsct_Fl</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_Cntl_ID_SIGNAL LIGHT WITH RED LIGHT RUNNING CAMERA</th>\n",
       "      <th>Traffic_Cntl_ID_STOP SIGN</th>\n",
       "      <th>Traffic_Cntl_ID_WARNING SIGN</th>\n",
       "      <th>Unit_Desc_ID_MOTOR VEHICLE</th>\n",
       "      <th>Unit_Desc_ID_MOTORIZED CONVEYANCE</th>\n",
       "      <th>Unit_Desc_ID_NON-CONTACT</th>\n",
       "      <th>Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)</th>\n",
       "      <th>Unit_Desc_ID_PEDALCYCLIST</th>\n",
       "      <th>Unit_Desc_ID_PEDESTRIAN</th>\n",
       "      <th>Unit_Desc_ID_TOWED/PUSHED/TRAILER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.660685</td>\n",
       "      <td>-93.893906</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.660685</td>\n",
       "      <td>-93.893906</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.203920</td>\n",
       "      <td>-96.596654</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.203920</td>\n",
       "      <td>-96.596654</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.792394</td>\n",
       "      <td>-95.746539</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prsn_Injry_Sev_ID  Unit_Nbr  Prsn_Age  Toll_Road_Fl  Crash_Speed_Limit  \\\n",
       "0                  0         1      48.0             0                 35   \n",
       "1                  2         2      58.0             0                 35   \n",
       "2                  0         1      68.0             0                 45   \n",
       "3                  0         3      67.0             0                 45   \n",
       "4                  0         1      36.0             0                 35   \n",
       "\n",
       "   Road_Constr_Zone_Fl  Road_Constr_Zone_Wrkr_Fl  At_Intrsct_Fl   Latitude  \\\n",
       "0                    0                         0              0  30.660685   \n",
       "1                    0                         0              0  30.660685   \n",
       "2                    0                         0              1  33.203920   \n",
       "3                    0                         0              1  33.203920   \n",
       "4                    0                         0              1  29.792394   \n",
       "\n",
       "   Longitude  ...  Traffic_Cntl_ID_SIGNAL LIGHT WITH RED LIGHT RUNNING CAMERA  \\\n",
       "0 -93.893906  ...                                                  0            \n",
       "1 -93.893906  ...                                                  0            \n",
       "2 -96.596654  ...                                                  0            \n",
       "3 -96.596654  ...                                                  0            \n",
       "4 -95.746539  ...                                                  0            \n",
       "\n",
       "   Traffic_Cntl_ID_STOP SIGN  Traffic_Cntl_ID_WARNING SIGN  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             1   \n",
       "\n",
       "   Unit_Desc_ID_MOTOR VEHICLE  Unit_Desc_ID_MOTORIZED CONVEYANCE  \\\n",
       "0                           1                                  0   \n",
       "1                           1                                  0   \n",
       "2                           1                                  0   \n",
       "3                           1                                  0   \n",
       "4                           1                                  0   \n",
       "\n",
       "   Unit_Desc_ID_NON-CONTACT  Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)  \\\n",
       "0                         0                                          0   \n",
       "1                         0                                          0   \n",
       "2                         0                                          0   \n",
       "3                         0                                          0   \n",
       "4                         0                                          0   \n",
       "\n",
       "   Unit_Desc_ID_PEDALCYCLIST  Unit_Desc_ID_PEDESTRIAN  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   Unit_Desc_ID_TOWED/PUSHED/TRAILER  \n",
       "0                                  0  \n",
       "1                                  0  \n",
       "2                                  0  \n",
       "3                                  0  \n",
       "4                                  0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link='https://github.com/duonghung86/Fatality-crashes/raw/master/Codes/final%20data.zip'\n",
    "url = urllib.request.urlopen(link)\n",
    "with ZipFile(BytesIO(url.read())) as my_zip_file:\n",
    "    for contained_file in my_zip_file.namelist():\n",
    "        fzip=my_zip_file.open(contained_file)\n",
    "        data=fzip.read()\n",
    "\n",
    "s=str(data,'utf-8')\n",
    "data = StringIO(s)\n",
    "df=pd.read_csv(data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:45:08.945606Z",
     "start_time": "2020-05-21T20:45:08.935127Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10132,
     "status": "ok",
     "timestamp": 1589212832818,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "0yIHRk4sJ1Tx",
    "outputId": "d91e40bd-c01e-4fd0-86d0-bdbcd3ed9f69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.where(df['Prsn_Injry_Sev_ID']==4,1,0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:45:12.593932Z",
     "start_time": "2020-05-21T20:45:12.582954Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10117,
     "status": "ok",
     "timestamp": 1589212832820,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "0Ba_lXcHJ1UI",
    "outputId": "b43fce0d-8bd8-477b-aa39-501a76edc1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 488849\n",
      "    Positive: 1494 (0.31% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(y)\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:45:19.140222Z",
     "start_time": "2020-05-21T20:45:17.017669Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11433,
     "status": "ok",
     "timestamp": 1589212834154,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "Cl4mz5NYJ1UV",
    "outputId": "65dad35a-0845-4226-f71e-61010fc5228e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit_Nbr</th>\n",
       "      <th>Prsn_Age</th>\n",
       "      <th>Toll_Road_Fl</th>\n",
       "      <th>Crash_Speed_Limit</th>\n",
       "      <th>Road_Constr_Zone_Fl</th>\n",
       "      <th>Road_Constr_Zone_Wrkr_Fl</th>\n",
       "      <th>At_Intrsct_Fl</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Crash_month</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_Cntl_ID_SIGNAL LIGHT WITH RED LIGHT RUNNING CAMERA</th>\n",
       "      <th>Traffic_Cntl_ID_STOP SIGN</th>\n",
       "      <th>Traffic_Cntl_ID_WARNING SIGN</th>\n",
       "      <th>Unit_Desc_ID_MOTOR VEHICLE</th>\n",
       "      <th>Unit_Desc_ID_MOTORIZED CONVEYANCE</th>\n",
       "      <th>Unit_Desc_ID_NON-CONTACT</th>\n",
       "      <th>Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)</th>\n",
       "      <th>Unit_Desc_ID_PEDALCYCLIST</th>\n",
       "      <th>Unit_Desc_ID_PEDESTRIAN</th>\n",
       "      <th>Unit_Desc_ID_TOWED/PUSHED/TRAILER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.660685</td>\n",
       "      <td>-93.893906</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.660685</td>\n",
       "      <td>-93.893906</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.203920</td>\n",
       "      <td>-96.596654</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.203920</td>\n",
       "      <td>-96.596654</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.792394</td>\n",
       "      <td>-95.746539</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488844</th>\n",
       "      <td>1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.954878</td>\n",
       "      <td>-97.987513</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488845</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.756880</td>\n",
       "      <td>-94.354907</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488846</th>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.756880</td>\n",
       "      <td>-94.354907</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488847</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.279209</td>\n",
       "      <td>-94.579816</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488848</th>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.279209</td>\n",
       "      <td>-94.579816</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488849 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unit_Nbr  Prsn_Age  Toll_Road_Fl  Crash_Speed_Limit  \\\n",
       "0              1      48.0             0                 35   \n",
       "1              2      58.0             0                 35   \n",
       "2              1      68.0             0                 45   \n",
       "3              3      67.0             0                 45   \n",
       "4              1      36.0             0                 35   \n",
       "...          ...       ...           ...                ...   \n",
       "488844         1      68.0             0                 70   \n",
       "488845         1      44.0             0                 55   \n",
       "488846         2      57.0             0                 55   \n",
       "488847         1      16.0             0                 40   \n",
       "488848         2      16.0             0                 40   \n",
       "\n",
       "        Road_Constr_Zone_Fl  Road_Constr_Zone_Wrkr_Fl  At_Intrsct_Fl  \\\n",
       "0                         0                         0              0   \n",
       "1                         0                         0              0   \n",
       "2                         0                         0              1   \n",
       "3                         0                         0              1   \n",
       "4                         0                         0              1   \n",
       "...                     ...                       ...            ...   \n",
       "488844                    0                         0              1   \n",
       "488845                    0                         0              1   \n",
       "488846                    0                         0              1   \n",
       "488847                    0                         0              0   \n",
       "488848                    0                         0              0   \n",
       "\n",
       "         Latitude  Longitude  Crash_month  ...  \\\n",
       "0       30.660685 -93.893906            6  ...   \n",
       "1       30.660685 -93.893906            6  ...   \n",
       "2       33.203920 -96.596654            6  ...   \n",
       "3       33.203920 -96.596654            6  ...   \n",
       "4       29.792394 -95.746539            6  ...   \n",
       "...           ...        ...          ...  ...   \n",
       "488844  28.954878 -97.987513           11  ...   \n",
       "488845  32.756880 -94.354907           11  ...   \n",
       "488846  32.756880 -94.354907           11  ...   \n",
       "488847  31.279209 -94.579816            9  ...   \n",
       "488848  31.279209 -94.579816            9  ...   \n",
       "\n",
       "        Traffic_Cntl_ID_SIGNAL LIGHT WITH RED LIGHT RUNNING CAMERA  \\\n",
       "0                                                       0            \n",
       "1                                                       0            \n",
       "2                                                       0            \n",
       "3                                                       0            \n",
       "4                                                       0            \n",
       "...                                                   ...            \n",
       "488844                                                  0            \n",
       "488845                                                  0            \n",
       "488846                                                  0            \n",
       "488847                                                  0            \n",
       "488848                                                  0            \n",
       "\n",
       "        Traffic_Cntl_ID_STOP SIGN  Traffic_Cntl_ID_WARNING SIGN  \\\n",
       "0                               0                             0   \n",
       "1                               0                             0   \n",
       "2                               0                             0   \n",
       "3                               0                             0   \n",
       "4                               0                             1   \n",
       "...                           ...                           ...   \n",
       "488844                          0                             0   \n",
       "488845                          1                             0   \n",
       "488846                          1                             0   \n",
       "488847                          1                             0   \n",
       "488848                          1                             0   \n",
       "\n",
       "        Unit_Desc_ID_MOTOR VEHICLE  Unit_Desc_ID_MOTORIZED CONVEYANCE  \\\n",
       "0                                1                                  0   \n",
       "1                                1                                  0   \n",
       "2                                1                                  0   \n",
       "3                                1                                  0   \n",
       "4                                1                                  0   \n",
       "...                            ...                                ...   \n",
       "488844                           1                                  0   \n",
       "488845                           1                                  0   \n",
       "488846                           1                                  0   \n",
       "488847                           1                                  0   \n",
       "488848                           1                                  0   \n",
       "\n",
       "        Unit_Desc_ID_NON-CONTACT  Unit_Desc_ID_OTHER (EXPLAIN IN NARRATIVE)  \\\n",
       "0                              0                                          0   \n",
       "1                              0                                          0   \n",
       "2                              0                                          0   \n",
       "3                              0                                          0   \n",
       "4                              0                                          0   \n",
       "...                          ...                                        ...   \n",
       "488844                         0                                          0   \n",
       "488845                         0                                          0   \n",
       "488846                         0                                          0   \n",
       "488847                         0                                          0   \n",
       "488848                         0                                          0   \n",
       "\n",
       "        Unit_Desc_ID_PEDALCYCLIST  Unit_Desc_ID_PEDESTRIAN  \\\n",
       "0                               0                        0   \n",
       "1                               0                        0   \n",
       "2                               0                        0   \n",
       "3                               0                        0   \n",
       "4                               0                        0   \n",
       "...                           ...                      ...   \n",
       "488844                          0                        0   \n",
       "488845                          0                        0   \n",
       "488846                          0                        0   \n",
       "488847                          0                        0   \n",
       "488848                          0                        0   \n",
       "\n",
       "        Unit_Desc_ID_TOWED/PUSHED/TRAILER  \n",
       "0                                       0  \n",
       "1                                       0  \n",
       "2                                       0  \n",
       "3                                       0  \n",
       "4                                       0  \n",
       "...                                   ...  \n",
       "488844                                  0  \n",
       "488845                                  0  \n",
       "488846                                  0  \n",
       "488847                                  0  \n",
       "488848                                  0  \n",
       "\n",
       "[488849 rows x 150 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,1:].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "548Mc3Y4J1Ui"
   },
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:33.818149Z",
     "start_time": "2020-05-21T20:49:32.580161Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5ERPlNBhJ1Ul"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:54.992352Z",
     "start_time": "2020-05-21T20:49:49.885793Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13534,
     "status": "ok",
     "timestamp": 1589212836277,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "6dDdGqNSJ1Uo",
    "outputId": "2750b62b-92b8-453e-98ba-cc5a1d23821f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (312863, 150)\n",
      "Validation features shape: (78216, 150)\n",
      "Test features shape: (97770, 150)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y, random_state=48)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2,stratify=y_train, random_state=48)\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "X_val=np.array(X_val)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Test features shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:55.014311Z",
     "start_time": "2020-05-21T20:49:54.996344Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13523,
     "status": "ok",
     "timestamp": 1589212836278,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "Ut-NVd4nJ1Uv",
    "outputId": "d5511c3a-2bc8-4caa-f7e8-fdb612ad8ac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (312863, 1)\n",
      "Validation features shape: (78216, 1)\n",
      "Test features shape: (97770, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train=np.array(y_train).reshape(len(y_train),1)\n",
    "y_test=np.array(y_test).reshape(len(y_test),1)\n",
    "y_val=np.array(y_val).reshape(len(y_val),1)\n",
    "\n",
    "print('Training features shape:', y_train.shape)\n",
    "print('Validation features shape:', y_val.shape)\n",
    "print('Test features shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:55.026787Z",
     "start_time": "2020-05-21T20:49:55.019800Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Lj2Ka9kMJ1U2"
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:49:57.786654Z",
     "start_time": "2020-05-21T20:49:55.030780Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BiA2g-qsJ1U6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcaKVTGuJ1Vm"
   },
   "source": [
    "# MLP simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HquajIY-J1Vn"
   },
   "source": [
    "## Mini functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Z54FMlfJ1Vp"
   },
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.647931Z",
     "start_time": "2020-05-21T20:49:57.789151Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15926,
     "status": "ok",
     "timestamp": 1589212838693,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "dBEUbS6cYuve",
    "outputId": "511d15ce-1237-4747-9635-9a334cac1bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.733470Z",
     "start_time": "2020-05-21T20:50:07.654421Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "          keras.metrics.Precision(name='precision'),\n",
    "          keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.762718Z",
     "start_time": "2020-05-21T20:50:07.738763Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.BinaryAccuracy(name='accuracy'),keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.785180Z",
     "start_time": "2020-05-21T20:50:07.771203Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yIup1KAaJ1Vr"
   },
   "outputs": [],
   "source": [
    "def create_model(nodes=20,actih='relu',actio='sigmoid',lr=1e-3,output_bias=None,logits=False):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(nodes, activation=actih,input_dim=X_train.shape[1]))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation=actio,bias_initializer=output_bias))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=logits),\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXXqeCA-J1Vu"
   },
   "source": [
    "### Show confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.799649Z",
     "start_time": "2020-05-21T20:50:07.790666Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BCMLDgLcYo6T"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.824106Z",
     "start_time": "2020-05-21T20:50:07.804143Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZhneEw4cRND_"
   },
   "outputs": [],
   "source": [
    "def CI(arr):\n",
    "    op=[arr[0,0],arr[1,1]]/arr.sum(axis=0)\n",
    "    op=np.append(op,(arr[0,0]+arr[1,1])/arr.sum())\n",
    "    op=pd.DataFrame(op,columns=['Precision'],index=['0','1','Global'])\n",
    "    op['n_p']=np.append(arr.sum(axis=0),arr.sum())\n",
    "    op['CI_p']=196*np.sqrt(op.Precision*(1-op.Precision)/op.n_p)\n",
    "    op['Precision']=op.Precision*100\n",
    "\n",
    "    op['Recall']=np.append([arr[0,0],arr[1,1]]/arr.sum(axis=1),(arr[0,0]+arr[1,1])/arr.sum())\n",
    "    op['n_r']=np.append(arr.sum(axis=1),arr.sum())\n",
    "    op['CI_r']=196*np.sqrt(op.Recall*(1-op.Recall)/op.n_r)\n",
    "    op['Recall']=op.Recall*100\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.838078Z",
     "start_time": "2020-05-21T20:50:07.828596Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uFfBF83bJ1V0"
   },
   "outputs": [],
   "source": [
    "def show_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    print(cm)\n",
    "    pcm=classification_report(labels, predictions > p, target_names=['Class 0','Class 1']) \n",
    "    print(pcm)\n",
    "    return CI(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7vWECLdJ1V_"
   },
   "source": [
    "### Plot ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.856545Z",
     "start_time": "2020-05-21T20:50:07.841073Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "C3yM0beyZCHc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:07.877006Z",
     "start_time": "2020-05-21T20:50:07.863531Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tuV1U8jcJ1WG"
   },
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name + ' (area = %0.2f)' % auc(fp, tp), linewidth=1.5, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([0,100.5])\n",
    "  plt.ylim([0,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.399036Z",
     "start_time": "2020-05-21T20:50:07.880499Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1508,
     "status": "ok",
     "timestamp": 1589212863809,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "gS6h-0G3J1WN",
    "outputId": "b164d038-a489-4aaa-8869-9fd59a9d66f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((150,), (1,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.518317Z",
     "start_time": "2020-05-21T20:50:08.404026Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1497,
     "status": "ok",
     "timestamp": 1589212863810,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "ruuam0vyJ1WT",
    "outputId": "78563a28-99b6-48f3-f572-a6ab749a9e9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((150,), (1,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.533286Z",
     "start_time": "2020-05-21T20:50:08.522306Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1589212863811,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "XkkyFt4uJ1WZ",
    "outputId": "0b58a826-057b-4f6a-fad5-5977d5d47db2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.78753572])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:22:45.429511Z",
     "start_time": "2020-05-21T21:22:45.422024Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3VS51FQTJ1Wk"
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=20,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.571713Z",
     "start_time": "2020-05-21T20:50:08.558738Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CA3Zf0VHJ1Wo"
   },
   "outputs": [],
   "source": [
    "batch_size=2048\n",
    "data_train = data_train.shuffle(len(X_train)).batch(batch_size)\n",
    "data_val = data_val.shuffle(len(X_val)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:08.583193Z",
     "start_time": "2020-05-21T20:50:08.576206Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wOnyvd3jK739"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:09.313344Z",
     "start_time": "2020-05-21T20:50:08.590678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00311799],\n",
       "       [0.00528466],\n",
       "       [0.00103418],\n",
       "       [0.00330786],\n",
       "       [0.00358931],\n",
       "       [0.00468287],\n",
       "       [0.00480542],\n",
       "       [0.00235316],\n",
       "       [0.00308255],\n",
       "       [0.00126995]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(output_bias = initial_bias)\n",
    "model.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:12.091676Z",
     "start_time": "2020-05-21T20:50:09.316341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0297\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_train, y_train, batch_size=2048, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:12.107148Z",
     "start_time": "2020-05-21T20:50:12.095670Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:12.259865Z",
     "start_time": "2020-05-21T20:50:12.112637Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:12.282323Z",
     "start_time": "2020-05-21T20:50:12.264357Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model2(nodes=20,actih='relu',actio='sigmoid',lr=1e-3,logits=False):\n",
    "    \n",
    "    #output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(nodes, activation=actih,input_dim=X_train.shape[1]))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation=actio,bias_initializer=None))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=logits),\n",
    "                  metrics=metrics)\n",
    "    model.load_weights(initial_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:47:44.768449Z",
     "start_time": "2020-05-08T22:47:44.455029Z"
    },
    "colab_type": "text",
    "id": "loWcs-MKJ1XR"
   },
   "source": [
    "## Class weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDLuSQMabKFn"
   },
   "source": [
    "### Class weight estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:50:40.197519Z",
     "start_time": "2020-05-21T20:50:40.191031Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1589212863815,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "y1tT_8gBbIl_",
    "outputId": "28410c3a-2595-4278-ed44-eca0b117068c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.50\n",
      "Weight for class 1: 163.60\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-G092TzzbPWJ"
   },
   "source": [
    "### Run model with class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:15.219205Z",
     "start_time": "2020-05-21T20:51:05.062612Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79639,
     "status": "ok",
     "timestamp": 1589212942074,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "s1fC3msPblwo",
    "outputId": "a782bb12-0d03-44b5-f7e4-31e3e555cd3d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 153 steps, validate for 39 steps\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 7s 44ms/step - loss: 2.3056 - accuracy: 0.9838 - auc: 0.6387 - val_loss: 0.8367 - val_accuracy: 0.9775 - val_auc: 0.8948\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.8647 - accuracy: 0.9277 - auc: 0.8421 - val_loss: 0.4974 - val_accuracy: 0.9348 - val_auc: 0.9242\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.6746 - accuracy: 0.8992 - auc: 0.8798 - val_loss: 0.4269 - val_accuracy: 0.9175 - val_auc: 0.9337\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 5s 30ms/step - loss: 0.5645 - accuracy: 0.8951 - auc: 0.9021 - val_loss: 0.3811 - val_accuracy: 0.9232 - val_auc: 0.9417\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.5087 - accuracy: 0.9041 - auc: 0.9163 - val_loss: 0.3494 - val_accuracy: 0.9238 - val_auc: 0.9482\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 4s 26ms/step - loss: 0.5033 - accuracy: 0.9009 - auc: 0.9141 - val_loss: 0.3280 - val_accuracy: 0.9227 - val_auc: 0.9521\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.4563 - accuracy: 0.9038 - auc: 0.9229 - val_loss: 0.3222 - val_accuracy: 0.9261 - val_auc: 0.9541\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.4434 - accuracy: 0.9057 - auc: 0.9267 - val_loss: 0.3140 - val_accuracy: 0.9271 - val_auc: 0.9555\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.4679 - accuracy: 0.9074 - auc: 0.9212 - val_loss: 0.3164 - val_accuracy: 0.9212 - val_auc: 0.9557\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.4188 - accuracy: 0.9077 - auc: 0.9316 - val_loss: 0.3136 - val_accuracy: 0.9279 - val_auc: 0.9563\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.4184 - accuracy: 0.9081 - auc: 0.9326 - val_loss: 0.3051 - val_accuracy: 0.9236 - val_auc: 0.9559\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 5s 31ms/step - loss: 0.4156 - accuracy: 0.9079 - auc: 0.9333 - val_loss: 0.3053 - val_accuracy: 0.9271 - val_auc: 0.9556\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3786 - accuracy: 0.9119 - auc: 0.9417 - val_loss: 0.3020 - val_accuracy: 0.9290 - val_auc: 0.9562auc: 0.94\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3904 - accuracy: 0.9106 - auc: 0.9376 - val_loss: 0.2925 - val_accuracy: 0.9261 - val_auc: 0.9573\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3819 - accuracy: 0.9111 - auc: 0.9398 - val_loss: 0.2956 - val_accuracy: 0.9265 - val_auc: 0.9567\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3679 - accuracy: 0.9109 - auc: 0.9429 - val_loss: 0.2974 - val_accuracy: 0.9205 - val_auc: 0.9561\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3522 - accuracy: 0.9101 - auc: 0.9459 - val_loss: 0.2949 - val_accuracy: 0.9261 - val_auc: 0.9567\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 5s 31ms/step - loss: 0.3784 - accuracy: 0.9120 - auc: 0.9404 - val_loss: 0.2982 - val_accuracy: 0.9194 - val_auc: 0.9561\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3546 - accuracy: 0.9123 - auc: 0.9446 - val_loss: 0.2937 - val_accuracy: 0.9235 - val_auc: 0.9563\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3392 - accuracy: 0.9136 - auc: 0.9479 - val_loss: 0.2985 - val_accuracy: 0.9239 - val_auc: 0.9560\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3496 - accuracy: 0.9134 - auc: 0.9464 - val_loss: 0.2944 - val_accuracy: 0.9229 - val_auc: 0.9559\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3430 - accuracy: 0.9130 - auc: 0.9466 - val_loss: 0.2899 - val_accuracy: 0.9224 - val_auc: 0.9567: 0.3\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3327 - accuracy: 0.9100 - auc: 0.9501 - val_loss: 0.2940 - val_accuracy: 0.9235 - val_auc: 0.9560\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3195 - accuracy: 0.9160 - auc: 0.9528 - val_loss: 0.2959 - val_accuracy: 0.9233 - val_auc: 0.9557\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3219 - accuracy: 0.9127 - auc: 0.9514 - val_loss: 0.2945 - val_accuracy: 0.9271 - val_auc: 0.9557\n",
      "Epoch 26/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3156 - accuracy: 0.9162 - auc: 0.9538 - val_loss: 0.2949 - val_accuracy: 0.9193 - val_auc: 0.9550\n",
      "Epoch 27/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3116 - accuracy: 0.9113 - auc: 0.9546 - val_loss: 0.2961 - val_accuracy: 0.9198 - val_auc: 0.9546\n",
      "Epoch 28/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3209 - accuracy: 0.9113 - auc: 0.9516 - val_loss: 0.3045 - val_accuracy: 0.9220 - val_auc: 0.9555\n",
      "Epoch 29/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3134 - accuracy: 0.9138 - auc: 0.9532 - val_loss: 0.2980 - val_accuracy: 0.9257 - val_auc: 0.9546\n",
      "Epoch 30/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3264 - accuracy: 0.9138 - auc: 0.9506 - val_loss: 0.2998 - val_accuracy: 0.9197 - val_auc: 0.9541\n",
      "Epoch 31/100\n",
      "153/153 [==============================] - 4s 26ms/step - loss: 0.2966 - accuracy: 0.9174 - auc: 0.9573 - val_loss: 0.3000 - val_accuracy: 0.9240 - val_auc: 0.9541\n",
      "Epoch 32/100\n",
      "153/153 [==============================] - 4s 28ms/step - loss: 0.3072 - accuracy: 0.9160 - auc: 0.9547 - val_loss: 0.3010 - val_accuracy: 0.9245 - val_auc: 0.9543\n",
      "Epoch 33/100\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3006 - accuracy: 0.9163 - auc: 0.9571 - val_loss: 0.3044 - val_accuracy: 0.9261 - val_auc: 0.9535\n",
      "Epoch 34/100\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.9152 - auc: 0.9558 ETA: 0s - loss: 0.3025 - accuracy: Restoring model weights from the end of the best epoch.\n",
      "153/153 [==============================] - 4s 27ms/step - loss: 0.3032 - accuracy: 0.9153 - auc: 0.9556 - val_loss: 0.3019 - val_accuracy: 0.9229 - val_auc: 0.9534\n",
      "Epoch 00034: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147.03937911987305"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "wei_model=create_model2()\n",
    "Monitor = wei_model.fit(data_train, epochs=100,callbacks=[es],validation_data = data_val,class_weight=class_weight, verbose = 1)\n",
    "end_time=time.time()\n",
    "end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:16.092237Z",
     "start_time": "2020-05-21T20:54:15.222699Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80136,
     "status": "ok",
     "timestamp": 1589212942584,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "gbJOrd5cb8dr",
    "outputId": "31c9319c-6bb8-4250-b977-0f828684e420"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.DataFrame(Monitor.history)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,4),dpi=150)\n",
    "hist[['loss','val_loss']].plot(ax=axes[0])\n",
    "hist[['auc','val_auc']].plot(ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGzf8FEoedp4"
   },
   "source": [
    "### Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:26.326017Z",
     "start_time": "2020-05-21T20:54:16.095973Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tNkmcPN9b8aA"
   },
   "outputs": [],
   "source": [
    "y_pred_train_b = wei_model.predict(X_train)\n",
    "y_pred_test_b = wei_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:27.681796Z",
     "start_time": "2020-05-21T20:54:26.329968Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87565,
     "status": "ok",
     "timestamp": 1589212950043,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "g1AwenWlcgTC",
    "outputId": "a4a70811-abfe-43b4-c30e-1418753a6ff5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(len(y_test)),y_pred_test_b,s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:28.274005Z",
     "start_time": "2020-05-21T20:54:27.684793Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87816,
     "status": "ok",
     "timestamp": 1589212950314,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "5kiSMFi8b8Xp",
    "outputId": "d107db44-9db4-4e01-ddaf-54159c8a4beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90137  7334]\n",
      " [   49   250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.92      0.96     97471\n",
      "     Class 1       0.03      0.84      0.06       299\n",
      "\n",
      "    accuracy                           0.92     97770\n",
      "   macro avg       0.52      0.88      0.51     97770\n",
      "weighted avg       1.00      0.92      0.96     97770\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>n_p</th>\n",
       "      <th>CI_p</th>\n",
       "      <th>Recall</th>\n",
       "      <th>n_r</th>\n",
       "      <th>CI_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.945668</td>\n",
       "      <td>90186</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>92.475711</td>\n",
       "      <td>97471</td>\n",
       "      <td>0.165602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.296414</td>\n",
       "      <td>7584</td>\n",
       "      <td>0.401836</td>\n",
       "      <td>83.612040</td>\n",
       "      <td>299</td>\n",
       "      <td>4.195825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global</th>\n",
       "      <td>92.448604</td>\n",
       "      <td>97770</td>\n",
       "      <td>0.165622</td>\n",
       "      <td>92.448604</td>\n",
       "      <td>97770</td>\n",
       "      <td>0.165622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Precision    n_p      CI_p     Recall    n_r      CI_r\n",
       "0       99.945668  90186  0.015209  92.475711  97471  0.165602\n",
       "1        3.296414   7584  0.401836  83.612040    299  4.195825\n",
       "Global  92.448604  97770  0.165622  92.448604  97770  0.165622"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_cm(y_test,y_pred_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:28.678629Z",
     "start_time": "2020-05-21T20:54:28.277976Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1589213180188,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "l3yBCZz7b8So",
    "outputId": "c6a139fd-2956-47d0-e10b-f8ee4d54f91e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHiCAYAAAAXsp52AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXxU9b3/8dd3JpOFsAUIGIgIKIvssqOoIIorqNVWrXVptRaty9W61drr2qtVW2/dy0+taL2IYhXbqlXRaMEdC4KigKyBsIeQELLNfH9/nCESyDJZzpycmffz8chj5pw5c85nDiHv+Z7l+zXWWkRERMRfAl4XICIiIo2nABcREfEhBbiIiIgPKcBFRER8SAEuIiLiQwpwERERH3ItwI0xTxtjthhjlu4zr5Mx5m1jzIroY1Z0vjHGPGSMWWmM+dIYM8KtukRERBKBmy3wZ4CT9pt3MzDPWtsXmBedBjgZ6Bv9uQx43MW6REREfM+42ZGLMaYX8A9r7eDo9LfARGttgTEmB8iz1vY3xvw5+nzW/svVt/6OHTvaww47zLX6k9nu3bvJzMz0uoyEo/3qHu1bd2i/umfvvl24cOE2a212Y9+f4kZR9ei2N5SjId41Or8HsH6f5fKj8+oN8G7duvH555+7Umiyy8vLY+LEiV6XkXC0Xxtnw849bNlVFtOyX3zxBSNGJNbZt4iFJ97/jlDQeFbDli1b6dq10dkidcgMF/GDrU+QZvewPnMYp19+N8aYtU1ZV7wDvC61/XbWemjAGHMZzmF2srOzycvLc7Gs5FVSUqJ964JE2a9bSyN8vSPM22sqyUgxGBfyJRyB74oijXvTxx+2fCGtRPe23oR4JBJh4+7NnmzbjzrbQg5iW52v97TfMj7yLzbQlfUmt1l/D+Id4JuNMTn7HELfEp2fDxy8z3K5wMbaVmCtnQHMAOjfv79Va8Ydaim6w+39On/FNtbu2N2o97z3zVaWFexqVCtvzfY91c+7tU/l0Oy2jdpmrDplRTi6bzZDcjs0uOySL79kyNChrtThpdRggDG9OxEKenPTkP4WNNKfhkPh6gYX63HF31nx9aZm7dt4B/hrwEXAvdHHufvMv9IY8wIwFihq6Py3iJvKKsOEIzUPAr399WbWbG9cOO7vxY9K2fLW66SltPwfYwuUVoSb/P7Th3ePedmhuR0ZkNOOUwbn0KtL6zg/agpSmNi/a8MLijTVu3fDqvfrX2bnOuh7Ioy5rO5l0ttDdn9gU7PKcS3AjTGzgIlAF2NMPnAbTnC/aIy5BFgH/DC6+OvAKcBKoBT4qVt1iey1raSckrIq/vrxWkorvw++D1duY832Ule3ffGYnq6sN2Lh1KEHcXBWm0a9r31GiPRQ0JWaWqVwFax6Dyrd/XdOBF22fgVfF3ldRuvw+V8gEISuA+teps+xMO5yOHSS6+W4FuDW2vPqeGlyLcta4Jdu1SKtXzhiWbKhiMpwI8951qOgqIyXPl9fazBt2VXG4vyaf5S6tE2L1uLUcMOJ/WscVjYYThmaQ/cO6U2uae/hSOPGSWOJ3dr58PzZXlfhC4MBvvK6ilZk7OVw8r1eVwG0novYJIFt3lXGwrWFNebN+nQdu8qqqq9eXLR+p2vb79I2jex2aTXmWWs5uFMGZ43IpU92W44b0JW2ae7/dzDGKLzrU14Cz5wKpdsb/dZxZWXwnxi/XO1teZ/9NGQPaPS2kslnn33G6NGjvS6j9ejSz+sKqinAxRVllWH+smAND81bwZ7Kus/LHtMvu/qxrCLML487jGALBlzHNiEG92j4AiiJs0gEvpwNZfsdmt29FQoWQc8joVPvRq2ycFMBOQflxP6GtPYw4DRISWt42SS2u+1W6DbI6zKkFgpwaZalG4r41YuL+XZzMan7XCVbsc+h8EHd2zNl4EGcNPigGu/t1aUNaSlJdN5Vvrd1Gbw6vY4XDUy6BXof3ahVfpuXR46ulpYkogCXRrPW8s6yLbyxtIC/fbGhev4lR9dsMYWCAS6Z0JsOGaF4lyheKC+Gh0c5regGRa/wP+spOPS4mi8FQ5DWrsXLE0k0CnCp1+7yKm59dSk7Syuq5y34bjsVVU4LO7tdGicPPog7Tx/sVYnSVBW74cNHoLJ5t8ZVKyuCkk3Q7yToFsPvQyjDWTbNnXvIRRKdAlwOkF9Yyowvy7l30Qd8s6m4ev7QaGca/bu1o7iskj/8aDgjD8nyqszkZS3s3kYdnRXGbvUHkPc/EEwF00L3pad1gAnXQc+xLbM+EamTAjzJLVi5jYue/pSObUIEohePbSkuj75azPGHd6Vdeoi7zxhMZhyu0pYYzH8Q5t3Rcuu79B3IGdZy6xORuNBf5CSVX1jKo+99x6xP1wGQEggwacD3AxbYos3cct5E2qfr/HWrsHg2rHzHeb7xCwi1gSl3NX+9aR2g25Dmr0dE4k4BngSKSiv5umAXf/14LakpASqqIvxzyfc91d51+iAuGN+rxnvy8vIU3i1t53raFn8HGzs2/r0f3Ae7NkLbbs704dNg9KUtW5+I+IoCPAFFIpaF6wrZXlLBE+9/V6OTlICB7h0z6NY+jWnDuvObU+vpElBaTlkRPDScUZEqWNjEdQw+G85+qkXLEhH/UoAnmEfeXcEDby2vMS8UNJwxvAdnHtGD8Yd2Vk9gbohEYO4VUJRf++tV5RCpYkP3k+lxzIVN20buqKbXJyIJRwGeQGZ9uq46vI/tl83Pj+5Dp8xUDs9pp9CuTyQMa/4NlXsaXrYuFbth8SzI6gXtexz4ejAEfSayofMp9BhwStO3IyISpQBPAIvW72T6cwvZtKsMgP89ZzhnHFFLiEjtVuXBX3/QMus69iYY/uM6Xy7Ny2uZ7YhI0lOA+9yj763k/n99Wz39xjVHc3hOew8rakWshVnnwbbl9S9XEe3I5KynoPOhTd9eIFT/MIMiIi1IAe4j32zaxaPvfceWaEsb4JPVOwC46aQBXD6xGeGTKPbshK/nQqQKbASWv+GEakPBmtERDp+qgS1ExDcU4K3c7vIqTvjj+6SFgqze9n2Xl2N7dwJg5CFZXH7soRw/sJtXJbYuX86GN26sOW/sdBh5kTf1iIi4RAHeiu0qq2To7W9VT5806CAmDcjm1KHd4zJ2ta9UlsHj42Hnemf66kVOZyeBIGR28bY2EREXKAVaqbLKcI3wXvm7k0kJtlB/1YmmaAN88jjsWAV9JjpjPDdyLGkREb9RgLcieyrCfF2wi9XbdnP9S4ur56++5xTdBrY/a53OUQC+mAkfPgwp6TDhWifERUQSnAK8lbh61n94bfHGGvMmHNaFGReOVHjX5q1b4aNHvp82Afj1BgjqV1pEkoP+2nls0fqdXPDUJxSXVQHOee7zxvYku20aA7vrdrAaPvkzFHzpPF/9AWR2dVrc4BwyV3iLSBLRXzwPWWv55fNfUFxWxahDsrj3rCEc1rWd12W1PpEwbFsB79zutLTTo4OBDDoTxl/haWkiIl5RgHtoyoMfsGGn033nnMuP9LiaVuz93zs/AEdfD5N/6209IiKtgAI8zgp3V3DlrC8wGFZsKQHg099M9riqVuqzp+Cbf8DW5RDKhDMfh97Hel2ViEiroACPsx/++SNWRoO7f7d23HzKALq2S/e4qlYgXAnrPoZwxffzPn4MSrZCdj8YOA0Gnu5dfSIirYwCPI6stdXh/d3/nEIwoKvLq309F16+5MD5g86EHz4T93JERFo7BXicfLGukKv+7z8AnD0yV+G9r3Dl9+F9zl+dq8v36nq4NzWJiLRyCvA4ePGz9dz48pfV0zee2N/DajywbQWs/6Tu18t2OY/pHaH/qRBQj3MiIg1RgLtsw8491eF9/ZR+XHlcX48r8sAbN8J37za83OmPKLxFRGKkAHfR7vIqjrrXCa5fHNMnOcN74yInvLsfAT96tu7lgqnQ7qD41SUi4nMKcBcNuu1fgNMl6vWJfNg8XAWfPQnlxQe+tnmp8zjsx9CxZ3zrEhFJYApwl5RWVFU/f/ZnYwgk8kVrGz6HN2+q+/X0jjDk7PjVIyKSBBTgLhn4307r+7enDUzs8P74cXjzZuf5T16G3hMPXMYEdG5bRKSFKcBd8ObSTdXPzx6Z62ElLthVAAv+9/sOV9Z97AzjOeVuOGSCBhQREYkT/bV1wfS/LgTgtSuPokNGyONqWkDpDthT6Dz/6hX45AnI6ASBoDPvsONhzM+9q09EJAkpwFtYJGIBODQ7k6G5HT2upgVU7oEHB0Flac35V34GmV28qUlERBTgLWnphiJOe3g+ACcN9vEtURWlDFj2IGx83DlUXlkKQ8+Fw6KDrmRmK7xFRDymAG8Bf/14Lc9+tIblm51+znOzMvj50X28Laoxdq6HwjXfT+/4joM250FFL0jvAD1GwdhfQI8RHhUoIiL7U4A3UWU4wrkzPqa4rLI6uLPbpXHLKQM48wifXbj27DTYserA+VMfgj4avlNEpDVSgDfB+h2lHH3fe9XTR/TsyK9O6M+Evq3wsPKOVfDKdOdcdl0K10K/k2H8L6tnLVyyjJG9jo5DgSIi0hQK8EYqKq2sEd7f3n0SaSlB7woq3eF0VWojtb++YaEzkMghEyCtXe3LdMiFcZdD7+8Du3htWPdui4i0YgrwRrDWMuzOtwAYfnBH5kwfT0rQ45D76FH49wP1L2MC8IMZ0KFHfGoSERHXKcAb4Yn3vz9P/MoVR2JMHHtYqyqHJ4+H4oKa88tLINQGps+v+71p7aBt17pfFxER31GAx6isMszv3/wGgA9umBTf8N6xGhb9H2z6EnqOh66H13y922DofGj86hEREc8pwGP06HsrATikcxt6dm4T341/+DB8/pRzKHzCddBvSny3LyIirY4CPAbWWh5+1wnwd66L821Vi2c74Z2ZDf+1FELp8d2+iIi0SgrwGLy2eCMA7dNTCMXjorXFs2HjF87z/M+cx9MfVXiLiEg1BXgM7nndOff90vQj47PBt34DZUUQynCmDx4L/U6Mz7ZFRMQXFOAx2L67nG7t0+h/UB33Ube0cCWM/Cmccl98ticiIr6jnjoasHBtIZVhS06HjPhscM0CKNsJAX23EhGRuiklGvD0/NUAXHN835ZZobWwaUndXZt+9Kjz2PuYltmeiIgkJAV4AxauLQRgUv8W6ghl7YfwzCn1L5PVG/qf1DLbExGRhKQAb8CO3RX06NiCh8/X/Nt5PPn+ujtf6eSjoUhFRMQTCvB6FJVWUhGOMPKQrJZZobWw4m3n+fAfQ1rbllmviIgkHV3EVo/lW4oBGN2rhQJ82wrY8LnzXOEtIiLNoACvR1FpJQD9urXQ7WNv/7fzePqjLbM+ERFJWjqEXodwxHLps05ruV16qHkrW/EObFsOBYuc6f4NXMQmIiLSAAV4Hf70znIAOmWmcnhOM1vgL10EFSXO8zGXQZtOzaxORESSnQK8Do/mfQfA/JuaOXRowZdOeI/+ORx3K6R3aKEKRUQkmSnAa7GtpJxwxALQJrWZu2jenc5jn2Mho2MzKxMREXEowGvxTYFz9fkd0wY1fSXWwq4NsDJ621jP8S1QmYiIiENXodfitteWAtC3WzNu9Xrvf+DB6BeAKb+DzC4tUJmIiIhDLfD9WGv5butuAMb17hzbmyIReOtWKNn8/bwNn0NaB5hyFwyc5kKlIiKSzBTg+6kIRwAY07sTgUCMF68VLIKPH4XMbEhr78wzQRh8Joy8yKVKRUQkmSnA91NW4QT4iYMOiv1Nz5zqPJ50Lww524WqREREalKA7+f6OYsBSA81cHlAyVaYewVU7IbKUjhoKByuQ+UiIhIfuohtH9Za3v7aOY99yuCc+hde/T6seAvKdzljd590D6SkxqFKERERtcBr2Bnt+/zskblkZTYQxktech7P/DN0a8btZiIiIk2gFvg+/jRvBQD9Grp9rCgflr8JoTYKbxER8YQCPKoyHOGZD9cAcM7onvUv/PHjzuPgs9wtSkREpA4K8KiCnWUAHDegKx0y6hl9rLIMPnrEeX7UNXGoTERE5EAK8Kj5K7cBcMLAbvUvuO1b53HCtdClr8tViYiI1E4BjnP1+S2vLAFg+MH1DDiydTkseMh53v2IOFQmIiJSOwU4sKW4HIBJ/bMZcFAdY3+XFcFHD8PSOZCRBbmj41ihiIhITbqNDPhmkzP62Jkjcmsf+3vxbHjlMud5uxz41TdxrE5ERORACnBg1x7n/u+DszJqX2DHKufxpHuh2+A4VSUiIlI3BTiwKjr6WHa7tNoX2PK1MzjJuMvjWJWIiEjddA4cSAk6h81rDfDV/4Zlr0GwnlvLRERE4syTFrgx5lrgUsACS4CfAjnAC0An4AvgAmttRTzquf9fzq1hqcHo95nPnoJlf3ee797qPE79UzxKERERiUncW+DGmB7A1cAoa+1gIAicC/weeNBa2xcoBC6JRz0bd+7Ztzbnybw7YcMXzkhjoTbQdwoMOC0e5YiIiMTEq3PgKUCGMaYSaAMUAMcBP46+PhO4HXjc7UJe/Hw9APedPdSZsXsblO107vO+9G23Ny8iItIkcW+BW2s3AA8A63CCuwhYCOy01lZFF8sHesSjns27nHvATx/eHaoq4JlTnReGnhOPzYuIiDRJ3Fvgxpgs4HSgN7ATeAk4uZZFbR3vvwy4DCA7O5u8vLxm1bP4O+cQ+kfz/01a2VbGb/0Gi+HjnZ0pb+a6/aykpKTZ+1YOpP3qHu1bd2i/uqe5+9aLQ+jHA6uttVsBjDF/A44EOhpjUqKt8FxgY21vttbOAGYA9O/f306cOLFZxVzx7ptkt0tj4sSJsHIefAzm5N8zfuyPmrVev8vLy6O5+1YOpP3qHu1bd2i/uqe5+9aL28jWAeOMMW2Mc9XYZOBr4D3g7OgyFwFz41FMaUWYvl2j43/baKO/+4h4bFpERKTJvDgH/gkwB+dWsSXRGmYANwHXGWNWAp2Bp9yupbwqDED/vf2fr/vIeQzo9ngREWndPLkK3Vp7G3DbfrNXAWPiWcdj730HwEHt050Zq993Htt1j2cZIiIijZbUTc2n568G4OyRuc4MG4E+k6B9jodViYiINCxpA3z+im0Ul1eREjB0bpsGy/4BGxZCSrrXpYmIiDQoaQP8j2873ae+NH28M+Pdu5zHXkd5VJGIiEjskjbAt5aU0yEjxBE9s6IzvoGeR8KRV3lbmIiISAySMsCLSitZv2PP9xevLZnjPHbI9a4oERGRRkjKAP/HEqePmNG9o63vBf/rPA4/z6OKREREGicpA3xTURkAPz2qtzNjx2ro1AcOPc7DqkRERGKXlAH+zrItAPTomAEr3oGKEujS3+OqREREYpeUAb5u+27apqWQHgrCu3c6M8f83NuiREREGiHpAjwcseyuCDOmdyco2QoFi50XDpvsbWEiIiKN4ElXql768LttBIhw59Zr4NHogGcn3ettUSIiIo2UdAG+fsceulJI7u6vIHe08zPoTK/LEhERaZSkC/C3vt7EpOAiZ+KIC2DkRd4WJCIi0gRJdQ7cWkvet1tJwRlGlAGneluQiIhIEyVVgBdE7//u0ib6sU1SfXwREUkgSZVg81duA2By7zbOjEDSnUEQEZEEkVQB/sC/nBHIBq14zJkRTPWwGhERkaZLuiZoVpsQJq0jtDsIQhr7W0RE/ClpWuCV4QhbissZ2TML9uyAnuO9LklERKTJkibAF6/fCcCYzE3OjMpSD6sRERFpnqQJ8E9W7wBgavk/nBn9T/GwGhERkeZJmgDftacSgOzKDc6MQ47ysBoREZHmSZoA//MHqwBIsWHodTRkdva4IhERkaZLmgDv1j6NzpmpsO5DdeAiIiK+lxRJFolYNu8qZ9rQbs6McKW3BYmIiDRTUgR4cXkVAD32LHdmdOnrYTUiIiLNlxQB/u2mYqYFFvCzb37uzNDwoSIi4nNJEeAbdpYyLfghASJw/B3Qc5zXJYmIiDRLUgT42u2lpBE97z3hvyCU4W1BIiIizZQUAf7Uv1djMYS7j/K6FBERkRaR8AFuraW4vIqMkCEYTLqxW0REJEElfIDv2lNFgAgDA+t1/7eIiCSMhE+0wtIKfhJ8m8yqQp37FhGRhJHwAb56224GmrXOxNT/9bYYERGRFpLwAf7oeyvZSVtnosPB3hYjIiLSQhI+wL/MLyJEGJvaDozxuhwREZEWkdABbq2lIhyhfarF6Ap0ERFJIAkd4Nt3VwCQ0y4EAQW4iIgkjoQO8G83FQPQvV0KBEIeVyMiItJyEjrA8wtLAei56S3AeluMiIhIC0roAI9YCBAhpWo3pKR5XY6IiEiLSegAX7i2kL4m35nIGeZtMSIiIi0ooQO8aE8lPwq+70wM+7G3xYiIiLSghA7wThlBLkl5w5noM9HLUkRERFpUQgd46p4tzpM2nSGU7m0xIiIiLSihA9xsXeY8mfhrbwsRERFpYQkd4Lnh6AVs3QZ5W4iIiEgLS+gAzyiLHkLXICYiIpJgEjrAJ9gvnCeZXbwtREREpIUlboDvXE9vu54taYdAKMPrakRERFpUwga43eJcwLak7VEeVyIiItLyEjbAS8orASjIOd7jSkRERFpewgb47vIqALLb6/5vERFJPAkb4OU7NwHQLl3DiIqISOJJ3AAv3u48SW3nbSEiIiIuSNgAz9r4AQBdu/f0uBIREZGWl7ABHi4tBKBN+04eVyIiItLyEjbAd5s27LIZdGmb5nUpIiIiLS5hAzxSWc6XkT6EgsbrUkRERFpcYga4tfQt/4pgahuMUYCLiEjiScwAL3EGMQkGFN4iIpKYEjPAv34VgPmBER4XIiIi4o7EDPCqMgCWdT7B40JERETckZgBHgkD0LVjB48LERERcUdCB3h6um4hExGRxJSYAZ7/KQApKSkeFyIiIuKOhAzwyJZvACivsh5XIiIi4o6EDHCzK58yG6Jvt7ZelyIiIuKKxAvwqgqMjfBieCJpKUGvqxEREXFF4gV4ZSkAZaTSTy1wERFJUIkX4DjnvTfZTrRJVQtcREQSU+IF+Mb/AJBCFblZbTwuRkRExB2JF+DlxQAUtB9GekgtcBERSUyJF+C7twKwrTLd40JERETck3gB/tGjAGR36exxISIiIu5JvAAPtWEtOWwNdPW6EhEREdckXoDvXM/S8MG0z1A3qiIikrg8CXBjTEdjzBxjzDfGmGXGmPHGmE7GmLeNMSuij1lNWnl5EV0CJaQEE++7iYiIyF5epdyfgDettQOAYcAy4GZgnrW2LzAvOt1oFsPicG/6dMlssWJFRERam7gHuDGmPXAM8BSAtbbCWrsTOB2YGV1sJnBGU7dRRgjT3EJFRERasTpPFBtj/hbD+3dYay9t5Db7AFuBvxhjhgELgWuAbtbaAgBrbYExpvFXoUUiGCxVNoXMNJ0DFxGRxFVfyg0BptfzusE5FN6UbY4ArrLWfmKM+RONOFxujLkMuAwgOzubvLy871dcWcwEwGDZmr+KvLz1TShPAEpKSmrsW2kZ2q/u0b51h/are5q7b+sL8NustfPqe7Mx5ndN2GY+kG+t/SQ6PQcnwDcbY3Kire8cYEttb7bWzgBmAPTv399OnDjx+xd3rIIFsIdUhgwayMThPZpQngDk5eVRY99Ki9B+dY/2rTu0X93T3H1b5zlwa+3/7T/PGJNqjGlT3zINsdZuAtYbY/pHZ00GvgZeAy6KzrsImNvYdROJALDZZqkbVRERSWgxnyg2xvwUuAQIGGPmWWt/24ztXgU8b4xJBVYBP8X5MvGiMeYSYB3ww0av1YYBiBCgW3t1pSoiIomrvovYTrbWvrHPrBOttROiry0Gmhzg1tpFwKhaXprc1HUCULodgDABhvTo0KxViYiItGb13UY21hjzijFmcHT6K2PMs8aYZ4Bv3C+tCcp2ARAKpRIM6EYyERFJXHW2wK21txtjegB3GWPKgduATkAba+0X8SqwUYqcq87XVbTzuBARERF3NXQOfAdwOTAIeBpYAPzR7aKaLMU57x3qmONxISIiIu6q8xC6MeYO4B3g38BR1trTgG+B140x58WpvsaJngO3wTSPCxEREXFXfefAT7fWHgWMxblKHGvt34CTgO5xqK3xdq4DoDJF/aCLiEhiq+8Q+jJjzF+ADGD+3pnW2krgD24X1iQpaYQJEA5meF2JiIiIq+q7iO08Y8wRQKW1dmkca2q6cAW7yKS8Kux1JSIiIq6q7xz4UGvtf+oLb2PMUHfKaqJwJZWk0KWtzoGLiEhiq+8Q+nPGGGdskLrNBI5o2ZKaoWAx1lp14iIiIgmvvgDvDHxF/QFe64AjXilPzSKF76gIR7wuRURExFX1nQPPjWchLSFcXsJK24PhB3f0uhQRERFX1Xcbme+kbV+GwZISSKiPJSIicoCESrqSlI5YDLlZuo1MREQSW0IFeFVVFfm2C726qCMXERFJbA0GuDFmnDGmTfT5ecaY+4wxB7tfWuMZGyFsg7RLi3mYcxEREV+KpQU+A9gTvef7FmAz8FdXq2oiG64iNTWVgIYSFRGRBBdLgFdZay1wOvAna+0fgFY5XqexVViTUGcFREREahXLsebdxpgbgAuAY40xASDkbllNY2yEthnpXpchIiLiuliaq+fgdObyC2ttAZBLaxwTPFxFlikhlKLz3yIikvgaDHBr7Ubg//aZtQV40bWKmqhyTxEAnTJ0CF1ERBJfLFeh/wx4DXgyOqsnMNfNopqicHcFANvSe3pciYiIiPtiaa5eDYwDdgFYa5cD3dwsqil27NgOQHamDqGLiEjiiyXAy6y1FXsnjDFBF+tpspLinQAEUlI9rkRERMR9sQT4AmPMjUC6MWYSMBv4h7tlNd6mnaUAZHbu4XElIiIi7oslwG8EioFvgGuAecBv3CyqKQLblwPQIb1VHiAQERFpUbGcMD4FeNJa+7jbxTRH2z0bAGjfvZ/HlYiIiLgvlhb4j4CVxpi/GGNObK3nwAORSgCCnXp5W4iIiEgcxHIf+AVAP+DvwM+AVcaYJ9wurLFspMp5kt7B20JERETiIKZ7rqy15caYucAeIIjTKp/uZmGNFg5TSZCQ0UAmIiKS+GLpyOV4Y8yTwHfAT8SuC/sAACAASURBVIBngYPcLqyxIqU7cHp8FRERSXyxtMCnAy8AV1lr97hcT5NlRXYQosrrMkREROKiwQC31p4dj0Kaq8ykU2g6kOV1ISIiInFQ5yF0Y8z70cdCY8yOfX4KjTE74ldibNqV5lMSaJXDlIuIiLS4+lrgk6KPXeJRSHO1N6W0C+/0ugwREZG4qLMFbq2NRJ8+Za0N7/sDPBWf8mLXJbyFdenqxEVERJJDLB25DN13ItqRy2h3ymm67YHOpNtyr8sQERGJi/rOgd9kjCkEhu57/hvYCrwetwpjFAlXsi1VA5mIiEhyqK8Ffh+QDTwYfcwGulhrO1lrb4hHcY2RQoTyiO4DFxGR5FDfRWyHWWtXGGOeAwbtnWmiPZ1Za790ubZGCRKmfWYbr8sQERGJi/oC/GbgEuDRWl6zwDGuVNQE1lraUIZtneOsiIiItLg6A9xae0n08ej4ldM0FRVlZJpybJUuYhMRkeQQS1/oPzDGtIs+v9kY86IxZpj7pcWusqwUgEDbbh5XIiIiEh+x3EZ2u7W22BhzJDAVmA382d2yGqeqogKA8nRf9DkjIiLSbLEEeDj6eBrwmLX2ZSDNvZIar6zCOXRugjGNjioiIuJ7sSRegTHmUeBkYKQxJpXYgj9uysudAK+wraosERER18SSeD8C3gdOsdYW4vSNfrOrVTWSLd4EQPvMDI8rERERiY8GA9xaWwJ8DUw0xkwHsqy1b7heWSO0/+p5ACIZOgcuIiLJIZar0K8EXgR6Rn9eNMZc4XZhjVEWhrA1bO7Wam5NFxERcVUs58AvA8ZEW+IYY/4H+BB4zM3CGsMA2+hAl7apXpciIiISF7GcAzdA5T7TldF5rUYk4ox8mpqii9hERCQ5xNICfw742BjzMk5wnwHMdLWqRsrYtQqoUoCLiEjSaDDArbX3GWPeA/Z2qTrdWvuZu2U1zs6UzhxEJSmBVnVgQERExDWx9nxSHv2JRB9blRAR1ttsOqSFvC5FREQkLmK5Cv03wCwgB8gF/s8Y82u3C2sMa8NECJASVAtcRESSQywt8J8AI621pQDGmN8BC4F73CysUSJhwgQIBXUOXEREkkMsibeWmkGfAqxyp5ymMXt2ECZAqgJcRESSRCwt8FLgK2PMvwALTAHmG2P+CGCtvc7F+mKSXb6OCjJ1CF1ERJJGLAH+z+jPXh+7VEuTpVftYpM9mD66Cl1ERJJELLeRPRWPQpqjJNSFQMRijAJcRESSQ4KcNLasJcfrIkREROImIQLc2DDWBL0uQ0REJG5iDnBjTJqbhTSHiVQRMQnxXURERCQmsXTkMsYYswRYEZ0eZox52PXKGiFgw+yp0vlvERFJHrE0Wx8CTgO2A1hrFwOT3CyqsQJESA1pKFEREUkesQR4wFq7dr95YTeKaapUW04gJdZu3UVERPwvltRbb4wZA1hjTBC4CljublmNUF4CQEd2e1yIiIhI/MTSAr8cuA7oCWwGxkXntQ6RKgA2pBzscSEiIiLxE0tHLluAc+NQS9PYCABlVdbjQkREROKnwQA3xvw/nD7Qa7DWXuZKRY0VcU7Hd2mf4XEhIiIi8RPLOfB39nmeDpwJrHennCawToBXWd1GJiIiySOWQ+iz9502xjwHvO1aRY0VbYF3atvG40JERETipyndl/UGDmnpQpos2gIv1zlwERFJIrGcAy/k+3PgAWAHcLObRTVGeNcmgkCntCqvSxEREYmbegPcOONzDgM2RGdFrLWtqqlbVVFBEChtf6jXpYiIiMRNvYfQo2H9irU2HP1pVeENUFW6w3mSku5tISIiInEUyznwT40xI1yvpInCuzYBUGbVlaqIiCSPOlPPGJNira0CJgA/N8Z8B+wGDE7jvFWEehXOOOCBdt08rkRERCR+6mu2fgqMAM6IUy1NEgk7V6FnpKkFLiIiyaO+1DMA1trv3NhwdGCUz4EN1trTjDG9gReATsAXwAXW2oqG1hOOBnhKUAEuIiLJo77UyzbGXFfXi9baPzZz29cAy4D20enfAw9aa18wxjwBXAI83tBKSsvKAUjRcKIiIpJE6ruILQi0BdrV8dNkxphc4FTgyei0AY4D5kQXmUmMh+4rq5wWeCAQbE5JIiIivlJfs7XAWnunS9v9X+BGvv8i0BnYGb1oDiAf6BHLisLRrlS7tldXqiIikjwaPAfe0owxpwFbrLULjTET69lWrfecG2MuAy4DyM7OZuOGDRwOLFnyJZvXr3aj5KRUUlJCXl6e12UkHO1X92jfukP71T3N3bf1BfjkJq+1fkcB04wxp+CMbtYep0XecZ9b13KBjbW92Vo7A5gB0L9/f9u2QxZshXFjx9AzR7eStZS8vDwmTpzodRkJR/vVPdq37tB+dU9z922d58CttTuavNZ6WGt/ba3Ntdb2As4F3rXWng+8B5wdXewiYG4s60unDIBQis6Bi4hI8mjKaGRuuQm4zhizEuec+FOxvCm13PmekZGe4V5lIiIirYyn915Za/OAvOjzVcCYxq6jLOBcvBZKTWvBykRERFq31tQCb5KSPRWU2RCpKb7/KCIiIjHzfeoFiRAhQErAlYvmRUREWiXfB7ghQsQEcPqCERERSQ6+D3AiEaw7t6yLiIi0Wv4PcBsmnAAfQ0REpDH8n3zWOQcuIiKSTHyffB0rCnQAXUREko7vA3x3oD1Z7PK6DBERkbjyfYBXVFWRb3K8LkNERCSufB/gQSKUR3QQXUREkovvAzyFCIGgpz3CioiIxJ3vAzxgw1ijkchERCS5+D7ADWHdRiYiIknH98nXoWq7WuAiIpJ0fH/y2BChvS3xugwREZG48n0LPEyQzcGDvC5DREQkrnwf4EEbpiKQ7nUZIiIiceX7AI9UVRA2Ia/LEBERiSvfB3gf8imvjHhdhoiISFz5PsBLyKR9qvW6DBERkbjyfYADFKbqIjYREUkuvg/wAGHQfeAiIpJkEiDAI+rIRUREko7vAzydCgj4/mOIiIg0iq+Tz1jn6vNIWbHHlYiIiMSXrwMcnAAv79DH4zpERETiy9cBbqKP4ZQ2ntYhIiISb74OcKK3fwcCuohNRESSi78DPJrggaACXEREkovPA9wRSYyPISIiEjNfJ5+NtsArIqaBJUVERBKLrwN87znwdhmp3tYhIiISZ/4O8GiCG13EJiIiScbfAR7tyCUUqfC4EBERkfjyd4BH7wQvT+/scR0iIiLx5fMA33sI3ecfQ0REpJESIvmMRiMTEZEk4+8Ar+6JTbeRiYhIcvF1gEeiCb6n0npciYiISHz5OsD36tw23esSRERE4srfAR5teOsiNhERSTY+Tz4nwYMazERERJKMzwPcoRa4iIgkm4RIvqC6UhURkSTj6wC31beR+fpjiIiINJqvk2/vcKIBtcBFRCTJ+DrA93bfEkEduYiISHLxdYAHbBUAmakKcBERSS6+DvBItHyTkeVxJSIiIvHl6wDfKyVF58BFRCS5+DrAI9HL0FN0EZuIiCQZXwf43jPfIbXARUQkyfg6wPdKC6V4XYKIiEhcJUSAp6QkxMcQERGJma+Tb29PbKEUtcBFRCS5+DrAqy9i02hkIiKSZHwd4IHoVWzG+PpjiIiINFpiJJ9RT2wiIpJcfB7g0ZPg6gtdRESSjM8DPEqH0EVEJMn4O/mqG+BqgYuISHLxdYDvzW+1wEVEJNn4Ovmq290KcBERSTK+Tr4UKp0nRveBi4hIcvF1gIdttPyUVG8LERERiTNfB7gFSkn3ugwREZG483WAB7BE/P0RREREmsT36RfR+W8REUlCvg7wIGGsemETEZEk5OsAB+hgd3ldgoiISNz5OsAtsCXQ1esyRERE4s7XAW6ASpPmdRkiIiJx5+sAB0vYpHhdhIiISNz5OsBTbaUGMhERkaTk6wCvIki6LfW6DBERkbjzdYADFAZ1EZuIiCQfXwe4wWI1EpmIiCShuKefMeZgY8x7xphlxpivjDHXROd3Msa8bYxZEX3MimV9Vj2xiYhIEvKi+VoF/MpaezgwDvilMWYgcDMwz1rbF5gXnW6AWuAiIpKc4p5+1toCa+0X0efFwDKgB3A6MDO62EzgjJjWpxa4iIgkIU+br8aYXsARwCdAN2ttATghDzR4dZoBysMuFigiItJKGWutNxs2pi3wPvA7a+3fjDE7rbUd93m90Fp7wHlwY8xlwGUAQ3NSRz75y6PZfdStcas7WZSUlNC2bVuvy0g42q/u0b51h/are/bu20mTJi201o5q7Ps96cbMGBMCXgaet9b+LTp7szEmx1pbYIzJAbbU9l5r7QxgBsCw7mk2O7SH0RMnxqPspJKXl8dE7dcWp/3qHu1bd2i/uqe5+9aLq9AN8BSwzFr7x31eeg24KPr8ImBuQ+uyGIpDXVq+SBERkVbOixb4UcAFwBJjzKLovFuAe4EXjTGXAOuAH8ayskgg1ZUiRUREWrO4B7i1dj7O9We1mdzoFeo2MhERSUK+Tj+DVYCLiEhS8n/6KcBFRCQJ+T79qry5C05ERMRTvg9wtcBFRCQZ+Tr9DJZQ0JNb2UVERDzl6wAHIOD/jyAiItJY/k8/HUIXEZEk5Ov0021kIiKSrHydfkEiGB1CFxGRJOT79Muo3Ol1CSIiInHn+wAvycj1ugQREZG4832AR4JpXpcgIiISd74P8D1VXlcgIiISf74P8MyMDK9LEBERiTvfB7gNBL0uQUREJO58H+Chqt1elyAiIhJ3vg/wsszuXpcgIiISd74PcHQIXUREkpDvA9wowEVEJAn5P8DVF7qIiCQh/6efWuAiIpKEfB/gaoGLiEgy8n36mUCK1yWIiIjEne8D3BrjdQkiIiJxlwABrnPgIiKSfHwf4Jkp1usSRERE4s73AR7O7OZ1CSIiInHn+wA3AZ0DFxGR5OP7AA/oNjIREUlCvk+/YMD3H0FERKTRfJ9+6shFRESSke/TzwR1DlxERJKP7wM8qBa4iIgkId+nn0UtcBERST6+D/BQinpiExGR5OP7AA/oKnQREUlCvk8/o8FMREQkCSVAgPv+I4iIiDSa79MvEAx5XYKIiEjc+T7ASWvndQUiIiJx5/sAN2qBi4hIEvJ/gOsqdBERSUK+T79AMMXrEkREROLO/wEeUICLiEjy8X36mZSaH6GyspL8/HzKyso8qigxdOjQgWXLlnldRsLxYr+mp6eTm5tLKKTrRUQSia8DPEzwgJ7Y8vPzadeuHb169VInL81QXFxMu3a6wr+lxXu/WmvZvn07+fn59O7dO27bFRH3+foQugUC+2V0WVkZnTt3VniL4PRU2LlzZx2REklAvg5wgEAtQa3wFvme/j+IJCbfB3hr/NsUDAYZPnw4w4YNY8SIEXz44YdelxSTZ555hiuvvLLZy9T2no0bNza6nieeeIJnn322Ue8pKCjgtNNOa/S24mnmzJn07duXvn37MnPmzFqXWbx4MePHj2fIkCFMnTqVXbt2AfD8888zfPjw6p9AIMCiRYsAOP744yksLIzb5xARb/k+wGtrgXstIyODRYsWsXjxYu655x5+/etfe12Sp+oL8HA4XOf7pk+fzoUXXtiobf3xj3/k5z//eczL17d9N+zYsYM77riDTz75hE8//ZQ77rij1tC99NJLuffee1myZAlnnnkm999/PwDnn38+ixYtYtGiRTz33HP06tWL4cOHA3DBBRfw2GOPxfXziIh3FOAu27VrF1lZWQCUlJQwefJkRowYwZAhQ5g7dy4Au3fv5tRTT2XYsGEMHjyY2bNnA7Bw4UKOPfZYRo4cyYknnkhBQcEB67/44ou5/PLLmTRpEn369OH999/nZz/7GYcffjgXX3xx9XKzZs1iyJAhDB48mJtuuql6/l/+8hf69evHsccey4IFC6rnb9u2jbPOOovRo0czevToGq81xpw5c/j88885//zzGT58OHv27KFXr17ceeedTJgwgZdeeon/9//+H6NHj2bYsGGcddZZlJaWAnD77bfzwAMPADBx4kRuuukmxowZQ79+/fj3v/9d6/ZefvllTjrpJADWrFnD0UcfzYgRI2ocCcnLy2PSpEn8+Mc/ZsiQIQD89a9/ZcyYMQwfPpxf/OIX1cF++eWXM2rUKAYNGsRtt93WpH2wr3nz5nHCCSfQqVMnsrKyOOGEE3jzzTcPWO7bb7/lmGOOAeCEE07g5ZdfPmCZWbNmcd5551VPT5s2jVmzZjW7RhHxB19fhQ4HXsS2rzv+/hVfb9zVotsb2L09t00dVO8ye/bsYfjw4ZSVlVFQUMC7774LOLfzvPLKK7Rv355t27Yxbtw4pk2bxptvvkn37t355z//CUBRURGVlZVcddVVzJ07l+zsbGbPns1vfvMbnn766QO2V1hYyLvvvstrr73G1KlTWbBgAU8++SSjR49m0aJFdO3alZtuuomFCxeSlZXFlClTePXVVxk7diy33XYbCxcupEOHDkyaNIkjjjgCgBtvvJFrr72WCRMmsG7dOk488cQm3f509tln88gjj/DAAw8watSo6vnp6enMnz8fgO3bt1e3mm+99VaeeuoprrrqqgPWVVVVxaeffsrrr7/OHXfcwTvvvFPj9dWrV5OVlUVaWhoAXbt25e233yY9PZ0VK1Zw3nnn8fnnnwPw6aefsnTpUnr37s2yZcuYPXs2CxYsIBQKccUVV/D8889z4YUX8rvf/Y5OnToRDoeZPHkyX375JUOHDq2x3fvvv5/nn3/+gHqPOeYYHnrooRrzCgoKOPjgg6unc3Nz2bBhwwHvHTx4MK+99hqnn346L730EuvXrz9gmdmzZ1d/CQTIysqivLyc7du307lz5wOWF5HE4vsAb40X6Ow9hA7w0UcfceGFF7J06VKstdxyyy188MEHBAIBNmzYwObNmxkyZAjXX389N910E6eddhpHH300S5cuZenSpZxwwgmAc6g3Jyen1u1NnToVYwxDhgyhW7du1a3KQYMGsWbNGtauXcvEiRPJzs4GnMOwH3zwAUCN+eeccw7Lly8HnFbqihUrqrexa9cuiouLW2wfnXPOOdXPly5dyq233srOnTspKSnhxBNPrPU9P/jBDwAYOXIka9asOeD1goKC6s8CTp8AV155JYsWLSIYDFZ/NoAxY8ZU31Y1b948Fi5cyOjRowHnC1jXrl0BePHFF5kxYwZVVVUUFBTw9ddfHxDgN9xwAzfccENMn9tae8C82n6Hn376aa6++mruvPNOpk2bRmpqao3XP/nkE9q0acPgwYNrzO/atSsbN25UgIskAZ8HeP3h3VBLOR7Gjx/Ptm3b2Lp1K6+//jpbt25l4cKFhEIhevXqRVlZGf369WPhwoW8/vrr/PrXv2bKlCmceeaZDBo0iI8++qjBbextcQYCgerne6erqqpISan7n7muL0CRSISPPvqIjIyMmD7niSeeyObNmxk1ahRPPvlkg8tnZmZWP7/44ot59dVXGTZsGM888wx5eXm1vmfvZwsGg1RVVR3wekZGRo3bpR588EG6devG4sWLiUQipKen17p9ay0XXXQR99xzT431rV69mgceeIDPPvuMrKwsLr744lpvx2pMC7x79+588skn1dP5+flMnDjxgPcOGDCAt956C4Dly5dXH53Z64UXXqhx+HyvsrKymP/NRMTffH0O/MC2TOvzzTffEA6H6dy5M0VFRXTt2pVQKMR7773H2rVrAdi4cSNt2rThJz/5Cddffz1ffPEF/fv3Z+vWrdUBXllZyVdffdWkGsaOHcv777/Ptm3bCIfDzJo1i2OPPZaxY8eSl5fH9u3bqays5KWXXqp+z3HHHccjjzxSPb33iEJd/vWvf7Fo0aJaw7tdu3b1tt6Li4vJycmhsrKy1iCMVb9+/Wq0zIuKisjJySEQCPDcc8/VecHa5MmTmTNnDlu2bAGcC83Wrl3Lrl27yMzMpEOHDmzevJk33nij1vffcMMN1ReW7fuzf3jv3dZbb71FYWEhhYWFvPXWW7UecdhbSyQS4e6772b69OnVr0UiEV566SXOPffcGu+x1rJp0yZ69epV734SkcTg8xZ467T3HDg4f1RnzpxJMBjk/PPPZ+rUqYwaNYrhw4czYMAAAJYsWcINN9xAIBAgFArx+OOPk5qaypw5c7j66qspKiqiqqqK//qv/2LQoMYfVcjJyeGee+5h0qRJWGs55ZRTOP300wHnQrHx48eTk5PDiBEjqkPu/vvv56abbmLo0KFUVVVxzDHH8MQTTzRpf1x88cVMnz6djIyMWo8o3HXXXYwdO5ZDDjmEIUOGNPlQfWZmJoceeigrV67ksMMO44orruCss87ipZdeYtKkSTVa3fsaOHAgd999N1OmTCESiRAKhXj00UcZN24cRxxxBIMGDaJPnz4cddRRTaprX506deK3v/1t9eH6//7v/6ZTp06Ac+X59OnTGTVqFLNmzeLRRx8FnFMHP/3pT6vX8cEHH5Cbm0ufPn1qrHvhwoWMGzeu3iMuIpI4TG3n5PxiWPc0u3hjeY15y5Yt4/DDD/eoosTh165UX3nlFRYuXMjdd9/tdSm1cnO/XnPNNUybNo3Jkycf8Foy/L/Iy8ur9XSENI/2q3v27ltjzEJr7aiG31GTvqpLQjnzzDPZvn2712V4YvDgwbWGt4gkJl+fAxepzaWXXup1CZ5oTAc2IuJ/CnAREREfUoCLiIj4kAJcRETEhxTgIiIiPqQAd4GGEz3wPU0ZThSc2yzq23+vvvoqd955Z5PWHQ/WWq6++moOO+wwhg4dWmeHOLNnz2bo0KEMGjSIG2+88YDX58yZgzGmui/3JUuW1BisRkSSj68D3DbQlapXNJxoTW4G+H333ccVV1wR8/pq64LVTW+88QYrVqxgxYoVzJgxg2uvvfaAZbZv384NN9zAvHnz+Oqrr9i8eTPz5s2rfr24uJiHHnqIsWPHVs8bMmQI+fn5rFu3Li6fQ0RaH18HuB9oONEDhxOt63M99NBDDBw4kKFDh3LuueeyZs0annjiCR588EGGDx9+wBCiy5cvJy0tjS5dugDw97//nbFjx3LEEUdw/PHHs3nzZsDpbe6yyy5jypQpXHjhhYTDYW644QZGjx7N0KFD+fOf/1zvv09zzJ07lwsvvBBjDOPGjaOoqOiAf8dVq1bRr1+/6oFYjj/++BrDh/72t7/lxhtvrNGXOziD2LzwwgvNrlFE/CmxO3J542bYtKRl13nQEDj53noX0XCi39t/ONH6Pte9997L6tWrSUtLY+fOnXTs2JHp06fTtm1brr/++gPWvWDBAkaMGFE9PWHCBD7++GOMMTz55JPcd999/OEPfwCcL0Pz588nIyODGTNm0KFDBz777DPKy8s56qijmDJlCgcffHCt/z77D/hyzjnn8O233x5Qz3XXXceFF15YY96GDRtqDB/ao0cPNmzYUGNkucMOO4xvvvmGNWvWkJuby6uvvkpFRQUA//nPf1i/fj2nnXZa9djoe40aNYp777231kPuIpL4EjvAPaLhROv27bff1vm5hg4dyvnnn88ZZ5zBGWec0eC69h8+ND8/n3POOYeCggIqKiqqhwsFmDZtWvUoXW+99RZffvklc+bMAZwvTCtWrCA3N7fWf5+DDjqoxnb3HiGJRSzDh2ZlZfH4449zzjnnEAgEOPLII1m1ahWRSIRrr72WZ555ptZ17x06VESSU2IHeAMt5XjQcKI1WWvr/Fz//Oc/+eCDD3jttde46667Ghx9LSMjg6Kiourpq666iuuuu45p06aRl5fH7bffXv3a/sOHPvzwwweMAvbMM8/U+u+zv8a0wHNzc1m/fn319IYNG+jevfsB7506dSpTp04FYMaMGQSDQYqLi1m6dGl1P9SbNm1i2rRpvPbaa4waNUpDh4okOZ0Dd5mGE605nGhdnysSibB+/XomTZrEfffdx86dOykpKal3KNLDDz+clStXVk8XFRXRo0cPAGbOnFlnrSeeeCKPP/44lZWVgHMufffu3XX+++xv9uzZtQ4fun94g9Pyf/bZZ7HW8vHHH9O+fftaj6TsHT60sLCQxx57jEsvvZQOHTqwbds21qxZw5o1axg3blx1eO+te/DgwXV+ThFJbIndAveIhhOtaf/hRGv7XP369eMnP/kJRUVFWGu59tpr6dixI1OnTuXss89m7ty5PPzwwxx99NHV6z3mmGP41a9+hbUWYwy33347P/zhD+nRowfjxo1j9erVtdZz6aWXsmbNGkaMGIG1luzsbF599dU6/32a45RTTuH111/nsMMOo02bNjW+FA0fPrz6i9E111zD4sWLAWeI0X79+jW47vfee49TTz212TWKiD/5ejjRod3T7Zcbax7iTIZhE+PBL8OJXnPNNUydOpXjjz/e61Ji0lL7tby8nGOPPZb58+fHNP53Mvy/0LCX7tB+dU9zhxPVIXTxtVtuuYXS0lKvy4i7devWce+998YU3iKSmPS/X3ytW7duTJs2zesy4q5v37707dvX6zJExEM+b4G3zp7YRERE3ObrAK/r7L2fz+uLtDT9fxBJTL4O8Nqkp6ezfft2/dESwQnv7du3H9ANq4j4X8KdA8/NzSU/P5+tW7d6XYqvlZWV6Y++C7zYr+np6eTm5sZ1myLivlYV4MaYk4A/AUHgSWtto7tSC4VCNbrQlKbJy8ur7hddWo72q4i0lFZzCN0YEwQeBU4GBgLnGWMGeluViIhI69RqAhwYA6y01q6y1lYALwCne1yTiIhIq9SaArwHsH6f6fzoPBEREdlPazoHXttN3QdcSm6MuQy4LDpZboxZ6mpVyasLsM3rIhKQ9qt7tG/dof3qnr379pCmvLk1BXg+cPA+07nAAYMdW2tnADMAjDGfN6X/WGmY9q07tF/do33rDu1X9zR337amQ+ifAX2NMb2NManAucBrHtckIiLSKrWaFri1tsoYcyXwL5zbyJ621jZtAGwRpNsEBwAACBdJREFUEZEE12oCHMBa+zrweiPeMsOtWkT71iXar+7RvnWH9qt7mrVvfT0euIiISLJqTefARUREJEa+DXBjzEnGmG+NMSuNMTd7XY9fGWMONsa8Z4xZZoz5yhhzTXR+J2PM28aYFdHHLK9r9SNjTNAY8x9jzD+i072NMZ9E9+vs6AWb0kjGmI7GmDnGmG+iv7vj9TvbMowx10b/Fiw1xswyxqTr97bxjDFPG2O27Hurc12/o8bxUDTPvjTGjIhlG74McHW72qKqgF9Zaw8HxgG/jO7Lm4F51tq+wLzotDTeNcCyfaZ/DzwY3a+FwCWeVOV/fwLetNYOAIbh7GP9zjaTMaYHcDUwylo7GOeC4nPR721TPAOctN+8un5HTwb6Rn8uAx6PZQO+DHDU7WqLsdYWWGu/iD4vxvlD2ANnf86MLjaT/9/evcbKVZVhHP8/0GJaUBqMGBXhtKiE4AWk0V60VvASbUO9tDaGSoHwoUZsJCAJQvGS4A0CtRJAAyrVWltLg6gf0NRyUbDFSqkRosRSEVJKiRYsFnqkjx/WOnE8zmnnnJ522O3zSyazZ8/ae68zWWfeWWvNrBc+1J0aNpekY4BpwI31sYDTgBW1SF7XIZD0MmAKcBOA7Z22t5E2O1xGAKMkjQBGA5tJux0023cBf++3e6A2OgNY7OK3wBhJr9rTNZoawLPs6j4gqQc4BVgDvNL2ZihBHji6ezVrrIXAxcCu+vjlwDbb/66P026HZhywFfhunZ64UdLhpM3uNduPA1cBj1IC99PAOtJuh8tAbXRIMa2pAbyjZVejc5KOAG4BPmP7mW7Xp+kkTQeetL2udXebomm3gzcCeCtwve1TgGfJcPmwqHOyM4CxwKuBwynDu/2l3Q6vIb03NDWAd7TsanRG0khK8F5ie2XdvaVvCKfeP9mt+jXUZOAMSZsoUzynUXrkY+rQJKTdDtVjwGO219THKygBPW12770HeMT2Vtu9wEpgEmm3w2WgNjqkmNbUAJ5lV4dJnZe9CXjI9tUtT90GzK3bc4Gf7O+6NZntS2wfY7uH0j5/ZftMYDUwsxbL6zoEtp8A/ibphLrrdOBB0maHw6PABEmj63tD32ubdjs8BmqjtwFn1W+jTwCe7htq353GLuQi6YOUHk3fsqtXdLlKjSTpHcDdwB/471zt5yjz4MuBYyn/1LNs9/9CRnRA0lTgItvTJY2j9MiPAu4H5th+vpv1ayJJJ1O+HHgYsBE4h9IhSZvdS5K+CMym/ELlfuA8ynxs2u0gSFoKTKVkHNsCfB64lTZttH5YupbyrfV/AefY/t0er9HUAB4REXEwa+oQekRExEEtATwiIqKBEsAjIiIaKAE8IiKigRLAIyIiGigBPGI/kfSCpPUtt57dlO1pzWLUTZLGS1pUt6dKmtTy3DxJZ+2j654taaukvrXkJ9dMTfdJel3dN0bS7fVnOH3HrZa0XdL4fVGviBeLEXsuEhHDZIftk7tdicGqv0ft+03qVGA7cE997oZ9fPllts+v2xcCHwV6gE/WxwuAL7vl97C23y3pjn1cr4iuSw88ootqT/tuSb+vt0ltypwkaW3ttW+Q9Pq6f07L/m/VNLv9j90k6Wu13NqWnutxklbV862SdGzdP0slD/QDku6q+6ZK+lkdMZgHXFCv+U5JX5B0kaQTJa3t93dtqNunSrpT0rraW+5bSnK+pAdrHX7UwcvVC4yiZMjqlXQ88Brbdw7iJY84YKQHHrH/jJK0vm4/YvvDlLWQ32v7uRqYlwL9h37nAd+wvaQuHXyopBMpq2VNtt0r6TrgTGBxm+s+Y/ttdah7ITCdsurTYts3SzoXWERJbXg58H7bj0sa03oS25sk3QBst30VgKTT63MPSTpM0jjbG2vdltd19r8JzLC9VdJs4ArgXEoCkrG2n+9/rQF8Bfg2sAP4BCVr1oIOjos4ICWAR+w/7YbQRwLX1qVBXwDe0Oa4e4FLVfKLr7T9cA2cpwL31enfUQycvGNpy/01dXsi8JG6/X3g63X7N8D3JC2nJLIYjOXAx4CvUgL4bOAE4I3AL2s9D6WkqQTYACyRdCtlicndsr0emAAgaQol2YMkLaP0zi+0vWWQdY5orATwiO66gLJO8lsoU1rP9S9g+4eS1gDTgNslnUdJP3iz7Us6uIYH2P6/MrbnSXp7vdb6+sGiU8uAH0taWU7lhyW9Cfij7Yltyk8DpgBnAAskndSSc3pA9Qtrl1E+IFxLWWO6B5gPXDqI+kY0WubAI7rrSGCz7V2UYeF289jjgI22F1GyFr0ZWAXMlHR0LXOUpOMGuMbslvt76/Y9lCxpUIbef13Pc7ztNbYvB57if1McAvwTeGm7i9j+C2UUYQElmAP8CXiFpIn1/CPrnP4hwGttrwYuBsYARwxQ//7mAj+3/Q/KfPiuehvd4fERB4T0wCO66zrgFkmzKCkbn21TZjYwR1Iv8ATwpZrB6DLgFzUY9gKfAv7a5viX1B78IcDH6775wHckfRbYSsnmBXBlnYsX5UPCA8C7Ws71U2CFpBnAp9tcaxlwJTAWwPZOSTOBRZKOpLznLAT+DPyg7hNwje1tu3uhACSNpgTw99VdV1Ny2e9s+dsiDgrJRhZxAJO0CRhv+6lu12WwJJ1Nqfv5eyrb5tg7KClc95iSMaKpMoQeES9WO4AP9C3k0ilJq4FxlFGJiANWeuARERENlB54REREAyWAR0RENFACeERERAMlgEdERDRQAnhEREQDJYBHREQ00H8AM7fKyDsqMOYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_roc('Base model - train',y_train,y_pred_train_b)\n",
    "plot_roc('Base model - test',y_test,y_pred_test_b)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iaw83EYPd20X"
   },
   "source": [
    "# Tuning parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T20:54:28.745489Z",
     "start_time": "2020-05-21T20:54:28.682123Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1589213605661,
     "user": {
      "displayName": "Duong Hung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfgs4FqFN7Yq3pQXoVHeQcc9w9kDV_fAGoQ3Nx4nk=s64",
      "userId": "01608720095171318435"
     },
     "user_tz": 300
    },
    "id": "91RuQ-tob8Lt",
    "outputId": "8c7ccd57-0239-48ec-ec01-f64d6f119f52"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:03:25.789999Z",
     "start_time": "2020-05-21T21:03:25.784509Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ijqe1QW9clTc"
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.1,0.01,0.001]\n",
    "nodes = [5,10,20]\n",
    "batches=[1024,2048,4096]\n",
    "param_options = {'lr': learning_rates,'nodes': nodes,'batch_size':batches}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T21:03:28.088963Z",
     "start_time": "2020-05-21T21:03:28.084967Z"
    }
   },
   "outputs": [],
   "source": [
    "scores={'BA':'balanced_accuracy','F1':'f1','AUC':'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T00:46:56.664071Z",
     "start_time": "2020-05-21T21:22:54.401397Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uetpo3uQfuSu",
    "outputId": "d2c9d310-5b2f-4ab7-8730-03f602afd365",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 0.8452 - accuracy: 0.7886 - auc: 0.7495 - val_loss: 0.5297 - val_accuracy: 0.9134 - val_auc: 0.9129\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7459 - accuracy: 0.8690 - auc: 0.7861 - val_loss: 0.4284 - val_accuracy: 0.7571 - val_auc: 0.9427\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6300 - accuracy: 0.7725 - auc: 0.8281 - val_loss: 0.6482 - val_accuracy: 0.9247 - val_auc: 0.8818\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8527 - accuracy: 0.5081 - auc: 0.7672 - val_loss: 1.1277 - val_accuracy: 0.5877 - val_auc: 0.7809\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.1729 - accuracy: 0.4101 - auc: 0.6856 - val_loss: 1.2473 - val_accuracy: 0.5651 - val_auc: 0.7618\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8083 - accuracy: 0.3897 - auc: 0.6859 - val_loss: 1.0504 - val_accuracy: 0.5773 - val_auc: 0.7721\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.7756 - accuracy: 0.3673 - auc: 0.6685 - val_loss: 1.5855 - val_accuracy: 0.5599 - val_auc: 0.7627\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8256 - accuracy: 0.3676 - auc: 0.6775 - val_loss: 1.4763 - val_accuracy: 0.5412 - val_auc: 0.7581\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.6583 - accuracy: 0.3904 - auc: 0.6913 - val_loss: 1.3681 - val_accuracy: 0.5406 - val_auc: 0.7591\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0219 - accuracy: 0.3282 - auc: 0.6508 - val_loss: 0.9856 - val_accuracy: 0.5201 - val_auc: 0.7476\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5913 - accuracy: 0.3569 - auc: 0.6667 - val_loss: 0.9566 - val_accuracy: 0.5546 - val_auc: 0.7637\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6359 - accuracy: 0.3977 - auc: 0.7007 - val_loss: 0.6525 - val_accuracy: 0.5698 - val_auc: 0.7773\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5508 - accuracy: 0.3840 - auc: 0.6838 - val_loss: 0.8697 - val_accuracy: 0.5907 - val_auc: 0.7851\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6640 - accuracy: 0.3831 - auc: 0.6862 - val_loss: 1.4292 - val_accuracy: 0.5711 - val_auc: 0.7716\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6370 - accuracy: 0.3941 - auc: 0.6865 - val_loss: 1.3623 - val_accuracy: 0.5757 - val_auc: 0.7763\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.7139 - accuracy: 0.3868 - auc: 0.6945 - val_loss: 2.0186 - val_accuracy: 0.5910 - val_auc: 0.7826\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6076 - accuracy: 0.4046 - auc: 0.7027 - val_loss: 1.9683 - val_accuracy: 0.5853 - val_auc: 0.7777\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.5692 - accuracy: 0.3978 - auc: 0.7028 - val_loss: 2.0501 - val_accuracy: 0.6073 - val_auc: 0.7874\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7277 - accuracy: 0.4136 - auc: 0.7019 - val_loss: 0.8331 - val_accuracy: 0.6391 - val_auc: 0.8015\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5569 - accuracy: 0.4104 - auc: 0.7013 - val_loss: 1.3567 - val_accuracy: 0.6138 - val_auc: 0.7884\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5740 - accuracy: 0.4103 - auc: 0.6980 - val_loss: 1.5738 - val_accuracy: 0.6131 - val_auc: 0.7959\n",
      "Epoch 22/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.5420 - accuracy: 0.4146 - auc: 0.7020Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5407 - accuracy: 0.4146 - auc: 0.7012 - val_loss: 1.4532 - val_accuracy: 0.6184 - val_auc: 0.7978\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 0.6401 - accuracy: 0.8723 - auc: 0.7812 - val_loss: 0.3814 - val_accuracy: 0.8911 - val_auc: 0.9410\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6527 - accuracy: 0.9160 - auc: 0.7447 - val_loss: 0.6496 - val_accuracy: 0.9638 - val_auc: 0.7708\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.8904 - accuracy: 0.5549 - auc: 0.6655 - val_loss: 0.7842 - val_accuracy: 0.9603 - val_auc: 0.7741\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 1.1331 - accuracy: 0.5743 - auc: 0.6558 - val_loss: 1.1400 - val_accuracy: 0.1996 - val_auc: 0.6126\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.7627 - accuracy: 0.4980 - auc: 0.6852 - val_loss: 0.6687 - val_accuracy: 0.9504 - val_auc: 0.8019\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.5790 - accuracy: 0.6260 - auc: 0.7139 - val_loss: 0.6322 - val_accuracy: 0.9887 - val_auc: 0.8253\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6172 - accuracy: 0.6204 - auc: 0.7263 - val_loss: 0.8923 - val_accuracy: 0.4946 - val_auc: 0.8152\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6027 - accuracy: 0.3448 - auc: 0.7089 - val_loss: 0.9131 - val_accuracy: 0.5329 - val_auc: 0.8310\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6295 - accuracy: 0.3501 - auc: 0.6947 - val_loss: 1.2085 - val_accuracy: 0.5237 - val_auc: 0.7790\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.6306 - accuracy: 0.3639 - auc: 0.7003 - val_loss: 1.4604 - val_accuracy: 0.5282 - val_auc: 0.8081\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.6970 - accuracy: 0.3582 - auc: 0.7045 - val_loss: 1.5442 - val_accuracy: 0.5305 - val_auc: 0.7552\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5807 - accuracy: 0.3473 - auc: 0.6608 - val_loss: 1.1652 - val_accuracy: 0.5434 - val_auc: 0.7578\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.6399 - accuracy: 0.3640 - auc: 0.6802 - val_loss: 1.4121 - val_accuracy: 0.5656 - val_auc: 0.7685\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5532 - accuracy: 0.4053 - auc: 0.6925 - val_loss: 1.3022 - val_accuracy: 0.5787 - val_auc: 0.7755\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5537 - accuracy: 0.3897 - auc: 0.6937 - val_loss: 1.1859 - val_accuracy: 0.5885 - val_auc: 0.7835\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5599 - accuracy: 0.3944 - auc: 0.6883 - val_loss: 0.8695 - val_accuracy: 0.6084 - val_auc: 0.7898\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.5673 - accuracy: 0.4205 - auc: 0.7019 - val_loss: 0.9181 - val_accuracy: 0.6482 - val_auc: 0.8145\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5972 - accuracy: 0.4189 - auc: 0.7151 - val_loss: 0.9951 - val_accuracy: 0.6097 - val_auc: 0.7974\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.5485 - accuracy: 0.4150 - auc: 0.7057 - val_loss: 1.0440 - val_accuracy: 0.6133 - val_auc: 0.7956\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.5291 - accuracy: 0.4290 - auc: 0.7105 - val_loss: 1.0864 - val_accuracy: 0.6344 - val_auc: 0.8071\n",
      "Epoch 21/100\n",
      "246784/250290 [============================>.] - ETA: 0s - loss: 0.5243 - accuracy: 0.4498 - auc: 0.7274 ETA: 0s - loss:Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.5246 - accuracy: 0.4499 - auc: 0.7280 - val_loss: 1.0269 - val_accuracy: 0.6656 - val_auc: 0.8217\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 1.0937 - accuracy: 0.7339 - auc: 0.7194 - val_loss: 0.6832 - val_accuracy: 0.8986 - val_auc: 0.8781\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7267 - accuracy: 0.7103 - auc: 0.7860 - val_loss: 0.6044 - val_accuracy: 0.9060 - val_auc: 0.9206\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5209 - accuracy: 0.6938 - auc: 0.8426 - val_loss: 0.4876 - val_accuracy: 0.5659 - val_auc: 0.9097\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5119 - accuracy: 0.6267 - auc: 0.8377 - val_loss: 0.4231 - val_accuracy: 0.7392 - val_auc: 0.9428\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7011 - accuracy: 0.5706 - auc: 0.7995 - val_loss: 0.5068 - val_accuracy: 0.6511 - val_auc: 0.8643\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5354 - accuracy: 0.4563 - auc: 0.7312 - val_loss: 0.7957 - val_accuracy: 0.5856 - val_auc: 0.8269\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6138 - accuracy: 0.3980 - auc: 0.7035 - val_loss: 1.0934 - val_accuracy: 0.6258 - val_auc: 0.8156\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7320 - accuracy: 0.4103 - auc: 0.7045 - val_loss: 0.9207 - val_accuracy: 0.6192 - val_auc: 0.8328\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.6289 - accuracy: 0.4061 - auc: 0.7226 - val_loss: 0.7326 - val_accuracy: 0.5979 - val_auc: 0.8199\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5381 - accuracy: 0.4249 - auc: 0.7236 - val_loss: 0.5934 - val_accuracy: 0.6421 - val_auc: 0.8462\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5199 - accuracy: 0.4516 - auc: 0.7466 - val_loss: 0.5928 - val_accuracy: 0.6605 - val_auc: 0.8425\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4955 - accuracy: 0.4655 - auc: 0.7664 - val_loss: 0.5753 - val_accuracy: 0.6831 - val_auc: 0.8872\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4734 - accuracy: 0.4920 - auc: 0.7994 - val_loss: 0.5657 - val_accuracy: 0.6397 - val_auc: 0.9104\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5270 - accuracy: 0.5147 - auc: 0.7766 - val_loss: 0.6568 - val_accuracy: 0.7102 - val_auc: 0.8505\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.5140 - accuracy: 0.5349 - auc: 0.7715 - val_loss: 0.6248 - val_accuracy: 0.7189 - val_auc: 0.8526\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 7s 29us/sample - loss: 0.5698 - accuracy: 0.5168 - auc: 0.7541 - val_loss: 1.0705 - val_accuracy: 0.6807 - val_auc: 0.8288\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.6941 - accuracy: 0.4979 - auc: 0.7422 - val_loss: 0.6909 - val_accuracy: 0.6340 - val_auc: 0.8165\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 1.2528 - accuracy: 0.4693 - auc: 0.7153 - val_loss: 4.5287 - val_accuracy: 0.6119 - val_auc: 0.7793\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9501 - accuracy: 0.4249 - auc: 0.6979 - val_loss: 1.1164 - val_accuracy: 0.5830 - val_auc: 0.7794\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6548 - accuracy: 0.4381 - auc: 0.7109 - val_loss: 1.1307 - val_accuracy: 0.6088 - val_auc: 0.7892\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5096 - accuracy: 0.4609 - auc: 0.7294 - val_loss: 1.1686 - val_accuracy: 0.6341 - val_auc: 0.8014\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5078 - accuracy: 0.4749 - auc: 0.7289 - val_loss: 1.1700 - val_accuracy: 0.6513 - val_auc: 0.8096\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5269 - accuracy: 0.4716 - auc: 0.7389 - val_loss: 1.0721 - val_accuracy: 0.6367 - val_auc: 0.8045\n",
      "Epoch 24/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.5194 - accuracy: 0.4764 - auc: 0.7374Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5189 - accuracy: 0.4766 - auc: 0.7373 - val_loss: 1.2518 - val_accuracy: 0.6449 - val_auc: 0.8051\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 20us/sample - loss: 0.7979 - accuracy: 0.6509 - auc: 0.6991 - val_loss: 0.5877 - val_accuracy: 0.6061 - val_auc: 0.8982\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0310 - accuracy: 0.7148 - auc: 0.7443 - val_loss: 1.6404 - val_accuracy: 0.5532 - val_auc: 0.5746\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9729 - accuracy: 0.5991 - auc: 0.7756 - val_loss: 0.7015 - val_accuracy: 0.5854 - val_auc: 0.8300\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0841 - accuracy: 0.4181 - auc: 0.6927 - val_loss: 1.3545 - val_accuracy: 0.5440 - val_auc: 0.7641\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9409 - accuracy: 0.4078 - auc: 0.7142 - val_loss: 0.7471 - val_accuracy: 0.5237 - val_auc: 0.8558\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9195 - accuracy: 0.3795 - auc: 0.6815 - val_loss: 0.9132 - val_accuracy: 0.5160 - val_auc: 0.7483\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7382 - accuracy: 0.4013 - auc: 0.6890 - val_loss: 0.6106 - val_accuracy: 0.4950 - val_auc: 0.7549\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5577 - accuracy: 0.4174 - auc: 0.7093 - val_loss: 0.9262 - val_accuracy: 0.5839 - val_auc: 0.7828\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5276 - accuracy: 0.4590 - auc: 0.7294 - val_loss: 0.6878 - val_accuracy: 0.6251 - val_auc: 0.8058\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5123 - accuracy: 0.4847 - auc: 0.7438 - val_loss: 0.6860 - val_accuracy: 0.6497 - val_auc: 0.8173\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4998 - accuracy: 0.5165 - auc: 0.7466 - val_loss: 0.6448 - val_accuracy: 0.6908 - val_auc: 0.8357\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5215 - accuracy: 0.5259 - auc: 0.7634 - val_loss: 0.9013 - val_accuracy: 0.6799 - val_auc: 0.8260\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4784 - accuracy: 0.5459 - auc: 0.7728 - val_loss: 0.9130 - val_accuracy: 0.7119 - val_auc: 0.8385\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4847 - accuracy: 0.5557 - auc: 0.7653 - val_loss: 0.7408 - val_accuracy: 0.6989 - val_auc: 0.8356\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6572 - accuracy: 0.5479 - auc: 0.7664 - val_loss: 1.1731 - val_accuracy: 0.6978 - val_auc: 0.8289\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5525 - accuracy: 0.5367 - auc: 0.7634 - val_loss: 0.8726 - val_accuracy: 0.6842 - val_auc: 0.8278\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6519 - accuracy: 0.5201 - auc: 0.7503 - val_loss: 0.9781 - val_accuracy: 0.6617 - val_auc: 0.8174\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4857 - accuracy: 0.5269 - auc: 0.7613 - val_loss: 1.0278 - val_accuracy: 0.6707 - val_auc: 0.8176\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5503 - accuracy: 0.5328 - auc: 0.7616 - val_loss: 1.3067 - val_accuracy: 0.6631 - val_auc: 0.8075\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.8246 - accuracy: 0.4978 - auc: 0.7418 - val_loss: 4.7863 - val_accuracy: 0.6023 - val_auc: 0.7760\n",
      "Epoch 21/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 1.5350 - accuracy: 0.4568 - auc: 0.7263Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.5331 - accuracy: 0.4568 - auc: 0.7263 - val_loss: 4.9042 - val_accuracy: 0.5771 - val_auc: 0.7687\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.8562 - accuracy: 0.8076 - auc: 0.7159 - val_loss: 0.6275 - val_accuracy: 0.9276 - val_auc: 0.8077\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9146 - accuracy: 0.8928 - auc: 0.6972 - val_loss: 0.7017 - val_accuracy: 0.9184 - val_auc: 0.7745\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6735 - accuracy: 0.8573 - auc: 0.6751 - val_loss: 0.6608 - val_accuracy: 0.9881 - val_auc: 0.6360\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6459 - accuracy: 0.4632 - auc: 0.6561 - val_loss: 0.5369 - val_accuracy: 0.6396 - val_auc: 0.8095\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6386 - accuracy: 0.3819 - auc: 0.6832 - val_loss: 0.5422 - val_accuracy: 0.6443 - val_auc: 0.8115\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7844 - accuracy: 0.3898 - auc: 0.6688 - val_loss: 0.5997 - val_accuracy: 0.6938 - val_auc: 0.8361\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6126 - accuracy: 0.4246 - auc: 0.6974 - val_loss: 0.6706 - val_accuracy: 0.7190 - val_auc: 0.8418\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7290 - accuracy: 0.4124 - auc: 0.7023 - val_loss: 0.6393 - val_accuracy: 0.6612 - val_auc: 0.8196\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5562 - accuracy: 0.4253 - auc: 0.7049 - val_loss: 0.6079 - val_accuracy: 0.6613 - val_auc: 0.8320\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6016 - accuracy: 0.4342 - auc: 0.7162 - val_loss: 0.8031 - val_accuracy: 0.6335 - val_auc: 0.8100\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5593 - accuracy: 0.4098 - auc: 0.6922 - val_loss: 0.7507 - val_accuracy: 0.6603 - val_auc: 0.8131\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5551 - accuracy: 0.4219 - auc: 0.7032 - val_loss: 0.7570 - val_accuracy: 0.6553 - val_auc: 0.8113\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5460 - accuracy: 0.4300 - auc: 0.7035 - val_loss: 0.7351 - val_accuracy: 0.6783 - val_auc: 0.8241\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5331 - accuracy: 0.4314 - auc: 0.7181 - val_loss: 0.8271 - val_accuracy: 0.6525 - val_auc: 0.8105\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5317 - accuracy: 0.4395 - auc: 0.7145 - val_loss: 0.7132 - val_accuracy: 0.6755 - val_auc: 0.8229\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5374 - accuracy: 0.4492 - auc: 0.7235 - val_loss: 0.8272 - val_accuracy: 0.6572 - val_auc: 0.8260\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5761 - accuracy: 0.4493 - auc: 0.7093 - val_loss: 1.5612 - val_accuracy: 0.6866 - val_auc: 0.8241\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5808 - accuracy: 0.4570 - auc: 0.7193 - val_loss: 1.9621 - val_accuracy: 0.7120 - val_auc: 0.8251\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 2.3085 - accuracy: 0.4612 - auc: 0.7221 - val_loss: 2.0036 - val_accuracy: 0.6355 - val_auc: 0.7954\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.1086 - accuracy: 0.3572 - auc: 0.6657 - val_loss: 0.9805 - val_accuracy: 0.5206 - val_auc: 0.7396\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6260 - accuracy: 0.3452 - auc: 0.6698 - val_loss: 1.9353 - val_accuracy: 0.5347 - val_auc: 0.7472\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6299 - accuracy: 0.3513 - auc: 0.6602 - val_loss: 1.2590 - val_accuracy: 0.5253 - val_auc: 0.7498\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9807 - accuracy: 0.3518 - auc: 0.6666 - val_loss: 1.9039 - val_accuracy: 0.5294 - val_auc: 0.7535\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7784 - accuracy: 0.3581 - auc: 0.6733 - val_loss: 2.0835 - val_accuracy: 0.5423 - val_auc: 0.7573\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5849 - accuracy: 0.3702 - auc: 0.6759 - val_loss: 1.9803 - val_accuracy: 0.5465 - val_auc: 0.7555\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5530 - accuracy: 0.3726 - auc: 0.6816 - val_loss: 1.9648 - val_accuracy: 0.5599 - val_auc: 0.7620\n",
      "Epoch 27/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.5438 - accuracy: 0.3817 - auc: 0.6854Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5457 - accuracy: 0.3820 - auc: 0.6858 - val_loss: 1.8381 - val_accuracy: 0.5772 - val_auc: 0.7706\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 1.7763 - accuracy: 0.7280 - auc: 0.7149 - val_loss: 0.7563 - val_accuracy: 0.9151 - val_auc: 0.9105\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.7228 - accuracy: 0.9108 - auc: 0.8039 - val_loss: 0.7664 - val_accuracy: 0.8894 - val_auc: 0.8870\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6710 - accuracy: 0.8798 - auc: 0.8238 - val_loss: 0.6758 - val_accuracy: 0.9621 - val_auc: 0.9009\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7436 - accuracy: 0.5046 - auc: 0.7528 - val_loss: 1.0132 - val_accuracy: 0.6376 - val_auc: 0.8302\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8305 - accuracy: 0.5107 - auc: 0.7619 - val_loss: 0.5662 - val_accuracy: 0.6302 - val_auc: 0.8703\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6987 - accuracy: 0.5408 - auc: 0.7960 - val_loss: 0.5050 - val_accuracy: 0.6115 - val_auc: 0.8558\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7110 - accuracy: 0.5232 - auc: 0.7656 - val_loss: 1.1151 - val_accuracy: 0.6527 - val_auc: 0.8089\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6015 - accuracy: 0.5306 - auc: 0.7637 - val_loss: 0.7552 - val_accuracy: 0.6847 - val_auc: 0.8324\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7824 - accuracy: 0.5526 - auc: 0.7601 - val_loss: 1.3759 - val_accuracy: 0.7145 - val_auc: 0.8306\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7360 - accuracy: 0.5341 - auc: 0.7583 - val_loss: 1.3873 - val_accuracy: 0.6908 - val_auc: 0.8304\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5587 - accuracy: 0.5352 - auc: 0.7685 - val_loss: 1.5595 - val_accuracy: 0.6725 - val_auc: 0.8135\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6423 - accuracy: 0.5181 - auc: 0.7474 - val_loss: 1.3492 - val_accuracy: 0.6422 - val_auc: 0.8067\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7578 - accuracy: 0.5160 - auc: 0.7570 - val_loss: 1.6846 - val_accuracy: 0.6585 - val_auc: 0.8066\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7198 - accuracy: 0.5354 - auc: 0.7622 - val_loss: 1.7426 - val_accuracy: 0.6590 - val_auc: 0.8045\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6672 - accuracy: 0.5466 - auc: 0.7768 - val_loss: 2.2343 - val_accuracy: 0.6871 - val_auc: 0.8202\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5579 - accuracy: 0.5519 - auc: 0.7708 - val_loss: 1.8543 - val_accuracy: 0.6976 - val_auc: 0.8244\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4945 - accuracy: 0.5649 - auc: 0.7789 - val_loss: 0.9858 - val_accuracy: 0.6749 - val_auc: 0.8284\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4961 - accuracy: 0.5574 - auc: 0.7803 - val_loss: 1.5384 - val_accuracy: 0.6834 - val_auc: 0.8260\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4874 - accuracy: 0.5624 - auc: 0.7821 - val_loss: 1.2084 - val_accuracy: 0.6720 - val_auc: 0.8243\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5458 - accuracy: 0.5613 - auc: 0.7826 - val_loss: 1.3861 - val_accuracy: 0.6800 - val_auc: 0.8222\n",
      "Epoch 21/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.5488 - auc: 0.7700Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5214 - accuracy: 0.5492 - auc: 0.7718 - val_loss: 1.2562 - val_accuracy: 0.6711 - val_auc: 0.8179\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 1.2509 - accuracy: 0.7900 - auc: 0.7747 - val_loss: 0.5809 - val_accuracy: 0.8467 - val_auc: 0.9214\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6901 - accuracy: 0.8939 - auc: 0.8344 - val_loss: 0.5226 - val_accuracy: 0.9527 - val_auc: 0.9206\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 1.5797 - accuracy: 0.8358 - auc: 0.7624 - val_loss: 0.7503 - val_accuracy: 0.3256 - val_auc: 0.8384\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9148 - accuracy: 0.7394 - auc: 0.7562 - val_loss: 0.5667 - val_accuracy: 0.5367 - val_auc: 0.8401\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6768 - accuracy: 0.4738 - auc: 0.7283 - val_loss: 0.5831 - val_accuracy: 0.6266 - val_auc: 0.8299\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6330 - accuracy: 0.3881 - auc: 0.7037 - val_loss: 0.6139 - val_accuracy: 0.6480 - val_auc: 0.8410\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5898 - accuracy: 0.4167 - auc: 0.7528 - val_loss: 0.5625 - val_accuracy: 0.6241 - val_auc: 0.8623\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7229 - accuracy: 0.5176 - auc: 0.7587 - val_loss: 0.7482 - val_accuracy: 0.6366 - val_auc: 0.8456\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5533 - accuracy: 0.3983 - auc: 0.7383 - val_loss: 0.7435 - val_accuracy: 0.5992 - val_auc: 0.8980\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5485 - accuracy: 0.5956 - auc: 0.7825 - val_loss: 0.7759 - val_accuracy: 0.5845 - val_auc: 0.8012\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5497 - accuracy: 0.4035 - auc: 0.7078 - val_loss: 0.7685 - val_accuracy: 0.6052 - val_auc: 0.7990\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7604 - accuracy: 0.4181 - auc: 0.6970 - val_loss: 0.9585 - val_accuracy: 0.6437 - val_auc: 0.7966\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6443 - accuracy: 0.4417 - auc: 0.7176 - val_loss: 1.4531 - val_accuracy: 0.6537 - val_auc: 0.8003\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6773 - accuracy: 0.4583 - auc: 0.7273 - val_loss: 1.5216 - val_accuracy: 0.6500 - val_auc: 0.8069\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6227 - accuracy: 0.4734 - auc: 0.7349 - val_loss: 1.4315 - val_accuracy: 0.6844 - val_auc: 0.8263\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6791 - accuracy: 0.4711 - auc: 0.7301 - val_loss: 1.6998 - val_accuracy: 0.6493 - val_auc: 0.8114\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5799 - accuracy: 0.4530 - auc: 0.7199 - val_loss: 1.5008 - val_accuracy: 0.6349 - val_auc: 0.8009\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5633 - accuracy: 0.4546 - auc: 0.7316 - val_loss: 1.3254 - val_accuracy: 0.6462 - val_auc: 0.8116\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5673 - accuracy: 0.4581 - auc: 0.7216 - val_loss: 1.3733 - val_accuracy: 0.6176 - val_auc: 0.8008\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5329 - accuracy: 0.4569 - auc: 0.7257 - val_loss: 1.5202 - val_accuracy: 0.6319 - val_auc: 0.8052\n",
      "Epoch 21/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.4622 - auc: 0.7299Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5137 - accuracy: 0.4621 - auc: 0.7304 - val_loss: 1.4128 - val_accuracy: 0.6223 - val_auc: 0.8023\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 1.2553 - accuracy: 0.7941 - auc: 0.7400 - val_loss: 1.3287 - val_accuracy: 0.9374 - val_auc: 0.6685\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 1.2967 - accuracy: 0.8639 - auc: 0.7891 - val_loss: 0.7091 - val_accuracy: 0.8806 - val_auc: 0.9056\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.7973 - accuracy: 0.7355 - auc: 0.7588 - val_loss: 0.5448 - val_accuracy: 0.6153 - val_auc: 0.9139\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 1.0994 - accuracy: 0.6880 - auc: 0.7868 - val_loss: 0.5712 - val_accuracy: 0.9215 - val_auc: 0.9260\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.9631 - accuracy: 0.4870 - auc: 0.7206 - val_loss: 0.9744 - val_accuracy: 0.9507 - val_auc: 0.8276\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9279 - accuracy: 0.4506 - auc: 0.7061 - val_loss: 1.0941 - val_accuracy: 0.5272 - val_auc: 0.7468\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9631 - accuracy: 0.4092 - auc: 0.6859 - val_loss: 1.1795 - val_accuracy: 0.6040 - val_auc: 0.7899\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7023 - accuracy: 0.4626 - auc: 0.7062 - val_loss: 0.8766 - val_accuracy: 0.6059 - val_auc: 0.7983\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5518 - accuracy: 0.4685 - auc: 0.7338 - val_loss: 1.1535 - val_accuracy: 0.6391 - val_auc: 0.8133\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5841 - accuracy: 0.4692 - auc: 0.7378 - val_loss: 1.0776 - val_accuracy: 0.6369 - val_auc: 0.8097\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6516 - accuracy: 0.4844 - auc: 0.7250 - val_loss: 0.7898 - val_accuracy: 0.6729 - val_auc: 0.8252\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7290 - accuracy: 0.4627 - auc: 0.7280 - val_loss: 1.4067 - val_accuracy: 0.6483 - val_auc: 0.8092\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5541 - accuracy: 0.4905 - auc: 0.7316 - val_loss: 1.2575 - val_accuracy: 0.6531 - val_auc: 0.8079\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5542 - accuracy: 0.4734 - auc: 0.7350 - val_loss: 1.4838 - val_accuracy: 0.6224 - val_auc: 0.7987\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5410 - accuracy: 0.4591 - auc: 0.7247 - val_loss: 1.2402 - val_accuracy: 0.6124 - val_auc: 0.7983\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6246 - accuracy: 0.4734 - auc: 0.7265 - val_loss: 0.9858 - val_accuracy: 0.6354 - val_auc: 0.8091\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5322 - accuracy: 0.4680 - auc: 0.7268 - val_loss: 1.8369 - val_accuracy: 0.6400 - val_auc: 0.8090\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6232 - accuracy: 0.4581 - auc: 0.7201 - val_loss: 2.3455 - val_accuracy: 0.6028 - val_auc: 0.7925\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5563 - accuracy: 0.4501 - auc: 0.7224 - val_loss: 2.3001 - val_accuracy: 0.6283 - val_auc: 0.8033\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5831 - accuracy: 0.4629 - auc: 0.7194 - val_loss: 1.3582 - val_accuracy: 0.6041 - val_auc: 0.7919\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5698 - accuracy: 0.4659 - auc: 0.7296 - val_loss: 0.8517 - val_accuracy: 0.5772 - val_auc: 0.7969\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5636 - accuracy: 0.4833 - auc: 0.7290 - val_loss: 2.5120 - val_accuracy: 0.6316 - val_auc: 0.8022\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6905 - accuracy: 0.4806 - auc: 0.7266 - val_loss: 2.6573 - val_accuracy: 0.5986 - val_auc: 0.7866\n",
      "Epoch 24/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.4622 - auc: 0.7303Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7279 - accuracy: 0.4601 - auc: 0.7285 - val_loss: 1.4764 - val_accuracy: 0.5592 - val_auc: 0.7511\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 22us/sample - loss: 1.2183 - accuracy: 0.8102 - auc: 0.7633 - val_loss: 1.2403 - val_accuracy: 0.9481 - val_auc: 0.8844\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.0566 - accuracy: 0.8764 - auc: 0.7619 - val_loss: 0.6231 - val_accuracy: 0.7180 - val_auc: 0.8641\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9333 - accuracy: 0.8837 - auc: 0.8163 - val_loss: 0.6509 - val_accuracy: 0.9536 - val_auc: 0.9308\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.4583 - accuracy: 0.8248 - auc: 0.7722 - val_loss: 1.0131 - val_accuracy: 0.8614 - val_auc: 0.9032\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7939 - accuracy: 0.5706 - auc: 0.7718 - val_loss: 0.6790 - val_accuracy: 0.5453 - val_auc: 0.9026\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7249 - accuracy: 0.8833 - auc: 0.8239 - val_loss: 0.6480 - val_accuracy: 0.9405 - val_auc: 0.9233\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7207 - accuracy: 0.6935 - auc: 0.7641 - val_loss: 0.7186 - val_accuracy: 0.9365 - val_auc: 0.8726\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8358 - accuracy: 0.6640 - auc: 0.7567 - val_loss: 0.6176 - val_accuracy: 0.9472 - val_auc: 0.8805\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5800 - accuracy: 0.6737 - auc: 0.7865 - val_loss: 0.5225 - val_accuracy: 0.4734 - val_auc: 0.8888\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5571 - accuracy: 0.5595 - auc: 0.7785 - val_loss: 0.5558 - val_accuracy: 0.5423 - val_auc: 0.8150\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5875 - accuracy: 0.4185 - auc: 0.7581 - val_loss: 0.7906 - val_accuracy: 0.5738 - val_auc: 0.8148\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5823 - accuracy: 0.4331 - auc: 0.7547 - val_loss: 0.9976 - val_accuracy: 0.5761 - val_auc: 0.8241\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2814 - accuracy: 0.3942 - auc: 0.7292 - val_loss: 1.4744 - val_accuracy: 0.5097 - val_auc: 0.8006\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7841 - accuracy: 0.4501 - auc: 0.7392 - val_loss: 1.0195 - val_accuracy: 0.4942 - val_auc: 0.7581\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8107 - accuracy: 0.3956 - auc: 0.7009 - val_loss: 1.7693 - val_accuracy: 0.5301 - val_auc: 0.7615\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7778 - accuracy: 0.3804 - auc: 0.6943 - val_loss: 1.6947 - val_accuracy: 0.5206 - val_auc: 0.7635\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6908 - accuracy: 0.3797 - auc: 0.6842 - val_loss: 1.3336 - val_accuracy: 0.5166 - val_auc: 0.7529\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5357 - accuracy: 0.3962 - auc: 0.7063 - val_loss: 1.1542 - val_accuracy: 0.5301 - val_auc: 0.7900\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5423 - accuracy: 0.4025 - auc: 0.7207 - val_loss: 0.9418 - val_accuracy: 0.5417 - val_auc: 0.8116\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5357 - accuracy: 0.4165 - auc: 0.7296 - val_loss: 1.4835 - val_accuracy: 0.5613 - val_auc: 0.7679\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5579 - accuracy: 0.4224 - auc: 0.7116 - val_loss: 1.4558 - val_accuracy: 0.5677 - val_auc: 0.7877\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6276 - accuracy: 0.4061 - auc: 0.6974 - val_loss: 1.2480 - val_accuracy: 0.5326 - val_auc: 0.7610\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.5578 - accuracy: 0.4067 - auc: 0.6984Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5566 - accuracy: 0.4069 - auc: 0.6988 - val_loss: 1.2506 - val_accuracy: 0.5461 - val_auc: 0.7697\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 1.4603 - accuracy: 0.7660 - auc: 0.7524 - val_loss: 1.4064 - val_accuracy: 0.5886 - val_auc: 0.7508\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2020 - accuracy: 0.8507 - auc: 0.8250 - val_loss: 0.6553 - val_accuracy: 0.8415 - val_auc: 0.9091\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9207 - accuracy: 0.8972 - auc: 0.8024 - val_loss: 0.7434 - val_accuracy: 0.9292 - val_auc: 0.9076\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.9004 - accuracy: 0.7477 - auc: 0.8013 - val_loss: 1.4582 - val_accuracy: 0.5539 - val_auc: 0.9238\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 1.2091 - accuracy: 0.6930 - auc: 0.7542 - val_loss: 0.9872 - val_accuracy: 0.5497 - val_auc: 0.9310\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7818 - accuracy: 0.7955 - auc: 0.7812 - val_loss: 0.9793 - val_accuracy: 0.3717 - val_auc: 0.8533\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6613 - accuracy: 0.3798 - auc: 0.6816 - val_loss: 0.6742 - val_accuracy: 0.5350 - val_auc: 0.8176\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.7330 - accuracy: 0.3914 - auc: 0.6964 - val_loss: 0.8682 - val_accuracy: 0.5408 - val_auc: 0.7611\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9006 - accuracy: 0.3700 - auc: 0.6848 - val_loss: 0.9531 - val_accuracy: 0.5895 - val_auc: 0.7649\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7002 - accuracy: 0.3768 - auc: 0.6824 - val_loss: 0.9346 - val_accuracy: 0.5821 - val_auc: 0.7654\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5594 - accuracy: 0.3819 - auc: 0.6888 - val_loss: 0.8407 - val_accuracy: 0.5863 - val_auc: 0.7814\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6063 - accuracy: 0.3940 - auc: 0.6848 - val_loss: 0.7575 - val_accuracy: 0.6022 - val_auc: 0.7825\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5606 - accuracy: 0.4300 - auc: 0.7143 - val_loss: 0.7079 - val_accuracy: 0.6156 - val_auc: 0.7965\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6262 - accuracy: 0.4468 - auc: 0.7176 - val_loss: 0.7303 - val_accuracy: 0.6197 - val_auc: 0.8063\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5424 - accuracy: 0.4540 - auc: 0.7233 - val_loss: 0.7498 - val_accuracy: 0.6538 - val_auc: 0.8119\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6153 - accuracy: 0.4809 - auc: 0.7302 - val_loss: 1.3022 - val_accuracy: 0.7032 - val_auc: 0.8251\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6818 - accuracy: 0.4387 - auc: 0.7241 - val_loss: 1.4399 - val_accuracy: 0.6298 - val_auc: 0.7970\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5667 - accuracy: 0.4249 - auc: 0.7176 - val_loss: 1.1470 - val_accuracy: 0.6454 - val_auc: 0.8065\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5862 - accuracy: 0.4305 - auc: 0.7090 - val_loss: 1.0203 - val_accuracy: 0.6694 - val_auc: 0.8153\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7440 - accuracy: 0.4346 - auc: 0.7137 - val_loss: 0.9992 - val_accuracy: 0.6086 - val_auc: 0.7952\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5387 - accuracy: 0.4316 - auc: 0.7152 - val_loss: 1.6404 - val_accuracy: 0.6442 - val_auc: 0.8044\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6215 - accuracy: 0.4413 - auc: 0.7215 - val_loss: 0.9586 - val_accuracy: 0.6425 - val_auc: 0.8080\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5436 - accuracy: 0.4690 - auc: 0.7241 - val_loss: 1.1675 - val_accuracy: 0.6766 - val_auc: 0.8187\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5623 - accuracy: 0.4651 - auc: 0.7269 - val_loss: 1.2621 - val_accuracy: 0.6778 - val_auc: 0.8216\n",
      "Epoch 25/100\n",
      "248832/250291 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.4732 - auc: 0.7279Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5237 - accuracy: 0.4731 - auc: 0.7279 - val_loss: 2.9271 - val_accuracy: 0.6649 - val_auc: 0.8098\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 2.2737 - accuracy: 0.7170 - auc: 0.7649 - val_loss: 1.7298 - val_accuracy: 0.7979 - val_auc: 0.8840\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.1755 - accuracy: 0.8233 - auc: 0.8225 - val_loss: 2.3847 - val_accuracy: 0.8112 - val_auc: 0.8774\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.6441 - accuracy: 0.8430 - auc: 0.7794 - val_loss: 3.3268 - val_accuracy: 0.9077 - val_auc: 0.9061\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6556 - accuracy: 0.6252 - auc: 0.7663 - val_loss: 3.1123 - val_accuracy: 0.9464 - val_auc: 0.8753\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.3438 - accuracy: 0.6449 - auc: 0.7490 - val_loss: 2.1604 - val_accuracy: 0.5921 - val_auc: 0.8960\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8252 - accuracy: 0.5985 - auc: 0.8064 - val_loss: 1.4358 - val_accuracy: 0.3898 - val_auc: 0.7289\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.3379 - accuracy: 0.4701 - auc: 0.7481 - val_loss: 2.2291 - val_accuracy: 0.6234 - val_auc: 0.8750\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 5.2094 - accuracy: 0.5195 - auc: 0.7484 - val_loss: 3.4769 - val_accuracy: 0.5508 - val_auc: 0.8183\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.4260 - accuracy: 0.4462 - auc: 0.7173 - val_loss: 3.4318 - val_accuracy: 0.4806 - val_auc: 0.8022\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8682 - accuracy: 0.5452 - auc: 0.7276 - val_loss: 3.3453 - val_accuracy: 0.4317 - val_auc: 0.7994\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.2664 - accuracy: 0.4700 - auc: 0.7121 - val_loss: 1.8361 - val_accuracy: 0.9581 - val_auc: 0.8150\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.6174 - accuracy: 0.6687 - auc: 0.7311 - val_loss: 2.3225 - val_accuracy: 0.4586 - val_auc: 0.8080\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.3829 - accuracy: 0.3158 - auc: 0.6899 - val_loss: 3.2855 - val_accuracy: 0.4871 - val_auc: 0.7788\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.5046 - accuracy: 0.3393 - auc: 0.7012 - val_loss: 3.4587 - val_accuracy: 0.5569 - val_auc: 0.7903\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.9288 - accuracy: 0.4113 - auc: 0.7045 - val_loss: 2.5497 - val_accuracy: 0.5822 - val_auc: 0.8200\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0586 - accuracy: 0.4520 - auc: 0.7693 - val_loss: 2.8300 - val_accuracy: 0.5800 - val_auc: 0.8909\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8349 - accuracy: 0.5168 - auc: 0.7671 - val_loss: 3.0390 - val_accuracy: 0.5779 - val_auc: 0.8986\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9757 - accuracy: 0.4597 - auc: 0.7664 - val_loss: 1.8724 - val_accuracy: 0.5836 - val_auc: 0.8175\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6720 - accuracy: 0.4277 - auc: 0.7557 - val_loss: 1.7642 - val_accuracy: 0.6222 - val_auc: 0.8494\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5602 - accuracy: 0.4236 - auc: 0.7635 - val_loss: 1.8673 - val_accuracy: 0.6134 - val_auc: 0.8600\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7569 - accuracy: 0.4421 - auc: 0.7365 - val_loss: 2.5183 - val_accuracy: 0.6230 - val_auc: 0.8036\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8726 - accuracy: 0.4430 - auc: 0.7402 - val_loss: 3.0229 - val_accuracy: 0.6222 - val_auc: 0.8089\n",
      "Epoch 23/100\n",
      "244736/250290 [============================>.] - ETA: 0s - loss: 0.7236 - accuracy: 0.4571 - auc: 0.7375Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7266 - accuracy: 0.4565 - auc: 0.7387 - val_loss: 3.2065 - val_accuracy: 0.6182 - val_auc: 0.8413\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 2.4506 - accuracy: 0.7084 - auc: 0.7607 - val_loss: 1.9681 - val_accuracy: 0.7249 - val_auc: 0.8812\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.4069 - accuracy: 0.8047 - auc: 0.7794 - val_loss: 2.8166 - val_accuracy: 0.5140 - val_auc: 0.6670\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.8804 - accuracy: 0.8103 - auc: 0.7563 - val_loss: 2.0852 - val_accuracy: 0.8523 - val_auc: 0.8631\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0580 - accuracy: 0.8827 - auc: 0.7885 - val_loss: 3.1081 - val_accuracy: 0.9514 - val_auc: 0.8679\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2154 - accuracy: 0.4986 - auc: 0.7194 - val_loss: 1.9594 - val_accuracy: 0.3210 - val_auc: 0.6830\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.6519 - accuracy: 0.5765 - auc: 0.6850 - val_loss: 1.7204 - val_accuracy: 0.9611 - val_auc: 0.7368\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9376 - accuracy: 0.5024 - auc: 0.7256 - val_loss: 1.3880 - val_accuracy: 0.5405 - val_auc: 0.8417\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6204 - accuracy: 0.5196 - auc: 0.7620 - val_loss: 1.1775 - val_accuracy: 0.5651 - val_auc: 0.8640\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8679 - accuracy: 0.6111 - auc: 0.7609 - val_loss: 2.1730 - val_accuracy: 0.4817 - val_auc: 0.8056\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9884 - accuracy: 0.3525 - auc: 0.6812 - val_loss: 2.0569 - val_accuracy: 0.5240 - val_auc: 0.7506\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0005 - accuracy: 0.3420 - auc: 0.6785 - val_loss: 2.0493 - val_accuracy: 0.5610 - val_auc: 0.8106\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4793 - accuracy: 0.3714 - auc: 0.6765 - val_loss: 1.9875 - val_accuracy: 0.4946 - val_auc: 0.7825\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8236 - accuracy: 0.3910 - auc: 0.6936 - val_loss: 2.1600 - val_accuracy: 0.4995 - val_auc: 0.7364\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6716 - accuracy: 0.3431 - auc: 0.6671 - val_loss: 2.0242 - val_accuracy: 0.5376 - val_auc: 0.7554\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9269 - accuracy: 0.3424 - auc: 0.6597 - val_loss: 2.8708 - val_accuracy: 0.5381 - val_auc: 0.7614\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6762 - accuracy: 0.3501 - auc: 0.6818 - val_loss: 2.9162 - val_accuracy: 0.5450 - val_auc: 0.7611\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7377 - accuracy: 0.3725 - auc: 0.6785 - val_loss: 2.9946 - val_accuracy: 0.5585 - val_auc: 0.7646\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.8038 - accuracy: 0.4094 - auc: 0.6644 - val_loss: 3.2361 - val_accuracy: 0.5342 - val_auc: 0.7607\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8010 - accuracy: 0.3354 - auc: 0.6562 - val_loss: 3.1073 - val_accuracy: 0.4894 - val_auc: 0.7339\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6282 - accuracy: 0.3536 - auc: 0.6734 - val_loss: 3.2277 - val_accuracy: 0.5169 - val_auc: 0.7539\n",
      "Epoch 21/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.5844 - accuracy: 0.3505 - auc: 0.6740Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5845 - accuracy: 0.3508 - auc: 0.6741 - val_loss: 3.1303 - val_accuracy: 0.5341 - val_auc: 0.7618\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 2.8242 - accuracy: 0.6961 - auc: 0.7465 - val_loss: 1.5404 - val_accuracy: 0.7087 - val_auc: 0.8628\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.5946 - accuracy: 0.8000 - auc: 0.7831 - val_loss: 2.3631 - val_accuracy: 0.8591 - val_auc: 0.8827\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.0392 - accuracy: 0.8456 - auc: 0.7987 - val_loss: 3.4070 - val_accuracy: 0.8738 - val_auc: 0.8455\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 2.9270 - accuracy: 0.7949 - auc: 0.7879 - val_loss: 2.4395 - val_accuracy: 0.9085 - val_auc: 0.8919\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 3.3689 - accuracy: 0.7221 - auc: 0.7629 - val_loss: 2.0621 - val_accuracy: 0.9196 - val_auc: 0.8680\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.7224 - accuracy: 0.5352 - auc: 0.7282 - val_loss: 1.7315 - val_accuracy: 0.5410 - val_auc: 0.8603\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4765 - accuracy: 0.4569 - auc: 0.7528 - val_loss: 1.7155 - val_accuracy: 0.6547 - val_auc: 0.8341\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9868 - accuracy: 0.4785 - auc: 0.7410 - val_loss: 1.7125 - val_accuracy: 0.5893 - val_auc: 0.8393\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7723 - accuracy: 0.4780 - auc: 0.7595 - val_loss: 2.0717 - val_accuracy: 0.5892 - val_auc: 0.8347\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.4870 - accuracy: 0.5053 - auc: 0.7650 - val_loss: 2.3843 - val_accuracy: 0.6189 - val_auc: 0.8572\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6519 - accuracy: 0.4909 - auc: 0.7821 - val_loss: 2.1077 - val_accuracy: 0.6241 - val_auc: 0.8737\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7013 - accuracy: 0.4877 - auc: 0.7639 - val_loss: 2.0454 - val_accuracy: 0.6027 - val_auc: 0.7928\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.6851 - accuracy: 0.4295 - auc: 0.6973 - val_loss: 5.2032 - val_accuracy: 0.5609 - val_auc: 0.7693\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 3.2700 - accuracy: 0.4057 - auc: 0.6674 - val_loss: 5.1241 - val_accuracy: 0.5331 - val_auc: 0.7473\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.2775 - accuracy: 0.3886 - auc: 0.6836 - val_loss: 3.8184 - val_accuracy: 0.5206 - val_auc: 0.7461\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9344 - accuracy: 0.3891 - auc: 0.6933 - val_loss: 3.1512 - val_accuracy: 0.5206 - val_auc: 0.7504\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.8028 - accuracy: 0.4042 - auc: 0.6945 - val_loss: 3.7064 - val_accuracy: 0.5904 - val_auc: 0.7773\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6483 - accuracy: 0.4177 - auc: 0.7176 - val_loss: 3.3560 - val_accuracy: 0.5495 - val_auc: 0.8098\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9097 - accuracy: 0.4018 - auc: 0.7269 - val_loss: 5.3294 - val_accuracy: 0.5359 - val_auc: 0.7537\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.6331 - accuracy: 0.4197 - auc: 0.6986 - val_loss: 5.3802 - val_accuracy: 0.5480 - val_auc: 0.7641\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5652 - accuracy: 0.4189 - auc: 0.7112 - val_loss: 5.2589 - val_accuracy: 0.5629 - val_auc: 0.7676\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.7035 - accuracy: 0.4298 - auc: 0.7101 - val_loss: 4.2601 - val_accuracy: 0.5517 - val_auc: 0.7607\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 1.0893 - accuracy: 0.4403 - auc: 0.7036 - val_loss: 4.2987 - val_accuracy: 0.5873 - val_auc: 0.7686\n",
      "Epoch 24/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.9625 - accuracy: 0.4182 - auc: 0.7116Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.9588 - accuracy: 0.4184 - auc: 0.7109 - val_loss: 6.3916 - val_accuracy: 0.5694 - val_auc: 0.7654\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 2.5126 - accuracy: 0.7341 - auc: 0.7818 - val_loss: 2.1921 - val_accuracy: 0.5693 - val_auc: 0.7966\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.1447 - accuracy: 0.7879 - auc: 0.7857 - val_loss: 2.5644 - val_accuracy: 0.8558 - val_auc: 0.8935\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.1816 - accuracy: 0.8588 - auc: 0.8328 - val_loss: 1.7912 - val_accuracy: 0.9507 - val_auc: 0.8979\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.7114 - accuracy: 0.8645 - auc: 0.8136 - val_loss: 1.1976 - val_accuracy: 0.8919 - val_auc: 0.9044\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.5694 - accuracy: 0.8608 - auc: 0.7871 - val_loss: 1.0678 - val_accuracy: 0.8878 - val_auc: 0.8670\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.0893 - accuracy: 0.8437 - auc: 0.7716 - val_loss: 0.6509 - val_accuracy: 0.4798 - val_auc: 0.8971\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8868 - accuracy: 0.4434 - auc: 0.7477 - val_loss: 0.7803 - val_accuracy: 0.5174 - val_auc: 0.8079\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9396 - accuracy: 0.4214 - auc: 0.7417 - val_loss: 0.7961 - val_accuracy: 0.5607 - val_auc: 0.8128\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.0782 - accuracy: 0.4747 - auc: 0.7499 - val_loss: 1.6566 - val_accuracy: 0.5595 - val_auc: 0.8229\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9537 - accuracy: 0.4630 - auc: 0.7379 - val_loss: 1.1312 - val_accuracy: 0.5492 - val_auc: 0.8401\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7198 - accuracy: 0.4585 - auc: 0.7661 - val_loss: 1.2960 - val_accuracy: 0.9532 - val_auc: 0.9042\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.3410 - accuracy: 0.5285 - auc: 0.7882 - val_loss: 1.5654 - val_accuracy: 0.8994 - val_auc: 0.8182\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9654 - accuracy: 0.5714 - auc: 0.7869 - val_loss: 0.9578 - val_accuracy: 0.5485 - val_auc: 0.8672\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8862 - accuracy: 0.4401 - auc: 0.7622 - val_loss: 1.4122 - val_accuracy: 0.4910 - val_auc: 0.7947\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1142 - accuracy: 0.4900 - auc: 0.7801 - val_loss: 2.5200 - val_accuracy: 0.5720 - val_auc: 0.8868\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7847 - accuracy: 0.5694 - auc: 0.8053 - val_loss: 2.4307 - val_accuracy: 0.5696 - val_auc: 0.8599\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7236 - accuracy: 0.4365 - auc: 0.7686 - val_loss: 2.3031 - val_accuracy: 0.5503 - val_auc: 0.8106\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1838 - accuracy: 0.4393 - auc: 0.7523 - val_loss: 2.9484 - val_accuracy: 0.5626 - val_auc: 0.8169\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7281 - accuracy: 0.4213 - auc: 0.7383 - val_loss: 1.9643 - val_accuracy: 0.5335 - val_auc: 0.8145\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7853 - accuracy: 0.4134 - auc: 0.7275 - val_loss: 1.8572 - val_accuracy: 0.5158 - val_auc: 0.7546\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7903 - accuracy: 0.4353 - auc: 0.7340 - val_loss: 3.1651 - val_accuracy: 0.5691 - val_auc: 0.8037\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7344 - accuracy: 0.4437 - auc: 0.7437 - val_loss: 2.3013 - val_accuracy: 0.5613 - val_auc: 0.8022\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.0224 - accuracy: 0.4328 - auc: 0.7378 - val_loss: 5.0958 - val_accuracy: 0.5354 - val_auc: 0.7950\n",
      "Epoch 24/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.9010 - accuracy: 0.4125 - auc: 0.7306Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8944 - accuracy: 0.4122 - auc: 0.7304 - val_loss: 4.3927 - val_accuracy: 0.5137 - val_auc: 0.7623\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 3.2732 - accuracy: 0.7139 - auc: 0.7700 - val_loss: 1.6288 - val_accuracy: 0.7745 - val_auc: 0.8851\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 3.3371 - accuracy: 0.7968 - auc: 0.7999 - val_loss: 1.2068 - val_accuracy: 0.8257 - val_auc: 0.9187\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.7866 - accuracy: 0.8246 - auc: 0.8209 - val_loss: 2.5299 - val_accuracy: 0.5758 - val_auc: 0.7554\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.1823 - accuracy: 0.8513 - auc: 0.7749 - val_loss: 1.4502 - val_accuracy: 0.9248 - val_auc: 0.9064\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.9634 - accuracy: 0.8014 - auc: 0.7974 - val_loss: 2.5181 - val_accuracy: 0.9004 - val_auc: 0.8812\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.6837 - accuracy: 0.6619 - auc: 0.7688 - val_loss: 1.6671 - val_accuracy: 0.9371 - val_auc: 0.8726\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.8205 - accuracy: 0.7000 - auc: 0.7760 - val_loss: 2.2943 - val_accuracy: 0.9302 - val_auc: 0.8827\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 2.9782 - accuracy: 0.8608 - auc: 0.7846 - val_loss: 1.7172 - val_accuracy: 0.4633 - val_auc: 0.9248\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.1311 - accuracy: 0.7834 - auc: 0.8032 - val_loss: 1.5315 - val_accuracy: 0.4900 - val_auc: 0.8813\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9152 - accuracy: 0.4631 - auc: 0.7210 - val_loss: 1.3806 - val_accuracy: 0.5090 - val_auc: 0.7850\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.4395 - accuracy: 0.4764 - auc: 0.7258 - val_loss: 1.6280 - val_accuracy: 0.5142 - val_auc: 0.8497\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.9137 - accuracy: 0.4311 - auc: 0.7204 - val_loss: 2.6917 - val_accuracy: 0.5026 - val_auc: 0.7767\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7942 - accuracy: 0.3914 - auc: 0.7391 - val_loss: 2.4744 - val_accuracy: 0.5209 - val_auc: 0.8683\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.5209 - accuracy: 0.4785 - auc: 0.7669 - val_loss: 3.9082 - val_accuracy: 0.5072 - val_auc: 0.8513\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2037 - accuracy: 0.6664 - auc: 0.7673 - val_loss: 4.8349 - val_accuracy: 0.4845 - val_auc: 0.8673\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 1.2758 - accuracy: 0.4290 - auc: 0.6931 - val_loss: 5.0735 - val_accuracy: 0.4682 - val_auc: 0.7174\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7757 - accuracy: 0.3320 - auc: 0.6603 - val_loss: 6.1104 - val_accuracy: 0.4795 - val_auc: 0.7220\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7386 - accuracy: 0.3401 - auc: 0.6678 - val_loss: 6.2480 - val_accuracy: 0.5228 - val_auc: 0.7380\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7825 - accuracy: 0.3531 - auc: 0.6663 - val_loss: 6.4258 - val_accuracy: 0.5100 - val_auc: 0.7325\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8678 - accuracy: 0.3452 - auc: 0.6625 - val_loss: 6.4240 - val_accuracy: 0.5189 - val_auc: 0.7348\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6400 - accuracy: 0.3487 - auc: 0.6724 - val_loss: 6.5179 - val_accuracy: 0.5333 - val_auc: 0.7415\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6099 - accuracy: 0.3597 - auc: 0.6824 - val_loss: 6.3578 - val_accuracy: 0.5515 - val_auc: 0.7499\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6147 - accuracy: 0.3728 - auc: 0.6825 - val_loss: 6.2123 - val_accuracy: 0.5437 - val_auc: 0.7442\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8268 - accuracy: 0.3347 - auc: 0.6632 - val_loss: 4.1597 - val_accuracy: 0.4755 - val_auc: 0.7208\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6927 - accuracy: 0.3062 - auc: 0.6463 - val_loss: 5.9351 - val_accuracy: 0.4587 - val_auc: 0.7116\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.7193 - accuracy: 0.2978 - auc: 0.6511 - val_loss: 3.3134 - val_accuracy: 0.4381 - val_auc: 0.7099\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.8646 - accuracy: 0.3186 - auc: 0.6344 - val_loss: 6.0138 - val_accuracy: 0.4552 - val_auc: 0.7157\n",
      "Epoch 28/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.6414 - accuracy: 0.3065 - auc: 0.6460Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.6411 - accuracy: 0.3064 - auc: 0.6462 - val_loss: 5.1341 - val_accuracy: 0.4561 - val_auc: 0.7173\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 0.5614 - accuracy: 0.6265 - auc: 0.8220 - val_loss: 0.3101 - val_accuracy: 0.8397 - val_auc: 0.9455\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4040 - accuracy: 0.7197 - auc: 0.8933 - val_loss: 0.3025 - val_accuracy: 0.8631 - val_auc: 0.9507\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4049 - accuracy: 0.7351 - auc: 0.8935 - val_loss: 0.2806 - val_accuracy: 0.8413 - val_auc: 0.9554\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3544 - accuracy: 0.7595 - auc: 0.9115 - val_loss: 0.2870 - val_accuracy: 0.8656 - val_auc: 0.9556\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3717 - accuracy: 0.7560 - auc: 0.9052 - val_loss: 0.2971 - val_accuracy: 0.8520 - val_auc: 0.9538\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3636 - accuracy: 0.7629 - auc: 0.9110 - val_loss: 0.2979 - val_accuracy: 0.8794 - val_auc: 0.9528\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3511 - accuracy: 0.7752 - auc: 0.9158 - val_loss: 0.2833 - val_accuracy: 0.8645 - val_auc: 0.9569\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3322 - accuracy: 0.7835 - auc: 0.9203 - val_loss: 0.2902 - val_accuracy: 0.8811 - val_auc: 0.9570\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3370 - accuracy: 0.7775 - auc: 0.9234 - val_loss: 0.2831 - val_accuracy: 0.8876 - val_auc: 0.9574\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3363 - accuracy: 0.7838 - auc: 0.9192 - val_loss: 0.3069 - val_accuracy: 0.8724 - val_auc: 0.9545\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3537 - accuracy: 0.7723 - auc: 0.9171 - val_loss: 0.2793 - val_accuracy: 0.8456 - val_auc: 0.9573\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3316 - accuracy: 0.7750 - auc: 0.9198 - val_loss: 0.2893 - val_accuracy: 0.8648 - val_auc: 0.9580\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3349 - accuracy: 0.7778 - auc: 0.9202 - val_loss: 0.2840 - val_accuracy: 0.8392 - val_auc: 0.9578\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3511 - accuracy: 0.7643 - auc: 0.9180 - val_loss: 0.2833 - val_accuracy: 0.8552 - val_auc: 0.9597\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3393 - accuracy: 0.7736 - auc: 0.9179 - val_loss: 0.2819 - val_accuracy: 0.8534 - val_auc: 0.9583\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3222 - accuracy: 0.7779 - auc: 0.9241 - val_loss: 0.2983 - val_accuracy: 0.8770 - val_auc: 0.9566\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3415 - accuracy: 0.7770 - auc: 0.9181 - val_loss: 0.2898 - val_accuracy: 0.8391 - val_auc: 0.9564\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3232 - accuracy: 0.7771 - auc: 0.9235 - val_loss: 0.2946 - val_accuracy: 0.8860 - val_auc: 0.9554\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3370 - accuracy: 0.7804 - auc: 0.9201 - val_loss: 0.2901 - val_accuracy: 0.8729 - val_auc: 0.9566\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3506 - accuracy: 0.7717 - auc: 0.9165 - val_loss: 0.2842 - val_accuracy: 0.8359 - val_auc: 0.9548\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3266 - accuracy: 0.7772 - auc: 0.9210 - val_loss: 0.3066 - val_accuracy: 0.8515 - val_auc: 0.9552\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3421 - accuracy: 0.7739 - auc: 0.9179 - val_loss: 0.2812 - val_accuracy: 0.8500 - val_auc: 0.9581\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3352 - accuracy: 0.7758 - auc: 0.9208 - val_loss: 0.2917 - val_accuracy: 0.8509 - val_auc: 0.9569\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3404 - accuracy: 0.7720 - auc: 0.9195 - val_loss: 0.2970 - val_accuracy: 0.8577 - val_auc: 0.9555\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3313 - accuracy: 0.7758 - auc: 0.9250 - val_loss: 0.2982 - val_accuracy: 0.8792 - val_auc: 0.9550\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3315 - accuracy: 0.7775 - auc: 0.9206 - val_loss: 0.2899 - val_accuracy: 0.8592 - val_auc: 0.9568\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3222 - accuracy: 0.7812 - auc: 0.9231 - val_loss: 0.3115 - val_accuracy: 0.8596 - val_auc: 0.9551\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3362 - accuracy: 0.7756 - auc: 0.9221 - val_loss: 0.3032 - val_accuracy: 0.8726 - val_auc: 0.9548\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3315 - accuracy: 0.7780 - auc: 0.9234 - val_loss: 0.3143 - val_accuracy: 0.8758 - val_auc: 0.9526\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3324 - accuracy: 0.7800 - auc: 0.9207 - val_loss: 0.2932 - val_accuracy: 0.8758 - val_auc: 0.9551\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3310 - accuracy: 0.7751 - auc: 0.9204 - val_loss: 0.3100 - val_accuracy: 0.8689 - val_auc: 0.9554\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3186 - accuracy: 0.7796 - auc: 0.9233 - val_loss: 0.3406 - val_accuracy: 0.8887 - val_auc: 0.9523\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3358 - accuracy: 0.7835 - auc: 0.9262 - val_loss: 0.3017 - val_accuracy: 0.8511 - val_auc: 0.9529\n",
      "Epoch 34/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3229 - accuracy: 0.7811 - auc: 0.9230Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3227 - accuracy: 0.7811 - auc: 0.9230 - val_loss: 0.3087 - val_accuracy: 0.8602 - val_auc: 0.9527\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.5869 - accuracy: 0.5984 - auc: 0.8054 - val_loss: 0.3479 - val_accuracy: 0.8258 - val_auc: 0.9443\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4617 - accuracy: 0.6866 - auc: 0.8704 - val_loss: 0.3154 - val_accuracy: 0.8195 - val_auc: 0.9535\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4020 - accuracy: 0.7133 - auc: 0.8916 - val_loss: 0.2908 - val_accuracy: 0.8367 - val_auc: 0.9557\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3697 - accuracy: 0.7316 - auc: 0.9031 - val_loss: 0.2896 - val_accuracy: 0.8740 - val_auc: 0.9555\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3660 - accuracy: 0.7427 - auc: 0.9062 - val_loss: 0.3224 - val_accuracy: 0.8697 - val_auc: 0.9477\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3628 - accuracy: 0.7552 - auc: 0.9116 - val_loss: 0.3105 - val_accuracy: 0.8584 - val_auc: 0.9509\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3423 - accuracy: 0.7689 - auc: 0.9172 - val_loss: 0.3196 - val_accuracy: 0.8690 - val_auc: 0.9491\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3400 - accuracy: 0.7683 - auc: 0.9151 - val_loss: 0.3364 - val_accuracy: 0.8537 - val_auc: 0.9461\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3524 - accuracy: 0.7581 - auc: 0.9126 - val_loss: 0.3171 - val_accuracy: 0.8502 - val_auc: 0.9491\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3419 - accuracy: 0.7625 - auc: 0.9202 - val_loss: 0.3383 - val_accuracy: 0.8954 - val_auc: 0.9478\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3392 - accuracy: 0.7683 - auc: 0.9154 - val_loss: 0.3576 - val_accuracy: 0.8657 - val_auc: 0.9461\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3357 - accuracy: 0.7656 - auc: 0.9197 - val_loss: 0.3379 - val_accuracy: 0.8726 - val_auc: 0.9487\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3284 - accuracy: 0.7689 - auc: 0.9191 - val_loss: 0.3429 - val_accuracy: 0.8589 - val_auc: 0.9484\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3405 - accuracy: 0.7650 - auc: 0.9144 - val_loss: 0.3364 - val_accuracy: 0.8479 - val_auc: 0.9512\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3383 - accuracy: 0.7672 - auc: 0.9195 - val_loss: 0.3391 - val_accuracy: 0.8487 - val_auc: 0.9482\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3395 - accuracy: 0.7665 - auc: 0.9185 - val_loss: 0.3415 - val_accuracy: 0.8627 - val_auc: 0.9497\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3355 - accuracy: 0.7687 - auc: 0.9176 - val_loss: 0.3460 - val_accuracy: 0.8528 - val_auc: 0.9477\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3431 - accuracy: 0.7617 - auc: 0.9168 - val_loss: 0.3475 - val_accuracy: 0.8456 - val_auc: 0.9490\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3268 - accuracy: 0.7633 - auc: 0.9212 - val_loss: 0.3549 - val_accuracy: 0.8791 - val_auc: 0.9493\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3243 - accuracy: 0.7714 - auc: 0.9215 - val_loss: 0.3560 - val_accuracy: 0.8718 - val_auc: 0.9484\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3334 - accuracy: 0.7726 - auc: 0.9181 - val_loss: 0.3462 - val_accuracy: 0.8273 - val_auc: 0.9459\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3241 - accuracy: 0.7705 - auc: 0.9236 - val_loss: 0.3630 - val_accuracy: 0.8721 - val_auc: 0.9486\n",
      "Epoch 23/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.7724 - auc: 0.9177Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3339 - accuracy: 0.7723 - auc: 0.9181 - val_loss: 0.3556 - val_accuracy: 0.8330 - val_auc: 0.9480\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 0.5238 - accuracy: 0.8792 - auc: 0.8097 - val_loss: 0.3325 - val_accuracy: 0.9000 - val_auc: 0.9470\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4272 - accuracy: 0.8936 - auc: 0.8785 - val_loss: 0.3005 - val_accuracy: 0.8907 - val_auc: 0.9556\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3902 - accuracy: 0.8986 - auc: 0.8954 - val_loss: 0.2802 - val_accuracy: 0.8937 - val_auc: 0.9585\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3933 - accuracy: 0.8831 - auc: 0.8966 - val_loss: 0.2725 - val_accuracy: 0.8774 - val_auc: 0.9573\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3723 - accuracy: 0.8798 - auc: 0.9054 - val_loss: 0.2851 - val_accuracy: 0.8595 - val_auc: 0.9568\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3558 - accuracy: 0.7150 - auc: 0.9123 - val_loss: 0.2824 - val_accuracy: 0.8673 - val_auc: 0.9561\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3574 - accuracy: 0.7038 - auc: 0.9093 - val_loss: 0.2883 - val_accuracy: 0.8424 - val_auc: 0.9556\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3584 - accuracy: 0.6939 - auc: 0.9131 - val_loss: 0.2700 - val_accuracy: 0.8545 - val_auc: 0.9580\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3372 - accuracy: 0.7050 - auc: 0.9182 - val_loss: 0.2827 - val_accuracy: 0.8548 - val_auc: 0.9561\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3496 - accuracy: 0.7003 - auc: 0.9143 - val_loss: 0.2869 - val_accuracy: 0.8469 - val_auc: 0.9559\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3389 - accuracy: 0.7025 - auc: 0.9181 - val_loss: 0.2893 - val_accuracy: 0.8518 - val_auc: 0.9573\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3413 - accuracy: 0.7016 - auc: 0.9157 - val_loss: 0.2859 - val_accuracy: 0.8431 - val_auc: 0.9577\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3406 - accuracy: 0.6953 - auc: 0.9155 - val_loss: 0.2866 - val_accuracy: 0.8485 - val_auc: 0.9570\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3291 - accuracy: 0.7066 - auc: 0.9212 - val_loss: 0.2890 - val_accuracy: 0.8353 - val_auc: 0.9555\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3322 - accuracy: 0.7052 - auc: 0.9219 - val_loss: 0.2881 - val_accuracy: 0.8575 - val_auc: 0.9569\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3383 - accuracy: 0.7069 - auc: 0.9153 - val_loss: 0.2972 - val_accuracy: 0.8654 - val_auc: 0.9533\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3314 - accuracy: 0.7074 - auc: 0.9184 - val_loss: 0.2978 - val_accuracy: 0.8514 - val_auc: 0.9546\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3208 - accuracy: 0.7124 - auc: 0.9275 - val_loss: 0.3222 - val_accuracy: 0.8659 - val_auc: 0.9496\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3341 - accuracy: 0.7133 - auc: 0.9210 - val_loss: 0.3178 - val_accuracy: 0.8380 - val_auc: 0.9513\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3300 - accuracy: 0.7022 - auc: 0.9229 - val_loss: 0.3039 - val_accuracy: 0.8601 - val_auc: 0.9529\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3224 - accuracy: 0.7105 - auc: 0.9256 - val_loss: 0.3091 - val_accuracy: 0.8626 - val_auc: 0.9535\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3336 - accuracy: 0.7067 - auc: 0.9212 - val_loss: 0.3191 - val_accuracy: 0.8498 - val_auc: 0.9519\n",
      "Epoch 23/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.7025 - auc: 0.9203Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3350 - accuracy: 0.7024 - auc: 0.9201 - val_loss: 0.3129 - val_accuracy: 0.8500 - val_auc: 0.9515\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.5885 - accuracy: 0.4391 - auc: 0.8386 - val_loss: 0.3455 - val_accuracy: 0.8918 - val_auc: 0.9469\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3859 - accuracy: 0.9016 - auc: 0.9132 - val_loss: 0.2965 - val_accuracy: 0.9171 - val_auc: 0.9520\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3757 - accuracy: 0.9157 - auc: 0.9110 - val_loss: 0.2822 - val_accuracy: 0.9211 - val_auc: 0.9567\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3610 - accuracy: 0.9146 - auc: 0.9169 - val_loss: 0.2848 - val_accuracy: 0.9274 - val_auc: 0.9560\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3500 - accuracy: 0.9203 - auc: 0.9218 - val_loss: 0.2827 - val_accuracy: 0.9130 - val_auc: 0.9533\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3488 - accuracy: 0.9183 - auc: 0.9187 - val_loss: 0.2765 - val_accuracy: 0.9295 - val_auc: 0.9560\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3574 - accuracy: 0.9214 - auc: 0.9187 - val_loss: 0.2725 - val_accuracy: 0.9206 - val_auc: 0.9566\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3570 - accuracy: 0.9181 - auc: 0.9190 - val_loss: 0.2850 - val_accuracy: 0.9301 - val_auc: 0.9552\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3438 - accuracy: 0.9229 - auc: 0.9298 - val_loss: 0.2731 - val_accuracy: 0.9067 - val_auc: 0.9577\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3532 - accuracy: 0.9227 - auc: 0.9175 - val_loss: 0.2813 - val_accuracy: 0.9170 - val_auc: 0.9539\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3494 - accuracy: 0.9216 - auc: 0.9231 - val_loss: 0.2889 - val_accuracy: 0.9174 - val_auc: 0.9519\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3463 - accuracy: 0.9244 - auc: 0.9261 - val_loss: 0.2835 - val_accuracy: 0.9220 - val_auc: 0.9533\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3359 - accuracy: 0.9277 - auc: 0.9311 - val_loss: 0.2753 - val_accuracy: 0.9216 - val_auc: 0.9552\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3302 - accuracy: 0.9278 - auc: 0.9335 - val_loss: 0.2775 - val_accuracy: 0.9268 - val_auc: 0.9559\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3382 - accuracy: 0.9258 - auc: 0.9273 - val_loss: 0.2821 - val_accuracy: 0.9174 - val_auc: 0.9545\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3501 - accuracy: 0.9256 - auc: 0.9199 - val_loss: 0.2806 - val_accuracy: 0.9272 - val_auc: 0.9557\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3457 - accuracy: 0.9272 - auc: 0.9217 - val_loss: 0.2900 - val_accuracy: 0.9240 - val_auc: 0.9518\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3430 - accuracy: 0.9278 - auc: 0.9226 - val_loss: 0.2859 - val_accuracy: 0.9275 - val_auc: 0.9527\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3427 - accuracy: 0.9301 - auc: 0.9288 - val_loss: 0.2970 - val_accuracy: 0.9306 - val_auc: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3313 - accuracy: 0.9288 - auc: 0.9288 - val_loss: 0.2924 - val_accuracy: 0.9198 - val_auc: 0.9523\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3446 - accuracy: 0.9316 - auc: 0.9256 - val_loss: 0.2899 - val_accuracy: 0.9243 - val_auc: 0.9530\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3427 - accuracy: 0.9288 - auc: 0.9254 - val_loss: 0.2945 - val_accuracy: 0.9177 - val_auc: 0.9529\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3407 - accuracy: 0.9300 - auc: 0.9260 - val_loss: 0.2841 - val_accuracy: 0.9303 - val_auc: 0.9543\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3424 - accuracy: 0.9286 - auc: 0.9297 - val_loss: 0.2900 - val_accuracy: 0.9280 - val_auc: 0.9528\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3331 - accuracy: 0.9278 - auc: 0.9309 - val_loss: 0.2983 - val_accuracy: 0.9409 - val_auc: 0.9527\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3290 - accuracy: 0.9355 - auc: 0.9259 - val_loss: 0.2994 - val_accuracy: 0.9181 - val_auc: 0.9530\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3552 - accuracy: 0.9293 - auc: 0.9163 - val_loss: 0.2967 - val_accuracy: 0.9307 - val_auc: 0.9541\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3423 - accuracy: 0.9305 - auc: 0.9232 - val_loss: 0.2938 - val_accuracy: 0.9349 - val_auc: 0.9542\n",
      "Epoch 29/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.9334 - auc: 0.9273Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3336 - accuracy: 0.9334 - auc: 0.9276 - val_loss: 0.3020 - val_accuracy: 0.9186 - val_auc: 0.9531\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.4873 - accuracy: 0.8379 - auc: 0.8549 - val_loss: 0.3062 - val_accuracy: 0.8963 - val_auc: 0.9541\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3937 - accuracy: 0.9096 - auc: 0.9071 - val_loss: 0.3096 - val_accuracy: 0.9118 - val_auc: 0.9556\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3750 - accuracy: 0.9179 - auc: 0.9128 - val_loss: 0.2897 - val_accuracy: 0.9311 - val_auc: 0.9567\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3698 - accuracy: 0.9162 - auc: 0.9143 - val_loss: 0.2905 - val_accuracy: 0.9300 - val_auc: 0.9561\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3441 - accuracy: 0.9178 - auc: 0.9323 - val_loss: 0.2751 - val_accuracy: 0.9234 - val_auc: 0.9557\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3566 - accuracy: 0.9153 - auc: 0.9246 - val_loss: 0.2914 - val_accuracy: 0.9377 - val_auc: 0.9557\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3392 - accuracy: 0.9205 - auc: 0.9302 - val_loss: 0.2760 - val_accuracy: 0.9105 - val_auc: 0.9571\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3467 - accuracy: 0.9191 - auc: 0.9314 - val_loss: 0.2778 - val_accuracy: 0.9208 - val_auc: 0.9566\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3400 - accuracy: 0.9218 - auc: 0.9281 - val_loss: 0.2845 - val_accuracy: 0.9148 - val_auc: 0.9542\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3299 - accuracy: 0.9208 - auc: 0.9362 - val_loss: 0.2867 - val_accuracy: 0.9191 - val_auc: 0.9541\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3494 - accuracy: 0.9242 - auc: 0.9266 - val_loss: 0.2928 - val_accuracy: 0.9004 - val_auc: 0.9539\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3459 - accuracy: 0.9192 - auc: 0.9263 - val_loss: 0.2913 - val_accuracy: 0.9287 - val_auc: 0.9527\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3382 - accuracy: 0.9223 - auc: 0.9308 - val_loss: 0.2949 - val_accuracy: 0.9132 - val_auc: 0.9529\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3415 - accuracy: 0.9231 - auc: 0.9305 - val_loss: 0.2966 - val_accuracy: 0.9172 - val_auc: 0.9513\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3465 - accuracy: 0.9230 - auc: 0.9247 - val_loss: 0.2922 - val_accuracy: 0.9039 - val_auc: 0.9534\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3472 - accuracy: 0.9222 - auc: 0.9223 - val_loss: 0.2933 - val_accuracy: 0.9122 - val_auc: 0.9534\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3330 - accuracy: 0.9222 - auc: 0.9320 - val_loss: 0.2952 - val_accuracy: 0.9279 - val_auc: 0.9545\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3266 - accuracy: 0.9271 - auc: 0.9353 - val_loss: 0.3016 - val_accuracy: 0.9166 - val_auc: 0.9518\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3306 - accuracy: 0.9253 - auc: 0.9345 - val_loss: 0.2901 - val_accuracy: 0.9282 - val_auc: 0.9555\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3426 - accuracy: 0.9251 - auc: 0.9248 - val_loss: 0.2916 - val_accuracy: 0.9255 - val_auc: 0.9554\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3421 - accuracy: 0.9269 - auc: 0.9291 - val_loss: 0.2973 - val_accuracy: 0.9242 - val_auc: 0.9527\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3266 - accuracy: 0.9281 - auc: 0.9344 - val_loss: 0.2944 - val_accuracy: 0.9292 - val_auc: 0.9529\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3407 - accuracy: 0.9274 - auc: 0.9290 - val_loss: 0.2971 - val_accuracy: 0.9277 - val_auc: 0.9519\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3398 - accuracy: 0.9265 - auc: 0.9284 - val_loss: 0.3020 - val_accuracy: 0.9307 - val_auc: 0.9515\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3262 - accuracy: 0.9287 - auc: 0.9346 - val_loss: 0.3051 - val_accuracy: 0.9186 - val_auc: 0.9508\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3377 - accuracy: 0.9283 - auc: 0.9279 - val_loss: 0.3145 - val_accuracy: 0.9296 - val_auc: 0.9498\n",
      "Epoch 27/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.3271 - accuracy: 0.9299 - auc: 0.9337Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3276 - accuracy: 0.9298 - auc: 0.9329 - val_loss: 0.3254 - val_accuracy: 0.9231 - val_auc: 0.9490\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.5452 - accuracy: 0.6625 - auc: 0.8622 - val_loss: 0.2992 - val_accuracy: 0.8653 - val_auc: 0.9474\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3854 - accuracy: 0.7875 - auc: 0.9260 - val_loss: 0.2776 - val_accuracy: 0.8848 - val_auc: 0.9537\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3396 - accuracy: 0.8362 - auc: 0.9353 - val_loss: 0.2784 - val_accuracy: 0.8815 - val_auc: 0.9531\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3186 - accuracy: 0.8445 - auc: 0.9412 - val_loss: 0.2744 - val_accuracy: 0.9025 - val_auc: 0.9572\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3159 - accuracy: 0.8758 - auc: 0.9442 - val_loss: 0.2694 - val_accuracy: 0.8957 - val_auc: 0.9567\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3074 - accuracy: 0.8661 - auc: 0.9465 - val_loss: 0.2594 - val_accuracy: 0.8791 - val_auc: 0.9596\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2985 - accuracy: 0.8638 - auc: 0.9488 - val_loss: 0.2650 - val_accuracy: 0.8948 - val_auc: 0.9581\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2939 - accuracy: 0.8598 - auc: 0.9496 - val_loss: 0.2791 - val_accuracy: 0.8996 - val_auc: 0.9574\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2945 - accuracy: 0.8224 - auc: 0.9487 - val_loss: 0.2868 - val_accuracy: 0.8792 - val_auc: 0.9531\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2735 - accuracy: 0.8292 - auc: 0.9559 - val_loss: 0.2841 - val_accuracy: 0.8814 - val_auc: 0.9539\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2831 - accuracy: 0.8233 - auc: 0.9521 - val_loss: 0.2928 - val_accuracy: 0.8762 - val_auc: 0.9524\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2814 - accuracy: 0.8198 - auc: 0.9542 - val_loss: 0.3004 - val_accuracy: 0.8877 - val_auc: 0.9539\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2808 - accuracy: 0.8227 - auc: 0.9525 - val_loss: 0.2868 - val_accuracy: 0.8706 - val_auc: 0.9541\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2777 - accuracy: 0.8243 - auc: 0.9537 - val_loss: 0.3108 - val_accuracy: 0.8896 - val_auc: 0.9538\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2820 - accuracy: 0.8224 - auc: 0.9542 - val_loss: 0.2900 - val_accuracy: 0.8900 - val_auc: 0.9538\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2698 - accuracy: 0.8241 - auc: 0.9572 - val_loss: 0.2988 - val_accuracy: 0.8888 - val_auc: 0.9522\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2708 - accuracy: 0.8264 - auc: 0.9568 - val_loss: 0.3152 - val_accuracy: 0.8959 - val_auc: 0.9521\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2648 - accuracy: 0.8285 - auc: 0.9576 - val_loss: 0.3062 - val_accuracy: 0.8850 - val_auc: 0.9524\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2717 - accuracy: 0.8221 - auc: 0.9561 - val_loss: 0.3100 - val_accuracy: 0.8886 - val_auc: 0.9520\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2632 - accuracy: 0.8237 - auc: 0.9586 - val_loss: 0.3189 - val_accuracy: 0.8859 - val_auc: 0.9494\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2704 - accuracy: 0.8159 - auc: 0.9564 - val_loss: 0.3475 - val_accuracy: 0.8961 - val_auc: 0.9470\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2534 - accuracy: 0.8264 - auc: 0.9610 - val_loss: 0.3345 - val_accuracy: 0.8926 - val_auc: 0.9501\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2686 - accuracy: 0.8177 - auc: 0.9574 - val_loss: 0.3308 - val_accuracy: 0.8913 - val_auc: 0.9505\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2681 - accuracy: 0.8148 - auc: 0.9577 - val_loss: 0.3316 - val_accuracy: 0.8907 - val_auc: 0.9506\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2655 - accuracy: 0.8166 - auc: 0.9577 - val_loss: 0.3175 - val_accuracy: 0.8866 - val_auc: 0.9544\n",
      "Epoch 26/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.8181 - auc: 0.9640Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2449 - accuracy: 0.8182 - auc: 0.9641 - val_loss: 0.3695 - val_accuracy: 0.8965 - val_auc: 0.9478\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.6431 - accuracy: 0.8526 - auc: 0.8430 - val_loss: 0.3437 - val_accuracy: 0.8869 - val_auc: 0.9397\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3687 - accuracy: 0.9065 - auc: 0.9228 - val_loss: 0.2856 - val_accuracy: 0.9096 - val_auc: 0.9543\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3625 - accuracy: 0.9078 - auc: 0.9275 - val_loss: 0.2877 - val_accuracy: 0.9339 - val_auc: 0.9519\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3359 - accuracy: 0.9171 - auc: 0.9397 - val_loss: 0.2768 - val_accuracy: 0.9141 - val_auc: 0.9544\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3419 - accuracy: 0.9095 - auc: 0.9351 - val_loss: 0.2830 - val_accuracy: 0.8976 - val_auc: 0.9536\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3210 - accuracy: 0.9124 - auc: 0.9422 - val_loss: 0.2876 - val_accuracy: 0.9213 - val_auc: 0.9519\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3216 - accuracy: 0.9109 - auc: 0.9451 - val_loss: 0.2871 - val_accuracy: 0.9090 - val_auc: 0.9530\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3050 - accuracy: 0.9128 - auc: 0.9467 - val_loss: 0.2981 - val_accuracy: 0.9210 - val_auc: 0.9503\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3043 - accuracy: 0.9161 - auc: 0.9499 - val_loss: 0.3051 - val_accuracy: 0.9111 - val_auc: 0.9491\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2883 - accuracy: 0.9120 - auc: 0.9522 - val_loss: 0.3122 - val_accuracy: 0.9072 - val_auc: 0.9501\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2833 - accuracy: 0.9109 - auc: 0.9527 - val_loss: 0.3295 - val_accuracy: 0.9181 - val_auc: 0.9479\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2873 - accuracy: 0.9109 - auc: 0.9538 - val_loss: 0.3329 - val_accuracy: 0.9091 - val_auc: 0.9459\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2825 - accuracy: 0.9096 - auc: 0.9539 - val_loss: 0.3440 - val_accuracy: 0.9099 - val_auc: 0.9449\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2756 - accuracy: 0.9077 - auc: 0.9573 - val_loss: 0.3353 - val_accuracy: 0.9150 - val_auc: 0.9489\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2786 - accuracy: 0.9107 - auc: 0.9568 - val_loss: 0.3701 - val_accuracy: 0.9218 - val_auc: 0.9431\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2650 - accuracy: 0.9109 - auc: 0.9588 - val_loss: 0.3889 - val_accuracy: 0.8997 - val_auc: 0.9442\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2585 - accuracy: 0.9098 - auc: 0.9609 - val_loss: 0.4135 - val_accuracy: 0.9153 - val_auc: 0.9424\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2622 - accuracy: 0.9064 - auc: 0.9586 - val_loss: 0.4030 - val_accuracy: 0.8980 - val_auc: 0.9445\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2576 - accuracy: 0.9073 - auc: 0.9609 - val_loss: 0.4107 - val_accuracy: 0.9110 - val_auc: 0.9451\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2611 - accuracy: 0.9040 - auc: 0.9590 - val_loss: 0.4256 - val_accuracy: 0.9078 - val_auc: 0.9432\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2637 - accuracy: 0.9065 - auc: 0.9591 - val_loss: 0.4418 - val_accuracy: 0.9089 - val_auc: 0.9379\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2549 - accuracy: 0.9061 - auc: 0.9610 - val_loss: 0.4480 - val_accuracy: 0.9173 - val_auc: 0.9391\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2526 - accuracy: 0.9089 - auc: 0.9630 - val_loss: 0.4695 - val_accuracy: 0.9305 - val_auc: 0.9403\n",
      "Epoch 24/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9082 - auc: 0.9605Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2503 - accuracy: 0.9082 - auc: 0.9606 - val_loss: 0.5177 - val_accuracy: 0.9147 - val_auc: 0.9388\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 0.4356 - accuracy: 0.8877 - auc: 0.8904 - val_loss: 0.3183 - val_accuracy: 0.9229 - val_auc: 0.9576\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3585 - accuracy: 0.9096 - auc: 0.9315 - val_loss: 0.2910 - val_accuracy: 0.9183 - val_auc: 0.9595\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3590 - accuracy: 0.9119 - auc: 0.9294 - val_loss: 0.2885 - val_accuracy: 0.9148 - val_auc: 0.9602\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3364 - accuracy: 0.9130 - auc: 0.9413 - val_loss: 0.2918 - val_accuracy: 0.9401 - val_auc: 0.9587\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3340 - accuracy: 0.9134 - auc: 0.9425 - val_loss: 0.3155 - val_accuracy: 0.8967 - val_auc: 0.9560\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3302 - accuracy: 0.9140 - auc: 0.9407 - val_loss: 0.2923 - val_accuracy: 0.9256 - val_auc: 0.9556\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3253 - accuracy: 0.9187 - auc: 0.9432 - val_loss: 0.2865 - val_accuracy: 0.9095 - val_auc: 0.9576\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3246 - accuracy: 0.9166 - auc: 0.9449 - val_loss: 0.2879 - val_accuracy: 0.9040 - val_auc: 0.9554\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3217 - accuracy: 0.9198 - auc: 0.9473 - val_loss: 0.2844 - val_accuracy: 0.9178 - val_auc: 0.9556\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3264 - accuracy: 0.9158 - auc: 0.9465 - val_loss: 0.2867 - val_accuracy: 0.9374 - val_auc: 0.9567\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3238 - accuracy: 0.9182 - auc: 0.9481 - val_loss: 0.2885 - val_accuracy: 0.9110 - val_auc: 0.9589\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3265 - accuracy: 0.9177 - auc: 0.9437 - val_loss: 0.2902 - val_accuracy: 0.9371 - val_auc: 0.9561\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3210 - accuracy: 0.9196 - auc: 0.9500 - val_loss: 0.3057 - val_accuracy: 0.9468 - val_auc: 0.9533\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3235 - accuracy: 0.9177 - auc: 0.9491 - val_loss: 0.2852 - val_accuracy: 0.9273 - val_auc: 0.9534\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3153 - accuracy: 0.9201 - auc: 0.9504 - val_loss: 0.3058 - val_accuracy: 0.9463 - val_auc: 0.9545\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3144 - accuracy: 0.9235 - auc: 0.9503 - val_loss: 0.3061 - val_accuracy: 0.9096 - val_auc: 0.9543\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3252 - accuracy: 0.9223 - auc: 0.9485 - val_loss: 0.2929 - val_accuracy: 0.9095 - val_auc: 0.9542\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3159 - accuracy: 0.9189 - auc: 0.9495 - val_loss: 0.2877 - val_accuracy: 0.9232 - val_auc: 0.9524\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3134 - accuracy: 0.9226 - auc: 0.9510 - val_loss: 0.3030 - val_accuracy: 0.9506 - val_auc: 0.9542\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3253 - accuracy: 0.9223 - auc: 0.9456 - val_loss: 0.2975 - val_accuracy: 0.9227 - val_auc: 0.9523\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3219 - accuracy: 0.9198 - auc: 0.9485 - val_loss: 0.2909 - val_accuracy: 0.9199 - val_auc: 0.9563\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3040 - accuracy: 0.9223 - auc: 0.9521 - val_loss: 0.2952 - val_accuracy: 0.9392 - val_auc: 0.9527\n",
      "Epoch 23/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.9241 - auc: 0.9481Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3156 - accuracy: 0.9241 - auc: 0.9481 - val_loss: 0.2897 - val_accuracy: 0.9295 - val_auc: 0.9562\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.4996 - accuracy: 0.8808 - auc: 0.8532 - val_loss: 0.3205 - val_accuracy: 0.9164 - val_auc: 0.9501\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3593 - accuracy: 0.9139 - auc: 0.9291 - val_loss: 0.3063 - val_accuracy: 0.8982 - val_auc: 0.9519\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3585 - accuracy: 0.9152 - auc: 0.9306 - val_loss: 0.3007 - val_accuracy: 0.9100 - val_auc: 0.9504\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3392 - accuracy: 0.9158 - auc: 0.9401 - val_loss: 0.3004 - val_accuracy: 0.9258 - val_auc: 0.9505\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3263 - accuracy: 0.9185 - auc: 0.9449 - val_loss: 0.2981 - val_accuracy: 0.9104 - val_auc: 0.9492\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3159 - accuracy: 0.9183 - auc: 0.9486 - val_loss: 0.2826 - val_accuracy: 0.9134 - val_auc: 0.9543\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3165 - accuracy: 0.9200 - auc: 0.9467 - val_loss: 0.2887 - val_accuracy: 0.9213 - val_auc: 0.9486\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3099 - accuracy: 0.9193 - auc: 0.9482 - val_loss: 0.2922 - val_accuracy: 0.9260 - val_auc: 0.9477\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3065 - accuracy: 0.9208 - auc: 0.9504 - val_loss: 0.3058 - val_accuracy: 0.9030 - val_auc: 0.9455\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3036 - accuracy: 0.9186 - auc: 0.9502 - val_loss: 0.2934 - val_accuracy: 0.9142 - val_auc: 0.9484\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3014 - accuracy: 0.9218 - auc: 0.9507 - val_loss: 0.3030 - val_accuracy: 0.9222 - val_auc: 0.9495\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2939 - accuracy: 0.9178 - auc: 0.9529 - val_loss: 0.2990 - val_accuracy: 0.9273 - val_auc: 0.9480\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2857 - accuracy: 0.9211 - auc: 0.9581 - val_loss: 0.3148 - val_accuracy: 0.9290 - val_auc: 0.9477\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2941 - accuracy: 0.9227 - auc: 0.9514 - val_loss: 0.3397 - val_accuracy: 0.8956 - val_auc: 0.9461\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2844 - accuracy: 0.9219 - auc: 0.9550 - val_loss: 0.3393 - val_accuracy: 0.9444 - val_auc: 0.9458\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2942 - accuracy: 0.9226 - auc: 0.9531 - val_loss: 0.3223 - val_accuracy: 0.9105 - val_auc: 0.9464\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2722 - accuracy: 0.9213 - auc: 0.9604 - val_loss: 0.3460 - val_accuracy: 0.9203 - val_auc: 0.9435\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2796 - accuracy: 0.9214 - auc: 0.9559 - val_loss: 0.3605 - val_accuracy: 0.9329 - val_auc: 0.9425\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2878 - accuracy: 0.9221 - auc: 0.9549 - val_loss: 0.3518 - val_accuracy: 0.9234 - val_auc: 0.9446\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3020 - accuracy: 0.9215 - auc: 0.9504 - val_loss: 0.3398 - val_accuracy: 0.9238 - val_auc: 0.9466\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2862 - accuracy: 0.9215 - auc: 0.9548 - val_loss: 0.3358 - val_accuracy: 0.9223 - val_auc: 0.9448\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2900 - accuracy: 0.9245 - auc: 0.9528 - val_loss: 0.3325 - val_accuracy: 0.9120 - val_auc: 0.9457\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2858 - accuracy: 0.9233 - auc: 0.9543 - val_loss: 0.3784 - val_accuracy: 0.9227 - val_auc: 0.9406\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2885 - accuracy: 0.9210 - auc: 0.9556 - val_loss: 0.3616 - val_accuracy: 0.9256 - val_auc: 0.9416\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2873 - accuracy: 0.9225 - auc: 0.9550 - val_loss: 0.3712 - val_accuracy: 0.9270 - val_auc: 0.9419\n",
      "Epoch 26/100\n",
      "248832/250291 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9241 - auc: 0.9572Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2777 - accuracy: 0.9241 - auc: 0.9571 - val_loss: 0.3722 - val_accuracy: 0.9193 - val_auc: 0.9416\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.5794 - accuracy: 0.8554 - auc: 0.8546 - val_loss: 0.3272 - val_accuracy: 0.9109 - val_auc: 0.9469\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3829 - accuracy: 0.9019 - auc: 0.9220 - val_loss: 0.2833 - val_accuracy: 0.9054 - val_auc: 0.9572\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3590 - accuracy: 0.9040 - auc: 0.9325 - val_loss: 0.2919 - val_accuracy: 0.9039 - val_auc: 0.9571\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3434 - accuracy: 0.9104 - auc: 0.9358 - val_loss: 0.2762 - val_accuracy: 0.9222 - val_auc: 0.9569\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3326 - accuracy: 0.9121 - auc: 0.9390 - val_loss: 0.2883 - val_accuracy: 0.8944 - val_auc: 0.9560\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3181 - accuracy: 0.9115 - auc: 0.9452 - val_loss: 0.2977 - val_accuracy: 0.9279 - val_auc: 0.9489\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2906 - accuracy: 0.9181 - auc: 0.9543 - val_loss: 0.2929 - val_accuracy: 0.9094 - val_auc: 0.9522\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3098 - accuracy: 0.9044 - auc: 0.9472 - val_loss: 0.2856 - val_accuracy: 0.9121 - val_auc: 0.9531\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2986 - accuracy: 0.9091 - auc: 0.9502 - val_loss: 0.2815 - val_accuracy: 0.8996 - val_auc: 0.9545\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2824 - accuracy: 0.9066 - auc: 0.9540 - val_loss: 0.3014 - val_accuracy: 0.9078 - val_auc: 0.9526\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2876 - accuracy: 0.9066 - auc: 0.9529 - val_loss: 0.3273 - val_accuracy: 0.9081 - val_auc: 0.9487\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2682 - accuracy: 0.9097 - auc: 0.9586 - val_loss: 0.3450 - val_accuracy: 0.9139 - val_auc: 0.9477\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2882 - accuracy: 0.8989 - auc: 0.9526 - val_loss: 0.3303 - val_accuracy: 0.9047 - val_auc: 0.9505\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2697 - accuracy: 0.9045 - auc: 0.9571 - val_loss: 0.3517 - val_accuracy: 0.9072 - val_auc: 0.9490\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2730 - accuracy: 0.9018 - auc: 0.9565 - val_loss: 0.3618 - val_accuracy: 0.9180 - val_auc: 0.9500\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2547 - accuracy: 0.9078 - auc: 0.9616 - val_loss: 0.3883 - val_accuracy: 0.9113 - val_auc: 0.9471\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2653 - accuracy: 0.9055 - auc: 0.9591 - val_loss: 0.3779 - val_accuracy: 0.9012 - val_auc: 0.9492\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2610 - accuracy: 0.9010 - auc: 0.9605 - val_loss: 0.3931 - val_accuracy: 0.9074 - val_auc: 0.9428\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2671 - accuracy: 0.9040 - auc: 0.9572 - val_loss: 0.4115 - val_accuracy: 0.9087 - val_auc: 0.9443\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2716 - accuracy: 0.9024 - auc: 0.9575 - val_loss: 0.3932 - val_accuracy: 0.9094 - val_auc: 0.9447\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2596 - accuracy: 0.9087 - auc: 0.9603 - val_loss: 0.4365 - val_accuracy: 0.9012 - val_auc: 0.9423\n",
      "Epoch 22/100\n",
      "246784/250291 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9055 - auc: 0.9601Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2584 - accuracy: 0.9053 - auc: 0.9601 - val_loss: 0.4636 - val_accuracy: 0.9016 - val_auc: 0.9416\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.4770 - accuracy: 0.8451 - auc: 0.8868 - val_loss: 0.2812 - val_accuracy: 0.9115 - val_auc: 0.9587\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3289 - accuracy: 0.9022 - auc: 0.9442 - val_loss: 0.2751 - val_accuracy: 0.8983 - val_auc: 0.9576\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3187 - accuracy: 0.9079 - auc: 0.9456 - val_loss: 0.2841 - val_accuracy: 0.9033 - val_auc: 0.9525\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3226 - accuracy: 0.9069 - auc: 0.9461 - val_loss: 0.2835 - val_accuracy: 0.9152 - val_auc: 0.9541\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2992 - accuracy: 0.9137 - auc: 0.9524 - val_loss: 0.2887 - val_accuracy: 0.9066 - val_auc: 0.9514\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3202 - accuracy: 0.9026 - auc: 0.9493 - val_loss: 0.2858 - val_accuracy: 0.9170 - val_auc: 0.9524\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2939 - accuracy: 0.9113 - auc: 0.9531 - val_loss: 0.2688 - val_accuracy: 0.9187 - val_auc: 0.9563\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2948 - accuracy: 0.9092 - auc: 0.9541 - val_loss: 0.2735 - val_accuracy: 0.9203 - val_auc: 0.9566\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2943 - accuracy: 0.9127 - auc: 0.9539 - val_loss: 0.2683 - val_accuracy: 0.9070 - val_auc: 0.9576\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2740 - accuracy: 0.9101 - auc: 0.9593 - val_loss: 0.2947 - val_accuracy: 0.9260 - val_auc: 0.9490\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2814 - accuracy: 0.9126 - auc: 0.9571 - val_loss: 0.2722 - val_accuracy: 0.9209 - val_auc: 0.9559\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2750 - accuracy: 0.9139 - auc: 0.9594 - val_loss: 0.3040 - val_accuracy: 0.9296 - val_auc: 0.9496\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2786 - accuracy: 0.9123 - auc: 0.9576 - val_loss: 0.3005 - val_accuracy: 0.9391 - val_auc: 0.9518\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2800 - accuracy: 0.9154 - auc: 0.9587 - val_loss: 0.2973 - val_accuracy: 0.9313 - val_auc: 0.9507\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2791 - accuracy: 0.9159 - auc: 0.9581 - val_loss: 0.3292 - val_accuracy: 0.9211 - val_auc: 0.9426\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2798 - accuracy: 0.9143 - auc: 0.9582 - val_loss: 0.3229 - val_accuracy: 0.9342 - val_auc: 0.9468\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2730 - accuracy: 0.9153 - auc: 0.9602 - val_loss: 0.3166 - val_accuracy: 0.9199 - val_auc: 0.9485\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2676 - accuracy: 0.9161 - auc: 0.9604 - val_loss: 0.3356 - val_accuracy: 0.9113 - val_auc: 0.9467\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2692 - accuracy: 0.9147 - auc: 0.9602 - val_loss: 0.3443 - val_accuracy: 0.9261 - val_auc: 0.9463\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2695 - accuracy: 0.9158 - auc: 0.9614 - val_loss: 0.3246 - val_accuracy: 0.9028 - val_auc: 0.9464\n",
      "Epoch 21/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2591 - accuracy: 0.9178 - auc: 0.9628Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2604 - accuracy: 0.9178 - auc: 0.9627 - val_loss: 0.3415 - val_accuracy: 0.9216 - val_auc: 0.9472\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.4913 - accuracy: 0.8302 - auc: 0.8801 - val_loss: 0.2969 - val_accuracy: 0.8921 - val_auc: 0.9517\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3475 - accuracy: 0.8967 - auc: 0.9347 - val_loss: 0.3003 - val_accuracy: 0.8938 - val_auc: 0.9528\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3254 - accuracy: 0.9042 - auc: 0.9415 - val_loss: 0.2944 - val_accuracy: 0.8845 - val_auc: 0.9551\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3092 - accuracy: 0.9066 - auc: 0.9483 - val_loss: 0.2899 - val_accuracy: 0.9194 - val_auc: 0.9518\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3032 - accuracy: 0.9090 - auc: 0.9508 - val_loss: 0.2808 - val_accuracy: 0.9067 - val_auc: 0.9556\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.2918 - accuracy: 0.9099 - auc: 0.9528 - val_loss: 0.2813 - val_accuracy: 0.9304 - val_auc: 0.9542\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 3s 12us/sample - loss: 0.3004 - accuracy: 0.9146 - auc: 0.9528 - val_loss: 0.2905 - val_accuracy: 0.8916 - val_auc: 0.9535\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.2957 - accuracy: 0.9093 - auc: 0.9531 - val_loss: 0.3192 - val_accuracy: 0.8967 - val_auc: 0.9509\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2801 - accuracy: 0.9163 - auc: 0.9569 - val_loss: 0.2961 - val_accuracy: 0.9042 - val_auc: 0.9531\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2733 - accuracy: 0.9115 - auc: 0.9587 - val_loss: 0.3167 - val_accuracy: 0.9281 - val_auc: 0.9499\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2762 - accuracy: 0.9116 - auc: 0.9586 - val_loss: 0.3134 - val_accuracy: 0.9258 - val_auc: 0.9517\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2686 - accuracy: 0.9137 - auc: 0.9603 - val_loss: 0.3117 - val_accuracy: 0.9121 - val_auc: 0.9537\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2582 - accuracy: 0.9168 - auc: 0.9632 - val_loss: 0.3218 - val_accuracy: 0.9162 - val_auc: 0.9516\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2573 - accuracy: 0.9141 - auc: 0.9633 - val_loss: 0.3585 - val_accuracy: 0.9246 - val_auc: 0.9480\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2769 - accuracy: 0.9119 - auc: 0.9574 - val_loss: 0.3564 - val_accuracy: 0.9120 - val_auc: 0.9465\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2570 - accuracy: 0.9166 - auc: 0.9633 - val_loss: 0.4029 - val_accuracy: 0.9171 - val_auc: 0.9454\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2687 - accuracy: 0.9119 - auc: 0.9619 - val_loss: 0.4128 - val_accuracy: 0.9234 - val_auc: 0.9465\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2600 - accuracy: 0.9137 - auc: 0.9622 - val_loss: 0.4168 - val_accuracy: 0.9196 - val_auc: 0.9440\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2570 - accuracy: 0.9161 - auc: 0.9631 - val_loss: 0.4550 - val_accuracy: 0.9187 - val_auc: 0.9424\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2478 - accuracy: 0.9133 - auc: 0.9649 - val_loss: 0.4761 - val_accuracy: 0.9316 - val_auc: 0.9425\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2640 - accuracy: 0.9111 - auc: 0.9621 - val_loss: 0.4730 - val_accuracy: 0.9272 - val_auc: 0.9415\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2510 - accuracy: 0.9164 - auc: 0.9645 - val_loss: 0.4483 - val_accuracy: 0.9025 - val_auc: 0.9420\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2579 - accuracy: 0.9156 - auc: 0.9647 - val_loss: 0.4649 - val_accuracy: 0.9175 - val_auc: 0.9444\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2490 - accuracy: 0.9155 - auc: 0.9652 - val_loss: 0.4793 - val_accuracy: 0.9255 - val_auc: 0.9391\n",
      "Epoch 25/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.9222 - auc: 0.9682Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2343 - accuracy: 0.9221 - auc: 0.9680 - val_loss: 0.5191 - val_accuracy: 0.9269 - val_auc: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 21us/sample - loss: 0.5658 - accuracy: 0.7380 - auc: 0.8668 - val_loss: 0.3145 - val_accuracy: 0.7964 - val_auc: 0.9557\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3702 - accuracy: 0.8500 - auc: 0.9264 - val_loss: 0.2782 - val_accuracy: 0.8987 - val_auc: 0.9585\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3164 - accuracy: 0.8964 - auc: 0.9438 - val_loss: 0.2744 - val_accuracy: 0.8862 - val_auc: 0.9570\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3133 - accuracy: 0.8936 - auc: 0.9459 - val_loss: 0.2638 - val_accuracy: 0.8994 - val_auc: 0.9591\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3046 - accuracy: 0.8958 - auc: 0.9474 - val_loss: 0.2737 - val_accuracy: 0.8871 - val_auc: 0.9552\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2782 - accuracy: 0.8989 - auc: 0.9547 - val_loss: 0.2770 - val_accuracy: 0.9203 - val_auc: 0.9574\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2726 - accuracy: 0.9017 - auc: 0.9566 - val_loss: 0.2886 - val_accuracy: 0.9141 - val_auc: 0.9526\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2910 - accuracy: 0.8955 - auc: 0.9516 - val_loss: 0.2974 - val_accuracy: 0.9186 - val_auc: 0.9535\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2882 - accuracy: 0.8967 - auc: 0.9557 - val_loss: 0.2792 - val_accuracy: 0.9129 - val_auc: 0.9561\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2744 - accuracy: 0.9023 - auc: 0.9563 - val_loss: 0.2890 - val_accuracy: 0.9086 - val_auc: 0.9549\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2715 - accuracy: 0.9025 - auc: 0.9570 - val_loss: 0.2955 - val_accuracy: 0.9128 - val_auc: 0.9526\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2654 - accuracy: 0.9007 - auc: 0.9581 - val_loss: 0.3126 - val_accuracy: 0.9084 - val_auc: 0.9486\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2604 - accuracy: 0.9025 - auc: 0.9605 - val_loss: 0.3118 - val_accuracy: 0.9123 - val_auc: 0.9518\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2574 - accuracy: 0.9025 - auc: 0.9604 - val_loss: 0.3273 - val_accuracy: 0.8978 - val_auc: 0.9517\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2504 - accuracy: 0.9016 - auc: 0.9621 - val_loss: 0.3401 - val_accuracy: 0.8966 - val_auc: 0.9517\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2464 - accuracy: 0.8998 - auc: 0.9639 - val_loss: 0.3634 - val_accuracy: 0.9034 - val_auc: 0.9486\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2486 - accuracy: 0.8998 - auc: 0.9629 - val_loss: 0.3902 - val_accuracy: 0.9153 - val_auc: 0.9492\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2512 - accuracy: 0.9031 - auc: 0.9630 - val_loss: 0.4233 - val_accuracy: 0.9044 - val_auc: 0.9434\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2519 - accuracy: 0.9048 - auc: 0.9634 - val_loss: 0.3900 - val_accuracy: 0.9010 - val_auc: 0.9461\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2519 - accuracy: 0.9012 - auc: 0.9632 - val_loss: 0.3514 - val_accuracy: 0.9091 - val_auc: 0.9475\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2408 - accuracy: 0.9017 - auc: 0.9642 - val_loss: 0.4142 - val_accuracy: 0.9144 - val_auc: 0.9464\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2365 - accuracy: 0.9022 - auc: 0.9657 - val_loss: 0.4861 - val_accuracy: 0.9149 - val_auc: 0.9380\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2545 - accuracy: 0.9039 - auc: 0.9616 - val_loss: 0.4657 - val_accuracy: 0.9168 - val_auc: 0.9411\n",
      "Epoch 24/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.9039 - auc: 0.9669Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2369 - accuracy: 0.9039 - auc: 0.9670 - val_loss: 0.4844 - val_accuracy: 0.9119 - val_auc: 0.9398\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.5371 - accuracy: 0.8757 - auc: 0.8579 - val_loss: 0.3158 - val_accuracy: 0.9196 - val_auc: 0.9462\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3567 - accuracy: 0.9045 - auc: 0.9317 - val_loss: 0.2950 - val_accuracy: 0.9185 - val_auc: 0.9559\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3268 - accuracy: 0.9133 - auc: 0.9450 - val_loss: 0.2931 - val_accuracy: 0.9119 - val_auc: 0.9509\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3269 - accuracy: 0.9092 - auc: 0.9428 - val_loss: 0.2893 - val_accuracy: 0.9256 - val_auc: 0.9517\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3443 - accuracy: 0.9161 - auc: 0.9392 - val_loss: 0.2859 - val_accuracy: 0.9120 - val_auc: 0.9549\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3185 - accuracy: 0.9114 - auc: 0.9487 - val_loss: 0.2903 - val_accuracy: 0.9123 - val_auc: 0.9571\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3281 - accuracy: 0.9134 - auc: 0.9435 - val_loss: 0.2843 - val_accuracy: 0.9256 - val_auc: 0.9539\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3041 - accuracy: 0.9128 - auc: 0.9520 - val_loss: 0.2877 - val_accuracy: 0.9433 - val_auc: 0.9571\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2912 - accuracy: 0.9207 - auc: 0.9565 - val_loss: 0.2876 - val_accuracy: 0.9351 - val_auc: 0.9499\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2940 - accuracy: 0.9155 - auc: 0.9536 - val_loss: 0.2952 - val_accuracy: 0.9172 - val_auc: 0.9498\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2982 - accuracy: 0.9150 - auc: 0.9526 - val_loss: 0.2854 - val_accuracy: 0.9170 - val_auc: 0.9532\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2883 - accuracy: 0.9170 - auc: 0.9562 - val_loss: 0.2851 - val_accuracy: 0.9177 - val_auc: 0.9541\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2779 - accuracy: 0.9148 - auc: 0.9586 - val_loss: 0.2894 - val_accuracy: 0.9305 - val_auc: 0.9532\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2805 - accuracy: 0.9147 - auc: 0.9579 - val_loss: 0.3019 - val_accuracy: 0.9208 - val_auc: 0.9507\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2746 - accuracy: 0.9191 - auc: 0.9589 - val_loss: 0.2956 - val_accuracy: 0.9226 - val_auc: 0.9506\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2944 - accuracy: 0.9143 - auc: 0.9581 - val_loss: 0.2890 - val_accuracy: 0.9315 - val_auc: 0.9531\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2771 - accuracy: 0.9182 - auc: 0.9587 - val_loss: 0.3074 - val_accuracy: 0.9195 - val_auc: 0.9500\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2555 - accuracy: 0.9217 - auc: 0.9633 - val_loss: 0.3248 - val_accuracy: 0.9285 - val_auc: 0.9480\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2603 - accuracy: 0.9188 - auc: 0.9621 - val_loss: 0.3494 - val_accuracy: 0.9203 - val_auc: 0.9459\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2671 - accuracy: 0.9172 - auc: 0.9609 - val_loss: 0.3505 - val_accuracy: 0.9262 - val_auc: 0.9452\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2678 - accuracy: 0.9192 - auc: 0.9608 - val_loss: 0.3810 - val_accuracy: 0.9238 - val_auc: 0.9448\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2632 - accuracy: 0.9158 - auc: 0.9619 - val_loss: 0.3589 - val_accuracy: 0.9166 - val_auc: 0.9459\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2601 - accuracy: 0.9177 - auc: 0.9629 - val_loss: 0.4069 - val_accuracy: 0.9285 - val_auc: 0.9433\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2532 - accuracy: 0.9213 - auc: 0.9650 - val_loss: 0.4247 - val_accuracy: 0.9270 - val_auc: 0.9416\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2597 - accuracy: 0.9189 - auc: 0.9627 - val_loss: 0.4296 - val_accuracy: 0.9179 - val_auc: 0.9440\n",
      "Epoch 26/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.9168 - auc: 0.9627Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2619 - accuracy: 0.9169 - auc: 0.9627 - val_loss: 0.4106 - val_accuracy: 0.9247 - val_auc: 0.9459\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 0.4960 - accuracy: 0.7526 - auc: 0.8856 - val_loss: 0.3061 - val_accuracy: 0.8564 - val_auc: 0.9477\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3479 - accuracy: 0.8538 - auc: 0.9339 - val_loss: 0.2677 - val_accuracy: 0.8896 - val_auc: 0.9585\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3227 - accuracy: 0.8885 - auc: 0.9430 - val_loss: 0.2726 - val_accuracy: 0.9184 - val_auc: 0.9542\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3072 - accuracy: 0.8956 - auc: 0.9474 - val_loss: 0.2746 - val_accuracy: 0.9035 - val_auc: 0.9553\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2983 - accuracy: 0.8996 - auc: 0.9521 - val_loss: 0.2798 - val_accuracy: 0.9103 - val_auc: 0.9530\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2934 - accuracy: 0.9016 - auc: 0.9526 - val_loss: 0.2840 - val_accuracy: 0.8831 - val_auc: 0.9561\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2854 - accuracy: 0.9030 - auc: 0.9554 - val_loss: 0.2784 - val_accuracy: 0.9177 - val_auc: 0.9556\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2858 - accuracy: 0.9033 - auc: 0.9568 - val_loss: 0.2842 - val_accuracy: 0.9145 - val_auc: 0.9538\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2865 - accuracy: 0.9037 - auc: 0.9542 - val_loss: 0.2962 - val_accuracy: 0.9053 - val_auc: 0.9506\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2523 - accuracy: 0.9080 - auc: 0.9632 - val_loss: 0.3369 - val_accuracy: 0.9214 - val_auc: 0.9486\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2727 - accuracy: 0.9034 - auc: 0.9591 - val_loss: 0.2943 - val_accuracy: 0.9043 - val_auc: 0.9522\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2538 - accuracy: 0.9063 - auc: 0.9629 - val_loss: 0.3061 - val_accuracy: 0.9087 - val_auc: 0.9525\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2541 - accuracy: 0.9039 - auc: 0.9627 - val_loss: 0.3185 - val_accuracy: 0.9076 - val_auc: 0.9497\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2496 - accuracy: 0.9073 - auc: 0.9639 - val_loss: 0.3267 - val_accuracy: 0.9034 - val_auc: 0.9509\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2526 - accuracy: 0.9028 - auc: 0.9635 - val_loss: 0.3388 - val_accuracy: 0.8864 - val_auc: 0.9499\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2367 - accuracy: 0.9071 - auc: 0.9671 - val_loss: 0.3632 - val_accuracy: 0.9172 - val_auc: 0.9469\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2425 - accuracy: 0.9089 - auc: 0.9661 - val_loss: 0.3866 - val_accuracy: 0.9132 - val_auc: 0.9430\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2507 - accuracy: 0.9039 - auc: 0.9641 - val_loss: 0.3657 - val_accuracy: 0.9085 - val_auc: 0.9451\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2476 - accuracy: 0.9056 - auc: 0.9644 - val_loss: 0.3549 - val_accuracy: 0.8990 - val_auc: 0.9439\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2376 - accuracy: 0.9044 - auc: 0.9668 - val_loss: 0.3910 - val_accuracy: 0.9014 - val_auc: 0.9435\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2420 - accuracy: 0.9025 - auc: 0.9660 - val_loss: 0.3899 - val_accuracy: 0.9083 - val_auc: 0.9442\n",
      "Epoch 22/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2353 - accuracy: 0.9032 - auc: 0.9674Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2344 - accuracy: 0.9033 - auc: 0.9676 - val_loss: 0.4946 - val_accuracy: 0.9168 - val_auc: 0.9407\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.8433 - accuracy: 0.2747 - auc: 0.6447 - val_loss: 0.5996 - val_accuracy: 0.4122 - val_auc: 0.8306\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5938 - accuracy: 0.4698 - auc: 0.8020 - val_loss: 0.4520 - val_accuracy: 0.6917 - val_auc: 0.9075\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5039 - accuracy: 0.6165 - auc: 0.8489 - val_loss: 0.3818 - val_accuracy: 0.7938 - val_auc: 0.9308\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4691 - accuracy: 0.6741 - auc: 0.8639 - val_loss: 0.3450 - val_accuracy: 0.8253 - val_auc: 0.9413\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4284 - accuracy: 0.7070 - auc: 0.8806 - val_loss: 0.3251 - val_accuracy: 0.8431 - val_auc: 0.9464\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4058 - accuracy: 0.7277 - auc: 0.8910 - val_loss: 0.3077 - val_accuracy: 0.8552 - val_auc: 0.9500\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4011 - accuracy: 0.7419 - auc: 0.8907 - val_loss: 0.3032 - val_accuracy: 0.8620 - val_auc: 0.9517\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3825 - accuracy: 0.7535 - auc: 0.9013 - val_loss: 0.2984 - val_accuracy: 0.8701 - val_auc: 0.9527\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3780 - accuracy: 0.7612 - auc: 0.9029 - val_loss: 0.2898 - val_accuracy: 0.8714 - val_auc: 0.9546\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3706 - accuracy: 0.7630 - auc: 0.9078 - val_loss: 0.2855 - val_accuracy: 0.8709 - val_auc: 0.9562\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3693 - accuracy: 0.7642 - auc: 0.9058 - val_loss: 0.2847 - val_accuracy: 0.8712 - val_auc: 0.9570\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3464 - accuracy: 0.7715 - auc: 0.9149 - val_loss: 0.2815 - val_accuracy: 0.8783 - val_auc: 0.9574\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3520 - accuracy: 0.7747 - auc: 0.9137 - val_loss: 0.2795 - val_accuracy: 0.8775 - val_auc: 0.9572\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3556 - accuracy: 0.7767 - auc: 0.9126 - val_loss: 0.2830 - val_accuracy: 0.8742 - val_auc: 0.9565\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3411 - accuracy: 0.7766 - auc: 0.9211 - val_loss: 0.2835 - val_accuracy: 0.8780 - val_auc: 0.9564\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3474 - accuracy: 0.7828 - auc: 0.9164 - val_loss: 0.2840 - val_accuracy: 0.8743 - val_auc: 0.9563\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3407 - accuracy: 0.7821 - auc: 0.9192 - val_loss: 0.2886 - val_accuracy: 0.8794 - val_auc: 0.9553\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3498 - accuracy: 0.7825 - auc: 0.9161 - val_loss: 0.2914 - val_accuracy: 0.8758 - val_auc: 0.9552\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3383 - accuracy: 0.7809 - auc: 0.9180 - val_loss: 0.2918 - val_accuracy: 0.8740 - val_auc: 0.9547\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3350 - accuracy: 0.7819 - auc: 0.9207 - val_loss: 0.2917 - val_accuracy: 0.8759 - val_auc: 0.9552\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3312 - accuracy: 0.7867 - auc: 0.9201 - val_loss: 0.2958 - val_accuracy: 0.8814 - val_auc: 0.9546\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3248 - accuracy: 0.7910 - auc: 0.9251 - val_loss: 0.2966 - val_accuracy: 0.8842 - val_auc: 0.9552\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3357 - accuracy: 0.7862 - auc: 0.9176 - val_loss: 0.2978 - val_accuracy: 0.8781 - val_auc: 0.9552\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3276 - accuracy: 0.7875 - auc: 0.9216 - val_loss: 0.3000 - val_accuracy: 0.8781 - val_auc: 0.9550\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3240 - accuracy: 0.7859 - auc: 0.9238 - val_loss: 0.3019 - val_accuracy: 0.8798 - val_auc: 0.9550\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3311 - accuracy: 0.7867 - auc: 0.9213 - val_loss: 0.3047 - val_accuracy: 0.8773 - val_auc: 0.9546\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3262 - accuracy: 0.7868 - auc: 0.9240 - val_loss: 0.3010 - val_accuracy: 0.8761 - val_auc: 0.9546\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3363 - accuracy: 0.7843 - auc: 0.9190 - val_loss: 0.3116 - val_accuracy: 0.8782 - val_auc: 0.9528\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3200 - accuracy: 0.7879 - auc: 0.9263 - val_loss: 0.3090 - val_accuracy: 0.8827 - val_auc: 0.9540\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3220 - accuracy: 0.7921 - auc: 0.9261 - val_loss: 0.3141 - val_accuracy: 0.8834 - val_auc: 0.9525\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3251 - accuracy: 0.7897 - auc: 0.9252 - val_loss: 0.3155 - val_accuracy: 0.8785 - val_auc: 0.9523\n",
      "Epoch 32/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.7893 - auc: 0.9235Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3217 - accuracy: 0.7893 - auc: 0.9236 - val_loss: 0.3232 - val_accuracy: 0.8817 - val_auc: 0.9521\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.9343 - accuracy: 0.7978 - auc: 0.6026 - val_loss: 0.4750 - val_accuracy: 0.8924 - val_auc: 0.8841\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5916 - accuracy: 0.8800 - auc: 0.7755 - val_loss: 0.4261 - val_accuracy: 0.9151 - val_auc: 0.9275\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5253 - accuracy: 0.9047 - auc: 0.8367 - val_loss: 0.3933 - val_accuracy: 0.9234 - val_auc: 0.9421\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4688 - accuracy: 0.9157 - auc: 0.8627 - val_loss: 0.3714 - val_accuracy: 0.9195 - val_auc: 0.9456\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5055 - accuracy: 0.9153 - auc: 0.8696 - val_loss: 0.3412 - val_accuracy: 0.9204 - val_auc: 0.9466\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4493 - accuracy: 0.9152 - auc: 0.8887 - val_loss: 0.3178 - val_accuracy: 0.9145 - val_auc: 0.9467\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4292 - accuracy: 0.9184 - auc: 0.8934 - val_loss: 0.3075 - val_accuracy: 0.9188 - val_auc: 0.9463\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4079 - accuracy: 0.9174 - auc: 0.9018 - val_loss: 0.3018 - val_accuracy: 0.9185 - val_auc: 0.9477\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4057 - accuracy: 0.9162 - auc: 0.8976 - val_loss: 0.3006 - val_accuracy: 0.9163 - val_auc: 0.9486\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3934 - accuracy: 0.9137 - auc: 0.9072 - val_loss: 0.2838 - val_accuracy: 0.9140 - val_auc: 0.9542\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3785 - accuracy: 0.9163 - auc: 0.9062 - val_loss: 0.2806 - val_accuracy: 0.9133 - val_auc: 0.9550\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3843 - accuracy: 0.9169 - auc: 0.9048 - val_loss: 0.2801 - val_accuracy: 0.9115 - val_auc: 0.9547\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3911 - accuracy: 0.9146 - auc: 0.9017 - val_loss: 0.2858 - val_accuracy: 0.9152 - val_auc: 0.9536\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3776 - accuracy: 0.9137 - auc: 0.9058 - val_loss: 0.2832 - val_accuracy: 0.9138 - val_auc: 0.9542\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3628 - accuracy: 0.9160 - auc: 0.9128 - val_loss: 0.2792 - val_accuracy: 0.9093 - val_auc: 0.9552\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3553 - accuracy: 0.9124 - auc: 0.9178 - val_loss: 0.2793 - val_accuracy: 0.9053 - val_auc: 0.9551\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3393 - accuracy: 0.9122 - auc: 0.9255 - val_loss: 0.2760 - val_accuracy: 0.9026 - val_auc: 0.9556\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3441 - accuracy: 0.9126 - auc: 0.9206 - val_loss: 0.2786 - val_accuracy: 0.9070 - val_auc: 0.9553\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3577 - accuracy: 0.9146 - auc: 0.9162 - val_loss: 0.2766 - val_accuracy: 0.9017 - val_auc: 0.9554\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3515 - accuracy: 0.9102 - auc: 0.9146 - val_loss: 0.2777 - val_accuracy: 0.9005 - val_auc: 0.9556\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3464 - accuracy: 0.9101 - auc: 0.9183 - val_loss: 0.2814 - val_accuracy: 0.9010 - val_auc: 0.9550\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3480 - accuracy: 0.9106 - auc: 0.9161 - val_loss: 0.2821 - val_accuracy: 0.8992 - val_auc: 0.9546\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3503 - accuracy: 0.9106 - auc: 0.9163 - val_loss: 0.2881 - val_accuracy: 0.9060 - val_auc: 0.9535\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3307 - accuracy: 0.9121 - auc: 0.9260 - val_loss: 0.2808 - val_accuracy: 0.8950 - val_auc: 0.9550\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3316 - accuracy: 0.9097 - auc: 0.9230 - val_loss: 0.2813 - val_accuracy: 0.8966 - val_auc: 0.9553\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3238 - accuracy: 0.9108 - auc: 0.9284 - val_loss: 0.2850 - val_accuracy: 0.8937 - val_auc: 0.9542\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3311 - accuracy: 0.8170 - auc: 0.9228 - val_loss: 0.2915 - val_accuracy: 0.8779 - val_auc: 0.9536\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3326 - accuracy: 0.7132 - auc: 0.9230 - val_loss: 0.2947 - val_accuracy: 0.8759 - val_auc: 0.9520\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3286 - accuracy: 0.7125 - auc: 0.9258 - val_loss: 0.2953 - val_accuracy: 0.8735 - val_auc: 0.9516\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3318 - accuracy: 0.7104 - auc: 0.9228 - val_loss: 0.3024 - val_accuracy: 0.8685 - val_auc: 0.9505\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3249 - accuracy: 0.7108 - auc: 0.9266 - val_loss: 0.3007 - val_accuracy: 0.8719 - val_auc: 0.9512\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3368 - accuracy: 0.7106 - auc: 0.9190 - val_loss: 0.3016 - val_accuracy: 0.8687 - val_auc: 0.9518\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3224 - accuracy: 0.7108 - auc: 0.9261 - val_loss: 0.3009 - val_accuracy: 0.8713 - val_auc: 0.9525\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3285 - accuracy: 0.7121 - auc: 0.9227 - val_loss: 0.3086 - val_accuracy: 0.8704 - val_auc: 0.9512\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3328 - accuracy: 0.7107 - auc: 0.9218 - val_loss: 0.3066 - val_accuracy: 0.8710 - val_auc: 0.9513\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3256 - accuracy: 0.7095 - auc: 0.9254 - val_loss: 0.3129 - val_accuracy: 0.8694 - val_auc: 0.9509\n",
      "Epoch 37/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3312 - accuracy: 0.7090 - auc: 0.9210Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3352 - accuracy: 0.7090 - auc: 0.9198 - val_loss: 0.3091 - val_accuracy: 0.8686 - val_auc: 0.9512\n",
      "Epoch 00037: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 0.6748 - accuracy: 0.5109 - auc: 0.7479 - val_loss: 0.4744 - val_accuracy: 0.7361 - val_auc: 0.9352\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4816 - accuracy: 0.8200 - auc: 0.8851 - val_loss: 0.4105 - val_accuracy: 0.8640 - val_auc: 0.9533\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4349 - accuracy: 0.8819 - auc: 0.9095 - val_loss: 0.3823 - val_accuracy: 0.8890 - val_auc: 0.9555\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3985 - accuracy: 0.8946 - auc: 0.9286 - val_loss: 0.3632 - val_accuracy: 0.9095 - val_auc: 0.9551\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3902 - accuracy: 0.9099 - auc: 0.9270 - val_loss: 0.3480 - val_accuracy: 0.9079 - val_auc: 0.9551\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3769 - accuracy: 0.9103 - auc: 0.9278 - val_loss: 0.3375 - val_accuracy: 0.9095 - val_auc: 0.9548\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3696 - accuracy: 0.9138 - auc: 0.9254 - val_loss: 0.3271 - val_accuracy: 0.9132 - val_auc: 0.9553\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3658 - accuracy: 0.9144 - auc: 0.9249 - val_loss: 0.3211 - val_accuracy: 0.9213 - val_auc: 0.9554\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3554 - accuracy: 0.9181 - auc: 0.9328 - val_loss: 0.3159 - val_accuracy: 0.9238 - val_auc: 0.9543\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3495 - accuracy: 0.9222 - auc: 0.9314 - val_loss: 0.3117 - val_accuracy: 0.9179 - val_auc: 0.9540\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3564 - accuracy: 0.9187 - auc: 0.9255 - val_loss: 0.3071 - val_accuracy: 0.9205 - val_auc: 0.9544\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3555 - accuracy: 0.9220 - auc: 0.9312 - val_loss: 0.3033 - val_accuracy: 0.9243 - val_auc: 0.9546\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3369 - accuracy: 0.9205 - auc: 0.9388 - val_loss: 0.3034 - val_accuracy: 0.9242 - val_auc: 0.9532\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3416 - accuracy: 0.9234 - auc: 0.9320 - val_loss: 0.2997 - val_accuracy: 0.9207 - val_auc: 0.9541\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3517 - accuracy: 0.9252 - auc: 0.9255 - val_loss: 0.2968 - val_accuracy: 0.9220 - val_auc: 0.9589\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3468 - accuracy: 0.9206 - auc: 0.9342 - val_loss: 0.2974 - val_accuracy: 0.9248 - val_auc: 0.9553\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3461 - accuracy: 0.9247 - auc: 0.9301 - val_loss: 0.2968 - val_accuracy: 0.9211 - val_auc: 0.9540\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3413 - accuracy: 0.9229 - auc: 0.9310 - val_loss: 0.2957 - val_accuracy: 0.9212 - val_auc: 0.9537\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3508 - accuracy: 0.9230 - auc: 0.9273 - val_loss: 0.2952 - val_accuracy: 0.9229 - val_auc: 0.9538\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3342 - accuracy: 0.9252 - auc: 0.9352 - val_loss: 0.2951 - val_accuracy: 0.9249 - val_auc: 0.9536\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3394 - accuracy: 0.9259 - auc: 0.9329 - val_loss: 0.2918 - val_accuracy: 0.9243 - val_auc: 0.9569\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3412 - accuracy: 0.9243 - auc: 0.9294 - val_loss: 0.2897 - val_accuracy: 0.9232 - val_auc: 0.9573\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3311 - accuracy: 0.9245 - auc: 0.9358 - val_loss: 0.2934 - val_accuracy: 0.9258 - val_auc: 0.9552\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3338 - accuracy: 0.9236 - auc: 0.9347 - val_loss: 0.2908 - val_accuracy: 0.9258 - val_auc: 0.9554\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3451 - accuracy: 0.9249 - auc: 0.9249 - val_loss: 0.2899 - val_accuracy: 0.9263 - val_auc: 0.9552\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3346 - accuracy: 0.9259 - auc: 0.9345 - val_loss: 0.2928 - val_accuracy: 0.9232 - val_auc: 0.9547\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3394 - accuracy: 0.9242 - auc: 0.9326 - val_loss: 0.2902 - val_accuracy: 0.9276 - val_auc: 0.9553\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3283 - accuracy: 0.9279 - auc: 0.9363 - val_loss: 0.2948 - val_accuracy: 0.9265 - val_auc: 0.9539\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3396 - accuracy: 0.9260 - auc: 0.9324 - val_loss: 0.2979 - val_accuracy: 0.9222 - val_auc: 0.9539\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3348 - accuracy: 0.9254 - auc: 0.9333 - val_loss: 0.2936 - val_accuracy: 0.9262 - val_auc: 0.9556\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3271 - accuracy: 0.9257 - auc: 0.9369 - val_loss: 0.2932 - val_accuracy: 0.9235 - val_auc: 0.9551\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3290 - accuracy: 0.9276 - auc: 0.9376 - val_loss: 0.2924 - val_accuracy: 0.9245 - val_auc: 0.9546\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3250 - accuracy: 0.9266 - auc: 0.9390 - val_loss: 0.2921 - val_accuracy: 0.9296 - val_auc: 0.9547\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3353 - accuracy: 0.9247 - auc: 0.9335 - val_loss: 0.2924 - val_accuracy: 0.9251 - val_auc: 0.9527\n",
      "Epoch 35/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.3453 - accuracy: 0.9251 - auc: 0.9321Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3452 - accuracy: 0.9251 - auc: 0.9317 - val_loss: 0.2946 - val_accuracy: 0.9246 - val_auc: 0.9546\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.8842 - accuracy: 0.3048 - auc: 0.6796 - val_loss: 0.5349 - val_accuracy: 0.4767 - val_auc: 0.8897\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.6076 - accuracy: 0.4794 - auc: 0.8203 - val_loss: 0.4195 - val_accuracy: 0.7312 - val_auc: 0.9178\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5024 - accuracy: 0.5876 - auc: 0.8640 - val_loss: 0.3474 - val_accuracy: 0.8127 - val_auc: 0.9369\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4520 - accuracy: 0.6411 - auc: 0.8788 - val_loss: 0.3234 - val_accuracy: 0.8362 - val_auc: 0.9437\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4201 - accuracy: 0.6667 - auc: 0.8940 - val_loss: 0.3057 - val_accuracy: 0.8507 - val_auc: 0.9473\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4156 - accuracy: 0.6854 - auc: 0.8986 - val_loss: 0.2958 - val_accuracy: 0.8667 - val_auc: 0.9500\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3824 - accuracy: 0.6984 - auc: 0.9071 - val_loss: 0.2872 - val_accuracy: 0.8784 - val_auc: 0.9519\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3762 - accuracy: 0.7125 - auc: 0.9095 - val_loss: 0.2841 - val_accuracy: 0.8815 - val_auc: 0.9534\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3695 - accuracy: 0.7138 - auc: 0.9110 - val_loss: 0.2843 - val_accuracy: 0.8858 - val_auc: 0.9532\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3652 - accuracy: 0.7201 - auc: 0.9139 - val_loss: 0.2833 - val_accuracy: 0.8796 - val_auc: 0.9524\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3629 - accuracy: 0.7189 - auc: 0.9100 - val_loss: 0.2828 - val_accuracy: 0.8783 - val_auc: 0.9530\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3521 - accuracy: 0.7190 - auc: 0.9164 - val_loss: 0.2813 - val_accuracy: 0.8809 - val_auc: 0.9529\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3416 - accuracy: 0.7253 - auc: 0.9206 - val_loss: 0.2831 - val_accuracy: 0.8810 - val_auc: 0.9527\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3485 - accuracy: 0.7259 - auc: 0.9177 - val_loss: 0.2845 - val_accuracy: 0.8839 - val_auc: 0.9519\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 10us/sample - loss: 0.3492 - accuracy: 0.7314 - auc: 0.9180 - val_loss: 0.2855 - val_accuracy: 0.8843 - val_auc: 0.9516\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 3s 10us/sample - loss: 0.3424 - accuracy: 0.7276 - auc: 0.9224 - val_loss: 0.2848 - val_accuracy: 0.8782 - val_auc: 0.9520\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3328 - accuracy: 0.7293 - auc: 0.9244 - val_loss: 0.2843 - val_accuracy: 0.8836 - val_auc: 0.9533\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3450 - accuracy: 0.7327 - auc: 0.9193 - val_loss: 0.2844 - val_accuracy: 0.8753 - val_auc: 0.9520\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3297 - accuracy: 0.7325 - auc: 0.9265 - val_loss: 0.2857 - val_accuracy: 0.8844 - val_auc: 0.9521\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3408 - accuracy: 0.7307 - auc: 0.9207 - val_loss: 0.2849 - val_accuracy: 0.8816 - val_auc: 0.9525\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3341 - accuracy: 0.7323 - auc: 0.9223 - val_loss: 0.2869 - val_accuracy: 0.8807 - val_auc: 0.9523\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3263 - accuracy: 0.7354 - auc: 0.9285 - val_loss: 0.2858 - val_accuracy: 0.8831 - val_auc: 0.9529\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3195 - accuracy: 0.7335 - auc: 0.9273 - val_loss: 0.2836 - val_accuracy: 0.8824 - val_auc: 0.9537\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3254 - accuracy: 0.7335 - auc: 0.9284 - val_loss: 0.2876 - val_accuracy: 0.8836 - val_auc: 0.9523\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3253 - accuracy: 0.7374 - auc: 0.9258 - val_loss: 0.2879 - val_accuracy: 0.8787 - val_auc: 0.9520\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3346 - accuracy: 0.7297 - auc: 0.9245 - val_loss: 0.2918 - val_accuracy: 0.8687 - val_auc: 0.9516\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3238 - accuracy: 0.7274 - auc: 0.9263 - val_loss: 0.2943 - val_accuracy: 0.8727 - val_auc: 0.9515\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3263 - accuracy: 0.7298 - auc: 0.9266 - val_loss: 0.2960 - val_accuracy: 0.8715 - val_auc: 0.9508\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3288 - accuracy: 0.7249 - auc: 0.9249 - val_loss: 0.2956 - val_accuracy: 0.8726 - val_auc: 0.9515\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3207 - accuracy: 0.7288 - auc: 0.9296 - val_loss: 0.2963 - val_accuracy: 0.8752 - val_auc: 0.9518\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3247 - accuracy: 0.7307 - auc: 0.9248 - val_loss: 0.3025 - val_accuracy: 0.8776 - val_auc: 0.9515\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3246 - accuracy: 0.7301 - auc: 0.9272 - val_loss: 0.3031 - val_accuracy: 0.8760 - val_auc: 0.9510\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3317 - accuracy: 0.7290 - auc: 0.9263 - val_loss: 0.3012 - val_accuracy: 0.8712 - val_auc: 0.9512\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3122 - accuracy: 0.7275 - auc: 0.9292 - val_loss: 0.2980 - val_accuracy: 0.8794 - val_auc: 0.9510\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3231 - accuracy: 0.7290 - auc: 0.9283 - val_loss: 0.3007 - val_accuracy: 0.8745 - val_auc: 0.9507\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3189 - accuracy: 0.7276 - auc: 0.9303 - val_loss: 0.3028 - val_accuracy: 0.8759 - val_auc: 0.9513\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3151 - accuracy: 0.7272 - auc: 0.9303 - val_loss: 0.3020 - val_accuracy: 0.8770 - val_auc: 0.9514\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3244 - accuracy: 0.7295 - auc: 0.9268 - val_loss: 0.3080 - val_accuracy: 0.8781 - val_auc: 0.9501\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3293 - accuracy: 0.7276 - auc: 0.9236 - val_loss: 0.3090 - val_accuracy: 0.8748 - val_auc: 0.9504\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3235 - accuracy: 0.7260 - auc: 0.9262 - val_loss: 0.3060 - val_accuracy: 0.8717 - val_auc: 0.9507\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3198 - accuracy: 0.7258 - auc: 0.9278 - val_loss: 0.3049 - val_accuracy: 0.8740 - val_auc: 0.9515\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3225 - accuracy: 0.7249 - auc: 0.9268 - val_loss: 0.3108 - val_accuracy: 0.8727 - val_auc: 0.9511\n",
      "Epoch 43/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.7281 - auc: 0.9297Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3153 - accuracy: 0.7284 - auc: 0.9297 - val_loss: 0.3111 - val_accuracy: 0.8747 - val_auc: 0.9517\n",
      "Epoch 00043: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.6586 - accuracy: 0.2993 - auc: 0.7385 - val_loss: 0.4803 - val_accuracy: 0.5379 - val_auc: 0.9108\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5001 - accuracy: 0.4563 - auc: 0.8603 - val_loss: 0.4024 - val_accuracy: 0.7580 - val_auc: 0.9367\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4551 - accuracy: 0.8098 - auc: 0.8828 - val_loss: 0.3519 - val_accuracy: 0.8635 - val_auc: 0.9460\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4143 - accuracy: 0.8573 - auc: 0.9015 - val_loss: 0.3217 - val_accuracy: 0.8883 - val_auc: 0.9498\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3840 - accuracy: 0.8784 - auc: 0.9124 - val_loss: 0.2997 - val_accuracy: 0.8982 - val_auc: 0.9530\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3671 - accuracy: 0.8912 - auc: 0.9162 - val_loss: 0.2852 - val_accuracy: 0.9017 - val_auc: 0.9553\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3567 - accuracy: 0.8912 - auc: 0.9222 - val_loss: 0.2813 - val_accuracy: 0.9059 - val_auc: 0.9547\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3565 - accuracy: 0.8959 - auc: 0.9222 - val_loss: 0.2780 - val_accuracy: 0.9066 - val_auc: 0.9555\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3502 - accuracy: 0.8995 - auc: 0.9229 - val_loss: 0.2748 - val_accuracy: 0.9062 - val_auc: 0.9560\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3603 - accuracy: 0.8992 - auc: 0.9211 - val_loss: 0.2744 - val_accuracy: 0.9039 - val_auc: 0.9559\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3489 - accuracy: 0.9013 - auc: 0.9209 - val_loss: 0.2735 - val_accuracy: 0.9109 - val_auc: 0.9562\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3498 - accuracy: 0.9067 - auc: 0.9213 - val_loss: 0.2721 - val_accuracy: 0.9050 - val_auc: 0.9566\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3423 - accuracy: 0.9048 - auc: 0.9293 - val_loss: 0.2724 - val_accuracy: 0.9054 - val_auc: 0.9558\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3385 - accuracy: 0.9064 - auc: 0.9280 - val_loss: 0.2720 - val_accuracy: 0.9103 - val_auc: 0.9562\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3403 - accuracy: 0.9099 - auc: 0.9248 - val_loss: 0.2758 - val_accuracy: 0.9057 - val_auc: 0.9556\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3345 - accuracy: 0.9089 - auc: 0.9293 - val_loss: 0.2773 - val_accuracy: 0.9072 - val_auc: 0.9552\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3311 - accuracy: 0.9096 - auc: 0.9287 - val_loss: 0.2804 - val_accuracy: 0.9138 - val_auc: 0.9540\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3385 - accuracy: 0.9135 - auc: 0.9281 - val_loss: 0.2791 - val_accuracy: 0.9103 - val_auc: 0.9543\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3326 - accuracy: 0.9135 - auc: 0.9278 - val_loss: 0.2807 - val_accuracy: 0.9094 - val_auc: 0.9545\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3276 - accuracy: 0.9125 - auc: 0.9306 - val_loss: 0.2823 - val_accuracy: 0.9103 - val_auc: 0.9544\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3194 - accuracy: 0.9117 - auc: 0.9333 - val_loss: 0.2832 - val_accuracy: 0.9108 - val_auc: 0.9538\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3354 - accuracy: 0.9153 - auc: 0.9284 - val_loss: 0.2848 - val_accuracy: 0.9111 - val_auc: 0.9539\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3365 - accuracy: 0.9127 - auc: 0.9275 - val_loss: 0.2874 - val_accuracy: 0.9093 - val_auc: 0.9533\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3294 - accuracy: 0.9135 - auc: 0.9307 - val_loss: 0.2880 - val_accuracy: 0.9097 - val_auc: 0.9537\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3146 - accuracy: 0.9130 - auc: 0.9384 - val_loss: 0.2909 - val_accuracy: 0.9117 - val_auc: 0.9532\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3155 - accuracy: 0.9154 - auc: 0.9360 - val_loss: 0.2947 - val_accuracy: 0.9138 - val_auc: 0.9524\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3143 - accuracy: 0.9156 - auc: 0.9371 - val_loss: 0.2941 - val_accuracy: 0.9118 - val_auc: 0.9530\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3221 - accuracy: 0.9175 - auc: 0.9344 - val_loss: 0.2973 - val_accuracy: 0.9105 - val_auc: 0.9526\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3176 - accuracy: 0.9155 - auc: 0.9365 - val_loss: 0.2996 - val_accuracy: 0.9159 - val_auc: 0.9519\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3163 - accuracy: 0.9179 - auc: 0.9358 - val_loss: 0.3035 - val_accuracy: 0.9156 - val_auc: 0.9512\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3161 - accuracy: 0.9182 - auc: 0.9362 - val_loss: 0.3078 - val_accuracy: 0.9186 - val_auc: 0.9499\n",
      "Epoch 32/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.3156 - accuracy: 0.9182 - auc: 0.9354Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3153 - accuracy: 0.9181 - auc: 0.9354 - val_loss: 0.3116 - val_accuracy: 0.9161 - val_auc: 0.9496\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 0.7782 - accuracy: 0.8168 - auc: 0.7364 - val_loss: 0.4047 - val_accuracy: 0.8597 - val_auc: 0.9127\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.5179 - accuracy: 0.8469 - auc: 0.8556 - val_loss: 0.3524 - val_accuracy: 0.8881 - val_auc: 0.9335\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4547 - accuracy: 0.8787 - auc: 0.8941 - val_loss: 0.3233 - val_accuracy: 0.8990 - val_auc: 0.9428\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4028 - accuracy: 0.8928 - auc: 0.9098 - val_loss: 0.3091 - val_accuracy: 0.9056 - val_auc: 0.9470\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3962 - accuracy: 0.8967 - auc: 0.9190 - val_loss: 0.2926 - val_accuracy: 0.9079 - val_auc: 0.9534\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3703 - accuracy: 0.8987 - auc: 0.9269 - val_loss: 0.2832 - val_accuracy: 0.9089 - val_auc: 0.9552\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3631 - accuracy: 0.9005 - auc: 0.9299 - val_loss: 0.2792 - val_accuracy: 0.9090 - val_auc: 0.9559\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3384 - accuracy: 0.9047 - auc: 0.9391 - val_loss: 0.2740 - val_accuracy: 0.9130 - val_auc: 0.9565\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3275 - accuracy: 0.9083 - auc: 0.9396 - val_loss: 0.2720 - val_accuracy: 0.9122 - val_auc: 0.9568\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3315 - accuracy: 0.9077 - auc: 0.9408 - val_loss: 0.2697 - val_accuracy: 0.9071 - val_auc: 0.9574\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3065 - accuracy: 0.9078 - auc: 0.9484 - val_loss: 0.2639 - val_accuracy: 0.9093 - val_auc: 0.9582\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3019 - accuracy: 0.9076 - auc: 0.9493 - val_loss: 0.2654 - val_accuracy: 0.9100 - val_auc: 0.9576\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2975 - accuracy: 0.9080 - auc: 0.9506 - val_loss: 0.2632 - val_accuracy: 0.9079 - val_auc: 0.9580\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2945 - accuracy: 0.9092 - auc: 0.9503 - val_loss: 0.2654 - val_accuracy: 0.9151 - val_auc: 0.9577\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2851 - accuracy: 0.9092 - auc: 0.9541 - val_loss: 0.2692 - val_accuracy: 0.9123 - val_auc: 0.9566\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2993 - accuracy: 0.9077 - auc: 0.9492 - val_loss: 0.2691 - val_accuracy: 0.9088 - val_auc: 0.9566\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2879 - accuracy: 0.9086 - auc: 0.9527 - val_loss: 0.2695 - val_accuracy: 0.9104 - val_auc: 0.9568\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2935 - accuracy: 0.9060 - auc: 0.9513 - val_loss: 0.2712 - val_accuracy: 0.9114 - val_auc: 0.9569\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2758 - accuracy: 0.9087 - auc: 0.9567 - val_loss: 0.2748 - val_accuracy: 0.9134 - val_auc: 0.9560\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2788 - accuracy: 0.9114 - auc: 0.9550 - val_loss: 0.2782 - val_accuracy: 0.9136 - val_auc: 0.9552\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2714 - accuracy: 0.9101 - auc: 0.9573 - val_loss: 0.2805 - val_accuracy: 0.9140 - val_auc: 0.9553\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2659 - accuracy: 0.9082 - auc: 0.9585 - val_loss: 0.2836 - val_accuracy: 0.9096 - val_auc: 0.9549\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2722 - accuracy: 0.9053 - auc: 0.9569 - val_loss: 0.2889 - val_accuracy: 0.9123 - val_auc: 0.9543\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2738 - accuracy: 0.9064 - auc: 0.9567 - val_loss: 0.2909 - val_accuracy: 0.9091 - val_auc: 0.9532\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2684 - accuracy: 0.9045 - auc: 0.9580 - val_loss: 0.2896 - val_accuracy: 0.9094 - val_auc: 0.9539\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2579 - accuracy: 0.9068 - auc: 0.9609 - val_loss: 0.2945 - val_accuracy: 0.9114 - val_auc: 0.9538\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2730 - accuracy: 0.9050 - auc: 0.9560 - val_loss: 0.2968 - val_accuracy: 0.9104 - val_auc: 0.9526\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2540 - accuracy: 0.9021 - auc: 0.9611 - val_loss: 0.2972 - val_accuracy: 0.9116 - val_auc: 0.9541\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2592 - accuracy: 0.9046 - auc: 0.9597 - val_loss: 0.3024 - val_accuracy: 0.9094 - val_auc: 0.9527\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2640 - accuracy: 0.9031 - auc: 0.9593 - val_loss: 0.3025 - val_accuracy: 0.9104 - val_auc: 0.9520\n",
      "Epoch 31/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2519 - accuracy: 0.9033 - auc: 0.9618Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2524 - accuracy: 0.9032 - auc: 0.9618 - val_loss: 0.3073 - val_accuracy: 0.9102 - val_auc: 0.9516\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 16us/sample - loss: 0.7183 - accuracy: 0.6793 - auc: 0.6945 - val_loss: 0.4592 - val_accuracy: 0.8122 - val_auc: 0.8891\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.5057 - accuracy: 0.8212 - auc: 0.8644 - val_loss: 0.3747 - val_accuracy: 0.8844 - val_auc: 0.9272\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4314 - accuracy: 0.8685 - auc: 0.8967 - val_loss: 0.3257 - val_accuracy: 0.8929 - val_auc: 0.9442\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3843 - accuracy: 0.8826 - auc: 0.9138 - val_loss: 0.3012 - val_accuracy: 0.9035 - val_auc: 0.9499\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3424 - accuracy: 0.8913 - auc: 0.9338 - val_loss: 0.2831 - val_accuracy: 0.8984 - val_auc: 0.9540\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3376 - accuracy: 0.8912 - auc: 0.9348 - val_loss: 0.2819 - val_accuracy: 0.8943 - val_auc: 0.9532\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3229 - accuracy: 0.8923 - auc: 0.9404 - val_loss: 0.2756 - val_accuracy: 0.9045 - val_auc: 0.9547\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3246 - accuracy: 0.8944 - auc: 0.9390 - val_loss: 0.2744 - val_accuracy: 0.9038 - val_auc: 0.9548\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2999 - accuracy: 0.8959 - auc: 0.9486 - val_loss: 0.2725 - val_accuracy: 0.9048 - val_auc: 0.9551\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3062 - accuracy: 0.8978 - auc: 0.9451 - val_loss: 0.2719 - val_accuracy: 0.9050 - val_auc: 0.9551\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2911 - accuracy: 0.9008 - auc: 0.9506 - val_loss: 0.2738 - val_accuracy: 0.9082 - val_auc: 0.9551\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2877 - accuracy: 0.9007 - auc: 0.9516 - val_loss: 0.2760 - val_accuracy: 0.9101 - val_auc: 0.9549\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2889 - accuracy: 0.8993 - auc: 0.9516 - val_loss: 0.2758 - val_accuracy: 0.9111 - val_auc: 0.9547\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2907 - accuracy: 0.9008 - auc: 0.9506 - val_loss: 0.2791 - val_accuracy: 0.9098 - val_auc: 0.9540\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2832 - accuracy: 0.9001 - auc: 0.9529 - val_loss: 0.2794 - val_accuracy: 0.9102 - val_auc: 0.9547\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2804 - accuracy: 0.9011 - auc: 0.9538 - val_loss: 0.2819 - val_accuracy: 0.9078 - val_auc: 0.9543\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2676 - accuracy: 0.9029 - auc: 0.9578 - val_loss: 0.2830 - val_accuracy: 0.9094 - val_auc: 0.9537\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2778 - accuracy: 0.9014 - auc: 0.9546 - val_loss: 0.2867 - val_accuracy: 0.9140 - val_auc: 0.9537\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2674 - accuracy: 0.8988 - auc: 0.9570 - val_loss: 0.2895 - val_accuracy: 0.9095 - val_auc: 0.9534\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2605 - accuracy: 0.9002 - auc: 0.9596 - val_loss: 0.2916 - val_accuracy: 0.9100 - val_auc: 0.9536\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2687 - accuracy: 0.9035 - auc: 0.9575 - val_loss: 0.2911 - val_accuracy: 0.9090 - val_auc: 0.9545\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2609 - accuracy: 0.9011 - auc: 0.9591 - val_loss: 0.2981 - val_accuracy: 0.9120 - val_auc: 0.9536\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2578 - accuracy: 0.9035 - auc: 0.9599 - val_loss: 0.3022 - val_accuracy: 0.9116 - val_auc: 0.9533\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2678 - accuracy: 0.9021 - auc: 0.9565 - val_loss: 0.3022 - val_accuracy: 0.9084 - val_auc: 0.9535\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2636 - accuracy: 0.8980 - auc: 0.9584 - val_loss: 0.3050 - val_accuracy: 0.9090 - val_auc: 0.9531\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2575 - accuracy: 0.8990 - auc: 0.9599 - val_loss: 0.3118 - val_accuracy: 0.9085 - val_auc: 0.9519\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2562 - accuracy: 0.8991 - auc: 0.9601 - val_loss: 0.3185 - val_accuracy: 0.9114 - val_auc: 0.9512\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2519 - accuracy: 0.9005 - auc: 0.9614 - val_loss: 0.3221 - val_accuracy: 0.9084 - val_auc: 0.9510\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2569 - accuracy: 0.8979 - auc: 0.9599 - val_loss: 0.3249 - val_accuracy: 0.9110 - val_auc: 0.9516\n",
      "Epoch 30/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9005 - auc: 0.9614Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2512 - accuracy: 0.9005 - auc: 0.9615 - val_loss: 0.3289 - val_accuracy: 0.9095 - val_auc: 0.9503\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 20us/sample - loss: 0.6915 - accuracy: 0.3289 - auc: 0.7004 - val_loss: 0.4802 - val_accuracy: 0.5665 - val_auc: 0.9054\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.4811 - accuracy: 0.5805 - auc: 0.8787 - val_loss: 0.3617 - val_accuracy: 0.8120 - val_auc: 0.9380\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3886 - accuracy: 0.7368 - auc: 0.9208 - val_loss: 0.3042 - val_accuracy: 0.8728 - val_auc: 0.9491\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3579 - accuracy: 0.7870 - auc: 0.9251 - val_loss: 0.2840 - val_accuracy: 0.8835 - val_auc: 0.9536\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3393 - accuracy: 0.8076 - auc: 0.9324 - val_loss: 0.2744 - val_accuracy: 0.8875 - val_auc: 0.9555\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3218 - accuracy: 0.8223 - auc: 0.9395 - val_loss: 0.2676 - val_accuracy: 0.8915 - val_auc: 0.9567\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3150 - accuracy: 0.8298 - auc: 0.9411 - val_loss: 0.2630 - val_accuracy: 0.8910 - val_auc: 0.9584\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3053 - accuracy: 0.8357 - auc: 0.9443 - val_loss: 0.2638 - val_accuracy: 0.8906 - val_auc: 0.9579\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 3s 11us/sample - loss: 0.3121 - accuracy: 0.8373 - auc: 0.9419 - val_loss: 0.2607 - val_accuracy: 0.8911 - val_auc: 0.9589\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2964 - accuracy: 0.8409 - auc: 0.9477 - val_loss: 0.2621 - val_accuracy: 0.8975 - val_auc: 0.9586\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2834 - accuracy: 0.8457 - auc: 0.9519 - val_loss: 0.2647 - val_accuracy: 0.8979 - val_auc: 0.9579\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2861 - accuracy: 0.8461 - auc: 0.9501 - val_loss: 0.2649 - val_accuracy: 0.8962 - val_auc: 0.9580\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2833 - accuracy: 0.8449 - auc: 0.9516 - val_loss: 0.2652 - val_accuracy: 0.8946 - val_auc: 0.9577\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2810 - accuracy: 0.8479 - auc: 0.9520 - val_loss: 0.2656 - val_accuracy: 0.8945 - val_auc: 0.9579\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2803 - accuracy: 0.8449 - auc: 0.9522 - val_loss: 0.2675 - val_accuracy: 0.8966 - val_auc: 0.9576\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2666 - accuracy: 0.8501 - auc: 0.9563 - val_loss: 0.2703 - val_accuracy: 0.8931 - val_auc: 0.9570\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2766 - accuracy: 0.8439 - auc: 0.9539 - val_loss: 0.2720 - val_accuracy: 0.8966 - val_auc: 0.9570\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2691 - accuracy: 0.8503 - auc: 0.9560 - val_loss: 0.2763 - val_accuracy: 0.8995 - val_auc: 0.9565\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2690 - accuracy: 0.8485 - auc: 0.9551 - val_loss: 0.2803 - val_accuracy: 0.9006 - val_auc: 0.9559\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2613 - accuracy: 0.8517 - auc: 0.9584 - val_loss: 0.2819 - val_accuracy: 0.9017 - val_auc: 0.9560\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2606 - accuracy: 0.8514 - auc: 0.9591 - val_loss: 0.2874 - val_accuracy: 0.8990 - val_auc: 0.9544\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2621 - accuracy: 0.8472 - auc: 0.9573 - val_loss: 0.2943 - val_accuracy: 0.9028 - val_auc: 0.9537\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2675 - accuracy: 0.8516 - auc: 0.9561 - val_loss: 0.3012 - val_accuracy: 0.9002 - val_auc: 0.9515\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2655 - accuracy: 0.8459 - auc: 0.9564 - val_loss: 0.2977 - val_accuracy: 0.8979 - val_auc: 0.9524\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2545 - accuracy: 0.8451 - auc: 0.9597 - val_loss: 0.2998 - val_accuracy: 0.8993 - val_auc: 0.9521\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2487 - accuracy: 0.8462 - auc: 0.9615 - val_loss: 0.3037 - val_accuracy: 0.9003 - val_auc: 0.9516\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2600 - accuracy: 0.8476 - auc: 0.9582 - val_loss: 0.3064 - val_accuracy: 0.8987 - val_auc: 0.9512\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2619 - accuracy: 0.8455 - auc: 0.9572 - val_loss: 0.3049 - val_accuracy: 0.8975 - val_auc: 0.9522\n",
      "Epoch 29/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2540 - accuracy: 0.8446 - auc: 0.9608Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2530 - accuracy: 0.8446 - auc: 0.9609 - val_loss: 0.3054 - val_accuracy: 0.8974 - val_auc: 0.9526\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.9337 - accuracy: 0.7490 - auc: 0.6560 - val_loss: 0.4620 - val_accuracy: 0.8198 - val_auc: 0.8953\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.5132 - accuracy: 0.8161 - auc: 0.8531 - val_loss: 0.3868 - val_accuracy: 0.8807 - val_auc: 0.9351\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4281 - accuracy: 0.8689 - auc: 0.9016 - val_loss: 0.3430 - val_accuracy: 0.9009 - val_auc: 0.9418\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3661 - accuracy: 0.8920 - auc: 0.9291 - val_loss: 0.3081 - val_accuracy: 0.9134 - val_auc: 0.9474\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3486 - accuracy: 0.8976 - auc: 0.9296 - val_loss: 0.2909 - val_accuracy: 0.9085 - val_auc: 0.9526\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3319 - accuracy: 0.8980 - auc: 0.9391 - val_loss: 0.2794 - val_accuracy: 0.9110 - val_auc: 0.9547\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3218 - accuracy: 0.9024 - auc: 0.9403 - val_loss: 0.2767 - val_accuracy: 0.9054 - val_auc: 0.9555\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3086 - accuracy: 0.8998 - auc: 0.9446 - val_loss: 0.2718 - val_accuracy: 0.9148 - val_auc: 0.9568\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3008 - accuracy: 0.9052 - auc: 0.9477 - val_loss: 0.2689 - val_accuracy: 0.9151 - val_auc: 0.9569\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2954 - accuracy: 0.9052 - auc: 0.9504 - val_loss: 0.2672 - val_accuracy: 0.9101 - val_auc: 0.9568\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2830 - accuracy: 0.9063 - auc: 0.9542 - val_loss: 0.2659 - val_accuracy: 0.9110 - val_auc: 0.9571\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2891 - accuracy: 0.9089 - auc: 0.9510 - val_loss: 0.2641 - val_accuracy: 0.9129 - val_auc: 0.9576\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2745 - accuracy: 0.9076 - auc: 0.9559 - val_loss: 0.2657 - val_accuracy: 0.9182 - val_auc: 0.9573\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2898 - accuracy: 0.9071 - auc: 0.9516 - val_loss: 0.2675 - val_accuracy: 0.9136 - val_auc: 0.9569\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2846 - accuracy: 0.9064 - auc: 0.9534 - val_loss: 0.2670 - val_accuracy: 0.9163 - val_auc: 0.9571\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2749 - accuracy: 0.9099 - auc: 0.9556 - val_loss: 0.2673 - val_accuracy: 0.9135 - val_auc: 0.9571\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2658 - accuracy: 0.9101 - auc: 0.9593 - val_loss: 0.2691 - val_accuracy: 0.9143 - val_auc: 0.9567\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2678 - accuracy: 0.9089 - auc: 0.9577 - val_loss: 0.2706 - val_accuracy: 0.9135 - val_auc: 0.9565\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2697 - accuracy: 0.9120 - auc: 0.9575 - val_loss: 0.2748 - val_accuracy: 0.9146 - val_auc: 0.9557\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2674 - accuracy: 0.9095 - auc: 0.9585 - val_loss: 0.2768 - val_accuracy: 0.9186 - val_auc: 0.9561\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2589 - accuracy: 0.9123 - auc: 0.9615 - val_loss: 0.2765 - val_accuracy: 0.9184 - val_auc: 0.9563\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2601 - accuracy: 0.9134 - auc: 0.9607 - val_loss: 0.2796 - val_accuracy: 0.9183 - val_auc: 0.9561\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2664 - accuracy: 0.9137 - auc: 0.9579 - val_loss: 0.2810 - val_accuracy: 0.9154 - val_auc: 0.9554\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2555 - accuracy: 0.9112 - auc: 0.9619 - val_loss: 0.2807 - val_accuracy: 0.9144 - val_auc: 0.9563\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2593 - accuracy: 0.9104 - auc: 0.9610 - val_loss: 0.2828 - val_accuracy: 0.9143 - val_auc: 0.9555\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2581 - accuracy: 0.9116 - auc: 0.9604 - val_loss: 0.2870 - val_accuracy: 0.9170 - val_auc: 0.9551\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2663 - accuracy: 0.9117 - auc: 0.9593 - val_loss: 0.2915 - val_accuracy: 0.9155 - val_auc: 0.9545\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2596 - accuracy: 0.9132 - auc: 0.9610 - val_loss: 0.2917 - val_accuracy: 0.9142 - val_auc: 0.9545\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2535 - accuracy: 0.9111 - auc: 0.9626 - val_loss: 0.2950 - val_accuracy: 0.9161 - val_auc: 0.9540\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2579 - accuracy: 0.9132 - auc: 0.9611 - val_loss: 0.3006 - val_accuracy: 0.9181 - val_auc: 0.9532\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2617 - accuracy: 0.9149 - auc: 0.9609 - val_loss: 0.3024 - val_accuracy: 0.9166 - val_auc: 0.9533\n",
      "Epoch 32/100\n",
      "244736/250291 [============================>.] - ETA: 0s - loss: 0.2534 - accuracy: 0.9145 - auc: 0.9623Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2539 - accuracy: 0.9145 - auc: 0.9621 - val_loss: 0.3056 - val_accuracy: 0.9164 - val_auc: 0.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 17us/sample - loss: 0.7931 - accuracy: 0.2961 - auc: 0.7484 - val_loss: 0.4594 - val_accuracy: 0.5795 - val_auc: 0.9267\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5130 - accuracy: 0.6170 - auc: 0.8776 - val_loss: 0.3448 - val_accuracy: 0.8273 - val_auc: 0.9437\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.4321 - accuracy: 0.7268 - auc: 0.9068 - val_loss: 0.3025 - val_accuracy: 0.8629 - val_auc: 0.9511\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3732 - accuracy: 0.7654 - auc: 0.9257 - val_loss: 0.2817 - val_accuracy: 0.8803 - val_auc: 0.9543\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3582 - accuracy: 0.7834 - auc: 0.9310 - val_loss: 0.2737 - val_accuracy: 0.8873 - val_auc: 0.9558\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3264 - accuracy: 0.8001 - auc: 0.9387 - val_loss: 0.2659 - val_accuracy: 0.8964 - val_auc: 0.9573\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3293 - accuracy: 0.8064 - auc: 0.9389 - val_loss: 0.2679 - val_accuracy: 0.9003 - val_auc: 0.9565\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3170 - accuracy: 0.8159 - auc: 0.9427 - val_loss: 0.2669 - val_accuracy: 0.9032 - val_auc: 0.9568\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.3063 - accuracy: 0.8170 - auc: 0.9464 - val_loss: 0.2650 - val_accuracy: 0.9020 - val_auc: 0.9570\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2967 - accuracy: 0.8210 - auc: 0.9501 - val_loss: 0.2650 - val_accuracy: 0.9073 - val_auc: 0.9570\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2975 - accuracy: 0.8416 - auc: 0.9487 - val_loss: 0.2647 - val_accuracy: 0.9078 - val_auc: 0.9573\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2897 - accuracy: 0.8867 - auc: 0.9510 - val_loss: 0.2631 - val_accuracy: 0.9025 - val_auc: 0.9577\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2861 - accuracy: 0.8854 - auc: 0.9520 - val_loss: 0.2681 - val_accuracy: 0.9076 - val_auc: 0.9569\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2695 - accuracy: 0.8894 - auc: 0.9586 - val_loss: 0.2684 - val_accuracy: 0.9106 - val_auc: 0.9570\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2739 - accuracy: 0.8943 - auc: 0.9570 - val_loss: 0.2716 - val_accuracy: 0.9104 - val_auc: 0.9566\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2736 - accuracy: 0.8958 - auc: 0.9569 - val_loss: 0.2720 - val_accuracy: 0.9111 - val_auc: 0.9568\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2653 - accuracy: 0.8975 - auc: 0.9595 - val_loss: 0.2727 - val_accuracy: 0.9119 - val_auc: 0.9563\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2733 - accuracy: 0.8995 - auc: 0.9567 - val_loss: 0.2790 - val_accuracy: 0.9133 - val_auc: 0.9551\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2577 - accuracy: 0.9028 - auc: 0.9617 - val_loss: 0.2809 - val_accuracy: 0.9118 - val_auc: 0.9551\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2680 - accuracy: 0.8978 - auc: 0.9577 - val_loss: 0.2871 - val_accuracy: 0.9125 - val_auc: 0.9538\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2598 - accuracy: 0.9020 - auc: 0.9604 - val_loss: 0.2850 - val_accuracy: 0.9136 - val_auc: 0.9551\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2608 - accuracy: 0.9046 - auc: 0.9605 - val_loss: 0.2880 - val_accuracy: 0.9128 - val_auc: 0.9545\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2587 - accuracy: 0.9029 - auc: 0.9614 - val_loss: 0.2928 - val_accuracy: 0.9160 - val_auc: 0.9542\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2609 - accuracy: 0.9048 - auc: 0.9599 - val_loss: 0.2914 - val_accuracy: 0.9092 - val_auc: 0.9548\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2549 - accuracy: 0.9006 - auc: 0.9626 - val_loss: 0.2965 - val_accuracy: 0.9121 - val_auc: 0.9534\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2538 - accuracy: 0.9038 - auc: 0.9623 - val_loss: 0.2982 - val_accuracy: 0.9133 - val_auc: 0.9538\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2589 - accuracy: 0.9039 - auc: 0.9602 - val_loss: 0.3050 - val_accuracy: 0.9127 - val_auc: 0.9523\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2572 - accuracy: 0.9042 - auc: 0.9608 - val_loss: 0.3078 - val_accuracy: 0.9100 - val_auc: 0.9520\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2452 - accuracy: 0.9033 - auc: 0.9645 - val_loss: 0.3124 - val_accuracy: 0.9124 - val_auc: 0.9522\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2559 - accuracy: 0.9051 - auc: 0.9616 - val_loss: 0.3136 - val_accuracy: 0.9130 - val_auc: 0.9526\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2455 - accuracy: 0.9038 - auc: 0.9646 - val_loss: 0.3216 - val_accuracy: 0.9162 - val_auc: 0.9517\n",
      "Epoch 32/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9059 - auc: 0.9647Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.2460 - accuracy: 0.9059 - auc: 0.9646 - val_loss: 0.3213 - val_accuracy: 0.9137 - val_auc: 0.9510\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 0.6524 - accuracy: 0.4778 - auc: 0.8055 - val_loss: 0.3905 - val_accuracy: 0.7970 - val_auc: 0.9325\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4327 - accuracy: 0.7558 - auc: 0.9059 - val_loss: 0.3239 - val_accuracy: 0.8724 - val_auc: 0.9451\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3579 - accuracy: 0.8183 - auc: 0.9327 - val_loss: 0.2894 - val_accuracy: 0.8966 - val_auc: 0.9511\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3420 - accuracy: 0.8416 - auc: 0.9348 - val_loss: 0.2688 - val_accuracy: 0.8940 - val_auc: 0.9575\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3012 - accuracy: 0.8514 - auc: 0.9490 - val_loss: 0.2605 - val_accuracy: 0.8990 - val_auc: 0.9591\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2983 - accuracy: 0.8594 - auc: 0.9496 - val_loss: 0.2578 - val_accuracy: 0.9003 - val_auc: 0.9599\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2743 - accuracy: 0.8675 - auc: 0.9563 - val_loss: 0.2580 - val_accuracy: 0.9049 - val_auc: 0.9593\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2861 - accuracy: 0.8676 - auc: 0.9530 - val_loss: 0.2549 - val_accuracy: 0.9037 - val_auc: 0.9605\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2599 - accuracy: 0.8733 - auc: 0.9605 - val_loss: 0.2563 - val_accuracy: 0.9091 - val_auc: 0.9602\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2639 - accuracy: 0.8771 - auc: 0.9589 - val_loss: 0.2547 - val_accuracy: 0.9058 - val_auc: 0.9605\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2503 - accuracy: 0.8795 - auc: 0.9626 - val_loss: 0.2576 - val_accuracy: 0.9046 - val_auc: 0.9599\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2516 - accuracy: 0.8800 - auc: 0.9627 - val_loss: 0.2585 - val_accuracy: 0.9079 - val_auc: 0.9600\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2402 - accuracy: 0.8843 - auc: 0.9652 - val_loss: 0.2555 - val_accuracy: 0.9036 - val_auc: 0.9610\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2454 - accuracy: 0.8836 - auc: 0.9638 - val_loss: 0.2568 - val_accuracy: 0.9088 - val_auc: 0.9612\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2418 - accuracy: 0.8894 - auc: 0.9650 - val_loss: 0.2643 - val_accuracy: 0.9097 - val_auc: 0.9599\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2392 - accuracy: 0.8895 - auc: 0.9654 - val_loss: 0.2690 - val_accuracy: 0.9108 - val_auc: 0.9591\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2291 - accuracy: 0.8922 - auc: 0.9682 - val_loss: 0.2712 - val_accuracy: 0.9099 - val_auc: 0.9590\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2350 - accuracy: 0.8916 - auc: 0.9672 - val_loss: 0.2722 - val_accuracy: 0.9134 - val_auc: 0.9594\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2312 - accuracy: 0.8935 - auc: 0.9674 - val_loss: 0.2779 - val_accuracy: 0.9166 - val_auc: 0.9576\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2281 - accuracy: 0.8960 - auc: 0.9681 - val_loss: 0.2807 - val_accuracy: 0.9124 - val_auc: 0.9568\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.2313 - accuracy: 0.8927 - auc: 0.9674 - val_loss: 0.2864 - val_accuracy: 0.9135 - val_auc: 0.9554\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2240 - accuracy: 0.8944 - auc: 0.9694 - val_loss: 0.2887 - val_accuracy: 0.9141 - val_auc: 0.9555\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2383 - accuracy: 0.8965 - auc: 0.9668 - val_loss: 0.2883 - val_accuracy: 0.9094 - val_auc: 0.9560\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2316 - accuracy: 0.8923 - auc: 0.9676 - val_loss: 0.2934 - val_accuracy: 0.9143 - val_auc: 0.9547\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2275 - accuracy: 0.8958 - auc: 0.9687 - val_loss: 0.2922 - val_accuracy: 0.9142 - val_auc: 0.9558\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2242 - accuracy: 0.8981 - auc: 0.9694 - val_loss: 0.2968 - val_accuracy: 0.9112 - val_auc: 0.9551\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2209 - accuracy: 0.8955 - auc: 0.9702 - val_loss: 0.3001 - val_accuracy: 0.9169 - val_auc: 0.9547\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2181 - accuracy: 0.9024 - auc: 0.9708 - val_loss: 0.3049 - val_accuracy: 0.9134 - val_auc: 0.9543\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2189 - accuracy: 0.8967 - auc: 0.9706 - val_loss: 0.3083 - val_accuracy: 0.9164 - val_auc: 0.9537\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2083 - accuracy: 0.9018 - auc: 0.9732 - val_loss: 0.3105 - val_accuracy: 0.9173 - val_auc: 0.9531\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2121 - accuracy: 0.9018 - auc: 0.9719 - val_loss: 0.3198 - val_accuracy: 0.9195 - val_auc: 0.9526\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2119 - accuracy: 0.8993 - auc: 0.9722 - val_loss: 0.3232 - val_accuracy: 0.9174 - val_auc: 0.9523\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2110 - accuracy: 0.9020 - auc: 0.9722 - val_loss: 0.3283 - val_accuracy: 0.9169 - val_auc: 0.9517\n",
      "Epoch 34/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.9005 - auc: 0.9721Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2127 - accuracy: 0.9005 - auc: 0.9720 - val_loss: 0.3311 - val_accuracy: 0.9166 - val_auc: 0.9521\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.7396 - accuracy: 0.4453 - auc: 0.7301 - val_loss: 0.4428 - val_accuracy: 0.7055 - val_auc: 0.9153\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.4852 - accuracy: 0.7093 - auc: 0.8818 - val_loss: 0.3431 - val_accuracy: 0.8607 - val_auc: 0.9412\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3816 - accuracy: 0.8226 - auc: 0.9220 - val_loss: 0.3010 - val_accuracy: 0.8793 - val_auc: 0.9499\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3374 - accuracy: 0.8490 - auc: 0.9355 - val_loss: 0.2817 - val_accuracy: 0.9005 - val_auc: 0.9531\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2985 - accuracy: 0.8688 - auc: 0.9483 - val_loss: 0.2730 - val_accuracy: 0.9039 - val_auc: 0.9552\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2886 - accuracy: 0.8771 - auc: 0.9530 - val_loss: 0.2708 - val_accuracy: 0.9084 - val_auc: 0.9556\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2842 - accuracy: 0.8844 - auc: 0.9523 - val_loss: 0.2686 - val_accuracy: 0.9073 - val_auc: 0.9561\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2726 - accuracy: 0.8873 - auc: 0.9566 - val_loss: 0.2728 - val_accuracy: 0.9126 - val_auc: 0.9553\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2637 - accuracy: 0.8923 - auc: 0.9584 - val_loss: 0.2749 - val_accuracy: 0.9125 - val_auc: 0.9545\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2565 - accuracy: 0.8937 - auc: 0.9610 - val_loss: 0.2753 - val_accuracy: 0.9151 - val_auc: 0.9552\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2528 - accuracy: 0.8963 - auc: 0.9617 - val_loss: 0.2794 - val_accuracy: 0.9087 - val_auc: 0.9542\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2462 - accuracy: 0.8934 - auc: 0.9635 - val_loss: 0.2839 - val_accuracy: 0.9176 - val_auc: 0.9539\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2440 - accuracy: 0.8982 - auc: 0.9645 - val_loss: 0.2860 - val_accuracy: 0.9146 - val_auc: 0.9530\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2416 - accuracy: 0.9013 - auc: 0.9649 - val_loss: 0.2914 - val_accuracy: 0.9172 - val_auc: 0.9528\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2355 - accuracy: 0.9036 - auc: 0.9664 - val_loss: 0.2929 - val_accuracy: 0.9148 - val_auc: 0.9533\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2376 - accuracy: 0.8997 - auc: 0.9659 - val_loss: 0.3001 - val_accuracy: 0.9155 - val_auc: 0.9526\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2357 - accuracy: 0.8997 - auc: 0.9664 - val_loss: 0.3023 - val_accuracy: 0.9163 - val_auc: 0.9522\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2329 - accuracy: 0.9041 - auc: 0.9671 - val_loss: 0.3036 - val_accuracy: 0.9130 - val_auc: 0.9517\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2163 - accuracy: 0.9038 - auc: 0.9713 - val_loss: 0.3143 - val_accuracy: 0.9240 - val_auc: 0.9517\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2359 - accuracy: 0.9066 - auc: 0.9662 - val_loss: 0.3121 - val_accuracy: 0.9176 - val_auc: 0.9519\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2255 - accuracy: 0.9063 - auc: 0.9691 - val_loss: 0.3189 - val_accuracy: 0.9182 - val_auc: 0.9507\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2214 - accuracy: 0.9073 - auc: 0.9701 - val_loss: 0.3225 - val_accuracy: 0.9185 - val_auc: 0.9515\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2146 - accuracy: 0.9060 - auc: 0.9718 - val_loss: 0.3274 - val_accuracy: 0.9218 - val_auc: 0.9517\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2238 - accuracy: 0.9059 - auc: 0.9693 - val_loss: 0.3322 - val_accuracy: 0.9205 - val_auc: 0.9517\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2166 - accuracy: 0.9070 - auc: 0.9709 - val_loss: 0.3408 - val_accuracy: 0.9189 - val_auc: 0.9498\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2127 - accuracy: 0.9069 - auc: 0.9721 - val_loss: 0.3458 - val_accuracy: 0.9248 - val_auc: 0.9499\n",
      "Epoch 27/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9084 - auc: 0.9701Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2216 - accuracy: 0.9084 - auc: 0.9698 - val_loss: 0.3504 - val_accuracy: 0.9220 - val_auc: 0.9489\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 17us/sample - loss: 0.7973 - accuracy: 0.4175 - auc: 0.7103 - val_loss: 0.4497 - val_accuracy: 0.6937 - val_auc: 0.9062\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.4611 - accuracy: 0.7143 - auc: 0.8930 - val_loss: 0.3432 - val_accuracy: 0.8546 - val_auc: 0.9334\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 10us/sample - loss: 0.3763 - accuracy: 0.8019 - auc: 0.9219 - val_loss: 0.3073 - val_accuracy: 0.8810 - val_auc: 0.9442\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 3s 10us/sample - loss: 0.3455 - accuracy: 0.8294 - auc: 0.9332 - val_loss: 0.2892 - val_accuracy: 0.8865 - val_auc: 0.9500\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.3199 - accuracy: 0.8438 - auc: 0.9401 - val_loss: 0.2824 - val_accuracy: 0.8929 - val_auc: 0.9523\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.3040 - accuracy: 0.8495 - auc: 0.9452 - val_loss: 0.2798 - val_accuracy: 0.8985 - val_auc: 0.9525\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2977 - accuracy: 0.8568 - auc: 0.9468 - val_loss: 0.2774 - val_accuracy: 0.8967 - val_auc: 0.9541\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2810 - accuracy: 0.8644 - auc: 0.9523 - val_loss: 0.2751 - val_accuracy: 0.8993 - val_auc: 0.9545\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 9us/sample - loss: 0.2655 - accuracy: 0.8687 - auc: 0.9575 - val_loss: 0.2754 - val_accuracy: 0.9023 - val_auc: 0.9541\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2724 - accuracy: 0.8695 - auc: 0.9561 - val_loss: 0.2777 - val_accuracy: 0.9036 - val_auc: 0.9542\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2563 - accuracy: 0.8759 - auc: 0.9601 - val_loss: 0.2809 - val_accuracy: 0.9061 - val_auc: 0.9540\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2602 - accuracy: 0.8735 - auc: 0.9587 - val_loss: 0.2791 - val_accuracy: 0.9029 - val_auc: 0.9543\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2546 - accuracy: 0.8771 - auc: 0.9606 - val_loss: 0.2851 - val_accuracy: 0.9078 - val_auc: 0.9538\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2416 - accuracy: 0.8789 - auc: 0.9641 - val_loss: 0.2901 - val_accuracy: 0.9107 - val_auc: 0.9536\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2474 - accuracy: 0.8815 - auc: 0.9623 - val_loss: 0.2919 - val_accuracy: 0.9045 - val_auc: 0.9529\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2498 - accuracy: 0.8813 - auc: 0.9618 - val_loss: 0.2986 - val_accuracy: 0.9057 - val_auc: 0.9516\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2477 - accuracy: 0.8785 - auc: 0.9621 - val_loss: 0.2974 - val_accuracy: 0.9041 - val_auc: 0.9516\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2380 - accuracy: 0.8827 - auc: 0.9651 - val_loss: 0.3005 - val_accuracy: 0.9088 - val_auc: 0.9519\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2399 - accuracy: 0.8833 - auc: 0.9645 - val_loss: 0.3083 - val_accuracy: 0.9102 - val_auc: 0.9504\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2296 - accuracy: 0.8874 - auc: 0.9672 - val_loss: 0.3101 - val_accuracy: 0.9135 - val_auc: 0.9515\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2276 - accuracy: 0.8879 - auc: 0.9678 - val_loss: 0.3173 - val_accuracy: 0.9119 - val_auc: 0.9498\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2274 - accuracy: 0.8892 - auc: 0.9676 - val_loss: 0.3240 - val_accuracy: 0.9122 - val_auc: 0.9494\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2278 - accuracy: 0.8854 - auc: 0.9675 - val_loss: 0.3349 - val_accuracy: 0.9133 - val_auc: 0.9470\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2208 - accuracy: 0.8907 - auc: 0.9691 - val_loss: 0.3404 - val_accuracy: 0.9095 - val_auc: 0.9466\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2246 - accuracy: 0.8879 - auc: 0.9679 - val_loss: 0.3400 - val_accuracy: 0.9060 - val_auc: 0.9469\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2181 - accuracy: 0.8859 - auc: 0.9695 - val_loss: 0.3463 - val_accuracy: 0.9127 - val_auc: 0.9458\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2278 - accuracy: 0.8902 - auc: 0.9674 - val_loss: 0.3527 - val_accuracy: 0.9116 - val_auc: 0.9453\n",
      "Epoch 28/100\n",
      "248832/250290 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.8882 - auc: 0.9690Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.2211 - accuracy: 0.8881 - auc: 0.9689 - val_loss: 0.3661 - val_accuracy: 0.9085 - val_auc: 0.9433\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.6475 - accuracy: 0.5888 - auc: 0.7968 - val_loss: 0.4051 - val_accuracy: 0.8147 - val_auc: 0.9117\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4563 - accuracy: 0.7676 - auc: 0.8922 - val_loss: 0.3382 - val_accuracy: 0.8714 - val_auc: 0.9338\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3714 - accuracy: 0.8304 - auc: 0.9208 - val_loss: 0.3131 - val_accuracy: 0.8911 - val_auc: 0.9404\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3428 - accuracy: 0.8507 - auc: 0.9328 - val_loss: 0.2951 - val_accuracy: 0.8967 - val_auc: 0.9467\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3133 - accuracy: 0.8702 - auc: 0.9434 - val_loss: 0.2909 - val_accuracy: 0.9057 - val_auc: 0.9474\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3012 - accuracy: 0.8794 - auc: 0.9457 - val_loss: 0.2892 - val_accuracy: 0.8976 - val_auc: 0.9487\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2828 - accuracy: 0.8807 - auc: 0.9526 - val_loss: 0.2849 - val_accuracy: 0.9045 - val_auc: 0.9500\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2726 - accuracy: 0.8868 - auc: 0.9558 - val_loss: 0.2782 - val_accuracy: 0.9016 - val_auc: 0.9526\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2688 - accuracy: 0.8868 - auc: 0.9569 - val_loss: 0.2779 - val_accuracy: 0.9036 - val_auc: 0.9527\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2662 - accuracy: 0.8898 - auc: 0.9575 - val_loss: 0.2779 - val_accuracy: 0.9034 - val_auc: 0.9533\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2635 - accuracy: 0.8929 - auc: 0.9582 - val_loss: 0.2784 - val_accuracy: 0.9023 - val_auc: 0.9534\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2445 - accuracy: 0.8926 - auc: 0.9643 - val_loss: 0.2812 - val_accuracy: 0.9100 - val_auc: 0.9536\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2477 - accuracy: 0.8963 - auc: 0.9631 - val_loss: 0.2846 - val_accuracy: 0.9100 - val_auc: 0.9527\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2509 - accuracy: 0.8971 - auc: 0.9620 - val_loss: 0.2846 - val_accuracy: 0.9091 - val_auc: 0.9534\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2418 - accuracy: 0.8972 - auc: 0.9647 - val_loss: 0.2915 - val_accuracy: 0.9123 - val_auc: 0.9521\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2360 - accuracy: 0.8993 - auc: 0.9663 - val_loss: 0.2958 - val_accuracy: 0.9179 - val_auc: 0.9529\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2368 - accuracy: 0.9001 - auc: 0.9659 - val_loss: 0.2941 - val_accuracy: 0.9136 - val_auc: 0.9528\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2277 - accuracy: 0.9034 - auc: 0.9684 - val_loss: 0.3040 - val_accuracy: 0.9148 - val_auc: 0.9521\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2312 - accuracy: 0.9015 - auc: 0.9673 - val_loss: 0.3065 - val_accuracy: 0.9139 - val_auc: 0.9512\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2270 - accuracy: 0.9008 - auc: 0.9682 - val_loss: 0.3069 - val_accuracy: 0.9141 - val_auc: 0.9516\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2261 - accuracy: 0.9019 - auc: 0.9687 - val_loss: 0.3159 - val_accuracy: 0.9172 - val_auc: 0.9512\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2354 - accuracy: 0.8999 - auc: 0.9666 - val_loss: 0.3162 - val_accuracy: 0.9142 - val_auc: 0.9515\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2248 - accuracy: 0.9040 - auc: 0.9692 - val_loss: 0.3231 - val_accuracy: 0.9123 - val_auc: 0.9509\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2228 - accuracy: 0.8987 - auc: 0.9694 - val_loss: 0.3325 - val_accuracy: 0.9130 - val_auc: 0.9495\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2183 - accuracy: 0.8993 - auc: 0.9702 - val_loss: 0.3420 - val_accuracy: 0.9175 - val_auc: 0.9497\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2160 - accuracy: 0.9047 - auc: 0.9709 - val_loss: 0.3474 - val_accuracy: 0.9138 - val_auc: 0.9487\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2178 - accuracy: 0.9011 - auc: 0.9704 - val_loss: 0.3548 - val_accuracy: 0.9142 - val_auc: 0.9456\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2075 - accuracy: 0.9038 - auc: 0.9729 - val_loss: 0.3631 - val_accuracy: 0.9187 - val_auc: 0.9459\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2136 - accuracy: 0.9042 - auc: 0.9717 - val_loss: 0.3682 - val_accuracy: 0.9158 - val_auc: 0.9454\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2083 - accuracy: 0.9023 - auc: 0.9726 - val_loss: 0.3793 - val_accuracy: 0.9174 - val_auc: 0.9447\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2096 - accuracy: 0.9051 - auc: 0.9727 - val_loss: 0.3898 - val_accuracy: 0.9148 - val_auc: 0.9435\n",
      "Epoch 32/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9031 - auc: 0.9731Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2053 - accuracy: 0.9032 - auc: 0.9734 - val_loss: 0.3944 - val_accuracy: 0.9160 - val_auc: 0.9443\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 16us/sample - loss: 0.9607 - accuracy: 0.8940 - auc: 0.7103 - val_loss: 0.4366 - val_accuracy: 0.8937 - val_auc: 0.8989\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4889 - accuracy: 0.8561 - auc: 0.8826 - val_loss: 0.3715 - val_accuracy: 0.8920 - val_auc: 0.9289\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4101 - accuracy: 0.8782 - auc: 0.9132 - val_loss: 0.3376 - val_accuracy: 0.8920 - val_auc: 0.9396\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3641 - accuracy: 0.8841 - auc: 0.9272 - val_loss: 0.3191 - val_accuracy: 0.9030 - val_auc: 0.9451\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3496 - accuracy: 0.8937 - auc: 0.9341 - val_loss: 0.3034 - val_accuracy: 0.9023 - val_auc: 0.9483\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3199 - accuracy: 0.8987 - auc: 0.9430 - val_loss: 0.2973 - val_accuracy: 0.9059 - val_auc: 0.9503\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.3028 - accuracy: 0.8978 - auc: 0.9490 - val_loss: 0.2911 - val_accuracy: 0.9113 - val_auc: 0.9517\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2928 - accuracy: 0.9074 - auc: 0.9522 - val_loss: 0.2910 - val_accuracy: 0.9132 - val_auc: 0.9518\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2913 - accuracy: 0.9064 - auc: 0.9549 - val_loss: 0.2832 - val_accuracy: 0.9145 - val_auc: 0.9522\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2814 - accuracy: 0.9057 - auc: 0.9557 - val_loss: 0.2797 - val_accuracy: 0.9146 - val_auc: 0.9534\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2691 - accuracy: 0.9113 - auc: 0.9585 - val_loss: 0.2823 - val_accuracy: 0.9149 - val_auc: 0.9532\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2744 - accuracy: 0.9083 - auc: 0.9573 - val_loss: 0.2826 - val_accuracy: 0.9212 - val_auc: 0.9531\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2601 - accuracy: 0.9121 - auc: 0.9613 - val_loss: 0.2821 - val_accuracy: 0.9149 - val_auc: 0.9531\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2641 - accuracy: 0.9106 - auc: 0.9606 - val_loss: 0.2855 - val_accuracy: 0.9204 - val_auc: 0.9528\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2516 - accuracy: 0.9134 - auc: 0.9638 - val_loss: 0.2926 - val_accuracy: 0.9206 - val_auc: 0.9522\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2437 - accuracy: 0.9133 - auc: 0.9660 - val_loss: 0.2908 - val_accuracy: 0.9170 - val_auc: 0.9518\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2472 - accuracy: 0.9147 - auc: 0.9647 - val_loss: 0.2956 - val_accuracy: 0.9211 - val_auc: 0.9501\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2433 - accuracy: 0.9141 - auc: 0.9659 - val_loss: 0.3014 - val_accuracy: 0.9200 - val_auc: 0.9496\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2427 - accuracy: 0.9158 - auc: 0.9658 - val_loss: 0.3016 - val_accuracy: 0.9197 - val_auc: 0.9493\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2401 - accuracy: 0.9151 - auc: 0.9663 - val_loss: 0.3092 - val_accuracy: 0.9216 - val_auc: 0.9490\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2361 - accuracy: 0.9149 - auc: 0.9672 - val_loss: 0.3151 - val_accuracy: 0.9207 - val_auc: 0.9484\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2335 - accuracy: 0.9146 - auc: 0.9679 - val_loss: 0.3239 - val_accuracy: 0.9218 - val_auc: 0.9482\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2356 - accuracy: 0.9141 - auc: 0.9675 - val_loss: 0.3335 - val_accuracy: 0.9207 - val_auc: 0.9478\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2220 - accuracy: 0.9170 - auc: 0.9704 - val_loss: 0.3365 - val_accuracy: 0.9209 - val_auc: 0.9486\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2277 - accuracy: 0.9118 - auc: 0.9687 - val_loss: 0.3444 - val_accuracy: 0.9215 - val_auc: 0.9487\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2243 - accuracy: 0.9158 - auc: 0.9698 - val_loss: 0.3464 - val_accuracy: 0.9183 - val_auc: 0.9479\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2192 - accuracy: 0.9147 - auc: 0.9707 - val_loss: 0.3537 - val_accuracy: 0.9181 - val_auc: 0.9474\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2249 - accuracy: 0.9108 - auc: 0.9690 - val_loss: 0.3624 - val_accuracy: 0.9221 - val_auc: 0.9471\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2181 - accuracy: 0.9121 - auc: 0.9709 - val_loss: 0.3738 - val_accuracy: 0.9263 - val_auc: 0.9458\n",
      "Epoch 30/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9140 - auc: 0.9718Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.2134 - accuracy: 0.9140 - auc: 0.9718 - val_loss: 0.3758 - val_accuracy: 0.9216 - val_auc: 0.9458\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.7047 - accuracy: 0.7775 - auc: 0.7506 - val_loss: 0.4200 - val_accuracy: 0.7589 - val_auc: 0.9349\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6237 - accuracy: 0.8837 - auc: 0.8119 - val_loss: 0.3855 - val_accuracy: 0.9125 - val_auc: 0.9353\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5363 - accuracy: 0.8585 - auc: 0.8452 - val_loss: 0.4784 - val_accuracy: 0.9284 - val_auc: 0.9090\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5210 - accuracy: 0.7898 - auc: 0.8462 - val_loss: 0.7487 - val_accuracy: 0.6810 - val_auc: 0.9352\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 8us/sample - loss: 0.4671 - accuracy: 0.5010 - auc: 0.8319 - val_loss: 0.7183 - val_accuracy: 0.7576 - val_auc: 0.9372\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4751 - accuracy: 0.5302 - auc: 0.8359 - val_loss: 0.5002 - val_accuracy: 0.7805 - val_auc: 0.9243\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5209 - accuracy: 0.5202 - auc: 0.8127 - val_loss: 0.5196 - val_accuracy: 0.7509 - val_auc: 0.9310\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5177 - accuracy: 0.5336 - auc: 0.8146 - val_loss: 0.8193 - val_accuracy: 0.7191 - val_auc: 0.8989\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5711 - accuracy: 0.4940 - auc: 0.7638 - val_loss: 0.6977 - val_accuracy: 0.7204 - val_auc: 0.8397\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5315 - accuracy: 0.4909 - auc: 0.7367 - val_loss: 0.6217 - val_accuracy: 0.7053 - val_auc: 0.8400\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5107 - accuracy: 0.5062 - auc: 0.7511 - val_loss: 0.6862 - val_accuracy: 0.7113 - val_auc: 0.8442\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4923 - accuracy: 0.5148 - auc: 0.7589 - val_loss: 0.7155 - val_accuracy: 0.7451 - val_auc: 0.8556\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6614 - accuracy: 0.5148 - auc: 0.7419 - val_loss: 1.2020 - val_accuracy: 0.5610 - val_auc: 0.7122\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6927 - accuracy: 0.4572 - auc: 0.7031 - val_loss: 1.1403 - val_accuracy: 0.6667 - val_auc: 0.8132\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.8644 - accuracy: 0.4277 - auc: 0.6972 - val_loss: 1.4322 - val_accuracy: 0.6417 - val_auc: 0.8035\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6030 - accuracy: 0.4231 - auc: 0.7041 - val_loss: 1.0887 - val_accuracy: 0.6075 - val_auc: 0.7922\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5839 - accuracy: 0.4214 - auc: 0.7099 - val_loss: 0.8458 - val_accuracy: 0.6034 - val_auc: 0.7918\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5408 - accuracy: 0.4234 - auc: 0.7031 - val_loss: 0.7543 - val_accuracy: 0.6118 - val_auc: 0.7976\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5259 - accuracy: 0.4408 - auc: 0.7271 - val_loss: 0.7187 - val_accuracy: 0.6398 - val_auc: 0.8076\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5137 - accuracy: 0.4545 - auc: 0.7261 - val_loss: 0.7532 - val_accuracy: 0.6618 - val_auc: 0.8160\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5073 - accuracy: 0.4712 - auc: 0.7332 - val_loss: 0.7733 - val_accuracy: 0.6823 - val_auc: 0.8254\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5065 - accuracy: 0.4765 - auc: 0.7407 - val_loss: 0.6326 - val_accuracy: 0.6778 - val_auc: 0.8283\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5783 - accuracy: 0.4626 - auc: 0.7299 - val_loss: 0.9160 - val_accuracy: 0.6431 - val_auc: 0.8054\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5227 - accuracy: 0.4610 - auc: 0.7302 - val_loss: 0.6509 - val_accuracy: 0.6475 - val_auc: 0.8149\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.4724 - auc: 0.7292Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5086 - accuracy: 0.4723 - auc: 0.7319 - val_loss: 0.7059 - val_accuracy: 0.6619 - val_auc: 0.8227\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.6464 - accuracy: 0.8257 - auc: 0.7442 - val_loss: 0.4178 - val_accuracy: 0.9245 - val_auc: 0.9320\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6910 - accuracy: 0.7136 - auc: 0.7570 - val_loss: 0.4329 - val_accuracy: 0.8550 - val_auc: 0.8995\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6864 - accuracy: 0.6150 - auc: 0.7816 - val_loss: 0.4313 - val_accuracy: 0.6839 - val_auc: 0.9316\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5519 - accuracy: 0.5656 - auc: 0.8194 - val_loss: 0.4597 - val_accuracy: 0.9134 - val_auc: 0.9397\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6954 - accuracy: 0.5475 - auc: 0.7812 - val_loss: 0.6895 - val_accuracy: 0.6657 - val_auc: 0.8220\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5478 - accuracy: 0.5041 - auc: 0.7567 - val_loss: 0.6401 - val_accuracy: 0.6307 - val_auc: 0.8345\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4945 - accuracy: 0.5414 - auc: 0.7699 - val_loss: 0.5432 - val_accuracy: 0.7194 - val_auc: 0.8494\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4757 - accuracy: 0.5704 - auc: 0.7856 - val_loss: 0.5466 - val_accuracy: 0.7046 - val_auc: 0.8556\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4929 - accuracy: 0.5719 - auc: 0.7852 - val_loss: 0.4941 - val_accuracy: 0.7086 - val_auc: 0.8554\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4675 - accuracy: 0.5760 - auc: 0.7848 - val_loss: 0.5992 - val_accuracy: 0.7386 - val_auc: 0.8535\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4795 - accuracy: 0.5736 - auc: 0.7878 - val_loss: 0.5468 - val_accuracy: 0.7278 - val_auc: 0.8567\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4692 - accuracy: 0.5873 - auc: 0.7963 - val_loss: 0.5498 - val_accuracy: 0.7558 - val_auc: 0.8723\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4714 - accuracy: 0.5918 - auc: 0.8001 - val_loss: 0.4936 - val_accuracy: 0.7255 - val_auc: 0.8757\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4443 - accuracy: 0.5970 - auc: 0.8064 - val_loss: 0.6673 - val_accuracy: 0.7655 - val_auc: 0.8617\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4627 - accuracy: 0.6101 - auc: 0.8377 - val_loss: 0.6650 - val_accuracy: 0.7686 - val_auc: 0.9257\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4557 - accuracy: 0.6074 - auc: 0.8312 - val_loss: 0.8394 - val_accuracy: 0.7723 - val_auc: 0.8929\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4655 - accuracy: 0.5991 - auc: 0.8178 - val_loss: 0.9503 - val_accuracy: 0.7462 - val_auc: 0.8944\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4795 - accuracy: 0.5811 - auc: 0.7993 - val_loss: 0.7790 - val_accuracy: 0.7100 - val_auc: 0.8556\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4713 - accuracy: 0.5793 - auc: 0.7834 - val_loss: 0.8606 - val_accuracy: 0.7239 - val_auc: 0.8528\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4496 - accuracy: 0.5785 - auc: 0.7926 - val_loss: 0.8162 - val_accuracy: 0.7263 - val_auc: 0.8497\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4785 - accuracy: 0.5783 - auc: 0.7945 - val_loss: 0.9839 - val_accuracy: 0.7411 - val_auc: 0.8573\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4515 - accuracy: 0.5886 - auc: 0.8043 - val_loss: 1.1238 - val_accuracy: 0.7501 - val_auc: 0.8686\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4630 - accuracy: 0.5839 - auc: 0.8143 - val_loss: 0.8657 - val_accuracy: 0.7432 - val_auc: 0.8834\n",
      "Epoch 24/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.5689 - auc: 0.8030Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4952 - accuracy: 0.5687 - auc: 0.8038 - val_loss: 1.0170 - val_accuracy: 0.7176 - val_auc: 0.8704\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 0.7005 - accuracy: 0.7574 - auc: 0.7640 - val_loss: 0.3945 - val_accuracy: 0.9688 - val_auc: 0.9378\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5444 - accuracy: 0.9077 - auc: 0.8358 - val_loss: 0.3423 - val_accuracy: 0.8759 - val_auc: 0.9435\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5879 - accuracy: 0.8065 - auc: 0.8438 - val_loss: 0.3655 - val_accuracy: 0.9102 - val_auc: 0.9347\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.7025 - accuracy: 0.6898 - auc: 0.8096 - val_loss: 0.5502 - val_accuracy: 0.6384 - val_auc: 0.9199\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6233 - accuracy: 0.7003 - auc: 0.8015 - val_loss: 0.5312 - val_accuracy: 0.8985 - val_auc: 0.9424\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6026 - accuracy: 0.6772 - auc: 0.8256 - val_loss: 0.4634 - val_accuracy: 0.9203 - val_auc: 0.9385\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4731 - accuracy: 0.7951 - auc: 0.8378 - val_loss: 0.4210 - val_accuracy: 0.6643 - val_auc: 0.9425\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4731 - accuracy: 0.7417 - auc: 0.8392 - val_loss: 0.3639 - val_accuracy: 0.9164 - val_auc: 0.9422\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4269 - accuracy: 0.8040 - auc: 0.8524 - val_loss: 0.4191 - val_accuracy: 0.9367 - val_auc: 0.9408\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4591 - accuracy: 0.6758 - auc: 0.8344 - val_loss: 0.3720 - val_accuracy: 0.6735 - val_auc: 0.9411\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4463 - accuracy: 0.6169 - auc: 0.8481 - val_loss: 0.4153 - val_accuracy: 0.9314 - val_auc: 0.9458\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4804 - accuracy: 0.6863 - auc: 0.8444 - val_loss: 0.4667 - val_accuracy: 0.9396 - val_auc: 0.9392\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4172 - accuracy: 0.6358 - auc: 0.8599 - val_loss: 0.4103 - val_accuracy: 0.7414 - val_auc: 0.9489\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4363 - accuracy: 0.7049 - auc: 0.8524 - val_loss: 0.4451 - val_accuracy: 0.6879 - val_auc: 0.8984\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4480 - accuracy: 0.4973 - auc: 0.8120 - val_loss: 0.4379 - val_accuracy: 0.6910 - val_auc: 0.9221\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4214 - accuracy: 0.5416 - auc: 0.8411 - val_loss: 0.4904 - val_accuracy: 0.7238 - val_auc: 0.9267\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4321 - accuracy: 0.5483 - auc: 0.8418 - val_loss: 0.3634 - val_accuracy: 0.7398 - val_auc: 0.9404\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4384 - accuracy: 0.6408 - auc: 0.8682 - val_loss: 0.4675 - val_accuracy: 0.7229 - val_auc: 0.9391\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4457 - accuracy: 0.6080 - auc: 0.8540 - val_loss: 0.5340 - val_accuracy: 0.7184 - val_auc: 0.9256\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4733 - accuracy: 0.5454 - auc: 0.8436 - val_loss: 0.7232 - val_accuracy: 0.7157 - val_auc: 0.9350\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4513 - accuracy: 0.5416 - auc: 0.8467 - val_loss: 0.7479 - val_accuracy: 0.7204 - val_auc: 0.9291\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4957 - accuracy: 0.5469 - auc: 0.8076 - val_loss: 0.9672 - val_accuracy: 0.7102 - val_auc: 0.8846\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4870 - accuracy: 0.5410 - auc: 0.8002 - val_loss: 0.8098 - val_accuracy: 0.7070 - val_auc: 0.8844\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4432 - accuracy: 0.5520 - auc: 0.8096 - val_loss: 0.7105 - val_accuracy: 0.7121 - val_auc: 0.8904\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4759 - accuracy: 0.5625 - auc: 0.8129 - val_loss: 0.8146 - val_accuracy: 0.7200 - val_auc: 0.8901\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4629 - accuracy: 0.5571 - auc: 0.8057 - val_loss: 0.9687 - val_accuracy: 0.7127 - val_auc: 0.8816\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4371 - accuracy: 0.5554 - auc: 0.8118 - val_loss: 1.0862 - val_accuracy: 0.7222 - val_auc: 0.8895\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4798 - accuracy: 0.5495 - auc: 0.8071 - val_loss: 0.5824 - val_accuracy: 0.6839 - val_auc: 0.8847\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4388 - accuracy: 0.5525 - auc: 0.8116 - val_loss: 0.8082 - val_accuracy: 0.7075 - val_auc: 0.8881\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4966 - accuracy: 0.5637 - auc: 0.8061 - val_loss: 0.9349 - val_accuracy: 0.7128 - val_auc: 0.8354\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4800 - accuracy: 0.5597 - auc: 0.7833 - val_loss: 0.9151 - val_accuracy: 0.7073 - val_auc: 0.8383\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4717 - accuracy: 0.5658 - auc: 0.7775 - val_loss: 0.9097 - val_accuracy: 0.7145 - val_auc: 0.8393\n",
      "Epoch 33/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.4604 - accuracy: 0.5666 - auc: 0.7772Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4628 - accuracy: 0.5666 - auc: 0.7770 - val_loss: 0.9276 - val_accuracy: 0.6997 - val_auc: 0.8329\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5681 - accuracy: 0.8866 - auc: 0.7965 - val_loss: 0.3739 - val_accuracy: 0.9427 - val_auc: 0.9390\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5366 - accuracy: 0.8973 - auc: 0.8371 - val_loss: 0.4184 - val_accuracy: 0.8683 - val_auc: 0.9315\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6468 - accuracy: 0.8909 - auc: 0.8369 - val_loss: 0.9018 - val_accuracy: 0.9329 - val_auc: 0.9209s: 0.6416 - accuracy: 0.8871 - auc: 0.\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.7821 - accuracy: 0.8776 - auc: 0.8134 - val_loss: 0.4214 - val_accuracy: 0.8668 - val_auc: 0.9338\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5266 - accuracy: 0.9197 - auc: 0.8440 - val_loss: 0.3768 - val_accuracy: 0.9184 - val_auc: 0.9403\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6346 - accuracy: 0.7796 - auc: 0.8257 - val_loss: 0.4440 - val_accuracy: 0.6002 - val_auc: 0.9094\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4777 - accuracy: 0.5849 - auc: 0.8085 - val_loss: 0.3715 - val_accuracy: 0.6315 - val_auc: 0.9430\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5330 - accuracy: 0.8098 - auc: 0.8178 - val_loss: 0.5346 - val_accuracy: 0.9298 - val_auc: 0.9301\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5155 - accuracy: 0.5794 - auc: 0.8069 - val_loss: 0.5580 - val_accuracy: 0.6213 - val_auc: 0.9167\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5150 - accuracy: 0.4936 - auc: 0.7871 - val_loss: 0.7056 - val_accuracy: 0.9595 - val_auc: 0.8676\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5050 - accuracy: 0.4449 - auc: 0.7686 - val_loss: 0.5748 - val_accuracy: 0.6198 - val_auc: 0.9329\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4582 - accuracy: 0.5294 - auc: 0.8143 - val_loss: 0.6757 - val_accuracy: 0.6377 - val_auc: 0.9376\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4840 - accuracy: 0.5357 - auc: 0.8005 - val_loss: 0.6044 - val_accuracy: 0.6585 - val_auc: 0.9375\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4735 - accuracy: 0.5788 - auc: 0.8139 - val_loss: 0.5969 - val_accuracy: 0.6276 - val_auc: 0.9342\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4593 - accuracy: 0.5648 - auc: 0.8181 - val_loss: 0.6283 - val_accuracy: 0.6633 - val_auc: 0.9228\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4624 - accuracy: 0.4839 - auc: 0.8250 - val_loss: 0.6855 - val_accuracy: 0.6782 - val_auc: 0.9308\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5088 - accuracy: 0.4744 - auc: 0.8197 - val_loss: 1.0569 - val_accuracy: 0.6809 - val_auc: 0.8970\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4904 - accuracy: 0.5628 - auc: 0.8217 - val_loss: 0.7642 - val_accuracy: 0.6504 - val_auc: 0.9226\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5178 - accuracy: 0.6081 - auc: 0.8125 - val_loss: 0.6197 - val_accuracy: 0.6241 - val_auc: 0.9339\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4608 - accuracy: 0.5360 - auc: 0.8083 - val_loss: 0.6745 - val_accuracy: 0.6352 - val_auc: 0.9145\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4558 - accuracy: 0.5222 - auc: 0.8098 - val_loss: 0.7176 - val_accuracy: 0.6442 - val_auc: 0.9352\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4691 - accuracy: 0.5023 - auc: 0.8099 - val_loss: 0.5369 - val_accuracy: 0.6416 - val_auc: 0.9194\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4512 - accuracy: 0.4560 - auc: 0.8047 - val_loss: 0.6707 - val_accuracy: 0.6579 - val_auc: 0.9148\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4471 - accuracy: 0.4734 - auc: 0.8235 - val_loss: 0.7169 - val_accuracy: 0.6731 - val_auc: 0.8774\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4925 - accuracy: 0.4963 - auc: 0.7937 - val_loss: 0.6278 - val_accuracy: 0.6676 - val_auc: 0.8491\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4738 - accuracy: 0.4774 - auc: 0.7756 - val_loss: 0.5978 - val_accuracy: 0.6889 - val_auc: 0.8758\n",
      "Epoch 27/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.4556 - accuracy: 0.4803 - auc: 0.8091Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4553 - accuracy: 0.4803 - auc: 0.8093 - val_loss: 0.5672 - val_accuracy: 0.6955 - val_auc: 0.9226\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.7079 - accuracy: 0.8368 - auc: 0.7518 - val_loss: 0.3782 - val_accuracy: 0.9409 - val_auc: 0.9280\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6045 - accuracy: 0.8504 - auc: 0.8004 - val_loss: 0.5012 - val_accuracy: 0.8332 - val_auc: 0.8964\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5552 - accuracy: 0.9217 - auc: 0.8293 - val_loss: 0.3193 - val_accuracy: 0.9001 - val_auc: 0.9472\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5610 - accuracy: 0.9103 - auc: 0.8294 - val_loss: 0.3613 - val_accuracy: 0.8255 - val_auc: 0.9465\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5620 - accuracy: 0.7702 - auc: 0.8328 - val_loss: 0.4721 - val_accuracy: 0.6541 - val_auc: 0.8749\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5814 - accuracy: 0.5213 - auc: 0.7828 - val_loss: 0.5112 - val_accuracy: 0.7025 - val_auc: 0.9061\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4987 - accuracy: 0.4855 - auc: 0.8000 - val_loss: 0.4861 - val_accuracy: 0.7284 - val_auc: 0.9130\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.8670 - accuracy: 0.4646 - auc: 0.7822 - val_loss: 0.6874 - val_accuracy: 0.6673 - val_auc: 0.8982\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5911 - accuracy: 0.5637 - auc: 0.7964 - val_loss: 0.5841 - val_accuracy: 0.6368 - val_auc: 0.8631\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5555 - accuracy: 0.4590 - auc: 0.7615 - val_loss: 0.6324 - val_accuracy: 0.6776 - val_auc: 0.8248\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5360 - accuracy: 0.4918 - auc: 0.7467 - val_loss: 0.5750 - val_accuracy: 0.7044 - val_auc: 0.8499\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5913 - accuracy: 0.5054 - auc: 0.7461 - val_loss: 0.6653 - val_accuracy: 0.6413 - val_auc: 0.8431\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5575 - accuracy: 0.4928 - auc: 0.7443 - val_loss: 1.1249 - val_accuracy: 0.7178 - val_auc: 0.8400\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 1.3966 - accuracy: 0.4811 - auc: 0.7467 - val_loss: 1.6577 - val_accuracy: 0.6323 - val_auc: 0.8534\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5941 - accuracy: 0.4278 - auc: 0.7439 - val_loss: 1.0426 - val_accuracy: 0.6236 - val_auc: 0.8355\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6571 - accuracy: 0.4289 - auc: 0.7464 - val_loss: 0.8938 - val_accuracy: 0.5746 - val_auc: 0.7710\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5466 - accuracy: 0.3998 - auc: 0.6944 - val_loss: 1.0498 - val_accuracy: 0.5990 - val_auc: 0.7807\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6534 - accuracy: 0.4151 - auc: 0.6918 - val_loss: 0.9091 - val_accuracy: 0.6064 - val_auc: 0.7917\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6210 - accuracy: 0.4278 - auc: 0.7047 - val_loss: 1.1008 - val_accuracy: 0.6304 - val_auc: 0.7992\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6028 - accuracy: 0.4365 - auc: 0.7214 - val_loss: 0.9833 - val_accuracy: 0.6237 - val_auc: 0.8046\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5413 - accuracy: 0.4370 - auc: 0.7238 - val_loss: 1.1209 - val_accuracy: 0.6421 - val_auc: 0.8106\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5152 - accuracy: 0.4519 - auc: 0.7307 - val_loss: 1.0204 - val_accuracy: 0.6705 - val_auc: 0.8555\n",
      "Epoch 23/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.5671 - accuracy: 0.4601 - auc: 0.7748Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5662 - accuracy: 0.4600 - auc: 0.7743 - val_loss: 1.0733 - val_accuracy: 0.6484 - val_auc: 0.8115\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.8247 - accuracy: 0.8210 - auc: 0.7988 - val_loss: 0.4559 - val_accuracy: 0.8700 - val_auc: 0.9057\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.9634 - accuracy: 0.8307 - auc: 0.7801 - val_loss: 0.6279 - val_accuracy: 0.9559 - val_auc: 0.8493\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6271 - accuracy: 0.9144 - auc: 0.8096 - val_loss: 0.4936 - val_accuracy: 0.8299 - val_auc: 0.9052\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.7958 - accuracy: 0.8359 - auc: 0.7973 - val_loss: 0.4733 - val_accuracy: 0.9753 - val_auc: 0.9363\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6947 - accuracy: 0.8151 - auc: 0.8098 - val_loss: 0.4855 - val_accuracy: 0.5732 - val_auc: 0.9344\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6848 - accuracy: 0.5995 - auc: 0.7794 - val_loss: 0.5128 - val_accuracy: 0.9421 - val_auc: 0.8930\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6703 - accuracy: 0.5695 - auc: 0.7867 - val_loss: 0.5168 - val_accuracy: 0.6634 - val_auc: 0.8447\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5638 - accuracy: 0.4903 - auc: 0.7750 - val_loss: 0.5240 - val_accuracy: 0.6862 - val_auc: 0.8728\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.8451 - accuracy: 0.4721 - auc: 0.7679 - val_loss: 0.6320 - val_accuracy: 0.6799 - val_auc: 0.8643\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 1.1348 - accuracy: 0.5119 - auc: 0.7629 - val_loss: 0.5060 - val_accuracy: 0.5750 - val_auc: 0.8621\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.7916 - accuracy: 0.4626 - auc: 0.7999 - val_loss: 0.4496 - val_accuracy: 0.6123 - val_auc: 0.9345\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5067 - accuracy: 0.6047 - auc: 0.8281 - val_loss: 0.5311 - val_accuracy: 0.6159 - val_auc: 0.9304\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5168 - accuracy: 0.5243 - auc: 0.8382 - val_loss: 0.3982 - val_accuracy: 0.6285 - val_auc: 0.9410\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4657 - accuracy: 0.5616 - auc: 0.8427 - val_loss: 0.4290 - val_accuracy: 0.6233 - val_auc: 0.9366\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5021 - accuracy: 0.5518 - auc: 0.8420 - val_loss: 0.4717 - val_accuracy: 0.6710 - val_auc: 0.9361\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4772 - accuracy: 0.5210 - auc: 0.8101 - val_loss: 0.6161 - val_accuracy: 0.6705 - val_auc: 0.8673\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4524 - accuracy: 0.5353 - auc: 0.8110 - val_loss: 0.5847 - val_accuracy: 0.6818 - val_auc: 0.9025\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5949 - accuracy: 0.5358 - auc: 0.8263 - val_loss: 0.7344 - val_accuracy: 0.6857 - val_auc: 0.9198\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4661 - accuracy: 0.5188 - auc: 0.8356 - val_loss: 0.7927 - val_accuracy: 0.6565 - val_auc: 0.8523\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5156 - accuracy: 0.4983 - auc: 0.7713 - val_loss: 0.9355 - val_accuracy: 0.6582 - val_auc: 0.8722\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.5150 - accuracy: 0.4947 - auc: 0.7889 - val_loss: 0.8450 - val_accuracy: 0.6489 - val_auc: 0.8786\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4779 - accuracy: 0.5066 - auc: 0.7947 - val_loss: 0.5978 - val_accuracy: 0.6607 - val_auc: 0.8815\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4646 - accuracy: 0.5161 - auc: 0.8027 - val_loss: 0.6901 - val_accuracy: 0.6575 - val_auc: 0.8710\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4722 - accuracy: 0.5246 - auc: 0.8085 - val_loss: 0.7723 - val_accuracy: 0.6879 - val_auc: 0.8332\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4850 - accuracy: 0.5316 - auc: 0.7629 - val_loss: 0.7355 - val_accuracy: 0.6853 - val_auc: 0.8321\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4822 - accuracy: 0.5371 - auc: 0.7751 - val_loss: 0.7215 - val_accuracy: 0.6883 - val_auc: 0.8354\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4724 - accuracy: 0.5426 - auc: 0.7697 - val_loss: 0.6789 - val_accuracy: 0.6918 - val_auc: 0.8392\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4626 - accuracy: 0.5505 - auc: 0.7724 - val_loss: 0.7147 - val_accuracy: 0.7088 - val_auc: 0.8408\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4600 - accuracy: 0.5624 - auc: 0.7888 - val_loss: 0.7186 - val_accuracy: 0.7203 - val_auc: 0.8480\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4676 - accuracy: 0.5592 - auc: 0.7860 - val_loss: 0.7542 - val_accuracy: 0.6868 - val_auc: 0.8442\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4603 - accuracy: 0.5622 - auc: 0.7886 - val_loss: 0.7201 - val_accuracy: 0.7255 - val_auc: 0.8505\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4588 - accuracy: 0.5719 - auc: 0.7879 - val_loss: 0.6840 - val_accuracy: 0.7120 - val_auc: 0.8468\n",
      "Epoch 33/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.5861 - auc: 0.7908Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4407 - accuracy: 0.5860 - auc: 0.7908 - val_loss: 0.7666 - val_accuracy: 0.7307 - val_auc: 0.8504\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.8012 - accuracy: 0.8173 - auc: 0.7911 - val_loss: 0.7149 - val_accuracy: 0.9053 - val_auc: 0.7703\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.8072 - accuracy: 0.8393 - auc: 0.8256 - val_loss: 0.6602 - val_accuracy: 0.8237 - val_auc: 0.9294\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 1.0295 - accuracy: 0.8585 - auc: 0.8158 - val_loss: 0.4493 - val_accuracy: 0.9340 - val_auc: 0.9338\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.7477 - accuracy: 0.8548 - auc: 0.8275 - val_loss: 0.6014 - val_accuracy: 0.8146 - val_auc: 0.9107\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6734 - accuracy: 0.8372 - auc: 0.8341 - val_loss: 0.5144 - val_accuracy: 0.8968 - val_auc: 0.9270\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6111 - accuracy: 0.8520 - auc: 0.8455 - val_loss: 0.6290 - val_accuracy: 0.8310 - val_auc: 0.9444\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4822 - accuracy: 0.8783 - auc: 0.8751 - val_loss: 0.6400 - val_accuracy: 0.9435 - val_auc: 0.9405\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4893 - accuracy: 0.7641 - auc: 0.8419 - val_loss: 0.5786 - val_accuracy: 0.6523 - val_auc: 0.9424\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4580 - accuracy: 0.7767 - auc: 0.8716 - val_loss: 0.6711 - val_accuracy: 0.6695 - val_auc: 0.9437\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4783 - accuracy: 0.6047 - auc: 0.8487 - val_loss: 0.6233 - val_accuracy: 0.6772 - val_auc: 0.9445\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4860 - accuracy: 0.5731 - auc: 0.8352 - val_loss: 0.7547 - val_accuracy: 0.6473 - val_auc: 0.8752\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4696 - accuracy: 0.5183 - auc: 0.8162 - val_loss: 0.7039 - val_accuracy: 0.6886 - val_auc: 0.8857\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4671 - accuracy: 0.5599 - auc: 0.8299 - val_loss: 0.6805 - val_accuracy: 0.6892 - val_auc: 0.8862\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4292 - accuracy: 0.5675 - auc: 0.8489 - val_loss: 0.8444 - val_accuracy: 0.7210 - val_auc: 0.9417\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4674 - accuracy: 0.5789 - auc: 0.8221 - val_loss: 0.8445 - val_accuracy: 0.7178 - val_auc: 0.8907\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4438 - accuracy: 0.5873 - auc: 0.8303 - val_loss: 0.8371 - val_accuracy: 0.7212 - val_auc: 0.9385\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4378 - accuracy: 0.5989 - auc: 0.8566 - val_loss: 0.7695 - val_accuracy: 0.7283 - val_auc: 0.9371\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3955 - accuracy: 0.6147 - auc: 0.8708 - val_loss: 0.7774 - val_accuracy: 0.7496 - val_auc: 0.9388\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4317 - accuracy: 0.6199 - auc: 0.8473 - val_loss: 0.8815 - val_accuracy: 0.7477 - val_auc: 0.8927\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4339 - accuracy: 0.6194 - auc: 0.8333 - val_loss: 0.8908 - val_accuracy: 0.7506 - val_auc: 0.8998\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4120 - accuracy: 0.6317 - auc: 0.8471 - val_loss: 0.8908 - val_accuracy: 0.7293 - val_auc: 0.8890\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4404 - accuracy: 0.6274 - auc: 0.8446 - val_loss: 0.9730 - val_accuracy: 0.7700 - val_auc: 0.9096\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4237 - accuracy: 0.6305 - auc: 0.8449 - val_loss: 0.8090 - val_accuracy: 0.7503 - val_auc: 0.8933\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4326 - accuracy: 0.6244 - auc: 0.8413 - val_loss: 0.9497 - val_accuracy: 0.7580 - val_auc: 0.9207\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4070 - accuracy: 0.6303 - auc: 0.8581 - val_loss: 1.0493 - val_accuracy: 0.7508 - val_auc: 0.9184\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4350 - accuracy: 0.6162 - auc: 0.8566 - val_loss: 1.2306 - val_accuracy: 0.7381 - val_auc: 0.9285\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4069 - accuracy: 0.6113 - auc: 0.8566 - val_loss: 1.0558 - val_accuracy: 0.7322 - val_auc: 0.9125\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4326 - accuracy: 0.5990 - auc: 0.8426 - val_loss: 1.1865 - val_accuracy: 0.7262 - val_auc: 0.8708\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4996 - accuracy: 0.5956 - auc: 0.8020 - val_loss: 2.1607 - val_accuracy: 0.7465 - val_auc: 0.8610\n",
      "Epoch 30/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.4313 - accuracy: 0.6120 - auc: 0.8194Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4315 - accuracy: 0.6118 - auc: 0.8194 - val_loss: 2.0185 - val_accuracy: 0.7234 - val_auc: 0.8526\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 0.9165 - accuracy: 0.8084 - auc: 0.7812 - val_loss: 0.6905 - val_accuracy: 0.8351 - val_auc: 0.9034\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.9539 - accuracy: 0.8352 - auc: 0.8247 - val_loss: 1.1828 - val_accuracy: 0.6560 - val_auc: 0.8915\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.8670 - accuracy: 0.8685 - auc: 0.8276 - val_loss: 0.4191 - val_accuracy: 0.8893 - val_auc: 0.9440\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6082 - accuracy: 0.8510 - auc: 0.8363 - val_loss: 0.7234 - val_accuracy: 0.7523 - val_auc: 0.9350\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7388 - accuracy: 0.5910 - auc: 0.7728 - val_loss: 0.6023 - val_accuracy: 0.6546 - val_auc: 0.8623\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 1.3012 - accuracy: 0.5013 - auc: 0.7519 - val_loss: 1.1282 - val_accuracy: 0.6607 - val_auc: 0.9272\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.9358 - accuracy: 0.5565 - auc: 0.7575 - val_loss: 1.2318 - val_accuracy: 0.6325 - val_auc: 0.8422\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.8686 - accuracy: 0.4607 - auc: 0.7419 - val_loss: 1.0477 - val_accuracy: 0.6411 - val_auc: 0.8697\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.8084 - accuracy: 0.5237 - auc: 0.7318 - val_loss: 0.6827 - val_accuracy: 0.6205 - val_auc: 0.9038\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6665 - accuracy: 0.4890 - auc: 0.7987 - val_loss: 0.6804 - val_accuracy: 0.6490 - val_auc: 0.8820\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.1794 - accuracy: 0.5484 - auc: 0.7844 - val_loss: 0.7234 - val_accuracy: 0.6497 - val_auc: 0.8864\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6091 - accuracy: 0.4975 - auc: 0.7911 - val_loss: 0.5116 - val_accuracy: 0.6330 - val_auc: 0.9050\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5193 - accuracy: 0.5293 - auc: 0.8145 - val_loss: 0.8060 - val_accuracy: 0.6905 - val_auc: 0.8983\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5146 - accuracy: 0.5542 - auc: 0.8222 - val_loss: 0.5459 - val_accuracy: 0.7002 - val_auc: 0.9129\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.0992 - accuracy: 0.5753 - auc: 0.8096 - val_loss: 1.4252 - val_accuracy: 0.7257 - val_auc: 0.9080\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 1.2727 - accuracy: 0.5409 - auc: 0.7706 - val_loss: 1.5066 - val_accuracy: 0.6944 - val_auc: 0.8655\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8929 - accuracy: 0.5417 - auc: 0.7885 - val_loss: 1.4064 - val_accuracy: 0.6755 - val_auc: 0.8708\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6906 - accuracy: 0.5393 - auc: 0.7893 - val_loss: 1.0089 - val_accuracy: 0.6870 - val_auc: 0.8726\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7347 - accuracy: 0.5342 - auc: 0.8013 - val_loss: 1.0807 - val_accuracy: 0.6427 - val_auc: 0.8223\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 4.0826 - accuracy: 0.5149 - auc: 0.7596 - val_loss: 2.1488 - val_accuracy: 0.6316 - val_auc: 0.8540\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8683 - accuracy: 0.4840 - auc: 0.7676 - val_loss: 2.1174 - val_accuracy: 0.6380 - val_auc: 0.8649\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8632 - accuracy: 0.4924 - auc: 0.7653 - val_loss: 1.7589 - val_accuracy: 0.6407 - val_auc: 0.8241\n",
      "Epoch 23/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.6245 - accuracy: 0.4979 - auc: 0.7745Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6315 - accuracy: 0.4981 - auc: 0.7736 - val_loss: 1.5809 - val_accuracy: 0.6531 - val_auc: 0.8902\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.8611 - accuracy: 0.7837 - auc: 0.7848 - val_loss: 0.4330 - val_accuracy: 0.8788 - val_auc: 0.9029\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.7471 - accuracy: 0.8565 - auc: 0.8314 - val_loss: 0.5130 - val_accuracy: 0.8557 - val_auc: 0.9307\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6527 - accuracy: 0.8467 - auc: 0.8322 - val_loss: 0.6798 - val_accuracy: 0.8690 - val_auc: 0.9304\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.7618 - accuracy: 0.8675 - auc: 0.8490 - val_loss: 0.8278 - val_accuracy: 0.5631 - val_auc: 0.9211\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.8621 - accuracy: 0.5885 - auc: 0.8073 - val_loss: 0.7080 - val_accuracy: 0.6768 - val_auc: 0.8867\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.9126 - accuracy: 0.5994 - auc: 0.8270 - val_loss: 0.5020 - val_accuracy: 0.6332 - val_auc: 0.8570\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4624 - accuracy: 0.5929 - auc: 0.8524 - val_loss: 1.0140 - val_accuracy: 0.7543 - val_auc: 0.7708\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5649 - accuracy: 0.5894 - auc: 0.8233 - val_loss: 0.6084 - val_accuracy: 0.7081 - val_auc: 0.9050\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5796 - accuracy: 0.5868 - auc: 0.8020 - val_loss: 0.8033 - val_accuracy: 0.7041 - val_auc: 0.8435\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4650 - accuracy: 0.6105 - auc: 0.8009 - val_loss: 0.8324 - val_accuracy: 0.7311 - val_auc: 0.8520\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.6338 - accuracy: 0.5727 - auc: 0.7417 - val_loss: 2.5073 - val_accuracy: 0.6642 - val_auc: 0.8132\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.7377 - accuracy: 0.5216 - auc: 0.7617 - val_loss: 1.9218 - val_accuracy: 0.6506 - val_auc: 0.8105\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5318 - accuracy: 0.5457 - auc: 0.7651 - val_loss: 1.0445 - val_accuracy: 0.6667 - val_auc: 0.8232\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5616 - accuracy: 0.5653 - auc: 0.7791 - val_loss: 1.0090 - val_accuracy: 0.6977 - val_auc: 0.8328\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6346 - accuracy: 0.5830 - auc: 0.7794 - val_loss: 1.3672 - val_accuracy: 0.7017 - val_auc: 0.8457\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5752 - accuracy: 0.5893 - auc: 0.7855 - val_loss: 1.6381 - val_accuracy: 0.7097 - val_auc: 0.8486\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4405 - accuracy: 0.6156 - auc: 0.8126 - val_loss: 1.6000 - val_accuracy: 0.7154 - val_auc: 0.8589\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4711 - accuracy: 0.6245 - auc: 0.8188 - val_loss: 1.4712 - val_accuracy: 0.7484 - val_auc: 0.8854\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4587 - accuracy: 0.6196 - auc: 0.8330 - val_loss: 1.7151 - val_accuracy: 0.7093 - val_auc: 0.8918\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4361 - accuracy: 0.6413 - auc: 0.8443 - val_loss: 1.3743 - val_accuracy: 0.7079 - val_auc: 0.8925\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4273 - accuracy: 0.6425 - auc: 0.8467 - val_loss: 1.5446 - val_accuracy: 0.7632 - val_auc: 0.8836\n",
      "Epoch 22/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.6144 - accuracy: 0.6521 - auc: 0.8475Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6116 - accuracy: 0.6520 - auc: 0.8481 - val_loss: 1.8328 - val_accuracy: 0.7671 - val_auc: 0.8962\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.7458 - accuracy: 0.8091 - auc: 0.8059 - val_loss: 0.6788 - val_accuracy: 0.8415 - val_auc: 0.9154\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.9499 - accuracy: 0.8378 - auc: 0.8313 - val_loss: 0.9189 - val_accuracy: 0.8981 - val_auc: 0.9221\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.9276 - accuracy: 0.8531 - auc: 0.8461 - val_loss: 0.6171 - val_accuracy: 0.9240 - val_auc: 0.9335\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.9724 - accuracy: 0.8746 - auc: 0.8577 - val_loss: 2.0263 - val_accuracy: 0.3657 - val_auc: 0.7346\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 1.1446 - accuracy: 0.6255 - auc: 0.7468 - val_loss: 1.1729 - val_accuracy: 0.5606 - val_auc: 0.7862\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.7896 - accuracy: 0.4472 - auc: 0.7532 - val_loss: 0.5657 - val_accuracy: 0.6169 - val_auc: 0.9267\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.7436 - accuracy: 0.4805 - auc: 0.7021 - val_loss: 1.7847 - val_accuracy: 0.5493 - val_auc: 0.7653\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.2003 - accuracy: 0.4044 - auc: 0.6913 - val_loss: 2.0813 - val_accuracy: 0.2931 - val_auc: 0.4960\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.0134 - accuracy: 0.4081 - auc: 0.6877 - val_loss: 1.0976 - val_accuracy: 0.5881 - val_auc: 0.7857\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.8186 - accuracy: 0.4197 - auc: 0.6910 - val_loss: 1.0312 - val_accuracy: 0.5727 - val_auc: 0.7783\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5296 - accuracy: 0.4499 - auc: 0.7484 - val_loss: 1.0016 - val_accuracy: 0.6205 - val_auc: 0.8449\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5035 - accuracy: 0.4821 - auc: 0.7882 - val_loss: 1.0135 - val_accuracy: 0.6265 - val_auc: 0.9021\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5065 - accuracy: 0.4791 - auc: 0.8052 - val_loss: 1.0722 - val_accuracy: 0.6342 - val_auc: 0.9049\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5647 - accuracy: 0.4951 - auc: 0.7597 - val_loss: 1.0292 - val_accuracy: 0.6602 - val_auc: 0.8142\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5533 - accuracy: 0.5075 - auc: 0.7500 - val_loss: 1.0607 - val_accuracy: 0.6784 - val_auc: 0.8240\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6630 - accuracy: 0.5004 - auc: 0.7415 - val_loss: 1.0015 - val_accuracy: 0.6459 - val_auc: 0.8119\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5024 - accuracy: 0.5117 - auc: 0.7633 - val_loss: 1.0683 - val_accuracy: 0.6804 - val_auc: 0.8230\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5452 - accuracy: 0.5323 - auc: 0.7612 - val_loss: 1.1454 - val_accuracy: 0.6856 - val_auc: 0.8275\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5296 - accuracy: 0.5343 - auc: 0.7752 - val_loss: 1.1604 - val_accuracy: 0.6902 - val_auc: 0.8283\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5600 - accuracy: 0.5354 - auc: 0.7629 - val_loss: 0.7767 - val_accuracy: 0.6896 - val_auc: 0.8356\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5073 - accuracy: 0.5382 - auc: 0.7703 - val_loss: 0.7930 - val_accuracy: 0.6758 - val_auc: 0.8371\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4895 - accuracy: 0.5483 - auc: 0.7719 - val_loss: 1.1097 - val_accuracy: 0.7200 - val_auc: 0.8439\n",
      "Epoch 23/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.4789 - accuracy: 0.5570 - auc: 0.7730Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4793 - accuracy: 0.5567 - auc: 0.7736 - val_loss: 1.1077 - val_accuracy: 0.7015 - val_auc: 0.8386\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 1.4857 - accuracy: 0.7438 - auc: 0.8159 - val_loss: 0.9215 - val_accuracy: 0.7082 - val_auc: 0.9031\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.3644 - accuracy: 0.8277 - auc: 0.8379 - val_loss: 0.7895 - val_accuracy: 0.9319 - val_auc: 0.9124\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.2828 - accuracy: 0.8448 - auc: 0.8504 - val_loss: 0.9123 - val_accuracy: 0.8880 - val_auc: 0.9097\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.1362 - accuracy: 0.8203 - auc: 0.8178 - val_loss: 0.7929 - val_accuracy: 0.8439 - val_auc: 0.9324\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.3941 - accuracy: 0.7654 - auc: 0.8418 - val_loss: 1.7366 - val_accuracy: 0.9147 - val_auc: 0.9072\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.8214 - accuracy: 0.6628 - auc: 0.8179 - val_loss: 2.2582 - val_accuracy: 0.7080 - val_auc: 0.9092\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 2.2861 - accuracy: 0.6066 - auc: 0.8151 - val_loss: 2.0712 - val_accuracy: 0.6380 - val_auc: 0.9130\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 2.0014 - accuracy: 0.5880 - auc: 0.7957 - val_loss: 3.0678 - val_accuracy: 0.6685 - val_auc: 0.8242\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 2.1166 - accuracy: 0.5613 - auc: 0.7744 - val_loss: 2.4438 - val_accuracy: 0.6130 - val_auc: 0.7703\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.4743 - accuracy: 0.5373 - auc: 0.7569 - val_loss: 5.7683 - val_accuracy: 0.6605 - val_auc: 0.8121\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.7242 - accuracy: 0.5439 - auc: 0.7562 - val_loss: 2.4160 - val_accuracy: 0.6348 - val_auc: 0.7992\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 2.0166 - accuracy: 0.5405 - auc: 0.7639 - val_loss: 4.6480 - val_accuracy: 0.6306 - val_auc: 0.8145\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.4684 - accuracy: 0.5563 - auc: 0.7869 - val_loss: 3.8897 - val_accuracy: 0.6223 - val_auc: 0.7932\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.4314 - accuracy: 0.5504 - auc: 0.7729 - val_loss: 3.6122 - val_accuracy: 0.6389 - val_auc: 0.8298\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.0456 - accuracy: 0.5663 - auc: 0.7756 - val_loss: 6.2797 - val_accuracy: 0.6564 - val_auc: 0.8137\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.9516 - accuracy: 0.5696 - auc: 0.7795 - val_loss: 5.6801 - val_accuracy: 0.6562 - val_auc: 0.8031\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.0043 - accuracy: 0.5626 - auc: 0.7757 - val_loss: 4.5268 - val_accuracy: 0.6509 - val_auc: 0.8002\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.5580 - accuracy: 0.5453 - auc: 0.7602 - val_loss: 8.8203 - val_accuracy: 0.6372 - val_auc: 0.7960\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8580 - accuracy: 0.5513 - auc: 0.7792 - val_loss: 6.6049 - val_accuracy: 0.6453 - val_auc: 0.8014\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.2578 - accuracy: 0.5463 - auc: 0.7912 - val_loss: 7.5489 - val_accuracy: 0.6371 - val_auc: 0.8512\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7231 - accuracy: 0.5414 - auc: 0.7992 - val_loss: 10.2874 - val_accuracy: 0.6232 - val_auc: 0.8370\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7336 - accuracy: 0.5360 - auc: 0.7939 - val_loss: 11.4842 - val_accuracy: 0.6189 - val_auc: 0.8421\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.2793 - accuracy: 0.5210 - auc: 0.7799 - val_loss: 5.8167 - val_accuracy: 0.6115 - val_auc: 0.8077\n",
      "Epoch 24/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.6972 - accuracy: 0.5294 - auc: 0.8340Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6985 - accuracy: 0.5295 - auc: 0.8342 - val_loss: 6.7225 - val_accuracy: 0.6220 - val_auc: 0.9166\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.5768 - accuracy: 0.7077 - auc: 0.7952 - val_loss: 1.0647 - val_accuracy: 0.8953 - val_auc: 0.8994\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.4377 - accuracy: 0.8257 - auc: 0.8388 - val_loss: 0.7518 - val_accuracy: 0.8591 - val_auc: 0.9198\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.3150 - accuracy: 0.8274 - auc: 0.8392 - val_loss: 0.6445 - val_accuracy: 0.8589 - val_auc: 0.9305\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.3871 - accuracy: 0.8235 - auc: 0.8252 - val_loss: 1.1580 - val_accuracy: 0.9359 - val_auc: 0.9244\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.5651 - accuracy: 0.8619 - auc: 0.8364 - val_loss: 1.3829 - val_accuracy: 0.8902 - val_auc: 0.8973\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8317 - accuracy: 0.8703 - auc: 0.8340 - val_loss: 0.7695 - val_accuracy: 0.8781 - val_auc: 0.9227\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7191 - accuracy: 0.6621 - auc: 0.8235 - val_loss: 1.1363 - val_accuracy: 0.5954 - val_auc: 0.8342\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.0770 - accuracy: 0.6028 - auc: 0.8060 - val_loss: 1.8172 - val_accuracy: 0.6801 - val_auc: 0.7852\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.0152 - accuracy: 0.6622 - auc: 0.8263 - val_loss: 1.6100 - val_accuracy: 0.9128 - val_auc: 0.9189\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6303 - accuracy: 0.6541 - auc: 0.8479 - val_loss: 1.3191 - val_accuracy: 0.9302 - val_auc: 0.9193\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5035 - accuracy: 0.6284 - auc: 0.8560 - val_loss: 1.3116 - val_accuracy: 0.9096 - val_auc: 0.9354\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.9427 - accuracy: 0.6818 - auc: 0.8269 - val_loss: 2.6623 - val_accuracy: 0.6529 - val_auc: 0.8238\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8884 - accuracy: 0.4908 - auc: 0.7448 - val_loss: 2.3460 - val_accuracy: 0.6279 - val_auc: 0.8248\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7268 - accuracy: 0.4727 - auc: 0.7669 - val_loss: 1.7374 - val_accuracy: 0.5986 - val_auc: 0.8076\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.8512 - accuracy: 0.5297 - auc: 0.7824 - val_loss: 1.9510 - val_accuracy: 0.6521 - val_auc: 0.8406\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5205 - accuracy: 0.4854 - auc: 0.8082 - val_loss: 1.9704 - val_accuracy: 0.6411 - val_auc: 0.8896\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6273 - accuracy: 0.5225 - auc: 0.8269 - val_loss: 2.0513 - val_accuracy: 0.9336 - val_auc: 0.9186\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4907 - accuracy: 0.6322 - auc: 0.8566 - val_loss: 2.1826 - val_accuracy: 0.9277 - val_auc: 0.9268\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4369 - accuracy: 0.5981 - auc: 0.8609 - val_loss: 2.1277 - val_accuracy: 0.6752 - val_auc: 0.9239\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4775 - accuracy: 0.5384 - auc: 0.8079 - val_loss: 1.9662 - val_accuracy: 0.6853 - val_auc: 0.8651\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4665 - accuracy: 0.5524 - auc: 0.8074 - val_loss: 2.1352 - val_accuracy: 0.7107 - val_auc: 0.8687\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4518 - accuracy: 0.5753 - auc: 0.8090 - val_loss: 2.1575 - val_accuracy: 0.7196 - val_auc: 0.8780\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5419 - accuracy: 0.5850 - auc: 0.8179 - val_loss: 2.7677 - val_accuracy: 0.7434 - val_auc: 0.8589\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4778 - accuracy: 0.5717 - auc: 0.7978 - val_loss: 2.8432 - val_accuracy: 0.7148 - val_auc: 0.8559\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4591 - accuracy: 0.5778 - auc: 0.8021 - val_loss: 2.5541 - val_accuracy: 0.7204 - val_auc: 0.8715\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4718 - accuracy: 0.5786 - auc: 0.8183 - val_loss: 2.5505 - val_accuracy: 0.7238 - val_auc: 0.8699\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4254 - accuracy: 0.5948 - auc: 0.8240 - val_loss: 2.6094 - val_accuracy: 0.7197 - val_auc: 0.8718\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4297 - accuracy: 0.5965 - auc: 0.8262 - val_loss: 2.4653 - val_accuracy: 0.7381 - val_auc: 0.8921\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4667 - accuracy: 0.6005 - auc: 0.8267 - val_loss: 3.0814 - val_accuracy: 0.7436 - val_auc: 0.8515\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4364 - accuracy: 0.6073 - auc: 0.8056 - val_loss: 3.0005 - val_accuracy: 0.7338 - val_auc: 0.8494\n",
      "Epoch 31/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.4330 - accuracy: 0.6084 - auc: 0.8105Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4329 - accuracy: 0.6084 - auc: 0.8103 - val_loss: 3.0114 - val_accuracy: 0.7532 - val_auc: 0.8533\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 1.8548 - accuracy: 0.7408 - auc: 0.7986 - val_loss: 0.7497 - val_accuracy: 0.7976 - val_auc: 0.9078\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.9966 - accuracy: 0.8411 - auc: 0.8381 - val_loss: 0.6769 - val_accuracy: 0.8621 - val_auc: 0.9199\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.9903 - accuracy: 0.8481 - auc: 0.8582 - val_loss: 0.6057 - val_accuracy: 0.8489 - val_auc: 0.9206\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.7534 - accuracy: 0.8782 - auc: 0.8731 - val_loss: 0.5409 - val_accuracy: 0.7882 - val_auc: 0.9166\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.0629 - accuracy: 0.8684 - auc: 0.8562 - val_loss: 1.9736 - val_accuracy: 0.8967 - val_auc: 0.9122\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 1.7602 - accuracy: 0.8895 - auc: 0.8549 - val_loss: 0.8461 - val_accuracy: 0.8704 - val_auc: 0.9279\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7720 - accuracy: 0.8996 - auc: 0.8640 - val_loss: 0.7793 - val_accuracy: 0.8953 - val_auc: 0.9322\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6099 - accuracy: 0.9127 - auc: 0.8793 - val_loss: 0.9351 - val_accuracy: 0.8870 - val_auc: 0.9286\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5023 - accuracy: 0.8760 - auc: 0.8821 - val_loss: 0.9003 - val_accuracy: 0.6179 - val_auc: 0.9212\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6484 - accuracy: 0.6669 - auc: 0.8338 - val_loss: 0.6046 - val_accuracy: 0.6276 - val_auc: 0.9251\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5354 - accuracy: 0.5958 - auc: 0.8591 - val_loss: 0.7312 - val_accuracy: 0.6973 - val_auc: 0.9406\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.6603 - accuracy: 0.5623 - auc: 0.8216 - val_loss: 0.5823 - val_accuracy: 0.6972 - val_auc: 0.9312\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4646 - accuracy: 0.5776 - auc: 0.8506 - val_loss: 0.5515 - val_accuracy: 0.6749 - val_auc: 0.9277\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4947 - accuracy: 0.5858 - auc: 0.8433 - val_loss: 0.4263 - val_accuracy: 0.7090 - val_auc: 0.9333\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4006 - accuracy: 0.6181 - auc: 0.8690 - val_loss: 0.5981 - val_accuracy: 0.7445 - val_auc: 0.9280\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4729 - accuracy: 0.6231 - auc: 0.8662 - val_loss: 0.4148 - val_accuracy: 0.7435 - val_auc: 0.9406\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5238 - accuracy: 0.6332 - auc: 0.8734 - val_loss: 1.4130 - val_accuracy: 0.6200 - val_auc: 0.8321\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7224 - accuracy: 0.6165 - auc: 0.8604 - val_loss: 1.5389 - val_accuracy: 0.7222 - val_auc: 0.9354\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5253 - accuracy: 0.5898 - auc: 0.8620 - val_loss: 1.1164 - val_accuracy: 0.6804 - val_auc: 0.9316\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5039 - accuracy: 0.5882 - auc: 0.8597 - val_loss: 1.1373 - val_accuracy: 0.6714 - val_auc: 0.8526\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.7663 - accuracy: 0.5600 - auc: 0.8087 - val_loss: 1.7515 - val_accuracy: 0.6828 - val_auc: 0.8810\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4421 - accuracy: 0.5751 - auc: 0.8516 - val_loss: 1.6489 - val_accuracy: 0.6892 - val_auc: 0.9097\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4353 - accuracy: 0.5677 - auc: 0.8558 - val_loss: 1.4899 - val_accuracy: 0.6779 - val_auc: 0.9285\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4447 - accuracy: 0.5771 - auc: 0.8212 - val_loss: 1.3612 - val_accuracy: 0.6907 - val_auc: 0.8713\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5548 - accuracy: 0.5754 - auc: 0.8029 - val_loss: 1.6830 - val_accuracy: 0.6799 - val_auc: 0.8526\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5042 - accuracy: 0.5730 - auc: 0.8295 - val_loss: 1.7400 - val_accuracy: 0.6916 - val_auc: 0.9221\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4696 - accuracy: 0.5853 - auc: 0.7917 - val_loss: 1.6665 - val_accuracy: 0.6902 - val_auc: 0.8290\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4424 - accuracy: 0.5948 - auc: 0.8003 - val_loss: 1.7312 - val_accuracy: 0.7002 - val_auc: 0.8356\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4355 - accuracy: 0.6028 - auc: 0.7997 - val_loss: 1.8873 - val_accuracy: 0.7083 - val_auc: 0.8356\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4236 - accuracy: 0.6086 - auc: 0.8093 - val_loss: 1.9662 - val_accuracy: 0.7187 - val_auc: 0.8351\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4418 - accuracy: 0.6231 - auc: 0.8161 - val_loss: 1.8427 - val_accuracy: 0.7280 - val_auc: 0.8398\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4463 - accuracy: 0.6207 - auc: 0.8102 - val_loss: 1.3860 - val_accuracy: 0.7180 - val_auc: 0.8409\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4332 - accuracy: 0.6149 - auc: 0.8037 - val_loss: 1.3255 - val_accuracy: 0.7126 - val_auc: 0.8421\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4722 - accuracy: 0.6149 - auc: 0.8089 - val_loss: 1.3341 - val_accuracy: 0.7150 - val_auc: 0.8359\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4187 - accuracy: 0.6234 - auc: 0.8173 - val_loss: 1.2444 - val_accuracy: 0.7263 - val_auc: 0.8397\n",
      "Epoch 36/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.4306 - accuracy: 0.6355 - auc: 0.8191Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4311 - accuracy: 0.6354 - auc: 0.8191 - val_loss: 1.2386 - val_accuracy: 0.7356 - val_auc: 0.8481\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 1.1547 - accuracy: 0.7420 - auc: 0.8074 - val_loss: 0.6370 - val_accuracy: 0.7915 - val_auc: 0.8995\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.5146 - accuracy: 0.8058 - auc: 0.8259 - val_loss: 1.4814 - val_accuracy: 0.6448 - val_auc: 0.8656\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 2.1974 - accuracy: 0.8156 - auc: 0.8209 - val_loss: 1.9512 - val_accuracy: 0.8241 - val_auc: 0.9195\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.8001 - accuracy: 0.8337 - auc: 0.8250 - val_loss: 1.9807 - val_accuracy: 0.8923 - val_auc: 0.8633\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.1396 - accuracy: 0.8204 - auc: 0.8295 - val_loss: 1.3713 - val_accuracy: 0.9464 - val_auc: 0.8986\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 2.3052 - accuracy: 0.8786 - auc: 0.8006 - val_loss: 0.8311 - val_accuracy: 0.9294 - val_auc: 0.9142\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7828 - accuracy: 0.9122 - auc: 0.8383 - val_loss: 1.0641 - val_accuracy: 0.5662 - val_auc: 0.9160\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.0109 - accuracy: 0.7567 - auc: 0.8360 - val_loss: 1.4337 - val_accuracy: 0.9082 - val_auc: 0.8977\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.4016 - accuracy: 0.5676 - auc: 0.7857 - val_loss: 1.0248 - val_accuracy: 0.5405 - val_auc: 0.8396\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.8900 - accuracy: 0.4996 - auc: 0.7968 - val_loss: 1.2023 - val_accuracy: 0.6305 - val_auc: 0.8715\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7546 - accuracy: 0.5258 - auc: 0.7847 - val_loss: 1.3541 - val_accuracy: 0.6288 - val_auc: 0.7917\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.8257 - accuracy: 0.5206 - auc: 0.7661 - val_loss: 2.0385 - val_accuracy: 0.6655 - val_auc: 0.8429\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6077 - accuracy: 0.5188 - auc: 0.8081 - val_loss: 2.2984 - val_accuracy: 0.6583 - val_auc: 0.8622\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5707 - accuracy: 0.5073 - auc: 0.8008 - val_loss: 2.3210 - val_accuracy: 0.6562 - val_auc: 0.8600\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5138 - accuracy: 0.5327 - auc: 0.8188 - val_loss: 1.7615 - val_accuracy: 0.6597 - val_auc: 0.8746\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5911 - accuracy: 0.5353 - auc: 0.8160 - val_loss: 1.3889 - val_accuracy: 0.6561 - val_auc: 0.8517\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4829 - accuracy: 0.5460 - auc: 0.8120 - val_loss: 1.7215 - val_accuracy: 0.6831 - val_auc: 0.8718\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4803 - accuracy: 0.5780 - auc: 0.8298 - val_loss: 1.5887 - val_accuracy: 0.6975 - val_auc: 0.8689\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4731 - accuracy: 0.5649 - auc: 0.8146 - val_loss: 1.4251 - val_accuracy: 0.6772 - val_auc: 0.8697\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5960 - accuracy: 0.5441 - auc: 0.8060 - val_loss: 1.5828 - val_accuracy: 0.6717 - val_auc: 0.8700\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4417 - accuracy: 0.5487 - auc: 0.8188 - val_loss: 1.5227 - val_accuracy: 0.6723 - val_auc: 0.8717\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4476 - accuracy: 0.5561 - auc: 0.8224 - val_loss: 1.3215 - val_accuracy: 0.6668 - val_auc: 0.8728\n",
      "Epoch 23/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.4473 - accuracy: 0.5813 - auc: 0.8214Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4459 - accuracy: 0.5817 - auc: 0.8224 - val_loss: 1.7422 - val_accuracy: 0.7475 - val_auc: 0.8909\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 1.4060 - accuracy: 0.7678 - auc: 0.8056 - val_loss: 0.8174 - val_accuracy: 0.8631 - val_auc: 0.9146\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.4235 - accuracy: 0.8302 - auc: 0.8486 - val_loss: 1.3817 - val_accuracy: 0.8950 - val_auc: 0.9188\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.8519 - accuracy: 0.8162 - auc: 0.8225 - val_loss: 1.5196 - val_accuracy: 0.8505 - val_auc: 0.9047\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.3991 - accuracy: 0.8678 - auc: 0.8523 - val_loss: 1.2980 - val_accuracy: 0.8936 - val_auc: 0.8893\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 1.5416 - accuracy: 0.8763 - auc: 0.8590 - val_loss: 1.2602 - val_accuracy: 0.8951 - val_auc: 0.9216\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 3.1328 - accuracy: 0.8660 - auc: 0.8553 - val_loss: 1.9931 - val_accuracy: 0.9427 - val_auc: 0.9391\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.8942 - accuracy: 0.9198 - auc: 0.8806 - val_loss: 1.1781 - val_accuracy: 0.8411 - val_auc: 0.9240\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 2.2104 - accuracy: 0.8731 - auc: 0.8177 - val_loss: 2.2750 - val_accuracy: 0.7104 - val_auc: 0.8323\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.9571 - accuracy: 0.9238 - auc: 0.8530 - val_loss: 1.3570 - val_accuracy: 0.9412 - val_auc: 0.9150\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6188 - accuracy: 0.9377 - auc: 0.8481 - val_loss: 1.3303 - val_accuracy: 0.9318 - val_auc: 0.8937\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.9387 - accuracy: 0.7006 - auc: 0.7976 - val_loss: 1.0540 - val_accuracy: 0.9174 - val_auc: 0.8934\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7403 - accuracy: 0.7738 - auc: 0.8284 - val_loss: 1.3628 - val_accuracy: 0.9049 - val_auc: 0.9281\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5689 - accuracy: 0.9331 - auc: 0.8651 - val_loss: 1.2718 - val_accuracy: 0.9526 - val_auc: 0.9121\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4408 - accuracy: 0.8472 - auc: 0.8795 - val_loss: 1.4608 - val_accuracy: 0.9253 - val_auc: 0.9275\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.6770 - accuracy: 0.6816 - auc: 0.8603 - val_loss: 1.3357 - val_accuracy: 0.5844 - val_auc: 0.9014\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.7724 - accuracy: 0.7639 - auc: 0.8420 - val_loss: 2.0603 - val_accuracy: 0.5948 - val_auc: 0.9203\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5799 - accuracy: 0.6051 - auc: 0.8373 - val_loss: 1.7630 - val_accuracy: 0.6252 - val_auc: 0.8774\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4865 - accuracy: 0.5005 - auc: 0.8183 - val_loss: 1.6825 - val_accuracy: 0.6276 - val_auc: 0.8817\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4685 - accuracy: 0.5136 - auc: 0.8237 - val_loss: 1.6688 - val_accuracy: 0.6560 - val_auc: 0.8736\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5617 - accuracy: 0.5246 - auc: 0.8087 - val_loss: 1.4340 - val_accuracy: 0.6226 - val_auc: 0.8540\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5661 - accuracy: 0.5334 - auc: 0.8158 - val_loss: 1.6561 - val_accuracy: 0.6660 - val_auc: 0.8888\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 9us/sample - loss: 0.5790 - accuracy: 0.5222 - auc: 0.8096 - val_loss: 1.5769 - val_accuracy: 0.6435 - val_auc: 0.8876\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 8us/sample - loss: 0.4869 - accuracy: 0.5297 - auc: 0.8304 - val_loss: 1.6133 - val_accuracy: 0.6553 - val_auc: 0.8946\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4537 - accuracy: 0.5345 - auc: 0.8349 - val_loss: 1.6860 - val_accuracy: 0.6685 - val_auc: 0.8977\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5375 - accuracy: 0.5430 - auc: 0.8203 - val_loss: 1.6452 - val_accuracy: 0.6529 - val_auc: 0.8833\n",
      "Epoch 26/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.5028 - accuracy: 0.5513 - auc: 0.8309Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5018 - accuracy: 0.5515 - auc: 0.8308 - val_loss: 1.6235 - val_accuracy: 0.6846 - val_auc: 0.9187\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.5166 - accuracy: 0.8709 - auc: 0.8385 - val_loss: 0.3349 - val_accuracy: 0.9254 - val_auc: 0.9502\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3955 - accuracy: 0.9175 - auc: 0.9018 - val_loss: 0.3145 - val_accuracy: 0.9191 - val_auc: 0.9503\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3909 - accuracy: 0.9175 - auc: 0.9084 - val_loss: 0.3083 - val_accuracy: 0.9235 - val_auc: 0.9523\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3836 - accuracy: 0.9209 - auc: 0.9092 - val_loss: 0.2917 - val_accuracy: 0.9124 - val_auc: 0.9554\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3615 - accuracy: 0.9174 - auc: 0.9207 - val_loss: 0.2848 - val_accuracy: 0.9193 - val_auc: 0.9567\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3531 - accuracy: 0.9207 - auc: 0.9244 - val_loss: 0.2735 - val_accuracy: 0.9132 - val_auc: 0.9582\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3519 - accuracy: 0.9172 - auc: 0.9230 - val_loss: 0.2730 - val_accuracy: 0.9104 - val_auc: 0.9562\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3487 - accuracy: 0.9195 - auc: 0.9283 - val_loss: 0.2746 - val_accuracy: 0.9024 - val_auc: 0.9564\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3504 - accuracy: 0.9166 - auc: 0.9285 - val_loss: 0.2758 - val_accuracy: 0.9165 - val_auc: 0.9540\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3428 - accuracy: 0.9186 - auc: 0.9306 - val_loss: 0.2752 - val_accuracy: 0.9174 - val_auc: 0.9530\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3475 - accuracy: 0.9179 - auc: 0.9276 - val_loss: 0.2840 - val_accuracy: 0.9150 - val_auc: 0.9492\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3425 - accuracy: 0.9188 - auc: 0.9246 - val_loss: 0.2861 - val_accuracy: 0.9127 - val_auc: 0.9485\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3305 - accuracy: 0.9206 - auc: 0.9337 - val_loss: 0.2906 - val_accuracy: 0.9252 - val_auc: 0.9483\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3380 - accuracy: 0.9222 - auc: 0.9285 - val_loss: 0.2845 - val_accuracy: 0.9256 - val_auc: 0.9530\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3550 - accuracy: 0.9219 - auc: 0.9239 - val_loss: 0.2863 - val_accuracy: 0.9222 - val_auc: 0.9520\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3428 - accuracy: 0.9219 - auc: 0.9266 - val_loss: 0.2888 - val_accuracy: 0.9120 - val_auc: 0.9498\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3301 - accuracy: 0.9219 - auc: 0.9324 - val_loss: 0.2911 - val_accuracy: 0.9178 - val_auc: 0.9487\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3365 - accuracy: 0.9235 - auc: 0.9292 - val_loss: 0.2916 - val_accuracy: 0.9208 - val_auc: 0.9495\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3405 - accuracy: 0.9220 - auc: 0.9271 - val_loss: 0.2951 - val_accuracy: 0.9213 - val_auc: 0.9496\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3526 - accuracy: 0.9245 - auc: 0.9204 - val_loss: 0.2982 - val_accuracy: 0.9136 - val_auc: 0.9502\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3311 - accuracy: 0.9223 - auc: 0.9342 - val_loss: 0.3047 - val_accuracy: 0.9143 - val_auc: 0.9475\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3381 - accuracy: 0.9243 - auc: 0.9284 - val_loss: 0.2990 - val_accuracy: 0.9204 - val_auc: 0.9493\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3415 - accuracy: 0.9247 - auc: 0.9302 - val_loss: 0.3005 - val_accuracy: 0.9152 - val_auc: 0.9480\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3325 - accuracy: 0.9226 - auc: 0.9284 - val_loss: 0.3003 - val_accuracy: 0.9256 - val_auc: 0.9481\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3371 - accuracy: 0.9252 - auc: 0.9313 - val_loss: 0.3032 - val_accuracy: 0.9302 - val_auc: 0.9483\n",
      "Epoch 26/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.3273 - accuracy: 0.9271 - auc: 0.9308Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3284 - accuracy: 0.9272 - auc: 0.9307 - val_loss: 0.3116 - val_accuracy: 0.9382 - val_auc: 0.9478\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5185 - accuracy: 0.4712 - auc: 0.8531 - val_loss: 0.3138 - val_accuracy: 0.8710 - val_auc: 0.9461\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3893 - accuracy: 0.8774 - auc: 0.9057 - val_loss: 0.2821 - val_accuracy: 0.9036 - val_auc: 0.9556\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3795 - accuracy: 0.8896 - auc: 0.9060 - val_loss: 0.2836 - val_accuracy: 0.8931 - val_auc: 0.9540\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3694 - accuracy: 0.8991 - auc: 0.9115 - val_loss: 0.2793 - val_accuracy: 0.8942 - val_auc: 0.9538\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3699 - accuracy: 0.8956 - auc: 0.9140 - val_loss: 0.2881 - val_accuracy: 0.9148 - val_auc: 0.9528\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3502 - accuracy: 0.9044 - auc: 0.9196 - val_loss: 0.2761 - val_accuracy: 0.9063 - val_auc: 0.9554\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3540 - accuracy: 0.9087 - auc: 0.9177 - val_loss: 0.2833 - val_accuracy: 0.9026 - val_auc: 0.9536\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3456 - accuracy: 0.9096 - auc: 0.9226 - val_loss: 0.2864 - val_accuracy: 0.9060 - val_auc: 0.9522\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3450 - accuracy: 0.9084 - auc: 0.9246 - val_loss: 0.2947 - val_accuracy: 0.9126 - val_auc: 0.9487\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3412 - accuracy: 0.9132 - auc: 0.9242 - val_loss: 0.3007 - val_accuracy: 0.9184 - val_auc: 0.9502\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3317 - accuracy: 0.9142 - auc: 0.9267 - val_loss: 0.3030 - val_accuracy: 0.9133 - val_auc: 0.9496\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3329 - accuracy: 0.9139 - auc: 0.9282 - val_loss: 0.3117 - val_accuracy: 0.9266 - val_auc: 0.9480\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3255 - accuracy: 0.9169 - auc: 0.9300 - val_loss: 0.3041 - val_accuracy: 0.9080 - val_auc: 0.9484\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3382 - accuracy: 0.9178 - auc: 0.9208 - val_loss: 0.3037 - val_accuracy: 0.9108 - val_auc: 0.9484\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3261 - accuracy: 0.9166 - auc: 0.9264 - val_loss: 0.3110 - val_accuracy: 0.9117 - val_auc: 0.9488\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3391 - accuracy: 0.9149 - auc: 0.9186 - val_loss: 0.3178 - val_accuracy: 0.9090 - val_auc: 0.9458\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3200 - accuracy: 0.9183 - auc: 0.9314 - val_loss: 0.3224 - val_accuracy: 0.9152 - val_auc: 0.9478\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3217 - accuracy: 0.9186 - auc: 0.9314 - val_loss: 0.3194 - val_accuracy: 0.9162 - val_auc: 0.9500\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3288 - accuracy: 0.9210 - auc: 0.9271 - val_loss: 0.3346 - val_accuracy: 0.9184 - val_auc: 0.9460\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3278 - accuracy: 0.9177 - auc: 0.9270 - val_loss: 0.3474 - val_accuracy: 0.9204 - val_auc: 0.9431\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3374 - accuracy: 0.9212 - auc: 0.9218 - val_loss: 0.3335 - val_accuracy: 0.9101 - val_auc: 0.9457\n",
      "Epoch 22/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.9212 - auc: 0.9275Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3254 - accuracy: 0.9213 - auc: 0.9276 - val_loss: 0.3469 - val_accuracy: 0.9199 - val_auc: 0.9455\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5673 - accuracy: 0.8288 - auc: 0.8247 - val_loss: 0.3593 - val_accuracy: 0.8943 - val_auc: 0.9424\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4026 - accuracy: 0.9002 - auc: 0.9059 - val_loss: 0.3047 - val_accuracy: 0.9039 - val_auc: 0.9496\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3892 - accuracy: 0.9083 - auc: 0.9040 - val_loss: 0.2942 - val_accuracy: 0.9050 - val_auc: 0.9517\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3836 - accuracy: 0.9102 - auc: 0.9043 - val_loss: 0.2873 - val_accuracy: 0.8982 - val_auc: 0.9537\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3590 - accuracy: 0.9099 - auc: 0.9131 - val_loss: 0.2822 - val_accuracy: 0.9128 - val_auc: 0.9547\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3455 - accuracy: 0.9091 - auc: 0.9195 - val_loss: 0.2724 - val_accuracy: 0.9121 - val_auc: 0.9570\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3473 - accuracy: 0.9135 - auc: 0.9226 - val_loss: 0.2749 - val_accuracy: 0.9042 - val_auc: 0.9553\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3417 - accuracy: 0.9110 - auc: 0.9207 - val_loss: 0.2821 - val_accuracy: 0.9060 - val_auc: 0.9526\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3502 - accuracy: 0.9083 - auc: 0.9180 - val_loss: 0.2846 - val_accuracy: 0.9110 - val_auc: 0.9527\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3423 - accuracy: 0.9107 - auc: 0.9175 - val_loss: 0.2845 - val_accuracy: 0.9030 - val_auc: 0.9533\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3340 - accuracy: 0.9101 - auc: 0.9229 - val_loss: 0.2762 - val_accuracy: 0.8940 - val_auc: 0.9551\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3323 - accuracy: 0.9098 - auc: 0.9254 - val_loss: 0.2755 - val_accuracy: 0.8921 - val_auc: 0.9561\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3369 - accuracy: 0.9033 - auc: 0.9231 - val_loss: 0.2848 - val_accuracy: 0.9075 - val_auc: 0.9550\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3439 - accuracy: 0.9049 - auc: 0.9180 - val_loss: 0.2896 - val_accuracy: 0.9058 - val_auc: 0.9542\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3287 - accuracy: 0.9098 - auc: 0.9239 - val_loss: 0.2960 - val_accuracy: 0.9021 - val_auc: 0.9540\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3310 - accuracy: 0.9122 - auc: 0.9233 - val_loss: 0.2994 - val_accuracy: 0.9009 - val_auc: 0.9534\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3351 - accuracy: 0.9122 - auc: 0.9243 - val_loss: 0.3068 - val_accuracy: 0.9021 - val_auc: 0.9526\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3198 - accuracy: 0.9114 - auc: 0.9300 - val_loss: 0.3292 - val_accuracy: 0.9129 - val_auc: 0.9496\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3294 - accuracy: 0.9152 - auc: 0.9236 - val_loss: 0.3141 - val_accuracy: 0.9126 - val_auc: 0.9500\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3284 - accuracy: 0.9122 - auc: 0.9261 - val_loss: 0.3183 - val_accuracy: 0.9108 - val_auc: 0.9514\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3292 - accuracy: 0.9129 - auc: 0.9252 - val_loss: 0.3118 - val_accuracy: 0.9035 - val_auc: 0.9533\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3371 - accuracy: 0.9122 - auc: 0.9203 - val_loss: 0.3234 - val_accuracy: 0.9127 - val_auc: 0.9513\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3194 - accuracy: 0.9147 - auc: 0.9295 - val_loss: 0.3280 - val_accuracy: 0.9160 - val_auc: 0.9518\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3252 - accuracy: 0.9157 - auc: 0.9283 - val_loss: 0.3271 - val_accuracy: 0.9133 - val_auc: 0.9520\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3332 - accuracy: 0.9207 - auc: 0.9258 - val_loss: 0.3039 - val_accuracy: 0.9225 - val_auc: 0.9546\n",
      "Epoch 26/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.9234 - auc: 0.9300Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3187 - accuracy: 0.9235 - auc: 0.9301 - val_loss: 0.3059 - val_accuracy: 0.9203 - val_auc: 0.9548\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.5703 - accuracy: 0.4221 - auc: 0.8251 - val_loss: 0.3303 - val_accuracy: 0.8682 - val_auc: 0.9468\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4165 - accuracy: 0.8692 - auc: 0.8984 - val_loss: 0.3144 - val_accuracy: 0.8844 - val_auc: 0.9501\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3739 - accuracy: 0.8938 - auc: 0.9063 - val_loss: 0.2929 - val_accuracy: 0.8953 - val_auc: 0.9506\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3580 - accuracy: 0.8992 - auc: 0.9223 - val_loss: 0.2858 - val_accuracy: 0.9112 - val_auc: 0.9523\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3668 - accuracy: 0.9097 - auc: 0.9094 - val_loss: 0.2874 - val_accuracy: 0.9035 - val_auc: 0.9508\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3488 - accuracy: 0.9076 - auc: 0.9195 - val_loss: 0.2758 - val_accuracy: 0.9055 - val_auc: 0.9553\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3353 - accuracy: 0.9108 - auc: 0.9249 - val_loss: 0.2809 - val_accuracy: 0.8999 - val_auc: 0.9531\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3316 - accuracy: 0.9078 - auc: 0.9265 - val_loss: 0.2908 - val_accuracy: 0.9149 - val_auc: 0.9514\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3362 - accuracy: 0.9105 - auc: 0.9258 - val_loss: 0.2939 - val_accuracy: 0.9130 - val_auc: 0.9498\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3320 - accuracy: 0.9129 - auc: 0.9241 - val_loss: 0.3017 - val_accuracy: 0.9143 - val_auc: 0.9489\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3427 - accuracy: 0.9131 - auc: 0.9206 - val_loss: 0.2927 - val_accuracy: 0.9130 - val_auc: 0.9505\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3375 - accuracy: 0.9136 - auc: 0.9243 - val_loss: 0.2966 - val_accuracy: 0.9183 - val_auc: 0.9505\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3423 - accuracy: 0.9158 - auc: 0.9231 - val_loss: 0.2933 - val_accuracy: 0.9067 - val_auc: 0.9515\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3327 - accuracy: 0.9142 - auc: 0.9272 - val_loss: 0.2938 - val_accuracy: 0.9088 - val_auc: 0.9510\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3156 - accuracy: 0.9191 - auc: 0.9325 - val_loss: 0.2958 - val_accuracy: 0.9204 - val_auc: 0.9519\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3265 - accuracy: 0.9219 - auc: 0.9291 - val_loss: 0.3020 - val_accuracy: 0.9170 - val_auc: 0.9504\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3379 - accuracy: 0.9157 - auc: 0.9220 - val_loss: 0.3007 - val_accuracy: 0.9200 - val_auc: 0.9491\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3312 - accuracy: 0.9182 - auc: 0.9243 - val_loss: 0.3029 - val_accuracy: 0.9124 - val_auc: 0.9489\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3369 - accuracy: 0.9206 - auc: 0.9222 - val_loss: 0.3011 - val_accuracy: 0.9261 - val_auc: 0.9515\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3265 - accuracy: 0.9239 - auc: 0.9254 - val_loss: 0.3044 - val_accuracy: 0.9236 - val_auc: 0.9509\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3268 - accuracy: 0.9190 - auc: 0.9256 - val_loss: 0.3167 - val_accuracy: 0.9164 - val_auc: 0.9497\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3188 - accuracy: 0.9218 - auc: 0.9325 - val_loss: 0.3116 - val_accuracy: 0.9132 - val_auc: 0.9492\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3179 - accuracy: 0.9263 - auc: 0.9332 - val_loss: 0.3079 - val_accuracy: 0.9172 - val_auc: 0.9496\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3341 - accuracy: 0.9231 - auc: 0.9249 - val_loss: 0.3264 - val_accuracy: 0.9291 - val_auc: 0.9487\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3289 - accuracy: 0.9253 - auc: 0.9263 - val_loss: 0.3222 - val_accuracy: 0.9162 - val_auc: 0.9482\n",
      "Epoch 26/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.3216 - accuracy: 0.9208 - auc: 0.9354Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3209 - accuracy: 0.9209 - auc: 0.9360 - val_loss: 0.3202 - val_accuracy: 0.9217 - val_auc: 0.9476\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.5759 - accuracy: 0.8740 - auc: 0.7898 - val_loss: 0.3624 - val_accuracy: 0.8932 - val_auc: 0.9462\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4477 - accuracy: 0.9039 - auc: 0.8749 - val_loss: 0.3075 - val_accuracy: 0.8906 - val_auc: 0.9540\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3919 - accuracy: 0.9027 - auc: 0.9028 - val_loss: 0.2688 - val_accuracy: 0.8936 - val_auc: 0.9590\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4014 - accuracy: 0.8963 - auc: 0.8972 - val_loss: 0.2976 - val_accuracy: 0.8877 - val_auc: 0.9519\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3626 - accuracy: 0.8934 - auc: 0.9148 - val_loss: 0.2775 - val_accuracy: 0.8774 - val_auc: 0.9548\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3485 - accuracy: 0.7951 - auc: 0.9157 - val_loss: 0.2777 - val_accuracy: 0.8629 - val_auc: 0.9564\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3372 - accuracy: 0.7094 - auc: 0.9227 - val_loss: 0.3018 - val_accuracy: 0.8732 - val_auc: 0.9507\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3542 - accuracy: 0.7107 - auc: 0.9132 - val_loss: 0.3015 - val_accuracy: 0.8472 - val_auc: 0.9512\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3410 - accuracy: 0.7018 - auc: 0.9216 - val_loss: 0.2959 - val_accuracy: 0.8547 - val_auc: 0.9535\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3250 - accuracy: 0.7212 - auc: 0.9271 - val_loss: 0.2966 - val_accuracy: 0.8531 - val_auc: 0.9523\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3313 - accuracy: 0.7206 - auc: 0.9243 - val_loss: 0.2890 - val_accuracy: 0.8589 - val_auc: 0.9550\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3296 - accuracy: 0.7196 - auc: 0.9236 - val_loss: 0.2986 - val_accuracy: 0.8573 - val_auc: 0.9527\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3220 - accuracy: 0.7181 - auc: 0.9274 - val_loss: 0.3105 - val_accuracy: 0.8603 - val_auc: 0.9520\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3217 - accuracy: 0.7169 - auc: 0.9291 - val_loss: 0.3211 - val_accuracy: 0.8701 - val_auc: 0.9517\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3253 - accuracy: 0.7202 - auc: 0.9259 - val_loss: 0.3261 - val_accuracy: 0.8570 - val_auc: 0.9518\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3249 - accuracy: 0.7140 - auc: 0.9293 - val_loss: 0.3202 - val_accuracy: 0.8576 - val_auc: 0.9507\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3216 - accuracy: 0.7071 - auc: 0.9253 - val_loss: 0.3368 - val_accuracy: 0.8617 - val_auc: 0.9508\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3127 - accuracy: 0.7194 - auc: 0.9310 - val_loss: 0.3397 - val_accuracy: 0.8646 - val_auc: 0.9518\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3187 - accuracy: 0.7159 - auc: 0.9264 - val_loss: 0.3335 - val_accuracy: 0.8654 - val_auc: 0.9520\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3081 - accuracy: 0.7247 - auc: 0.9326 - val_loss: 0.3429 - val_accuracy: 0.8620 - val_auc: 0.9512\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3246 - accuracy: 0.7176 - auc: 0.9229 - val_loss: 0.3427 - val_accuracy: 0.8548 - val_auc: 0.9517\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3243 - accuracy: 0.7106 - auc: 0.9272 - val_loss: 0.3422 - val_accuracy: 0.8541 - val_auc: 0.9522\n",
      "Epoch 23/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.7152 - auc: 0.9331 ETA: 0s - loss: 0.3050 - accuracy: 0.7136Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3039 - accuracy: 0.7156 - auc: 0.9333 - val_loss: 0.3728 - val_accuracy: 0.8657 - val_auc: 0.9483\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6134 - accuracy: 0.7250 - auc: 0.8425 - val_loss: 0.3288 - val_accuracy: 0.9042 - val_auc: 0.9417\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3918 - accuracy: 0.8720 - auc: 0.9179 - val_loss: 0.2666 - val_accuracy: 0.8834 - val_auc: 0.9592\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3674 - accuracy: 0.8699 - auc: 0.9271 - val_loss: 0.2655 - val_accuracy: 0.8912 - val_auc: 0.9580\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3499 - accuracy: 0.8733 - auc: 0.9303 - val_loss: 0.2719 - val_accuracy: 0.8951 - val_auc: 0.9553\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3160 - accuracy: 0.8558 - auc: 0.9415 - val_loss: 0.2652 - val_accuracy: 0.8870 - val_auc: 0.9579\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3130 - accuracy: 0.8360 - auc: 0.9434 - val_loss: 0.2661 - val_accuracy: 0.8869 - val_auc: 0.9582\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3079 - accuracy: 0.8288 - auc: 0.9438 - val_loss: 0.2717 - val_accuracy: 0.8787 - val_auc: 0.9569\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2898 - accuracy: 0.8260 - auc: 0.9491 - val_loss: 0.2808 - val_accuracy: 0.8866 - val_auc: 0.9532\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2910 - accuracy: 0.8274 - auc: 0.9485 - val_loss: 0.2970 - val_accuracy: 0.8933 - val_auc: 0.9526\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2822 - accuracy: 0.8340 - auc: 0.9500 - val_loss: 0.2862 - val_accuracy: 0.8813 - val_auc: 0.9546\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2877 - accuracy: 0.8272 - auc: 0.9503 - val_loss: 0.2878 - val_accuracy: 0.8743 - val_auc: 0.9544\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2832 - accuracy: 0.8272 - auc: 0.9510 - val_loss: 0.2995 - val_accuracy: 0.8892 - val_auc: 0.9534\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2751 - accuracy: 0.8349 - auc: 0.9545 - val_loss: 0.3058 - val_accuracy: 0.8883 - val_auc: 0.9528\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2615 - accuracy: 0.8480 - auc: 0.9588 - val_loss: 0.3111 - val_accuracy: 0.8911 - val_auc: 0.9517\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2736 - accuracy: 0.8401 - auc: 0.9546 - val_loss: 0.3063 - val_accuracy: 0.8861 - val_auc: 0.9528\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2759 - accuracy: 0.8394 - auc: 0.9543 - val_loss: 0.3018 - val_accuracy: 0.8746 - val_auc: 0.9516\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2764 - accuracy: 0.8308 - auc: 0.9531 - val_loss: 0.3159 - val_accuracy: 0.8766 - val_auc: 0.9491\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2635 - accuracy: 0.8355 - auc: 0.9574 - val_loss: 0.3270 - val_accuracy: 0.8957 - val_auc: 0.9513\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2732 - accuracy: 0.8372 - auc: 0.9548 - val_loss: 0.3037 - val_accuracy: 0.8765 - val_auc: 0.9528\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2723 - accuracy: 0.8334 - auc: 0.9541 - val_loss: 0.3212 - val_accuracy: 0.8876 - val_auc: 0.9503\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2584 - accuracy: 0.8364 - auc: 0.9576 - val_loss: 0.3252 - val_accuracy: 0.8913 - val_auc: 0.9522\n",
      "Epoch 22/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2610 - accuracy: 0.8349 - auc: 0.9591Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2605 - accuracy: 0.8347 - auc: 0.9597 - val_loss: 0.3281 - val_accuracy: 0.8783 - val_auc: 0.9503\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5396 - accuracy: 0.4514 - auc: 0.8817 - val_loss: 0.3133 - val_accuracy: 0.8272 - val_auc: 0.9448\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3616 - accuracy: 0.7320 - auc: 0.9337 - val_loss: 0.2941 - val_accuracy: 0.8882 - val_auc: 0.9506\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3442 - accuracy: 0.8782 - auc: 0.9428 - val_loss: 0.2715 - val_accuracy: 0.8778 - val_auc: 0.9579\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3187 - accuracy: 0.8879 - auc: 0.9427 - val_loss: 0.2676 - val_accuracy: 0.9050 - val_auc: 0.9581\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3057 - accuracy: 0.9022 - auc: 0.9467 - val_loss: 0.2656 - val_accuracy: 0.9072 - val_auc: 0.9585\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2883 - accuracy: 0.9083 - auc: 0.9518 - val_loss: 0.2823 - val_accuracy: 0.9135 - val_auc: 0.9542\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2817 - accuracy: 0.9076 - auc: 0.9559 - val_loss: 0.2788 - val_accuracy: 0.9055 - val_auc: 0.9566\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2865 - accuracy: 0.9060 - auc: 0.9538 - val_loss: 0.2845 - val_accuracy: 0.9223 - val_auc: 0.9535\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2762 - accuracy: 0.9160 - auc: 0.9565 - val_loss: 0.2898 - val_accuracy: 0.9038 - val_auc: 0.9535\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2764 - accuracy: 0.9110 - auc: 0.9569 - val_loss: 0.2789 - val_accuracy: 0.9239 - val_auc: 0.9569\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2757 - accuracy: 0.9093 - auc: 0.9573 - val_loss: 0.2740 - val_accuracy: 0.9163 - val_auc: 0.9582\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2648 - accuracy: 0.9157 - auc: 0.9613 - val_loss: 0.2804 - val_accuracy: 0.9200 - val_auc: 0.9565\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2770 - accuracy: 0.9132 - auc: 0.9583 - val_loss: 0.2944 - val_accuracy: 0.9282 - val_auc: 0.9550\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2696 - accuracy: 0.9170 - auc: 0.9590 - val_loss: 0.2967 - val_accuracy: 0.9121 - val_auc: 0.9539\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2733 - accuracy: 0.9161 - auc: 0.9577 - val_loss: 0.2921 - val_accuracy: 0.9177 - val_auc: 0.9536\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2661 - accuracy: 0.9137 - auc: 0.9604 - val_loss: 0.3270 - val_accuracy: 0.9364 - val_auc: 0.9463\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2653 - accuracy: 0.9158 - auc: 0.9594 - val_loss: 0.3196 - val_accuracy: 0.9252 - val_auc: 0.9477\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2667 - accuracy: 0.9121 - auc: 0.9596 - val_loss: 0.3200 - val_accuracy: 0.9269 - val_auc: 0.9506\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2605 - accuracy: 0.9167 - auc: 0.9627 - val_loss: 0.3090 - val_accuracy: 0.9209 - val_auc: 0.9538\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2641 - accuracy: 0.9182 - auc: 0.9613 - val_loss: 0.3089 - val_accuracy: 0.9166 - val_auc: 0.9533\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2689 - accuracy: 0.9122 - auc: 0.9585 - val_loss: 0.3068 - val_accuracy: 0.9215 - val_auc: 0.9530\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2626 - accuracy: 0.9204 - auc: 0.9603 - val_loss: 0.3135 - val_accuracy: 0.9173 - val_auc: 0.9525\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2618 - accuracy: 0.9146 - auc: 0.9602 - val_loss: 0.3421 - val_accuracy: 0.9269 - val_auc: 0.9480\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2701 - accuracy: 0.9183 - auc: 0.9581 - val_loss: 0.3456 - val_accuracy: 0.9176 - val_auc: 0.9478\n",
      "Epoch 25/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2576 - accuracy: 0.9165 - auc: 0.9624Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2587 - accuracy: 0.9165 - auc: 0.9619 - val_loss: 0.3477 - val_accuracy: 0.9191 - val_auc: 0.9486\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5938 - accuracy: 0.8330 - auc: 0.8383 - val_loss: 0.3248 - val_accuracy: 0.9130 - val_auc: 0.9407\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3840 - accuracy: 0.9045 - auc: 0.9150 - val_loss: 0.3013 - val_accuracy: 0.9075 - val_auc: 0.9472\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3567 - accuracy: 0.9076 - auc: 0.9294 - val_loss: 0.2885 - val_accuracy: 0.9135 - val_auc: 0.9554\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3412 - accuracy: 0.9072 - auc: 0.9363 - val_loss: 0.2817 - val_accuracy: 0.9106 - val_auc: 0.9544\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3291 - accuracy: 0.9116 - auc: 0.9407 - val_loss: 0.2958 - val_accuracy: 0.9185 - val_auc: 0.9483\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3267 - accuracy: 0.9124 - auc: 0.9405 - val_loss: 0.2782 - val_accuracy: 0.8949 - val_auc: 0.9567\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3150 - accuracy: 0.9130 - auc: 0.9442 - val_loss: 0.2752 - val_accuracy: 0.9075 - val_auc: 0.9545\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3041 - accuracy: 0.9081 - auc: 0.9475 - val_loss: 0.2761 - val_accuracy: 0.8987 - val_auc: 0.9550\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2897 - accuracy: 0.9083 - auc: 0.9520 - val_loss: 0.2777 - val_accuracy: 0.9141 - val_auc: 0.9545\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3012 - accuracy: 0.9065 - auc: 0.9467 - val_loss: 0.2900 - val_accuracy: 0.9030 - val_auc: 0.9521\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2942 - accuracy: 0.9090 - auc: 0.9505 - val_loss: 0.2913 - val_accuracy: 0.9101 - val_auc: 0.9508\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2812 - accuracy: 0.9087 - auc: 0.9549 - val_loss: 0.3144 - val_accuracy: 0.9256 - val_auc: 0.9503\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2865 - accuracy: 0.9061 - auc: 0.9518 - val_loss: 0.3096 - val_accuracy: 0.9014 - val_auc: 0.9515\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2860 - accuracy: 0.9061 - auc: 0.9528 - val_loss: 0.2978 - val_accuracy: 0.9050 - val_auc: 0.9526\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2795 - accuracy: 0.9069 - auc: 0.9551 - val_loss: 0.3011 - val_accuracy: 0.8971 - val_auc: 0.9526\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2784 - accuracy: 0.9079 - auc: 0.9544 - val_loss: 0.3164 - val_accuracy: 0.9156 - val_auc: 0.9512\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2735 - accuracy: 0.9077 - auc: 0.9560 - val_loss: 0.3195 - val_accuracy: 0.9032 - val_auc: 0.9518\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2683 - accuracy: 0.9066 - auc: 0.9577 - val_loss: 0.3368 - val_accuracy: 0.9137 - val_auc: 0.9495\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2746 - accuracy: 0.9048 - auc: 0.9554 - val_loss: 0.3407 - val_accuracy: 0.9057 - val_auc: 0.9492\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2698 - accuracy: 0.9034 - auc: 0.9566 - val_loss: 0.3562 - val_accuracy: 0.9084 - val_auc: 0.9481\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2614 - accuracy: 0.9019 - auc: 0.9589 - val_loss: 0.3732 - val_accuracy: 0.9147 - val_auc: 0.9485\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2626 - accuracy: 0.9125 - auc: 0.9584 - val_loss: 0.3659 - val_accuracy: 0.9069 - val_auc: 0.9483\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2642 - accuracy: 0.9062 - auc: 0.9574 - val_loss: 0.3775 - val_accuracy: 0.9056 - val_auc: 0.9479\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2558 - accuracy: 0.9052 - auc: 0.9614 - val_loss: 0.3875 - val_accuracy: 0.9106 - val_auc: 0.9471\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2582 - accuracy: 0.9100 - auc: 0.9596 - val_loss: 0.3820 - val_accuracy: 0.9157 - val_auc: 0.9503\n",
      "Epoch 26/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.9052 - auc: 0.9610Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2513 - accuracy: 0.9050 - auc: 0.9616 - val_loss: 0.3970 - val_accuracy: 0.9099 - val_auc: 0.9513\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 18us/sample - loss: 0.4764 - accuracy: 0.6266 - auc: 0.8802 - val_loss: 0.2948 - val_accuracy: 0.8869 - val_auc: 0.9530\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3373 - accuracy: 0.8670 - auc: 0.9357 - val_loss: 0.2775 - val_accuracy: 0.9097 - val_auc: 0.9548\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3313 - accuracy: 0.8972 - auc: 0.9419 - val_loss: 0.2714 - val_accuracy: 0.8973 - val_auc: 0.9562\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3039 - accuracy: 0.9026 - auc: 0.9466 - val_loss: 0.2719 - val_accuracy: 0.9219 - val_auc: 0.9577\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2958 - accuracy: 0.9072 - auc: 0.9494 - val_loss: 0.2615 - val_accuracy: 0.9135 - val_auc: 0.9594\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2878 - accuracy: 0.9089 - auc: 0.9523 - val_loss: 0.2714 - val_accuracy: 0.9132 - val_auc: 0.9566\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2893 - accuracy: 0.9092 - auc: 0.9540 - val_loss: 0.2780 - val_accuracy: 0.9095 - val_auc: 0.9547\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2747 - accuracy: 0.9116 - auc: 0.9572 - val_loss: 0.2889 - val_accuracy: 0.9143 - val_auc: 0.9521\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2857 - accuracy: 0.9121 - auc: 0.9517 - val_loss: 0.2880 - val_accuracy: 0.8972 - val_auc: 0.9527\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2848 - accuracy: 0.9070 - auc: 0.9539 - val_loss: 0.2823 - val_accuracy: 0.9301 - val_auc: 0.9563\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2814 - accuracy: 0.9098 - auc: 0.9539 - val_loss: 0.2852 - val_accuracy: 0.9204 - val_auc: 0.9550\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2931 - accuracy: 0.9136 - auc: 0.9527 - val_loss: 0.2916 - val_accuracy: 0.9043 - val_auc: 0.9524\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2776 - accuracy: 0.9146 - auc: 0.9566 - val_loss: 0.2965 - val_accuracy: 0.9198 - val_auc: 0.9507\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2773 - accuracy: 0.9150 - auc: 0.9562 - val_loss: 0.3106 - val_accuracy: 0.9244 - val_auc: 0.9494\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2736 - accuracy: 0.9155 - auc: 0.9566 - val_loss: 0.3238 - val_accuracy: 0.9278 - val_auc: 0.9482\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2818 - accuracy: 0.9145 - auc: 0.9561 - val_loss: 0.3076 - val_accuracy: 0.9214 - val_auc: 0.9491\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2792 - accuracy: 0.9179 - auc: 0.9560 - val_loss: 0.3113 - val_accuracy: 0.9156 - val_auc: 0.9505\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2722 - accuracy: 0.9180 - auc: 0.9570 - val_loss: 0.3241 - val_accuracy: 0.9276 - val_auc: 0.9490\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2778 - accuracy: 0.9152 - auc: 0.9550 - val_loss: 0.3230 - val_accuracy: 0.9272 - val_auc: 0.9493\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2783 - accuracy: 0.9156 - auc: 0.9562 - val_loss: 0.3127 - val_accuracy: 0.9235 - val_auc: 0.9501\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2710 - accuracy: 0.9175 - auc: 0.9582 - val_loss: 0.3273 - val_accuracy: 0.9286 - val_auc: 0.9484\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2721 - accuracy: 0.9183 - auc: 0.9570 - val_loss: 0.3288 - val_accuracy: 0.9266 - val_auc: 0.9490\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2653 - accuracy: 0.9204 - auc: 0.9588 - val_loss: 0.3476 - val_accuracy: 0.9191 - val_auc: 0.9486\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2669 - accuracy: 0.9182 - auc: 0.9580 - val_loss: 0.3336 - val_accuracy: 0.9255 - val_auc: 0.9485\n",
      "Epoch 25/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9213 - auc: 0.9605Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2573 - accuracy: 0.9212 - auc: 0.9606 - val_loss: 0.3483 - val_accuracy: 0.9184 - val_auc: 0.9460\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.6221 - accuracy: 0.8939 - auc: 0.8123 - val_loss: 0.3346 - val_accuracy: 0.8994 - val_auc: 0.9498\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3836 - accuracy: 0.9077 - auc: 0.9196 - val_loss: 0.2965 - val_accuracy: 0.9207 - val_auc: 0.9560\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3478 - accuracy: 0.9104 - auc: 0.9354 - val_loss: 0.2855 - val_accuracy: 0.9123 - val_auc: 0.9569\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3426 - accuracy: 0.9149 - auc: 0.9376 - val_loss: 0.2910 - val_accuracy: 0.9030 - val_auc: 0.9553\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3341 - accuracy: 0.9164 - auc: 0.9401 - val_loss: 0.2822 - val_accuracy: 0.9312 - val_auc: 0.9569\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3264 - accuracy: 0.9166 - auc: 0.9421 - val_loss: 0.2769 - val_accuracy: 0.9216 - val_auc: 0.9563\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3294 - accuracy: 0.9166 - auc: 0.9438 - val_loss: 0.2856 - val_accuracy: 0.9088 - val_auc: 0.9523\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3233 - accuracy: 0.9155 - auc: 0.9432 - val_loss: 0.2815 - val_accuracy: 0.9125 - val_auc: 0.9532\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3075 - accuracy: 0.9180 - auc: 0.9505 - val_loss: 0.2833 - val_accuracy: 0.9169 - val_auc: 0.9529\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3007 - accuracy: 0.9196 - auc: 0.9514 - val_loss: 0.2845 - val_accuracy: 0.9278 - val_auc: 0.9526\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3056 - accuracy: 0.9206 - auc: 0.9500 - val_loss: 0.2884 - val_accuracy: 0.9113 - val_auc: 0.9511\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3033 - accuracy: 0.9183 - auc: 0.9509 - val_loss: 0.2960 - val_accuracy: 0.9148 - val_auc: 0.9503\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3120 - accuracy: 0.9174 - auc: 0.9485 - val_loss: 0.2907 - val_accuracy: 0.9151 - val_auc: 0.9525\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3009 - accuracy: 0.9176 - auc: 0.9534 - val_loss: 0.2982 - val_accuracy: 0.9302 - val_auc: 0.9500\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2941 - accuracy: 0.9174 - auc: 0.9522 - val_loss: 0.2961 - val_accuracy: 0.9227 - val_auc: 0.9507\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2807 - accuracy: 0.9202 - auc: 0.9549 - val_loss: 0.3240 - val_accuracy: 0.9218 - val_auc: 0.9462\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2941 - accuracy: 0.9144 - auc: 0.9523 - val_loss: 0.3145 - val_accuracy: 0.9255 - val_auc: 0.9493\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2847 - accuracy: 0.9144 - auc: 0.9554 - val_loss: 0.3169 - val_accuracy: 0.9251 - val_auc: 0.9501\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2752 - accuracy: 0.9169 - auc: 0.9573 - val_loss: 0.3335 - val_accuracy: 0.9264 - val_auc: 0.9505\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2791 - accuracy: 0.9169 - auc: 0.9575 - val_loss: 0.3395 - val_accuracy: 0.9220 - val_auc: 0.9491\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2661 - accuracy: 0.9162 - auc: 0.9597 - val_loss: 0.3424 - val_accuracy: 0.9229 - val_auc: 0.9481\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2711 - accuracy: 0.9157 - auc: 0.9593 - val_loss: 0.3512 - val_accuracy: 0.9242 - val_auc: 0.9472\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2725 - accuracy: 0.9193 - auc: 0.9570 - val_loss: 0.3685 - val_accuracy: 0.9174 - val_auc: 0.9478\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2642 - accuracy: 0.9161 - auc: 0.9600 - val_loss: 0.3866 - val_accuracy: 0.9126 - val_auc: 0.9461\n",
      "Epoch 25/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.9167 - auc: 0.9605Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2673 - accuracy: 0.9167 - auc: 0.9603 - val_loss: 0.3787 - val_accuracy: 0.9147 - val_auc: 0.9469\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.4912 - accuracy: 0.7766 - auc: 0.8790 - val_loss: 0.2990 - val_accuracy: 0.8658 - val_auc: 0.9500\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3295 - accuracy: 0.8756 - auc: 0.9394 - val_loss: 0.2733 - val_accuracy: 0.8611 - val_auc: 0.9588\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3179 - accuracy: 0.8816 - auc: 0.9440 - val_loss: 0.2728 - val_accuracy: 0.9029 - val_auc: 0.9560\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2905 - accuracy: 0.8962 - auc: 0.9516 - val_loss: 0.2726 - val_accuracy: 0.8889 - val_auc: 0.9568\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2725 - accuracy: 0.8893 - auc: 0.9566 - val_loss: 0.2796 - val_accuracy: 0.8984 - val_auc: 0.9553\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2794 - accuracy: 0.8888 - auc: 0.9562 - val_loss: 0.2966 - val_accuracy: 0.9065 - val_auc: 0.9517\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2656 - accuracy: 0.9008 - auc: 0.9591 - val_loss: 0.2862 - val_accuracy: 0.9002 - val_auc: 0.9527\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2842 - accuracy: 0.8900 - auc: 0.9553 - val_loss: 0.2820 - val_accuracy: 0.8929 - val_auc: 0.9555\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2555 - accuracy: 0.8963 - auc: 0.9622 - val_loss: 0.2751 - val_accuracy: 0.9092 - val_auc: 0.9560\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2635 - accuracy: 0.8950 - auc: 0.9594 - val_loss: 0.2898 - val_accuracy: 0.9048 - val_auc: 0.9547\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2551 - accuracy: 0.8984 - auc: 0.9613 - val_loss: 0.3133 - val_accuracy: 0.9048 - val_auc: 0.9513\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2597 - accuracy: 0.8960 - auc: 0.9611 - val_loss: 0.2981 - val_accuracy: 0.8930 - val_auc: 0.9532\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2500 - accuracy: 0.8948 - auc: 0.9627 - val_loss: 0.3216 - val_accuracy: 0.9142 - val_auc: 0.9517\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2569 - accuracy: 0.8965 - auc: 0.9621 - val_loss: 0.3401 - val_accuracy: 0.9124 - val_auc: 0.9466\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2323 - accuracy: 0.9004 - auc: 0.9672 - val_loss: 0.3641 - val_accuracy: 0.9024 - val_auc: 0.9480\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2379 - accuracy: 0.8949 - auc: 0.9659 - val_loss: 0.3785 - val_accuracy: 0.9115 - val_auc: 0.9467\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2453 - accuracy: 0.8904 - auc: 0.9651 - val_loss: 0.3665 - val_accuracy: 0.8920 - val_auc: 0.9469\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2483 - accuracy: 0.8885 - auc: 0.9647 - val_loss: 0.3793 - val_accuracy: 0.9019 - val_auc: 0.9446\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2324 - accuracy: 0.8952 - auc: 0.9675 - val_loss: 0.3981 - val_accuracy: 0.9008 - val_auc: 0.9467\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2370 - accuracy: 0.8863 - auc: 0.9673 - val_loss: 0.4203 - val_accuracy: 0.9138 - val_auc: 0.9472\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2357 - accuracy: 0.8947 - auc: 0.9667 - val_loss: 0.4099 - val_accuracy: 0.9094 - val_auc: 0.9466\n",
      "Epoch 22/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.8973 - auc: 0.9662Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2402 - accuracy: 0.8973 - auc: 0.9662 - val_loss: 0.4221 - val_accuracy: 0.9071 - val_auc: 0.9432\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5069 - accuracy: 0.7125 - auc: 0.8788 - val_loss: 0.2905 - val_accuracy: 0.8999 - val_auc: 0.9502\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3373 - accuracy: 0.8558 - auc: 0.9383 - val_loss: 0.2855 - val_accuracy: 0.9017 - val_auc: 0.9508\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3003 - accuracy: 0.8781 - auc: 0.9486 - val_loss: 0.2807 - val_accuracy: 0.8873 - val_auc: 0.9547\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2964 - accuracy: 0.8886 - auc: 0.9497 - val_loss: 0.2971 - val_accuracy: 0.9031 - val_auc: 0.9483\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2722 - accuracy: 0.8959 - auc: 0.9565 - val_loss: 0.3065 - val_accuracy: 0.9027 - val_auc: 0.9479\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2758 - accuracy: 0.8950 - auc: 0.9560 - val_loss: 0.3037 - val_accuracy: 0.9013 - val_auc: 0.9488\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2531 - accuracy: 0.8964 - auc: 0.9623 - val_loss: 0.3231 - val_accuracy: 0.9081 - val_auc: 0.9480\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2740 - accuracy: 0.8992 - auc: 0.9584 - val_loss: 0.2960 - val_accuracy: 0.9078 - val_auc: 0.9504\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2534 - accuracy: 0.8995 - auc: 0.9627 - val_loss: 0.3131 - val_accuracy: 0.9104 - val_auc: 0.9495\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2592 - accuracy: 0.9006 - auc: 0.9618 - val_loss: 0.3195 - val_accuracy: 0.9212 - val_auc: 0.9480\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2504 - accuracy: 0.9065 - auc: 0.9635 - val_loss: 0.3488 - val_accuracy: 0.9194 - val_auc: 0.9459\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2394 - accuracy: 0.9061 - auc: 0.9656 - val_loss: 0.3632 - val_accuracy: 0.9075 - val_auc: 0.9456\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2423 - accuracy: 0.8981 - auc: 0.9650 - val_loss: 0.3686 - val_accuracy: 0.9047 - val_auc: 0.9434\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2328 - accuracy: 0.8999 - auc: 0.9671 - val_loss: 0.3909 - val_accuracy: 0.9098 - val_auc: 0.9444\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2304 - accuracy: 0.8944 - auc: 0.9678 - val_loss: 0.4311 - val_accuracy: 0.9107 - val_auc: 0.9448\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2372 - accuracy: 0.8968 - auc: 0.9664 - val_loss: 0.4243 - val_accuracy: 0.9155 - val_auc: 0.9435\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2220 - accuracy: 0.9054 - auc: 0.9698 - val_loss: 0.4420 - val_accuracy: 0.9097 - val_auc: 0.9458\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2187 - accuracy: 0.8993 - auc: 0.9705 - val_loss: 0.4618 - val_accuracy: 0.9076 - val_auc: 0.9453\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2335 - accuracy: 0.8872 - auc: 0.9669 - val_loss: 0.4804 - val_accuracy: 0.9102 - val_auc: 0.9368\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2368 - accuracy: 0.8986 - auc: 0.9672 - val_loss: 0.4875 - val_accuracy: 0.9121 - val_auc: 0.9387\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2199 - accuracy: 0.8901 - auc: 0.9698 - val_loss: 0.5169 - val_accuracy: 0.9087 - val_auc: 0.9373\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2176 - accuracy: 0.8744 - auc: 0.9706 - val_loss: 0.5163 - val_accuracy: 0.9031 - val_auc: 0.9383\n",
      "Epoch 23/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2099 - accuracy: 0.8755 - auc: 0.9721Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2093 - accuracy: 0.8755 - auc: 0.9721 - val_loss: 0.5835 - val_accuracy: 0.9103 - val_auc: 0.9384\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.5325 - accuracy: 0.7747 - auc: 0.8696 - val_loss: 0.2948 - val_accuracy: 0.8883 - val_auc: 0.9508\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3353 - accuracy: 0.8686 - auc: 0.9353 - val_loss: 0.2862 - val_accuracy: 0.9079 - val_auc: 0.9536\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3297 - accuracy: 0.8835 - auc: 0.9413 - val_loss: 0.2699 - val_accuracy: 0.8848 - val_auc: 0.9575\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2866 - accuracy: 0.8913 - auc: 0.9522 - val_loss: 0.2749 - val_accuracy: 0.8903 - val_auc: 0.9555\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2888 - accuracy: 0.8925 - auc: 0.9515 - val_loss: 0.2641 - val_accuracy: 0.9208 - val_auc: 0.9590\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2721 - accuracy: 0.9032 - auc: 0.9559 - val_loss: 0.2746 - val_accuracy: 0.9057 - val_auc: 0.9556\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2680 - accuracy: 0.8992 - auc: 0.9572 - val_loss: 0.2817 - val_accuracy: 0.9010 - val_auc: 0.9527\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2734 - accuracy: 0.9009 - auc: 0.9559 - val_loss: 0.2880 - val_accuracy: 0.8855 - val_auc: 0.9524\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2652 - accuracy: 0.8970 - auc: 0.9580 - val_loss: 0.2889 - val_accuracy: 0.8957 - val_auc: 0.9544\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2617 - accuracy: 0.8996 - auc: 0.9593 - val_loss: 0.2942 - val_accuracy: 0.9020 - val_auc: 0.9522\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2493 - accuracy: 0.9015 - auc: 0.9631 - val_loss: 0.3194 - val_accuracy: 0.9089 - val_auc: 0.9482\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2486 - accuracy: 0.9008 - auc: 0.9624 - val_loss: 0.3182 - val_accuracy: 0.9118 - val_auc: 0.9497\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2411 - accuracy: 0.8998 - auc: 0.9641 - val_loss: 0.3303 - val_accuracy: 0.8997 - val_auc: 0.9486\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2328 - accuracy: 0.8994 - auc: 0.9667 - val_loss: 0.3436 - val_accuracy: 0.9105 - val_auc: 0.9480\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2400 - accuracy: 0.9019 - auc: 0.9643 - val_loss: 0.3433 - val_accuracy: 0.9058 - val_auc: 0.9482\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2380 - accuracy: 0.8966 - auc: 0.9647 - val_loss: 0.3555 - val_accuracy: 0.9092 - val_auc: 0.9477\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2376 - accuracy: 0.9000 - auc: 0.9665 - val_loss: 0.3740 - val_accuracy: 0.9025 - val_auc: 0.9471\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2395 - accuracy: 0.8989 - auc: 0.9652 - val_loss: 0.3744 - val_accuracy: 0.9064 - val_auc: 0.9462\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2474 - accuracy: 0.8930 - auc: 0.9635 - val_loss: 0.3455 - val_accuracy: 0.9001 - val_auc: 0.9462\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2289 - accuracy: 0.8917 - auc: 0.9675 - val_loss: 0.3789 - val_accuracy: 0.9017 - val_auc: 0.9466\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2218 - accuracy: 0.8979 - auc: 0.9689 - val_loss: 0.4387 - val_accuracy: 0.9150 - val_auc: 0.9420\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2297 - accuracy: 0.8928 - auc: 0.9667 - val_loss: 0.4345 - val_accuracy: 0.9061 - val_auc: 0.9439\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2343 - accuracy: 0.8917 - auc: 0.9670 - val_loss: 0.4326 - val_accuracy: 0.9145 - val_auc: 0.9470\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2337 - accuracy: 0.8971 - auc: 0.9665 - val_loss: 0.4424 - val_accuracy: 0.9056 - val_auc: 0.9414\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2178 - accuracy: 0.8961 - auc: 0.9703Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2179 - accuracy: 0.8962 - auc: 0.9702 - val_loss: 0.4983 - val_accuracy: 0.9184 - val_auc: 0.9413\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.4827 - accuracy: 0.7006 - auc: 0.8840 - val_loss: 0.3005 - val_accuracy: 0.8976 - val_auc: 0.9483\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3506 - accuracy: 0.8652 - auc: 0.9354 - val_loss: 0.2793 - val_accuracy: 0.8948 - val_auc: 0.9540\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3113 - accuracy: 0.8837 - auc: 0.9443 - val_loss: 0.2764 - val_accuracy: 0.9127 - val_auc: 0.9543\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2870 - accuracy: 0.8953 - auc: 0.9541 - val_loss: 0.2643 - val_accuracy: 0.9030 - val_auc: 0.9592\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2781 - accuracy: 0.9030 - auc: 0.9548 - val_loss: 0.2630 - val_accuracy: 0.9014 - val_auc: 0.9578\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2780 - accuracy: 0.8983 - auc: 0.9555 - val_loss: 0.2830 - val_accuracy: 0.9200 - val_auc: 0.9530\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2563 - accuracy: 0.9091 - auc: 0.9621 - val_loss: 0.2669 - val_accuracy: 0.9139 - val_auc: 0.9582\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2594 - accuracy: 0.9087 - auc: 0.9609 - val_loss: 0.2853 - val_accuracy: 0.9162 - val_auc: 0.9552\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2584 - accuracy: 0.9115 - auc: 0.9607 - val_loss: 0.2890 - val_accuracy: 0.9088 - val_auc: 0.9518\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2550 - accuracy: 0.9074 - auc: 0.9619 - val_loss: 0.2858 - val_accuracy: 0.9206 - val_auc: 0.9544\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2525 - accuracy: 0.9088 - auc: 0.9628 - val_loss: 0.3161 - val_accuracy: 0.9228 - val_auc: 0.9476\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2447 - accuracy: 0.9072 - auc: 0.9643 - val_loss: 0.3015 - val_accuracy: 0.9179 - val_auc: 0.9511\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2536 - accuracy: 0.9097 - auc: 0.9629 - val_loss: 0.3232 - val_accuracy: 0.9210 - val_auc: 0.9487\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2461 - accuracy: 0.9110 - auc: 0.9650 - val_loss: 0.3064 - val_accuracy: 0.9093 - val_auc: 0.9511\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2435 - accuracy: 0.9088 - auc: 0.9644 - val_loss: 0.3211 - val_accuracy: 0.9193 - val_auc: 0.9503\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2462 - accuracy: 0.9068 - auc: 0.9650 - val_loss: 0.3270 - val_accuracy: 0.9197 - val_auc: 0.9479\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2348 - accuracy: 0.9103 - auc: 0.9671 - val_loss: 0.3393 - val_accuracy: 0.9258 - val_auc: 0.9483\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2336 - accuracy: 0.9131 - auc: 0.9672 - val_loss: 0.3447 - val_accuracy: 0.9136 - val_auc: 0.9488\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2258 - accuracy: 0.9096 - auc: 0.9696 - val_loss: 0.3640 - val_accuracy: 0.9213 - val_auc: 0.9440\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2321 - accuracy: 0.9121 - auc: 0.9677 - val_loss: 0.3734 - val_accuracy: 0.9144 - val_auc: 0.9447\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2315 - accuracy: 0.9091 - auc: 0.9678 - val_loss: 0.3716 - val_accuracy: 0.9194 - val_auc: 0.9449\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2285 - accuracy: 0.9107 - auc: 0.9682 - val_loss: 0.3982 - val_accuracy: 0.9305 - val_auc: 0.9434\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2428 - accuracy: 0.9104 - auc: 0.9667 - val_loss: 0.4039 - val_accuracy: 0.9285 - val_auc: 0.9399\n",
      "Epoch 24/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.9135 - auc: 0.9694Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2259 - accuracy: 0.9136 - auc: 0.9692 - val_loss: 0.4274 - val_accuracy: 0.9304 - val_auc: 0.9398\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 19us/sample - loss: 0.5499 - accuracy: 0.7093 - auc: 0.8798 - val_loss: 0.3119 - val_accuracy: 0.8158 - val_auc: 0.9487\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3259 - accuracy: 0.8230 - auc: 0.9409 - val_loss: 0.2824 - val_accuracy: 0.9131 - val_auc: 0.9536\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3030 - accuracy: 0.8535 - auc: 0.9468 - val_loss: 0.2845 - val_accuracy: 0.8731 - val_auc: 0.9537\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2830 - accuracy: 0.8592 - auc: 0.9560 - val_loss: 0.2824 - val_accuracy: 0.8922 - val_auc: 0.9540\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2629 - accuracy: 0.8715 - auc: 0.9601 - val_loss: 0.2784 - val_accuracy: 0.8965 - val_auc: 0.9561\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2638 - accuracy: 0.8758 - auc: 0.9593 - val_loss: 0.2863 - val_accuracy: 0.8800 - val_auc: 0.9532\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2489 - accuracy: 0.8764 - auc: 0.9632 - val_loss: 0.3000 - val_accuracy: 0.8912 - val_auc: 0.9511\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2467 - accuracy: 0.8729 - auc: 0.9633 - val_loss: 0.3256 - val_accuracy: 0.9108 - val_auc: 0.9517\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2551 - accuracy: 0.8684 - auc: 0.9616 - val_loss: 0.3325 - val_accuracy: 0.9012 - val_auc: 0.9491\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2494 - accuracy: 0.8752 - auc: 0.9636 - val_loss: 0.3286 - val_accuracy: 0.8915 - val_auc: 0.9501\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2349 - accuracy: 0.8767 - auc: 0.9667 - val_loss: 0.3493 - val_accuracy: 0.9065 - val_auc: 0.9525\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2323 - accuracy: 0.8782 - auc: 0.9667 - val_loss: 0.3688 - val_accuracy: 0.9155 - val_auc: 0.9471\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2287 - accuracy: 0.8807 - auc: 0.9676 - val_loss: 0.3755 - val_accuracy: 0.9028 - val_auc: 0.9475\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2269 - accuracy: 0.8768 - auc: 0.9681 - val_loss: 0.4066 - val_accuracy: 0.9069 - val_auc: 0.9448\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2518 - accuracy: 0.8757 - auc: 0.9660 - val_loss: 0.3629 - val_accuracy: 0.8740 - val_auc: 0.9464\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2333 - accuracy: 0.8806 - auc: 0.9683 - val_loss: 0.4012 - val_accuracy: 0.9003 - val_auc: 0.9438\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2275 - accuracy: 0.8800 - auc: 0.9685 - val_loss: 0.4405 - val_accuracy: 0.9143 - val_auc: 0.9425\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2390 - accuracy: 0.8771 - auc: 0.9663 - val_loss: 0.4342 - val_accuracy: 0.9123 - val_auc: 0.9418\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2260 - accuracy: 0.8793 - auc: 0.9692 - val_loss: 0.4305 - val_accuracy: 0.9142 - val_auc: 0.9455\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2239 - accuracy: 0.8791 - auc: 0.9687 - val_loss: 0.4517 - val_accuracy: 0.9049 - val_auc: 0.9425\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2325 - accuracy: 0.8721 - auc: 0.9682 - val_loss: 0.4610 - val_accuracy: 0.9019 - val_auc: 0.9421\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2178 - accuracy: 0.8738 - auc: 0.9707 - val_loss: 0.4831 - val_accuracy: 0.9062 - val_auc: 0.9409\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2283 - accuracy: 0.8688 - auc: 0.9691 - val_loss: 0.4936 - val_accuracy: 0.9086 - val_auc: 0.9428\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2112 - accuracy: 0.8794 - auc: 0.9720 - val_loss: 0.4989 - val_accuracy: 0.9049 - val_auc: 0.9412\n",
      "Epoch 25/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2209 - accuracy: 0.8763 - auc: 0.9705Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2249 - accuracy: 0.8762 - auc: 0.9695 - val_loss: 0.5336 - val_accuracy: 0.9071 - val_auc: 0.9407\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.8078 - accuracy: 0.7514 - auc: 0.6839 - val_loss: 0.5088 - val_accuracy: 0.8117 - val_auc: 0.8546\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6261 - accuracy: 0.8226 - auc: 0.7799 - val_loss: 0.4422 - val_accuracy: 0.8638 - val_auc: 0.9008\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5590 - accuracy: 0.8561 - auc: 0.8186 - val_loss: 0.3959 - val_accuracy: 0.8789 - val_auc: 0.9184\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4972 - accuracy: 0.8747 - auc: 0.8516 - val_loss: 0.3689 - val_accuracy: 0.8923 - val_auc: 0.9286\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4671 - accuracy: 0.8845 - auc: 0.8643 - val_loss: 0.3443 - val_accuracy: 0.8911 - val_auc: 0.9361\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4641 - accuracy: 0.8892 - auc: 0.8628 - val_loss: 0.3321 - val_accuracy: 0.8964 - val_auc: 0.9406\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4324 - accuracy: 0.8918 - auc: 0.8787 - val_loss: 0.3198 - val_accuracy: 0.9005 - val_auc: 0.9464\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4219 - accuracy: 0.8991 - auc: 0.8831 - val_loss: 0.3123 - val_accuracy: 0.8975 - val_auc: 0.9483\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3936 - accuracy: 0.8963 - auc: 0.8978 - val_loss: 0.3052 - val_accuracy: 0.8933 - val_auc: 0.9496\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3835 - accuracy: 0.8975 - auc: 0.9026 - val_loss: 0.2996 - val_accuracy: 0.9003 - val_auc: 0.9502\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3852 - accuracy: 0.9011 - auc: 0.9031 - val_loss: 0.2946 - val_accuracy: 0.9025 - val_auc: 0.9511\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3899 - accuracy: 0.9053 - auc: 0.8999 - val_loss: 0.2937 - val_accuracy: 0.9016 - val_auc: 0.9511\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3614 - accuracy: 0.9048 - auc: 0.9130 - val_loss: 0.2864 - val_accuracy: 0.8999 - val_auc: 0.9527\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3715 - accuracy: 0.9061 - auc: 0.9049 - val_loss: 0.2856 - val_accuracy: 0.8995 - val_auc: 0.9531\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3707 - accuracy: 0.9034 - auc: 0.9060 - val_loss: 0.2814 - val_accuracy: 0.9011 - val_auc: 0.9542\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3689 - accuracy: 0.9046 - auc: 0.9072 - val_loss: 0.2824 - val_accuracy: 0.9005 - val_auc: 0.9542\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3540 - accuracy: 0.9064 - auc: 0.9153 - val_loss: 0.2775 - val_accuracy: 0.8978 - val_auc: 0.9551\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3514 - accuracy: 0.9040 - auc: 0.9165 - val_loss: 0.2831 - val_accuracy: 0.9013 - val_auc: 0.9545\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3553 - accuracy: 0.9043 - auc: 0.9132 - val_loss: 0.2795 - val_accuracy: 0.8999 - val_auc: 0.9545\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3487 - accuracy: 0.9068 - auc: 0.9164 - val_loss: 0.2785 - val_accuracy: 0.8998 - val_auc: 0.9548\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3485 - accuracy: 0.9056 - auc: 0.9170 - val_loss: 0.2760 - val_accuracy: 0.8981 - val_auc: 0.9550\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3434 - accuracy: 0.9070 - auc: 0.9207 - val_loss: 0.2756 - val_accuracy: 0.8996 - val_auc: 0.9553\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3496 - accuracy: 0.9067 - auc: 0.9176 - val_loss: 0.2768 - val_accuracy: 0.9019 - val_auc: 0.9550\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3448 - accuracy: 0.9059 - auc: 0.9213 - val_loss: 0.2763 - val_accuracy: 0.8943 - val_auc: 0.9547\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3385 - accuracy: 0.9067 - auc: 0.9219 - val_loss: 0.2756 - val_accuracy: 0.8960 - val_auc: 0.9554\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3508 - accuracy: 0.8003 - auc: 0.9164 - val_loss: 0.2772 - val_accuracy: 0.8837 - val_auc: 0.9550\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3317 - accuracy: 0.7169 - auc: 0.9233 - val_loss: 0.2791 - val_accuracy: 0.8879 - val_auc: 0.9550\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3270 - accuracy: 0.7230 - auc: 0.9287 - val_loss: 0.2771 - val_accuracy: 0.8855 - val_auc: 0.9558\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3359 - accuracy: 0.7194 - auc: 0.9242 - val_loss: 0.2769 - val_accuracy: 0.8827 - val_auc: 0.9557\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3338 - accuracy: 0.7215 - auc: 0.9255 - val_loss: 0.2760 - val_accuracy: 0.8858 - val_auc: 0.9564\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3329 - accuracy: 0.7214 - auc: 0.9264 - val_loss: 0.2781 - val_accuracy: 0.8855 - val_auc: 0.9559\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3196 - accuracy: 0.7233 - auc: 0.9281 - val_loss: 0.2785 - val_accuracy: 0.8841 - val_auc: 0.9558\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3287 - accuracy: 0.7256 - auc: 0.9256 - val_loss: 0.2797 - val_accuracy: 0.8835 - val_auc: 0.9554\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3232 - accuracy: 0.7225 - auc: 0.9284 - val_loss: 0.2825 - val_accuracy: 0.8831 - val_auc: 0.9557\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3173 - accuracy: 0.7258 - auc: 0.9301 - val_loss: 0.2812 - val_accuracy: 0.8810 - val_auc: 0.9559\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3167 - accuracy: 0.7261 - auc: 0.9295 - val_loss: 0.2826 - val_accuracy: 0.8843 - val_auc: 0.9559\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3161 - accuracy: 0.7285 - auc: 0.9297 - val_loss: 0.2848 - val_accuracy: 0.8870 - val_auc: 0.9560\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3196 - accuracy: 0.7302 - auc: 0.9293 - val_loss: 0.2802 - val_accuracy: 0.8849 - val_auc: 0.9561\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3272 - accuracy: 0.7288 - auc: 0.9271 - val_loss: 0.2830 - val_accuracy: 0.8828 - val_auc: 0.9561\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3219 - accuracy: 0.7311 - auc: 0.9308 - val_loss: 0.2858 - val_accuracy: 0.8833 - val_auc: 0.9554\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3179 - accuracy: 0.7307 - auc: 0.9290 - val_loss: 0.2881 - val_accuracy: 0.8866 - val_auc: 0.9552\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3190 - accuracy: 0.7325 - auc: 0.9300 - val_loss: 0.2860 - val_accuracy: 0.8884 - val_auc: 0.9551\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3119 - accuracy: 0.7329 - auc: 0.9325 - val_loss: 0.2832 - val_accuracy: 0.8881 - val_auc: 0.9558\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3263 - accuracy: 0.7344 - auc: 0.9251 - val_loss: 0.2826 - val_accuracy: 0.8839 - val_auc: 0.9559\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3212 - accuracy: 0.7304 - auc: 0.9285 - val_loss: 0.2867 - val_accuracy: 0.8808 - val_auc: 0.9551\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3244 - accuracy: 0.7277 - auc: 0.9270 - val_loss: 0.2923 - val_accuracy: 0.8794 - val_auc: 0.9546\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3106 - accuracy: 0.7291 - auc: 0.9355 - val_loss: 0.2933 - val_accuracy: 0.8858 - val_auc: 0.9531\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3265 - accuracy: 0.7299 - auc: 0.9293 - val_loss: 0.2944 - val_accuracy: 0.8796 - val_auc: 0.9529\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3163 - accuracy: 0.7283 - auc: 0.9309 - val_loss: 0.2985 - val_accuracy: 0.8814 - val_auc: 0.9518\n",
      "Epoch 50/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.3086 - accuracy: 0.7292 - auc: 0.9342Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3101 - accuracy: 0.7293 - auc: 0.9334 - val_loss: 0.3018 - val_accuracy: 0.8820 - val_auc: 0.9513\n",
      "Epoch 00050: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 1.1244 - accuracy: 0.9594 - auc: 0.5397 - val_loss: 0.8857 - val_accuracy: 0.9893 - val_auc: 0.6501\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.9573 - accuracy: 0.9637 - auc: 0.6141 - val_loss: 0.7867 - val_accuracy: 0.9894 - val_auc: 0.7282\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.8492 - accuracy: 0.9530 - auc: 0.6594 - val_loss: 0.6824 - val_accuracy: 0.9811 - val_auc: 0.7912\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6945 - accuracy: 0.9356 - auc: 0.7303 - val_loss: 0.4616 - val_accuracy: 0.9652 - val_auc: 0.9138\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6208 - accuracy: 0.9301 - auc: 0.7757 - val_loss: 0.4065 - val_accuracy: 0.9599 - val_auc: 0.9385\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5865 - accuracy: 0.9343 - auc: 0.7948 - val_loss: 0.3934 - val_accuracy: 0.9584 - val_auc: 0.9424\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5484 - accuracy: 0.9358 - auc: 0.8132 - val_loss: 0.3867 - val_accuracy: 0.9574 - val_auc: 0.9463\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5588 - accuracy: 0.9347 - auc: 0.8066 - val_loss: 0.3844 - val_accuracy: 0.9559 - val_auc: 0.9488\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5449 - accuracy: 0.9360 - auc: 0.8171 - val_loss: 0.3764 - val_accuracy: 0.9541 - val_auc: 0.9505\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5287 - accuracy: 0.9364 - auc: 0.8280 - val_loss: 0.3660 - val_accuracy: 0.9500 - val_auc: 0.9514\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5289 - accuracy: 0.9332 - auc: 0.8354 - val_loss: 0.3601 - val_accuracy: 0.9481 - val_auc: 0.9519\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5183 - accuracy: 0.9313 - auc: 0.8442 - val_loss: 0.3554 - val_accuracy: 0.9430 - val_auc: 0.9518\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5023 - accuracy: 0.9314 - auc: 0.8549 - val_loss: 0.3497 - val_accuracy: 0.9405 - val_auc: 0.9518\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4809 - accuracy: 0.9337 - auc: 0.8638 - val_loss: 0.3380 - val_accuracy: 0.9342 - val_auc: 0.9530\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4769 - accuracy: 0.9317 - auc: 0.8709 - val_loss: 0.3317 - val_accuracy: 0.9353 - val_auc: 0.9533\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4528 - accuracy: 0.9329 - auc: 0.8809 - val_loss: 0.3294 - val_accuracy: 0.9268 - val_auc: 0.9535\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4564 - accuracy: 0.9290 - auc: 0.8778 - val_loss: 0.3270 - val_accuracy: 0.9237 - val_auc: 0.9532\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4541 - accuracy: 0.9325 - auc: 0.8823 - val_loss: 0.3162 - val_accuracy: 0.9202 - val_auc: 0.9538\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4240 - accuracy: 0.9300 - auc: 0.8924 - val_loss: 0.3161 - val_accuracy: 0.9152 - val_auc: 0.9543\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4336 - accuracy: 0.9300 - auc: 0.8866 - val_loss: 0.3069 - val_accuracy: 0.9093 - val_auc: 0.9553\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4105 - accuracy: 0.9282 - auc: 0.8970 - val_loss: 0.3084 - val_accuracy: 0.9085 - val_auc: 0.9553\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3970 - accuracy: 0.9303 - auc: 0.9013 - val_loss: 0.3015 - val_accuracy: 0.9035 - val_auc: 0.9555\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4001 - accuracy: 0.9282 - auc: 0.8990 - val_loss: 0.3029 - val_accuracy: 0.9016 - val_auc: 0.9558\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3851 - accuracy: 0.9295 - auc: 0.9025 - val_loss: 0.2978 - val_accuracy: 0.9003 - val_auc: 0.9565\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3873 - accuracy: 0.9141 - auc: 0.9039 - val_loss: 0.2912 - val_accuracy: 0.8899 - val_auc: 0.9565\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3839 - accuracy: 0.7797 - auc: 0.9047 - val_loss: 0.2972 - val_accuracy: 0.8876 - val_auc: 0.9562\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3593 - accuracy: 0.7794 - auc: 0.9146 - val_loss: 0.2988 - val_accuracy: 0.8880 - val_auc: 0.9553\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3722 - accuracy: 0.7780 - auc: 0.9086 - val_loss: 0.2984 - val_accuracy: 0.8837 - val_auc: 0.9558\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3598 - accuracy: 0.7778 - auc: 0.9123 - val_loss: 0.2949 - val_accuracy: 0.8839 - val_auc: 0.9559\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3548 - accuracy: 0.7788 - auc: 0.9164 - val_loss: 0.2957 - val_accuracy: 0.8826 - val_auc: 0.9558\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3552 - accuracy: 0.7771 - auc: 0.9133 - val_loss: 0.2959 - val_accuracy: 0.8801 - val_auc: 0.9550\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3452 - accuracy: 0.7749 - auc: 0.9165 - val_loss: 0.2967 - val_accuracy: 0.8735 - val_auc: 0.9557\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3489 - accuracy: 0.7744 - auc: 0.9149 - val_loss: 0.2951 - val_accuracy: 0.8742 - val_auc: 0.9560\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3374 - accuracy: 0.7770 - auc: 0.9162 - val_loss: 0.2964 - val_accuracy: 0.8783 - val_auc: 0.9560\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3295 - accuracy: 0.7803 - auc: 0.9218 - val_loss: 0.2941 - val_accuracy: 0.8772 - val_auc: 0.9564\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3235 - accuracy: 0.7782 - auc: 0.9243 - val_loss: 0.2932 - val_accuracy: 0.8758 - val_auc: 0.9568\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3285 - accuracy: 0.7780 - auc: 0.9211 - val_loss: 0.2941 - val_accuracy: 0.8752 - val_auc: 0.9568\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3254 - accuracy: 0.7806 - auc: 0.9206 - val_loss: 0.3008 - val_accuracy: 0.8753 - val_auc: 0.9557\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3193 - accuracy: 0.7823 - auc: 0.9234 - val_loss: 0.2973 - val_accuracy: 0.8801 - val_auc: 0.9562\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3200 - accuracy: 0.7844 - auc: 0.9242 - val_loss: 0.2969 - val_accuracy: 0.8771 - val_auc: 0.9561\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3301 - accuracy: 0.7824 - auc: 0.9190 - val_loss: 0.3011 - val_accuracy: 0.8729 - val_auc: 0.9556\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3178 - accuracy: 0.7807 - auc: 0.9248 - val_loss: 0.3017 - val_accuracy: 0.8747 - val_auc: 0.9541\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3218 - accuracy: 0.7820 - auc: 0.9218 - val_loss: 0.3047 - val_accuracy: 0.8733 - val_auc: 0.9537\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3111 - accuracy: 0.7827 - auc: 0.9269 - val_loss: 0.3059 - val_accuracy: 0.8757 - val_auc: 0.9534\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3044 - accuracy: 0.7836 - auc: 0.9287 - val_loss: 0.3061 - val_accuracy: 0.8776 - val_auc: 0.9538\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3183 - accuracy: 0.7850 - auc: 0.9250 - val_loss: 0.3068 - val_accuracy: 0.8768 - val_auc: 0.9527\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3141 - accuracy: 0.7838 - auc: 0.9269 - val_loss: 0.3042 - val_accuracy: 0.8736 - val_auc: 0.9526\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3202 - accuracy: 0.7810 - auc: 0.9218 - val_loss: 0.3068 - val_accuracy: 0.8723 - val_auc: 0.9527\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3088 - accuracy: 0.7811 - auc: 0.9290 - val_loss: 0.3136 - val_accuracy: 0.8765 - val_auc: 0.9519\n",
      "Epoch 50/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3212 - accuracy: 0.7852 - auc: 0.9229 - val_loss: 0.3120 - val_accuracy: 0.8728 - val_auc: 0.9523\n",
      "Epoch 51/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3109 - accuracy: 0.7843 - auc: 0.9268 - val_loss: 0.3125 - val_accuracy: 0.8741 - val_auc: 0.9525\n",
      "Epoch 52/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3063 - accuracy: 0.7860 - auc: 0.9284 - val_loss: 0.3135 - val_accuracy: 0.8791 - val_auc: 0.9529\n",
      "Epoch 53/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3085 - accuracy: 0.7885 - auc: 0.9277 - val_loss: 0.3195 - val_accuracy: 0.8787 - val_auc: 0.9524\n",
      "Epoch 54/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3077 - accuracy: 0.7898 - auc: 0.9284 - val_loss: 0.3215 - val_accuracy: 0.8799 - val_auc: 0.9519\n",
      "Epoch 55/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3008 - accuracy: 0.7893 - auc: 0.9316 - val_loss: 0.3200 - val_accuracy: 0.8799 - val_auc: 0.9522\n",
      "Epoch 56/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.7886 - auc: 0.9333Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2988 - accuracy: 0.7886 - auc: 0.9332 - val_loss: 0.3224 - val_accuracy: 0.8810 - val_auc: 0.9523\n",
      "Epoch 00056: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.8290 - accuracy: 0.3841 - auc: 0.6048 - val_loss: 0.5532 - val_accuracy: 0.6228 - val_auc: 0.8265\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6161 - accuracy: 0.5165 - auc: 0.7717 - val_loss: 0.4590 - val_accuracy: 0.8135 - val_auc: 0.8993\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5142 - accuracy: 0.6035 - auc: 0.8255 - val_loss: 0.4101 - val_accuracy: 0.8669 - val_auc: 0.9238\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4876 - accuracy: 0.6394 - auc: 0.8456 - val_loss: 0.3694 - val_accuracy: 0.8779 - val_auc: 0.9354\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4470 - accuracy: 0.6562 - auc: 0.8729 - val_loss: 0.3412 - val_accuracy: 0.8788 - val_auc: 0.9402\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4111 - accuracy: 0.6735 - auc: 0.8898 - val_loss: 0.3235 - val_accuracy: 0.8843 - val_auc: 0.9436\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4008 - accuracy: 0.8721 - auc: 0.8978 - val_loss: 0.3115 - val_accuracy: 0.8878 - val_auc: 0.9462\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3939 - accuracy: 0.8770 - auc: 0.8979 - val_loss: 0.3030 - val_accuracy: 0.8897 - val_auc: 0.9482\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3864 - accuracy: 0.8835 - auc: 0.9012 - val_loss: 0.2943 - val_accuracy: 0.8889 - val_auc: 0.9510\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3808 - accuracy: 0.8812 - auc: 0.9012 - val_loss: 0.2898 - val_accuracy: 0.8880 - val_auc: 0.9518\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3601 - accuracy: 0.8848 - auc: 0.9109 - val_loss: 0.2856 - val_accuracy: 0.8910 - val_auc: 0.9528\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3710 - accuracy: 0.8864 - auc: 0.9054 - val_loss: 0.2836 - val_accuracy: 0.8923 - val_auc: 0.9533\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3569 - accuracy: 0.8879 - auc: 0.9110 - val_loss: 0.2829 - val_accuracy: 0.8920 - val_auc: 0.9535\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3644 - accuracy: 0.8895 - auc: 0.9075 - val_loss: 0.2839 - val_accuracy: 0.8913 - val_auc: 0.9538\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3556 - accuracy: 0.8900 - auc: 0.9148 - val_loss: 0.2815 - val_accuracy: 0.8907 - val_auc: 0.9543\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3499 - accuracy: 0.8910 - auc: 0.9151 - val_loss: 0.2778 - val_accuracy: 0.8887 - val_auc: 0.9553\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3465 - accuracy: 0.8909 - auc: 0.9153 - val_loss: 0.2760 - val_accuracy: 0.8914 - val_auc: 0.9551\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3531 - accuracy: 0.8930 - auc: 0.9131 - val_loss: 0.2778 - val_accuracy: 0.8897 - val_auc: 0.9553\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3504 - accuracy: 0.8937 - auc: 0.9145 - val_loss: 0.2789 - val_accuracy: 0.8881 - val_auc: 0.9548\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3486 - accuracy: 0.8918 - auc: 0.9151 - val_loss: 0.2772 - val_accuracy: 0.8881 - val_auc: 0.9549\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3460 - accuracy: 0.8869 - auc: 0.9161 - val_loss: 0.2786 - val_accuracy: 0.8833 - val_auc: 0.9551\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3245 - accuracy: 0.7847 - auc: 0.9275 - val_loss: 0.2765 - val_accuracy: 0.8894 - val_auc: 0.9548\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3429 - accuracy: 0.7370 - auc: 0.9156 - val_loss: 0.2786 - val_accuracy: 0.8791 - val_auc: 0.9548\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3314 - accuracy: 0.7152 - auc: 0.9244 - val_loss: 0.2757 - val_accuracy: 0.8795 - val_auc: 0.9553\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3276 - accuracy: 0.7163 - auc: 0.9252 - val_loss: 0.2753 - val_accuracy: 0.8787 - val_auc: 0.9555\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3342 - accuracy: 0.7184 - auc: 0.9204 - val_loss: 0.2791 - val_accuracy: 0.8808 - val_auc: 0.9550\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3317 - accuracy: 0.7165 - auc: 0.9197 - val_loss: 0.2775 - val_accuracy: 0.8801 - val_auc: 0.9554\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3284 - accuracy: 0.7179 - auc: 0.9233 - val_loss: 0.2776 - val_accuracy: 0.8787 - val_auc: 0.9555\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3263 - accuracy: 0.7183 - auc: 0.9241 - val_loss: 0.2801 - val_accuracy: 0.8772 - val_auc: 0.9549\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3332 - accuracy: 0.7178 - auc: 0.9200 - val_loss: 0.2798 - val_accuracy: 0.8771 - val_auc: 0.9553\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3210 - accuracy: 0.7194 - auc: 0.9262 - val_loss: 0.2834 - val_accuracy: 0.8787 - val_auc: 0.9552\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3279 - accuracy: 0.7182 - auc: 0.9238 - val_loss: 0.2843 - val_accuracy: 0.8773 - val_auc: 0.9553\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3236 - accuracy: 0.7189 - auc: 0.9232 - val_loss: 0.2849 - val_accuracy: 0.8770 - val_auc: 0.9550\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3284 - accuracy: 0.7183 - auc: 0.9234 - val_loss: 0.2866 - val_accuracy: 0.8781 - val_auc: 0.9550\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3141 - accuracy: 0.7190 - auc: 0.9293 - val_loss: 0.2847 - val_accuracy: 0.8747 - val_auc: 0.9551\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3208 - accuracy: 0.7155 - auc: 0.9236 - val_loss: 0.2803 - val_accuracy: 0.8749 - val_auc: 0.9556\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3183 - accuracy: 0.7189 - auc: 0.9260 - val_loss: 0.2839 - val_accuracy: 0.8750 - val_auc: 0.9551\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3081 - accuracy: 0.7180 - auc: 0.9319 - val_loss: 0.2847 - val_accuracy: 0.8759 - val_auc: 0.9555\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3176 - accuracy: 0.7205 - auc: 0.9266 - val_loss: 0.2841 - val_accuracy: 0.8752 - val_auc: 0.9560\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3178 - accuracy: 0.7169 - auc: 0.9261 - val_loss: 0.2859 - val_accuracy: 0.8747 - val_auc: 0.9557 0.3179 - accuracy: 0.7164\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3287 - accuracy: 0.7155 - auc: 0.9239 - val_loss: 0.2890 - val_accuracy: 0.8704 - val_auc: 0.9552\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3233 - accuracy: 0.7149 - auc: 0.9220 - val_loss: 0.2901 - val_accuracy: 0.8714 - val_auc: 0.9550\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3256 - accuracy: 0.7180 - auc: 0.9246 - val_loss: 0.2937 - val_accuracy: 0.8676 - val_auc: 0.9550\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3046 - accuracy: 0.7153 - auc: 0.9326 - val_loss: 0.2939 - val_accuracy: 0.8709 - val_auc: 0.9534\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3135 - accuracy: 0.7156 - auc: 0.9285 - val_loss: 0.2975 - val_accuracy: 0.8731 - val_auc: 0.9540\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3150 - accuracy: 0.7158 - auc: 0.9288 - val_loss: 0.2967 - val_accuracy: 0.8690 - val_auc: 0.9541\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3071 - accuracy: 0.7137 - auc: 0.9314 - val_loss: 0.3007 - val_accuracy: 0.8687 - val_auc: 0.9522\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3147 - accuracy: 0.7149 - auc: 0.9291 - val_loss: 0.3002 - val_accuracy: 0.8698 - val_auc: 0.9523\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3168 - accuracy: 0.7164 - auc: 0.9263 - val_loss: 0.2997 - val_accuracy: 0.8716 - val_auc: 0.9523\n",
      "Epoch 50/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3030 - accuracy: 0.7152 - auc: 0.9337 - val_loss: 0.3006 - val_accuracy: 0.8740 - val_auc: 0.9518\n",
      "Epoch 51/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3191 - accuracy: 0.7158 - auc: 0.9264 - val_loss: 0.3015 - val_accuracy: 0.8704 - val_auc: 0.9523\n",
      "Epoch 52/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3149 - accuracy: 0.7167 - auc: 0.9258 - val_loss: 0.3016 - val_accuracy: 0.8678 - val_auc: 0.9523\n",
      "Epoch 53/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3141 - accuracy: 0.7126 - auc: 0.9286 - val_loss: 0.3041 - val_accuracy: 0.8706 - val_auc: 0.9521\n",
      "Epoch 54/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3139 - accuracy: 0.7146 - auc: 0.9293 - val_loss: 0.3052 - val_accuracy: 0.8696 - val_auc: 0.9524\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3120 - accuracy: 0.7137 - auc: 0.9291 - val_loss: 0.3077 - val_accuracy: 0.8692 - val_auc: 0.9522\n",
      "Epoch 56/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3107 - accuracy: 0.7137 - auc: 0.9298 - val_loss: 0.3080 - val_accuracy: 0.8695 - val_auc: 0.9523\n",
      "Epoch 57/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3119 - accuracy: 0.7148 - auc: 0.9289 - val_loss: 0.3054 - val_accuracy: 0.8656 - val_auc: 0.9527\n",
      "Epoch 58/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3139 - accuracy: 0.7107 - auc: 0.9252 - val_loss: 0.3086 - val_accuracy: 0.8647 - val_auc: 0.9524\n",
      "Epoch 59/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3155 - accuracy: 0.7131 - auc: 0.9265Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3173 - accuracy: 0.7131 - auc: 0.9257 - val_loss: 0.3100 - val_accuracy: 0.8655 - val_auc: 0.9526\n",
      "Epoch 00059: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.7466 - accuracy: 0.2091 - auc: 0.7060 - val_loss: 0.5278 - val_accuracy: 0.4704 - val_auc: 0.9017\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5454 - accuracy: 0.6165 - auc: 0.8139 - val_loss: 0.4144 - val_accuracy: 0.8017 - val_auc: 0.9450\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4503 - accuracy: 0.8220 - auc: 0.8886 - val_loss: 0.3520 - val_accuracy: 0.8668 - val_auc: 0.9542\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4147 - accuracy: 0.8577 - auc: 0.8989 - val_loss: 0.3205 - val_accuracy: 0.8886 - val_auc: 0.9563\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3986 - accuracy: 0.8741 - auc: 0.9002 - val_loss: 0.3037 - val_accuracy: 0.8972 - val_auc: 0.9578\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3844 - accuracy: 0.8848 - auc: 0.9065 - val_loss: 0.2972 - val_accuracy: 0.9028 - val_auc: 0.9577\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3843 - accuracy: 0.8885 - auc: 0.9040 - val_loss: 0.2906 - val_accuracy: 0.9057 - val_auc: 0.9584curacy: 0.8867 -\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3749 - accuracy: 0.8969 - auc: 0.9104 - val_loss: 0.2866 - val_accuracy: 0.9062 - val_auc: 0.9589\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3696 - accuracy: 0.8980 - auc: 0.9116 - val_loss: 0.2818 - val_accuracy: 0.9095 - val_auc: 0.9592\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3641 - accuracy: 0.9042 - auc: 0.9177 - val_loss: 0.2783 - val_accuracy: 0.9100 - val_auc: 0.9595\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3612 - accuracy: 0.9029 - auc: 0.9158 - val_loss: 0.2766 - val_accuracy: 0.9072 - val_auc: 0.9598\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3697 - accuracy: 0.9051 - auc: 0.9099 - val_loss: 0.2752 - val_accuracy: 0.9102 - val_auc: 0.9595\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3508 - accuracy: 0.9062 - auc: 0.9224 - val_loss: 0.2712 - val_accuracy: 0.9102 - val_auc: 0.9597\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3447 - accuracy: 0.9109 - auc: 0.9240 - val_loss: 0.2730 - val_accuracy: 0.9132 - val_auc: 0.9587\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3536 - accuracy: 0.9110 - auc: 0.9176 - val_loss: 0.2711 - val_accuracy: 0.9116 - val_auc: 0.9591\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3484 - accuracy: 0.9091 - auc: 0.9226 - val_loss: 0.2686 - val_accuracy: 0.9105 - val_auc: 0.9597\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3342 - accuracy: 0.9119 - auc: 0.9262 - val_loss: 0.2701 - val_accuracy: 0.9104 - val_auc: 0.9587\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3334 - accuracy: 0.9144 - auc: 0.9255 - val_loss: 0.2680 - val_accuracy: 0.9143 - val_auc: 0.9594\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3482 - accuracy: 0.9159 - auc: 0.9202 - val_loss: 0.2669 - val_accuracy: 0.9121 - val_auc: 0.9592\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3317 - accuracy: 0.9167 - auc: 0.9290 - val_loss: 0.2663 - val_accuracy: 0.9153 - val_auc: 0.9595accuracy: 0.9166 - auc: 0.\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3381 - accuracy: 0.9158 - auc: 0.9241 - val_loss: 0.2681 - val_accuracy: 0.9121 - val_auc: 0.9590\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3346 - accuracy: 0.9157 - auc: 0.9254 - val_loss: 0.2689 - val_accuracy: 0.9167 - val_auc: 0.9590\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3424 - accuracy: 0.9147 - auc: 0.9229 - val_loss: 0.2663 - val_accuracy: 0.9135 - val_auc: 0.9591\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3458 - accuracy: 0.9158 - auc: 0.9215 - val_loss: 0.2671 - val_accuracy: 0.9165 - val_auc: 0.9586\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3322 - accuracy: 0.9188 - auc: 0.9280 - val_loss: 0.2630 - val_accuracy: 0.9133 - val_auc: 0.9597\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3433 - accuracy: 0.9159 - auc: 0.9207 - val_loss: 0.2622 - val_accuracy: 0.9130 - val_auc: 0.9600\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3305 - accuracy: 0.9185 - auc: 0.9269 - val_loss: 0.2635 - val_accuracy: 0.9184 - val_auc: 0.9601\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3270 - accuracy: 0.9186 - auc: 0.9284 - val_loss: 0.2620 - val_accuracy: 0.9152 - val_auc: 0.9601\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3324 - accuracy: 0.9188 - auc: 0.9258 - val_loss: 0.2617 - val_accuracy: 0.9144 - val_auc: 0.9602\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3389 - accuracy: 0.9174 - auc: 0.9239 - val_loss: 0.2632 - val_accuracy: 0.9156 - val_auc: 0.9599\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3291 - accuracy: 0.9195 - auc: 0.9291 - val_loss: 0.2639 - val_accuracy: 0.9181 - val_auc: 0.9597\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3452 - accuracy: 0.9199 - auc: 0.9203 - val_loss: 0.2631 - val_accuracy: 0.9185 - val_auc: 0.9598\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3328 - accuracy: 0.9230 - auc: 0.9242 - val_loss: 0.2632 - val_accuracy: 0.9202 - val_auc: 0.9599\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3310 - accuracy: 0.9196 - auc: 0.9268 - val_loss: 0.2629 - val_accuracy: 0.9166 - val_auc: 0.9596\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3198 - accuracy: 0.9192 - auc: 0.9354 - val_loss: 0.2644 - val_accuracy: 0.9191 - val_auc: 0.9593\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3305 - accuracy: 0.9217 - auc: 0.9269 - val_loss: 0.2644 - val_accuracy: 0.9180 - val_auc: 0.9591\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3274 - accuracy: 0.9195 - auc: 0.9285 - val_loss: 0.2657 - val_accuracy: 0.9175 - val_auc: 0.9587\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3291 - accuracy: 0.9225 - auc: 0.9287 - val_loss: 0.2617 - val_accuracy: 0.9190 - val_auc: 0.9597\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3246 - accuracy: 0.9241 - auc: 0.9261 - val_loss: 0.2640 - val_accuracy: 0.9196 - val_auc: 0.9591\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3278 - accuracy: 0.9245 - auc: 0.9267 - val_loss: 0.2644 - val_accuracy: 0.9216 - val_auc: 0.9592\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3268 - accuracy: 0.9241 - auc: 0.9309 - val_loss: 0.2647 - val_accuracy: 0.9190 - val_auc: 0.9585\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3147 - accuracy: 0.9208 - auc: 0.9356 - val_loss: 0.2646 - val_accuracy: 0.9210 - val_auc: 0.9587\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3251 - accuracy: 0.9239 - auc: 0.9303 - val_loss: 0.2655 - val_accuracy: 0.9204 - val_auc: 0.9585\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3191 - accuracy: 0.9231 - auc: 0.9316 - val_loss: 0.2642 - val_accuracy: 0.9209 - val_auc: 0.9589\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3290 - accuracy: 0.9253 - auc: 0.9261 - val_loss: 0.2657 - val_accuracy: 0.9233 - val_auc: 0.9588\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3101 - accuracy: 0.9236 - auc: 0.9371 - val_loss: 0.2630 - val_accuracy: 0.9180 - val_auc: 0.9592\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3232 - accuracy: 0.9216 - auc: 0.9312 - val_loss: 0.2644 - val_accuracy: 0.9172 - val_auc: 0.9586\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3302 - accuracy: 0.9228 - auc: 0.9285 - val_loss: 0.2668 - val_accuracy: 0.9192 - val_auc: 0.9579\n",
      "Epoch 49/100\n",
      "243712/250291 [============================>.] - ETA: 0s - loss: 0.3260 - accuracy: 0.9240 - auc: 0.9275Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3255 - accuracy: 0.9241 - auc: 0.9272 - val_loss: 0.2685 - val_accuracy: 0.9171 - val_auc: 0.9572\n",
      "Epoch 00049: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 18us/sample - loss: 1.5857 - accuracy: 0.4683 - auc: 0.4959 - val_loss: 0.7752 - val_accuracy: 0.5431 - val_auc: 0.7106\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.8134 - accuracy: 0.4750 - auc: 0.7086 - val_loss: 0.6579 - val_accuracy: 0.6006 - val_auc: 0.8253\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6873 - accuracy: 0.5307 - auc: 0.7728 - val_loss: 0.5893 - val_accuracy: 0.6698 - val_auc: 0.8633\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6209 - accuracy: 0.5867 - auc: 0.8069 - val_loss: 0.5375 - val_accuracy: 0.7376 - val_auc: 0.8872\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5375 - accuracy: 0.6407 - auc: 0.8326 - val_loss: 0.5023 - val_accuracy: 0.7863 - val_auc: 0.9035\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5233 - accuracy: 0.6732 - auc: 0.8496 - val_loss: 0.4672 - val_accuracy: 0.8230 - val_auc: 0.9148\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5063 - accuracy: 0.7002 - auc: 0.8557 - val_loss: 0.4412 - val_accuracy: 0.8426 - val_auc: 0.9232\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4844 - accuracy: 0.7195 - auc: 0.8664 - val_loss: 0.4214 - val_accuracy: 0.8522 - val_auc: 0.9274\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4591 - accuracy: 0.7311 - auc: 0.8754 - val_loss: 0.4013 - val_accuracy: 0.8593 - val_auc: 0.9320\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4362 - accuracy: 0.7415 - auc: 0.8823 - val_loss: 0.3881 - val_accuracy: 0.8646 - val_auc: 0.9340\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4169 - accuracy: 0.7440 - auc: 0.8841 - val_loss: 0.3751 - val_accuracy: 0.8679 - val_auc: 0.9370\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4154 - accuracy: 0.7565 - auc: 0.8904 - val_loss: 0.3694 - val_accuracy: 0.8696 - val_auc: 0.9369\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4048 - accuracy: 0.7587 - auc: 0.8924 - val_loss: 0.3610 - val_accuracy: 0.8733 - val_auc: 0.9386\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3979 - accuracy: 0.7647 - auc: 0.8962 - val_loss: 0.3579 - val_accuracy: 0.8737 - val_auc: 0.9385\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3933 - accuracy: 0.7642 - auc: 0.8962 - val_loss: 0.3543 - val_accuracy: 0.8693 - val_auc: 0.9391\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3696 - accuracy: 0.7661 - auc: 0.9040 - val_loss: 0.3509 - val_accuracy: 0.8729 - val_auc: 0.9392\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3779 - accuracy: 0.7714 - auc: 0.9011 - val_loss: 0.3477 - val_accuracy: 0.8726 - val_auc: 0.9406\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3657 - accuracy: 0.7739 - auc: 0.9032 - val_loss: 0.3447 - val_accuracy: 0.8758 - val_auc: 0.9410\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3623 - accuracy: 0.7768 - auc: 0.9053 - val_loss: 0.3469 - val_accuracy: 0.8732 - val_auc: 0.9402\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3581 - accuracy: 0.7741 - auc: 0.9064 - val_loss: 0.3480 - val_accuracy: 0.8727 - val_auc: 0.9399\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3598 - accuracy: 0.7788 - auc: 0.9050 - val_loss: 0.3470 - val_accuracy: 0.8720 - val_auc: 0.9394\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3497 - accuracy: 0.7791 - auc: 0.9098 - val_loss: 0.3444 - val_accuracy: 0.8776 - val_auc: 0.9414\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3442 - accuracy: 0.7834 - auc: 0.9118 - val_loss: 0.3428 - val_accuracy: 0.8789 - val_auc: 0.9425\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3471 - accuracy: 0.7870 - auc: 0.9121 - val_loss: 0.3451 - val_accuracy: 0.8807 - val_auc: 0.9423\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3367 - accuracy: 0.7902 - auc: 0.9138 - val_loss: 0.3454 - val_accuracy: 0.8811 - val_auc: 0.9427\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3432 - accuracy: 0.7897 - auc: 0.9122 - val_loss: 0.3444 - val_accuracy: 0.8756 - val_auc: 0.9416\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3336 - accuracy: 0.7898 - auc: 0.9139 - val_loss: 0.3458 - val_accuracy: 0.8765 - val_auc: 0.9410\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3412 - accuracy: 0.7937 - auc: 0.9133 - val_loss: 0.3478 - val_accuracy: 0.8762 - val_auc: 0.9408\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3366 - accuracy: 0.7932 - auc: 0.9137 - val_loss: 0.3473 - val_accuracy: 0.8757 - val_auc: 0.9414\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3393 - accuracy: 0.7921 - auc: 0.9144 - val_loss: 0.3501 - val_accuracy: 0.8721 - val_auc: 0.9403\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3369 - accuracy: 0.7894 - auc: 0.9154 - val_loss: 0.3507 - val_accuracy: 0.8736 - val_auc: 0.9410\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3234 - accuracy: 0.7954 - auc: 0.9176 - val_loss: 0.3501 - val_accuracy: 0.8792 - val_auc: 0.9418\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3301 - accuracy: 0.7990 - auc: 0.9173 - val_loss: 0.3539 - val_accuracy: 0.8807 - val_auc: 0.9417\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3312 - accuracy: 0.7969 - auc: 0.9169 - val_loss: 0.3527 - val_accuracy: 0.8791 - val_auc: 0.9416\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3274 - accuracy: 0.7995 - auc: 0.9171 - val_loss: 0.3552 - val_accuracy: 0.8777 - val_auc: 0.9415\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3279 - accuracy: 0.7997 - auc: 0.9166 - val_loss: 0.3582 - val_accuracy: 0.8710 - val_auc: 0.9384\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3247 - accuracy: 0.7970 - auc: 0.9165 - val_loss: 0.3595 - val_accuracy: 0.8754 - val_auc: 0.9390\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3212 - accuracy: 0.8013 - auc: 0.9188 - val_loss: 0.3614 - val_accuracy: 0.8752 - val_auc: 0.9390\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3204 - accuracy: 0.8029 - auc: 0.9197 - val_loss: 0.3635 - val_accuracy: 0.8777 - val_auc: 0.9393\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3187 - accuracy: 0.8020 - auc: 0.9187 - val_loss: 0.3667 - val_accuracy: 0.8730 - val_auc: 0.9384\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3150 - accuracy: 0.8025 - auc: 0.9193 - val_loss: 0.3669 - val_accuracy: 0.8765 - val_auc: 0.9392\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3208 - accuracy: 0.8037 - auc: 0.9192 - val_loss: 0.3708 - val_accuracy: 0.8726 - val_auc: 0.9385\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3173 - accuracy: 0.8025 - auc: 0.9203 - val_loss: 0.3710 - val_accuracy: 0.8726 - val_auc: 0.9387\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3074 - accuracy: 0.8038 - auc: 0.9212 - val_loss: 0.3749 - val_accuracy: 0.8814 - val_auc: 0.9401\n",
      "Epoch 45/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3106 - accuracy: 0.8070 - auc: 0.9211Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3095 - accuracy: 0.8072 - auc: 0.9215 - val_loss: 0.3809 - val_accuracy: 0.8812 - val_auc: 0.9393\n",
      "Epoch 00045: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 1.0647 - accuracy: 0.2255 - auc: 0.6866 - val_loss: 0.5953 - val_accuracy: 0.2867 - val_auc: 0.9042\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6418 - accuracy: 0.4691 - auc: 0.8297 - val_loss: 0.4245 - val_accuracy: 0.6905 - val_auc: 0.9291\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5193 - accuracy: 0.6295 - auc: 0.8843 - val_loss: 0.3555 - val_accuracy: 0.8007 - val_auc: 0.9379\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4398 - accuracy: 0.7013 - auc: 0.9018 - val_loss: 0.3197 - val_accuracy: 0.8448 - val_auc: 0.9435\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.4147 - accuracy: 0.7404 - auc: 0.9122 - val_loss: 0.3023 - val_accuracy: 0.8557 - val_auc: 0.9479\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3883 - accuracy: 0.7562 - auc: 0.9217 - val_loss: 0.2898 - val_accuracy: 0.8665 - val_auc: 0.9507\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3754 - accuracy: 0.7712 - auc: 0.9237 - val_loss: 0.2814 - val_accuracy: 0.8686 - val_auc: 0.9534\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3441 - accuracy: 0.7851 - auc: 0.9355 - val_loss: 0.2759 - val_accuracy: 0.8799 - val_auc: 0.9540\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3410 - accuracy: 0.7957 - auc: 0.9333 - val_loss: 0.2741 - val_accuracy: 0.8745 - val_auc: 0.9549\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3330 - accuracy: 0.8042 - auc: 0.9400 - val_loss: 0.2704 - val_accuracy: 0.8826 - val_auc: 0.9559\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3203 - accuracy: 0.8062 - auc: 0.9403 - val_loss: 0.2673 - val_accuracy: 0.8844 - val_auc: 0.9569\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3064 - accuracy: 0.8160 - auc: 0.9466 - val_loss: 0.2672 - val_accuracy: 0.8829 - val_auc: 0.9572\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3084 - accuracy: 0.8144 - auc: 0.9462 - val_loss: 0.2644 - val_accuracy: 0.8858 - val_auc: 0.9579\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3066 - accuracy: 0.8198 - auc: 0.9465 - val_loss: 0.2653 - val_accuracy: 0.8858 - val_auc: 0.9579\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2855 - accuracy: 0.8264 - auc: 0.9523 - val_loss: 0.2644 - val_accuracy: 0.8908 - val_auc: 0.9585\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2942 - accuracy: 0.8275 - auc: 0.9490 - val_loss: 0.2663 - val_accuracy: 0.8882 - val_auc: 0.9579\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2909 - accuracy: 0.8296 - auc: 0.9516 - val_loss: 0.2668 - val_accuracy: 0.8877 - val_auc: 0.9580\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2787 - accuracy: 0.8321 - auc: 0.9543 - val_loss: 0.2673 - val_accuracy: 0.8910 - val_auc: 0.9582\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2810 - accuracy: 0.8349 - auc: 0.9545 - val_loss: 0.2670 - val_accuracy: 0.8902 - val_auc: 0.9586\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2713 - accuracy: 0.8353 - auc: 0.9567 - val_loss: 0.2691 - val_accuracy: 0.8931 - val_auc: 0.9582\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2725 - accuracy: 0.8390 - auc: 0.9561 - val_loss: 0.2689 - val_accuracy: 0.8916 - val_auc: 0.9581\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2671 - accuracy: 0.8406 - auc: 0.9579 - val_loss: 0.2708 - val_accuracy: 0.8938 - val_auc: 0.9581\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2833 - accuracy: 0.8359 - auc: 0.9529 - val_loss: 0.2718 - val_accuracy: 0.8905 - val_auc: 0.9579\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2719 - accuracy: 0.8399 - auc: 0.9571 - val_loss: 0.2745 - val_accuracy: 0.8946 - val_auc: 0.9577\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2548 - accuracy: 0.8455 - auc: 0.9610 - val_loss: 0.2770 - val_accuracy: 0.8969 - val_auc: 0.9574\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2630 - accuracy: 0.8463 - auc: 0.9595 - val_loss: 0.2771 - val_accuracy: 0.8955 - val_auc: 0.9575\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2626 - accuracy: 0.8457 - auc: 0.9593 - val_loss: 0.2789 - val_accuracy: 0.8953 - val_auc: 0.9574\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2611 - accuracy: 0.8442 - auc: 0.9595 - val_loss: 0.2816 - val_accuracy: 0.8972 - val_auc: 0.9572\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2637 - accuracy: 0.8454 - auc: 0.9585 - val_loss: 0.2812 - val_accuracy: 0.8942 - val_auc: 0.9573\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2576 - accuracy: 0.8474 - auc: 0.9593 - val_loss: 0.2860 - val_accuracy: 0.8962 - val_auc: 0.9568\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2523 - accuracy: 0.8464 - auc: 0.9620 - val_loss: 0.2881 - val_accuracy: 0.8943 - val_auc: 0.9555\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2589 - accuracy: 0.8485 - auc: 0.9604 - val_loss: 0.2898 - val_accuracy: 0.8964 - val_auc: 0.9544\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2568 - accuracy: 0.8484 - auc: 0.9611 - val_loss: 0.2919 - val_accuracy: 0.8976 - val_auc: 0.9552\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2652 - accuracy: 0.8487 - auc: 0.9583 - val_loss: 0.2902 - val_accuracy: 0.8917 - val_auc: 0.9543\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2505 - accuracy: 0.8454 - auc: 0.9623 - val_loss: 0.2923 - val_accuracy: 0.8947 - val_auc: 0.9543\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2589 - accuracy: 0.8462 - auc: 0.9599 - val_loss: 0.2927 - val_accuracy: 0.8925 - val_auc: 0.9544\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2560 - accuracy: 0.8470 - auc: 0.9603 - val_loss: 0.2949 - val_accuracy: 0.8945 - val_auc: 0.9544\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2473 - accuracy: 0.8435 - auc: 0.9630 - val_loss: 0.2976 - val_accuracy: 0.8969 - val_auc: 0.9544\n",
      "Epoch 39/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2537 - accuracy: 0.8470 - auc: 0.9615Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2537 - accuracy: 0.8470 - auc: 0.9616 - val_loss: 0.2973 - val_accuracy: 0.8969 - val_auc: 0.9543\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.7744 - accuracy: 0.2443 - auc: 0.7936 - val_loss: 0.5336 - val_accuracy: 0.4391 - val_auc: 0.8996\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5739 - accuracy: 0.4737 - auc: 0.8737 - val_loss: 0.4052 - val_accuracy: 0.6921 - val_auc: 0.9288\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4620 - accuracy: 0.5958 - auc: 0.9057 - val_loss: 0.3440 - val_accuracy: 0.8014 - val_auc: 0.9387\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4090 - accuracy: 0.6713 - auc: 0.9181 - val_loss: 0.3156 - val_accuracy: 0.8373 - val_auc: 0.9448\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3931 - accuracy: 0.7046 - auc: 0.9256 - val_loss: 0.2945 - val_accuracy: 0.8575 - val_auc: 0.9503\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3689 - accuracy: 0.7310 - auc: 0.9316 - val_loss: 0.2831 - val_accuracy: 0.8675 - val_auc: 0.9529\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3491 - accuracy: 0.7483 - auc: 0.9356 - val_loss: 0.2743 - val_accuracy: 0.8736 - val_auc: 0.9553\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3386 - accuracy: 0.7632 - auc: 0.9390 - val_loss: 0.2702 - val_accuracy: 0.8801 - val_auc: 0.9561\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3326 - accuracy: 0.7676 - auc: 0.9402 - val_loss: 0.2695 - val_accuracy: 0.8772 - val_auc: 0.9565\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3252 - accuracy: 0.7718 - auc: 0.9430 - val_loss: 0.2695 - val_accuracy: 0.8786 - val_auc: 0.9565\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3089 - accuracy: 0.7755 - auc: 0.9484 - val_loss: 0.2690 - val_accuracy: 0.8824 - val_auc: 0.9566\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3103 - accuracy: 0.7782 - auc: 0.9473 - val_loss: 0.2692 - val_accuracy: 0.8841 - val_auc: 0.9567\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3060 - accuracy: 0.7812 - auc: 0.9480 - val_loss: 0.2685 - val_accuracy: 0.8861 - val_auc: 0.9567\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2908 - accuracy: 0.7838 - auc: 0.9532 - val_loss: 0.2681 - val_accuracy: 0.8894 - val_auc: 0.9569\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2947 - accuracy: 0.7844 - auc: 0.9528 - val_loss: 0.2685 - val_accuracy: 0.8887 - val_auc: 0.9569\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2874 - accuracy: 0.7883 - auc: 0.9548 - val_loss: 0.2688 - val_accuracy: 0.8922 - val_auc: 0.9573\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2866 - accuracy: 0.7909 - auc: 0.9550 - val_loss: 0.2689 - val_accuracy: 0.8888 - val_auc: 0.9572\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2823 - accuracy: 0.7903 - auc: 0.9556 - val_loss: 0.2710 - val_accuracy: 0.8882 - val_auc: 0.9569\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2717 - accuracy: 0.7906 - auc: 0.9592 - val_loss: 0.2724 - val_accuracy: 0.8950 - val_auc: 0.9572\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2714 - accuracy: 0.7933 - auc: 0.9590 - val_loss: 0.2732 - val_accuracy: 0.8962 - val_auc: 0.9569\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2703 - accuracy: 0.7976 - auc: 0.9579 - val_loss: 0.2759 - val_accuracy: 0.8969 - val_auc: 0.9566\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2745 - accuracy: 0.7968 - auc: 0.9571 - val_loss: 0.2716 - val_accuracy: 0.8939 - val_auc: 0.9575\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2729 - accuracy: 0.7954 - auc: 0.9576 - val_loss: 0.2771 - val_accuracy: 0.9015 - val_auc: 0.9567\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2562 - accuracy: 0.7998 - auc: 0.9625 - val_loss: 0.2755 - val_accuracy: 0.8976 - val_auc: 0.9572\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2694 - accuracy: 0.8426 - auc: 0.9588 - val_loss: 0.2781 - val_accuracy: 0.9042 - val_auc: 0.9568\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2704 - accuracy: 0.8837 - auc: 0.9581 - val_loss: 0.2785 - val_accuracy: 0.8997 - val_auc: 0.9567\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2714 - accuracy: 0.8817 - auc: 0.9578 - val_loss: 0.2807 - val_accuracy: 0.9031 - val_auc: 0.9566\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2587 - accuracy: 0.8879 - auc: 0.9620 - val_loss: 0.2823 - val_accuracy: 0.9040 - val_auc: 0.9564\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2592 - accuracy: 0.8937 - auc: 0.9618 - val_loss: 0.2841 - val_accuracy: 0.9056 - val_auc: 0.9564accuracy: 0.8927 -\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2647 - accuracy: 0.8903 - auc: 0.9591 - val_loss: 0.2886 - val_accuracy: 0.9067 - val_auc: 0.9558\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2509 - accuracy: 0.8993 - auc: 0.9635 - val_loss: 0.2903 - val_accuracy: 0.9094 - val_auc: 0.9557\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2642 - accuracy: 0.8958 - auc: 0.9595 - val_loss: 0.2891 - val_accuracy: 0.9075 - val_auc: 0.9557\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2537 - accuracy: 0.8997 - auc: 0.9625 - val_loss: 0.2920 - val_accuracy: 0.9087 - val_auc: 0.9559\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2479 - accuracy: 0.9020 - auc: 0.9640 - val_loss: 0.2977 - val_accuracy: 0.9108 - val_auc: 0.9539\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2508 - accuracy: 0.9039 - auc: 0.9645 - val_loss: 0.2974 - val_accuracy: 0.9103 - val_auc: 0.9542\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2553 - accuracy: 0.9033 - auc: 0.9622 - val_loss: 0.3004 - val_accuracy: 0.9142 - val_auc: 0.9540\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2523 - accuracy: 0.9067 - auc: 0.9626 - val_loss: 0.3019 - val_accuracy: 0.9094 - val_auc: 0.9537\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2514 - accuracy: 0.9059 - auc: 0.9629 - val_loss: 0.3016 - val_accuracy: 0.9115 - val_auc: 0.9546\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2546 - accuracy: 0.9075 - auc: 0.9631 - val_loss: 0.3081 - val_accuracy: 0.9136 - val_auc: 0.9528\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2545 - accuracy: 0.9076 - auc: 0.9623 - val_loss: 0.3094 - val_accuracy: 0.9134 - val_auc: 0.9528\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2536 - accuracy: 0.9095 - auc: 0.9619 - val_loss: 0.3156 - val_accuracy: 0.9117 - val_auc: 0.9525\n",
      "Epoch 42/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2501 - accuracy: 0.9077 - auc: 0.9636Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2497 - accuracy: 0.9077 - auc: 0.9638 - val_loss: 0.3148 - val_accuracy: 0.9159 - val_auc: 0.9517\n",
      "Epoch 00042: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.9691 - accuracy: 0.1093 - auc: 0.7207 - val_loss: 0.6891 - val_accuracy: 0.1109 - val_auc: 0.8816\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.6693 - accuracy: 0.3413 - auc: 0.8412 - val_loss: 0.4723 - val_accuracy: 0.5613 - val_auc: 0.9253\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5227 - accuracy: 0.5348 - auc: 0.8867 - val_loss: 0.3714 - val_accuracy: 0.7677 - val_auc: 0.9384\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4733 - accuracy: 0.6231 - auc: 0.8965 - val_loss: 0.3288 - val_accuracy: 0.8082 - val_auc: 0.9481\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4310 - accuracy: 0.6602 - auc: 0.9158 - val_loss: 0.3057 - val_accuracy: 0.8423 - val_auc: 0.9495\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4182 - accuracy: 0.6960 - auc: 0.9148 - val_loss: 0.2929 - val_accuracy: 0.8489 - val_auc: 0.9521\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3988 - accuracy: 0.7068 - auc: 0.9237 - val_loss: 0.2875 - val_accuracy: 0.8529 - val_auc: 0.9526\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3638 - accuracy: 0.7249 - auc: 0.9340 - val_loss: 0.2780 - val_accuracy: 0.8618 - val_auc: 0.9547\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3564 - accuracy: 0.7377 - auc: 0.9326 - val_loss: 0.2752 - val_accuracy: 0.8656 - val_auc: 0.9552\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3414 - accuracy: 0.7461 - auc: 0.9404 - val_loss: 0.2745 - val_accuracy: 0.8709 - val_auc: 0.9550\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3424 - accuracy: 0.7518 - auc: 0.9407 - val_loss: 0.2738 - val_accuracy: 0.8709 - val_auc: 0.9552\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3376 - accuracy: 0.7541 - auc: 0.9429 - val_loss: 0.2734 - val_accuracy: 0.8754 - val_auc: 0.9550\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3199 - accuracy: 0.7643 - auc: 0.9475 - val_loss: 0.2715 - val_accuracy: 0.8816 - val_auc: 0.9553\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3225 - accuracy: 0.7687 - auc: 0.9438 - val_loss: 0.2733 - val_accuracy: 0.8765 - val_auc: 0.9548\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3159 - accuracy: 0.7671 - auc: 0.9469 - val_loss: 0.2739 - val_accuracy: 0.8799 - val_auc: 0.9550\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3116 - accuracy: 0.7714 - auc: 0.9475 - val_loss: 0.2721 - val_accuracy: 0.8756 - val_auc: 0.9551\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3058 - accuracy: 0.7703 - auc: 0.9493 - val_loss: 0.2732 - val_accuracy: 0.8772 - val_auc: 0.9552\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3119 - accuracy: 0.7705 - auc: 0.9485 - val_loss: 0.2737 - val_accuracy: 0.8753 - val_auc: 0.9550\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3018 - accuracy: 0.7736 - auc: 0.9499 - val_loss: 0.2755 - val_accuracy: 0.8786 - val_auc: 0.9550\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3001 - accuracy: 0.7723 - auc: 0.9513 - val_loss: 0.2751 - val_accuracy: 0.8765 - val_auc: 0.9552\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2914 - accuracy: 0.7779 - auc: 0.9529 - val_loss: 0.2756 - val_accuracy: 0.8798 - val_auc: 0.9552\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2850 - accuracy: 0.7811 - auc: 0.9543 - val_loss: 0.2769 - val_accuracy: 0.8801 - val_auc: 0.9549\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2805 - accuracy: 0.7782 - auc: 0.9555 - val_loss: 0.2774 - val_accuracy: 0.8836 - val_auc: 0.9553\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2833 - accuracy: 0.7835 - auc: 0.9534 - val_loss: 0.2779 - val_accuracy: 0.8841 - val_auc: 0.9555\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2777 - accuracy: 0.7853 - auc: 0.9563 - val_loss: 0.2791 - val_accuracy: 0.8829 - val_auc: 0.9556\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2721 - accuracy: 0.7839 - auc: 0.9572 - val_loss: 0.2793 - val_accuracy: 0.8853 - val_auc: 0.9560\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2792 - accuracy: 0.7854 - auc: 0.9550 - val_loss: 0.2814 - val_accuracy: 0.8876 - val_auc: 0.9551\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2795 - accuracy: 0.7852 - auc: 0.9560 - val_loss: 0.2814 - val_accuracy: 0.8860 - val_auc: 0.9552\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2694 - accuracy: 0.7832 - auc: 0.9584 - val_loss: 0.2828 - val_accuracy: 0.8836 - val_auc: 0.9550\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2737 - accuracy: 0.7845 - auc: 0.9574 - val_loss: 0.2851 - val_accuracy: 0.8875 - val_auc: 0.9549\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2686 - accuracy: 0.7850 - auc: 0.9580 - val_loss: 0.2873 - val_accuracy: 0.8887 - val_auc: 0.9548\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2690 - accuracy: 0.7850 - auc: 0.9591 - val_loss: 0.2870 - val_accuracy: 0.8869 - val_auc: 0.9549\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2634 - accuracy: 0.8211 - auc: 0.9594 - val_loss: 0.2906 - val_accuracy: 0.8977 - val_auc: 0.9543\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2706 - accuracy: 0.8781 - auc: 0.9579 - val_loss: 0.2905 - val_accuracy: 0.8991 - val_auc: 0.9537\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2618 - accuracy: 0.8849 - auc: 0.9592 - val_loss: 0.2920 - val_accuracy: 0.9024 - val_auc: 0.9543\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2631 - accuracy: 0.8840 - auc: 0.9602 - val_loss: 0.2965 - val_accuracy: 0.9031 - val_auc: 0.9537\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2557 - accuracy: 0.8855 - auc: 0.9618 - val_loss: 0.2989 - val_accuracy: 0.9046 - val_auc: 0.9530\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2553 - accuracy: 0.8905 - auc: 0.9622 - val_loss: 0.3023 - val_accuracy: 0.9071 - val_auc: 0.9529\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2568 - accuracy: 0.8934 - auc: 0.9617 - val_loss: 0.3037 - val_accuracy: 0.9088 - val_auc: 0.9528\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2572 - accuracy: 0.8956 - auc: 0.9612 - val_loss: 0.3088 - val_accuracy: 0.9096 - val_auc: 0.9519\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2560 - accuracy: 0.8999 - auc: 0.9619 - val_loss: 0.3141 - val_accuracy: 0.9114 - val_auc: 0.9510\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2565 - accuracy: 0.9002 - auc: 0.9610 - val_loss: 0.3119 - val_accuracy: 0.9100 - val_auc: 0.9520\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2645 - accuracy: 0.9000 - auc: 0.9585 - val_loss: 0.3126 - val_accuracy: 0.9082 - val_auc: 0.9521\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2504 - accuracy: 0.8991 - auc: 0.9631 - val_loss: 0.3125 - val_accuracy: 0.9123 - val_auc: 0.9527\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2482 - accuracy: 0.9013 - auc: 0.9639 - val_loss: 0.3152 - val_accuracy: 0.9129 - val_auc: 0.9521\n",
      "Epoch 46/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2506 - accuracy: 0.9044 - auc: 0.9615Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2489 - accuracy: 0.9043 - auc: 0.9618 - val_loss: 0.3171 - val_accuracy: 0.9136 - val_auc: 0.9525\n",
      "Epoch 00046: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 1.1174 - accuracy: 0.4261 - auc: 0.4985 - val_loss: 0.6430 - val_accuracy: 0.4846 - val_auc: 0.7415\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6321 - accuracy: 0.4907 - auc: 0.7596 - val_loss: 0.5065 - val_accuracy: 0.6789 - val_auc: 0.8744\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.5313 - accuracy: 0.6157 - auc: 0.8465 - val_loss: 0.4265 - val_accuracy: 0.7916 - val_auc: 0.9111\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4602 - accuracy: 0.7026 - auc: 0.8807 - val_loss: 0.3767 - val_accuracy: 0.8414 - val_auc: 0.9274\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.4279 - accuracy: 0.7548 - auc: 0.9006 - val_loss: 0.3428 - val_accuracy: 0.8609 - val_auc: 0.9378\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3987 - accuracy: 0.7831 - auc: 0.9125 - val_loss: 0.3184 - val_accuracy: 0.8712 - val_auc: 0.9444\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3833 - accuracy: 0.8011 - auc: 0.9161 - val_loss: 0.3042 - val_accuracy: 0.8810 - val_auc: 0.9479\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3496 - accuracy: 0.8191 - auc: 0.9293 - val_loss: 0.2933 - val_accuracy: 0.8848 - val_auc: 0.9503\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3424 - accuracy: 0.8322 - auc: 0.9320 - val_loss: 0.2878 - val_accuracy: 0.8934 - val_auc: 0.9512\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3412 - accuracy: 0.8371 - auc: 0.9308 - val_loss: 0.2843 - val_accuracy: 0.8920 - val_auc: 0.9525\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3181 - accuracy: 0.8399 - auc: 0.9402 - val_loss: 0.2817 - val_accuracy: 0.8919 - val_auc: 0.9528\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3220 - accuracy: 0.8441 - auc: 0.9399 - val_loss: 0.2801 - val_accuracy: 0.8932 - val_auc: 0.9532\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3166 - accuracy: 0.8474 - auc: 0.9406 - val_loss: 0.2798 - val_accuracy: 0.8969 - val_auc: 0.9531\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3172 - accuracy: 0.8504 - auc: 0.9398 - val_loss: 0.2789 - val_accuracy: 0.8986 - val_auc: 0.9537\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3041 - accuracy: 0.8531 - auc: 0.9447 - val_loss: 0.2803 - val_accuracy: 0.9036 - val_auc: 0.9537\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3101 - accuracy: 0.8577 - auc: 0.9430 - val_loss: 0.2777 - val_accuracy: 0.9010 - val_auc: 0.9542\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2957 - accuracy: 0.8563 - auc: 0.9482 - val_loss: 0.2761 - val_accuracy: 0.8993 - val_auc: 0.9546\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2920 - accuracy: 0.8567 - auc: 0.9488 - val_loss: 0.2753 - val_accuracy: 0.9006 - val_auc: 0.9552\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2839 - accuracy: 0.8596 - auc: 0.9513 - val_loss: 0.2756 - val_accuracy: 0.9034 - val_auc: 0.9554\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2958 - accuracy: 0.8605 - auc: 0.9477 - val_loss: 0.2768 - val_accuracy: 0.9023 - val_auc: 0.9552\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2868 - accuracy: 0.8590 - auc: 0.9506 - val_loss: 0.2767 - val_accuracy: 0.9049 - val_auc: 0.9552\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2789 - accuracy: 0.8626 - auc: 0.9530 - val_loss: 0.2786 - val_accuracy: 0.9049 - val_auc: 0.9552\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2740 - accuracy: 0.8611 - auc: 0.9541 - val_loss: 0.2785 - val_accuracy: 0.9051 - val_auc: 0.9552\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2778 - accuracy: 0.8628 - auc: 0.9537 - val_loss: 0.2812 - val_accuracy: 0.9029 - val_auc: 0.9544\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2813 - accuracy: 0.8616 - auc: 0.9514 - val_loss: 0.2855 - val_accuracy: 0.8997 - val_auc: 0.9540\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2717 - accuracy: 0.8577 - auc: 0.9554 - val_loss: 0.2856 - val_accuracy: 0.9011 - val_auc: 0.9542\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2669 - accuracy: 0.8614 - auc: 0.9564 - val_loss: 0.2903 - val_accuracy: 0.9012 - val_auc: 0.9531\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2757 - accuracy: 0.8599 - auc: 0.9532 - val_loss: 0.2943 - val_accuracy: 0.9015 - val_auc: 0.9528\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2654 - accuracy: 0.8601 - auc: 0.9564 - val_loss: 0.2932 - val_accuracy: 0.9012 - val_auc: 0.9535\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2539 - accuracy: 0.8623 - auc: 0.9608 - val_loss: 0.2974 - val_accuracy: 0.9054 - val_auc: 0.9532\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2646 - accuracy: 0.8627 - auc: 0.9563 - val_loss: 0.2978 - val_accuracy: 0.9059 - val_auc: 0.9534\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2571 - accuracy: 0.8655 - auc: 0.9587 - val_loss: 0.2990 - val_accuracy: 0.9070 - val_auc: 0.9537\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2717 - accuracy: 0.8619 - auc: 0.9547 - val_loss: 0.3001 - val_accuracy: 0.9010 - val_auc: 0.9524\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2548 - accuracy: 0.8607 - auc: 0.9593 - val_loss: 0.3055 - val_accuracy: 0.9040 - val_auc: 0.9523\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2572 - accuracy: 0.8590 - auc: 0.9587 - val_loss: 0.3102 - val_accuracy: 0.9061 - val_auc: 0.9518\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2536 - accuracy: 0.8627 - auc: 0.9598 - val_loss: 0.3078 - val_accuracy: 0.9033 - val_auc: 0.9521\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2589 - accuracy: 0.8583 - auc: 0.9573 - val_loss: 0.3111 - val_accuracy: 0.9002 - val_auc: 0.9506\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2520 - accuracy: 0.8574 - auc: 0.9605 - val_loss: 0.3172 - val_accuracy: 0.9026 - val_auc: 0.9492\n",
      "Epoch 39/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2455 - accuracy: 0.8599 - auc: 0.9618Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2449 - accuracy: 0.8599 - auc: 0.9620 - val_loss: 0.3200 - val_accuracy: 0.9040 - val_auc: 0.9496\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 1.0022 - accuracy: 0.3257 - auc: 0.5980 - val_loss: 0.6357 - val_accuracy: 0.4308 - val_auc: 0.8038\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6601 - accuracy: 0.5012 - auc: 0.7904 - val_loss: 0.4690 - val_accuracy: 0.6959 - val_auc: 0.8983\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4936 - accuracy: 0.6262 - auc: 0.8734 - val_loss: 0.3779 - val_accuracy: 0.8223 - val_auc: 0.9242\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4410 - accuracy: 0.7024 - auc: 0.8985 - val_loss: 0.3303 - val_accuracy: 0.8567 - val_auc: 0.9387\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3981 - accuracy: 0.7431 - auc: 0.9101 - val_loss: 0.3116 - val_accuracy: 0.8681 - val_auc: 0.9446\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3773 - accuracy: 0.7689 - auc: 0.9222 - val_loss: 0.3023 - val_accuracy: 0.8757 - val_auc: 0.9474\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3558 - accuracy: 0.7891 - auc: 0.9260 - val_loss: 0.2959 - val_accuracy: 0.8840 - val_auc: 0.9490\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3473 - accuracy: 0.7991 - auc: 0.9307 - val_loss: 0.2927 - val_accuracy: 0.8819 - val_auc: 0.9504\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3350 - accuracy: 0.8024 - auc: 0.9356 - val_loss: 0.2897 - val_accuracy: 0.8811 - val_auc: 0.9513\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3184 - accuracy: 0.8135 - auc: 0.9411 - val_loss: 0.2898 - val_accuracy: 0.8879 - val_auc: 0.9521\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3107 - accuracy: 0.8240 - auc: 0.9421 - val_loss: 0.2904 - val_accuracy: 0.8878 - val_auc: 0.9521\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3080 - accuracy: 0.8280 - auc: 0.9435 - val_loss: 0.2909 - val_accuracy: 0.8885 - val_auc: 0.9525\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2986 - accuracy: 0.8322 - auc: 0.9463 - val_loss: 0.2926 - val_accuracy: 0.8915 - val_auc: 0.9523\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.3018 - accuracy: 0.8351 - auc: 0.9465 - val_loss: 0.2971 - val_accuracy: 0.8911 - val_auc: 0.9526\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2971 - accuracy: 0.8372 - auc: 0.9466 - val_loss: 0.3006 - val_accuracy: 0.8908 - val_auc: 0.9513\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2904 - accuracy: 0.8405 - auc: 0.9485 - val_loss: 0.3004 - val_accuracy: 0.8906 - val_auc: 0.9511\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2873 - accuracy: 0.8362 - auc: 0.9499 - val_loss: 0.3046 - val_accuracy: 0.8908 - val_auc: 0.9510\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2840 - accuracy: 0.8437 - auc: 0.9503 - val_loss: 0.3068 - val_accuracy: 0.8932 - val_auc: 0.9511\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2847 - accuracy: 0.8437 - auc: 0.9499 - val_loss: 0.3115 - val_accuracy: 0.8905 - val_auc: 0.9506\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2805 - accuracy: 0.8446 - auc: 0.9511 - val_loss: 0.3143 - val_accuracy: 0.8927 - val_auc: 0.9510\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2764 - accuracy: 0.8460 - auc: 0.9535 - val_loss: 0.3150 - val_accuracy: 0.8928 - val_auc: 0.9514\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2766 - accuracy: 0.8449 - auc: 0.9526 - val_loss: 0.3179 - val_accuracy: 0.8906 - val_auc: 0.9511\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2680 - accuracy: 0.8484 - auc: 0.9550 - val_loss: 0.3235 - val_accuracy: 0.8921 - val_auc: 0.9507\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2778 - accuracy: 0.8473 - auc: 0.9506 - val_loss: 0.3258 - val_accuracy: 0.8906 - val_auc: 0.9505\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2646 - accuracy: 0.8456 - auc: 0.9562 - val_loss: 0.3268 - val_accuracy: 0.8918 - val_auc: 0.9511\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2650 - accuracy: 0.8488 - auc: 0.9553 - val_loss: 0.3324 - val_accuracy: 0.8914 - val_auc: 0.9510\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2594 - accuracy: 0.8489 - auc: 0.9573 - val_loss: 0.3364 - val_accuracy: 0.8923 - val_auc: 0.9508\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2562 - accuracy: 0.8504 - auc: 0.9573 - val_loss: 0.3405 - val_accuracy: 0.8926 - val_auc: 0.9498\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2538 - accuracy: 0.8542 - auc: 0.9587 - val_loss: 0.3442 - val_accuracy: 0.8964 - val_auc: 0.9478\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2603 - accuracy: 0.8523 - auc: 0.9566 - val_loss: 0.3479 - val_accuracy: 0.8938 - val_auc: 0.9474\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2556 - accuracy: 0.8516 - auc: 0.9577 - val_loss: 0.3554 - val_accuracy: 0.8959 - val_auc: 0.9460\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2587 - accuracy: 0.8540 - auc: 0.9583 - val_loss: 0.3578 - val_accuracy: 0.8930 - val_auc: 0.9460\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2563 - accuracy: 0.8545 - auc: 0.9578 - val_loss: 0.3609 - val_accuracy: 0.8913 - val_auc: 0.9462\n",
      "Epoch 34/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2550 - accuracy: 0.8533 - auc: 0.9571Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2548 - accuracy: 0.8534 - auc: 0.9571 - val_loss: 0.3639 - val_accuracy: 0.8944 - val_auc: 0.9465\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.7508 - accuracy: 0.5110 - auc: 0.7519 - val_loss: 0.4401 - val_accuracy: 0.7580 - val_auc: 0.9160\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4920 - accuracy: 0.7604 - auc: 0.8787 - val_loss: 0.3756 - val_accuracy: 0.8587 - val_auc: 0.9349\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4286 - accuracy: 0.8199 - auc: 0.9044 - val_loss: 0.3321 - val_accuracy: 0.8807 - val_auc: 0.9473\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3820 - accuracy: 0.8492 - auc: 0.9257 - val_loss: 0.3070 - val_accuracy: 0.8822 - val_auc: 0.9513\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3307 - accuracy: 0.8667 - auc: 0.9411 - val_loss: 0.2879 - val_accuracy: 0.8950 - val_auc: 0.9528\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3193 - accuracy: 0.8755 - auc: 0.9464 - val_loss: 0.2725 - val_accuracy: 0.9033 - val_auc: 0.9569\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3131 - accuracy: 0.8841 - auc: 0.9487 - val_loss: 0.2705 - val_accuracy: 0.9098 - val_auc: 0.9571\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3142 - accuracy: 0.8911 - auc: 0.9449 - val_loss: 0.2671 - val_accuracy: 0.9054 - val_auc: 0.9578\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2841 - accuracy: 0.8920 - auc: 0.9547 - val_loss: 0.2642 - val_accuracy: 0.9061 - val_auc: 0.9579\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2784 - accuracy: 0.8946 - auc: 0.9564 - val_loss: 0.2637 - val_accuracy: 0.9055 - val_auc: 0.9582\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2705 - accuracy: 0.8944 - auc: 0.9580 - val_loss: 0.2642 - val_accuracy: 0.9099 - val_auc: 0.9578\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2580 - accuracy: 0.8998 - auc: 0.9617 - val_loss: 0.2623 - val_accuracy: 0.9118 - val_auc: 0.9583\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2719 - accuracy: 0.8992 - auc: 0.9585 - val_loss: 0.2630 - val_accuracy: 0.9102 - val_auc: 0.9583\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2563 - accuracy: 0.9013 - auc: 0.9618 - val_loss: 0.2635 - val_accuracy: 0.9136 - val_auc: 0.9583\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2557 - accuracy: 0.9052 - auc: 0.9619 - val_loss: 0.2618 - val_accuracy: 0.9096 - val_auc: 0.9585\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2478 - accuracy: 0.8995 - auc: 0.9641 - val_loss: 0.2646 - val_accuracy: 0.9138 - val_auc: 0.9584\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2453 - accuracy: 0.9050 - auc: 0.9648 - val_loss: 0.2655 - val_accuracy: 0.9163 - val_auc: 0.9582\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2521 - accuracy: 0.9059 - auc: 0.9624 - val_loss: 0.2665 - val_accuracy: 0.9179 - val_auc: 0.9582\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2490 - accuracy: 0.9079 - auc: 0.9636 - val_loss: 0.2625 - val_accuracy: 0.9141 - val_auc: 0.9589\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2418 - accuracy: 0.9040 - auc: 0.9653 - val_loss: 0.2668 - val_accuracy: 0.9147 - val_auc: 0.9578\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2428 - accuracy: 0.9056 - auc: 0.9650 - val_loss: 0.2683 - val_accuracy: 0.9158 - val_auc: 0.9582\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2349 - accuracy: 0.9078 - auc: 0.9672 - val_loss: 0.2706 - val_accuracy: 0.9180 - val_auc: 0.9567\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2328 - accuracy: 0.9114 - auc: 0.9676 - val_loss: 0.2723 - val_accuracy: 0.9181 - val_auc: 0.9569\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2298 - accuracy: 0.9091 - auc: 0.9684 - val_loss: 0.2738 - val_accuracy: 0.9198 - val_auc: 0.9567\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2389 - accuracy: 0.9087 - auc: 0.9660 - val_loss: 0.2765 - val_accuracy: 0.9147 - val_auc: 0.9554\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2301 - accuracy: 0.9091 - auc: 0.9685 - val_loss: 0.2786 - val_accuracy: 0.9197 - val_auc: 0.9553\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2364 - accuracy: 0.9084 - auc: 0.9667 - val_loss: 0.2782 - val_accuracy: 0.9166 - val_auc: 0.9552\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2291 - accuracy: 0.9077 - auc: 0.9684 - val_loss: 0.2786 - val_accuracy: 0.9176 - val_auc: 0.9554\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2308 - accuracy: 0.9090 - auc: 0.9682 - val_loss: 0.2849 - val_accuracy: 0.9199 - val_auc: 0.9545\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2271 - accuracy: 0.9128 - auc: 0.9693 - val_loss: 0.2843 - val_accuracy: 0.9173 - val_auc: 0.9550\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2301 - accuracy: 0.9072 - auc: 0.9681 - val_loss: 0.2901 - val_accuracy: 0.9215 - val_auc: 0.9534\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2245 - accuracy: 0.9131 - auc: 0.9697 - val_loss: 0.2871 - val_accuracy: 0.9195 - val_auc: 0.9544\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2244 - accuracy: 0.9124 - auc: 0.9697 - val_loss: 0.2889 - val_accuracy: 0.9198 - val_auc: 0.9529\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2239 - accuracy: 0.9107 - auc: 0.9699 - val_loss: 0.2955 - val_accuracy: 0.9212 - val_auc: 0.9525\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2268 - accuracy: 0.9124 - auc: 0.9690 - val_loss: 0.2977 - val_accuracy: 0.9198 - val_auc: 0.9521\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2199 - accuracy: 0.9121 - auc: 0.9707 - val_loss: 0.3012 - val_accuracy: 0.9217 - val_auc: 0.9519\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2151 - accuracy: 0.9135 - auc: 0.9720 - val_loss: 0.2983 - val_accuracy: 0.9199 - val_auc: 0.9527\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2204 - accuracy: 0.9134 - auc: 0.9703 - val_loss: 0.3048 - val_accuracy: 0.9214 - val_auc: 0.9521\n",
      "Epoch 39/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2127 - accuracy: 0.9125 - auc: 0.9724Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2133 - accuracy: 0.9126 - auc: 0.9722 - val_loss: 0.3082 - val_accuracy: 0.9228 - val_auc: 0.9512\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.7481 - accuracy: 0.3173 - auc: 0.7792 - val_loss: 0.4553 - val_accuracy: 0.6213 - val_auc: 0.9230\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4990 - accuracy: 0.6342 - auc: 0.8813 - val_loss: 0.3407 - val_accuracy: 0.8220 - val_auc: 0.9449\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4004 - accuracy: 0.7459 - auc: 0.9180 - val_loss: 0.3008 - val_accuracy: 0.8559 - val_auc: 0.9515\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3680 - accuracy: 0.7899 - auc: 0.9290 - val_loss: 0.2813 - val_accuracy: 0.8745 - val_auc: 0.9544\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3421 - accuracy: 0.8079 - auc: 0.9342 - val_loss: 0.2759 - val_accuracy: 0.8701 - val_auc: 0.9556\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3278 - accuracy: 0.8200 - auc: 0.9408 - val_loss: 0.2697 - val_accuracy: 0.8848 - val_auc: 0.9564\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3087 - accuracy: 0.8334 - auc: 0.9452 - val_loss: 0.2657 - val_accuracy: 0.8843 - val_auc: 0.9576\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2868 - accuracy: 0.8418 - auc: 0.9528 - val_loss: 0.2638 - val_accuracy: 0.8929 - val_auc: 0.9580\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2927 - accuracy: 0.8443 - auc: 0.9502 - val_loss: 0.2644 - val_accuracy: 0.8903 - val_auc: 0.9579\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2761 - accuracy: 0.8521 - auc: 0.9558 - val_loss: 0.2639 - val_accuracy: 0.8959 - val_auc: 0.9585\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2651 - accuracy: 0.8578 - auc: 0.9587 - val_loss: 0.2661 - val_accuracy: 0.8980 - val_auc: 0.9579\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2611 - accuracy: 0.8594 - auc: 0.9594 - val_loss: 0.2681 - val_accuracy: 0.8995 - val_auc: 0.9570\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2653 - accuracy: 0.8647 - auc: 0.9582 - val_loss: 0.2685 - val_accuracy: 0.8970 - val_auc: 0.9572\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2576 - accuracy: 0.8614 - auc: 0.9620 - val_loss: 0.2711 - val_accuracy: 0.9001 - val_auc: 0.9569\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2476 - accuracy: 0.8661 - auc: 0.9634 - val_loss: 0.2710 - val_accuracy: 0.9020 - val_auc: 0.9571\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2566 - accuracy: 0.8632 - auc: 0.9617 - val_loss: 0.2724 - val_accuracy: 0.9003 - val_auc: 0.9569\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2493 - accuracy: 0.8679 - auc: 0.9627 - val_loss: 0.2768 - val_accuracy: 0.8998 - val_auc: 0.9564\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2456 - accuracy: 0.8684 - auc: 0.9646 - val_loss: 0.2796 - val_accuracy: 0.9010 - val_auc: 0.9558\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2415 - accuracy: 0.8712 - auc: 0.9648 - val_loss: 0.2822 - val_accuracy: 0.9041 - val_auc: 0.9558\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2406 - accuracy: 0.8695 - auc: 0.9651 - val_loss: 0.2874 - val_accuracy: 0.9012 - val_auc: 0.9540\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2364 - accuracy: 0.8734 - auc: 0.9661 - val_loss: 0.2883 - val_accuracy: 0.8998 - val_auc: 0.9538\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2298 - accuracy: 0.8750 - auc: 0.9678 - val_loss: 0.2913 - val_accuracy: 0.9054 - val_auc: 0.9541\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2369 - accuracy: 0.8749 - auc: 0.9662 - val_loss: 0.2913 - val_accuracy: 0.9036 - val_auc: 0.9542\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2277 - accuracy: 0.8768 - auc: 0.9684 - val_loss: 0.2931 - val_accuracy: 0.9054 - val_auc: 0.9546\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2315 - accuracy: 0.8765 - auc: 0.9680 - val_loss: 0.2991 - val_accuracy: 0.9072 - val_auc: 0.9539\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2228 - accuracy: 0.8811 - auc: 0.9698 - val_loss: 0.3035 - val_accuracy: 0.9114 - val_auc: 0.9528\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2232 - accuracy: 0.8813 - auc: 0.9698 - val_loss: 0.3051 - val_accuracy: 0.9101 - val_auc: 0.9527\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2232 - accuracy: 0.8819 - auc: 0.9696 - val_loss: 0.3096 - val_accuracy: 0.9097 - val_auc: 0.9520\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2191 - accuracy: 0.8830 - auc: 0.9700 - val_loss: 0.3103 - val_accuracy: 0.9103 - val_auc: 0.9514\n",
      "Epoch 30/100\n",
      "247808/250290 [============================>.] - ETA: 0s - loss: 0.2166 - accuracy: 0.8821 - auc: 0.9708Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2175 - accuracy: 0.8821 - auc: 0.9706 - val_loss: 0.3154 - val_accuracy: 0.9130 - val_auc: 0.9512\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 15us/sample - loss: 0.8589 - accuracy: 0.5143 - auc: 0.6643 - val_loss: 0.4921 - val_accuracy: 0.6797 - val_auc: 0.8865\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.5464 - accuracy: 0.6868 - auc: 0.8515 - val_loss: 0.3897 - val_accuracy: 0.8285 - val_auc: 0.9251\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4196 - accuracy: 0.7937 - auc: 0.9007 - val_loss: 0.3400 - val_accuracy: 0.8764 - val_auc: 0.9373\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.4124 - accuracy: 0.8327 - auc: 0.9037 - val_loss: 0.3187 - val_accuracy: 0.8822 - val_auc: 0.9448\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3553 - accuracy: 0.8505 - auc: 0.9299 - val_loss: 0.2969 - val_accuracy: 0.8924 - val_auc: 0.9483\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.3366 - accuracy: 0.8583 - auc: 0.9344 - val_loss: 0.2787 - val_accuracy: 0.8975 - val_auc: 0.9543\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3060 - accuracy: 0.8700 - auc: 0.9439 - val_loss: 0.2762 - val_accuracy: 0.9037 - val_auc: 0.9541\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3048 - accuracy: 0.8742 - auc: 0.9439 - val_loss: 0.2699 - val_accuracy: 0.8993 - val_auc: 0.9560\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.3012 - accuracy: 0.8765 - auc: 0.9450 - val_loss: 0.2663 - val_accuracy: 0.8991 - val_auc: 0.9571\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2775 - accuracy: 0.8788 - auc: 0.9537 - val_loss: 0.2680 - val_accuracy: 0.9045 - val_auc: 0.9564\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2746 - accuracy: 0.8836 - auc: 0.9550 - val_loss: 0.2693 - val_accuracy: 0.9051 - val_auc: 0.9557\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2778 - accuracy: 0.8835 - auc: 0.9530 - val_loss: 0.2695 - val_accuracy: 0.9060 - val_auc: 0.9558\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 2s 7us/sample - loss: 0.2624 - accuracy: 0.8876 - auc: 0.9593 - val_loss: 0.2716 - val_accuracy: 0.9100 - val_auc: 0.9555\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2598 - accuracy: 0.8883 - auc: 0.9589 - val_loss: 0.2719 - val_accuracy: 0.9076 - val_auc: 0.9551\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2668 - accuracy: 0.8899 - auc: 0.9565 - val_loss: 0.2727 - val_accuracy: 0.9074 - val_auc: 0.9552\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2554 - accuracy: 0.8931 - auc: 0.9601 - val_loss: 0.2756 - val_accuracy: 0.9084 - val_auc: 0.9544\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2502 - accuracy: 0.8914 - auc: 0.9616 - val_loss: 0.2773 - val_accuracy: 0.9095 - val_auc: 0.9546\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2480 - accuracy: 0.8934 - auc: 0.9626 - val_loss: 0.2803 - val_accuracy: 0.9122 - val_auc: 0.9543\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2541 - accuracy: 0.8959 - auc: 0.9612 - val_loss: 0.2836 - val_accuracy: 0.9099 - val_auc: 0.9533\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2405 - accuracy: 0.8958 - auc: 0.9646 - val_loss: 0.2871 - val_accuracy: 0.9122 - val_auc: 0.9525\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2447 - accuracy: 0.8977 - auc: 0.9631 - val_loss: 0.2875 - val_accuracy: 0.9124 - val_auc: 0.9529\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2430 - accuracy: 0.8976 - auc: 0.9637 - val_loss: 0.2929 - val_accuracy: 0.9131 - val_auc: 0.9519\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2446 - accuracy: 0.8984 - auc: 0.9631 - val_loss: 0.2901 - val_accuracy: 0.9104 - val_auc: 0.9527\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2355 - accuracy: 0.8976 - auc: 0.9657 - val_loss: 0.2950 - val_accuracy: 0.9135 - val_auc: 0.9520\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2343 - accuracy: 0.9013 - auc: 0.9660 - val_loss: 0.2973 - val_accuracy: 0.9121 - val_auc: 0.9518\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2282 - accuracy: 0.8989 - auc: 0.9676 - val_loss: 0.3034 - val_accuracy: 0.9140 - val_auc: 0.9505\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2326 - accuracy: 0.8997 - auc: 0.9662 - val_loss: 0.3058 - val_accuracy: 0.9136 - val_auc: 0.9498\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2253 - accuracy: 0.9016 - auc: 0.9685 - val_loss: 0.3100 - val_accuracy: 0.9164 - val_auc: 0.9494\n",
      "Epoch 29/100\n",
      "243712/250290 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9004 - auc: 0.9678Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 2s 6us/sample - loss: 0.2297 - accuracy: 0.9003 - auc: 0.9672 - val_loss: 0.3136 - val_accuracy: 0.9162 - val_auc: 0.9491\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.8465 - accuracy: 0.1990 - auc: 0.7720 - val_loss: 0.5447 - val_accuracy: 0.3894 - val_auc: 0.9032\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5513 - accuracy: 0.5378 - auc: 0.8739 - val_loss: 0.3838 - val_accuracy: 0.7632 - val_auc: 0.9298\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4300 - accuracy: 0.6956 - auc: 0.9115 - val_loss: 0.3236 - val_accuracy: 0.8495 - val_auc: 0.9406\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3774 - accuracy: 0.7648 - auc: 0.9256 - val_loss: 0.2999 - val_accuracy: 0.8677 - val_auc: 0.9462\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3506 - accuracy: 0.7910 - auc: 0.9327 - val_loss: 0.2940 - val_accuracy: 0.8790 - val_auc: 0.9473\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3202 - accuracy: 0.8067 - auc: 0.9429 - val_loss: 0.2858 - val_accuracy: 0.8895 - val_auc: 0.9499\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3138 - accuracy: 0.8269 - auc: 0.9447 - val_loss: 0.2828 - val_accuracy: 0.8907 - val_auc: 0.9512\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3130 - accuracy: 0.8272 - auc: 0.9450 - val_loss: 0.2839 - val_accuracy: 0.8856 - val_auc: 0.9511\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2945 - accuracy: 0.8312 - auc: 0.9513 - val_loss: 0.2843 - val_accuracy: 0.8900 - val_auc: 0.9513\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2742 - accuracy: 0.8413 - auc: 0.9566 - val_loss: 0.2864 - val_accuracy: 0.8985 - val_auc: 0.9513\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2800 - accuracy: 0.8491 - auc: 0.9546 - val_loss: 0.2859 - val_accuracy: 0.8963 - val_auc: 0.9522\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2811 - accuracy: 0.8467 - auc: 0.9547 - val_loss: 0.2911 - val_accuracy: 0.8966 - val_auc: 0.9507\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2753 - accuracy: 0.8485 - auc: 0.9565 - val_loss: 0.2915 - val_accuracy: 0.8950 - val_auc: 0.9511\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2574 - accuracy: 0.8512 - auc: 0.9615 - val_loss: 0.2947 - val_accuracy: 0.9009 - val_auc: 0.9505\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2584 - accuracy: 0.8594 - auc: 0.9607 - val_loss: 0.2975 - val_accuracy: 0.9019 - val_auc: 0.9507\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2565 - accuracy: 0.8611 - auc: 0.9613 - val_loss: 0.3011 - val_accuracy: 0.9013 - val_auc: 0.9493\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2546 - accuracy: 0.8592 - auc: 0.9613 - val_loss: 0.3008 - val_accuracy: 0.9011 - val_auc: 0.9496\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2496 - accuracy: 0.8603 - auc: 0.9637 - val_loss: 0.3023 - val_accuracy: 0.9019 - val_auc: 0.9499\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2486 - accuracy: 0.8648 - auc: 0.9634 - val_loss: 0.3051 - val_accuracy: 0.9025 - val_auc: 0.9499\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2359 - accuracy: 0.8659 - auc: 0.9666 - val_loss: 0.3078 - val_accuracy: 0.9059 - val_auc: 0.9502\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2511 - accuracy: 0.8654 - auc: 0.9631 - val_loss: 0.3092 - val_accuracy: 0.9054 - val_auc: 0.9500\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2351 - accuracy: 0.8705 - auc: 0.9666 - val_loss: 0.3108 - val_accuracy: 0.9055 - val_auc: 0.9496\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2382 - accuracy: 0.8688 - auc: 0.9664 - val_loss: 0.3135 - val_accuracy: 0.9051 - val_auc: 0.9493\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2335 - accuracy: 0.8726 - auc: 0.9669 - val_loss: 0.3166 - val_accuracy: 0.9078 - val_auc: 0.9496\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2347 - accuracy: 0.8719 - auc: 0.9669 - val_loss: 0.3189 - val_accuracy: 0.9083 - val_auc: 0.9494\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2302 - accuracy: 0.8756 - auc: 0.9677 - val_loss: 0.3197 - val_accuracy: 0.9088 - val_auc: 0.9492\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2263 - accuracy: 0.8724 - auc: 0.9687 - val_loss: 0.3237 - val_accuracy: 0.9100 - val_auc: 0.9494\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2336 - accuracy: 0.8741 - auc: 0.9663 - val_loss: 0.3269 - val_accuracy: 0.9071 - val_auc: 0.9491\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2262 - accuracy: 0.8760 - auc: 0.9691 - val_loss: 0.3347 - val_accuracy: 0.9108 - val_auc: 0.9484\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2273 - accuracy: 0.8779 - auc: 0.9699 - val_loss: 0.3378 - val_accuracy: 0.9106 - val_auc: 0.9479\n",
      "Epoch 31/100\n",
      "247808/250291 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.8796 - auc: 0.9687Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2266 - accuracy: 0.8796 - auc: 0.9688 - val_loss: 0.3398 - val_accuracy: 0.9097 - val_auc: 0.9478\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 15us/sample - loss: 0.9066 - accuracy: 0.4921 - auc: 0.6575 - val_loss: 0.5146 - val_accuracy: 0.6575 - val_auc: 0.8844\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.5255 - accuracy: 0.6772 - auc: 0.8621 - val_loss: 0.3865 - val_accuracy: 0.8360 - val_auc: 0.9235\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.4153 - accuracy: 0.7889 - auc: 0.9082 - val_loss: 0.3251 - val_accuracy: 0.8799 - val_auc: 0.9367\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3842 - accuracy: 0.8278 - auc: 0.9207 - val_loss: 0.3023 - val_accuracy: 0.8899 - val_auc: 0.9439\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3449 - accuracy: 0.8374 - auc: 0.9362 - val_loss: 0.2861 - val_accuracy: 0.8971 - val_auc: 0.9492\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3179 - accuracy: 0.8572 - auc: 0.9421 - val_loss: 0.2782 - val_accuracy: 0.9032 - val_auc: 0.9517\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.3187 - accuracy: 0.8627 - auc: 0.9419 - val_loss: 0.2765 - val_accuracy: 0.9043 - val_auc: 0.9529\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2963 - accuracy: 0.8643 - auc: 0.9486 - val_loss: 0.2761 - val_accuracy: 0.9012 - val_auc: 0.9528\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2846 - accuracy: 0.8706 - auc: 0.9526 - val_loss: 0.2760 - val_accuracy: 0.9052 - val_auc: 0.9535\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2722 - accuracy: 0.8752 - auc: 0.9559 - val_loss: 0.2789 - val_accuracy: 0.9058 - val_auc: 0.9535\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2708 - accuracy: 0.8762 - auc: 0.9564 - val_loss: 0.2814 - val_accuracy: 0.9069 - val_auc: 0.9528\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2654 - accuracy: 0.8763 - auc: 0.9576 - val_loss: 0.2861 - val_accuracy: 0.9071 - val_auc: 0.9525\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 2s 7us/sample - loss: 0.2533 - accuracy: 0.8823 - auc: 0.9616 - val_loss: 0.2893 - val_accuracy: 0.9109 - val_auc: 0.9520\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2580 - accuracy: 0.8867 - auc: 0.9605 - val_loss: 0.2910 - val_accuracy: 0.9101 - val_auc: 0.9522\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2535 - accuracy: 0.8818 - auc: 0.9619 - val_loss: 0.2908 - val_accuracy: 0.9073 - val_auc: 0.9523\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2399 - accuracy: 0.8857 - auc: 0.9651 - val_loss: 0.2917 - val_accuracy: 0.9133 - val_auc: 0.9536\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2391 - accuracy: 0.8891 - auc: 0.9650 - val_loss: 0.2929 - val_accuracy: 0.9109 - val_auc: 0.9533\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2446 - accuracy: 0.8882 - auc: 0.9637 - val_loss: 0.2961 - val_accuracy: 0.9108 - val_auc: 0.9531\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2311 - accuracy: 0.8891 - auc: 0.9672 - val_loss: 0.3006 - val_accuracy: 0.9124 - val_auc: 0.9531\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2254 - accuracy: 0.8918 - auc: 0.9692 - val_loss: 0.3067 - val_accuracy: 0.9143 - val_auc: 0.9529\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2403 - accuracy: 0.8914 - auc: 0.9647 - val_loss: 0.3081 - val_accuracy: 0.9117 - val_auc: 0.9526\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2302 - accuracy: 0.8891 - auc: 0.9675 - val_loss: 0.3157 - val_accuracy: 0.9127 - val_auc: 0.9519\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2305 - accuracy: 0.8898 - auc: 0.9680 - val_loss: 0.3227 - val_accuracy: 0.9121 - val_auc: 0.9508\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2250 - accuracy: 0.8896 - auc: 0.9689 - val_loss: 0.3258 - val_accuracy: 0.9107 - val_auc: 0.9507\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2346 - accuracy: 0.8880 - auc: 0.9670 - val_loss: 0.3312 - val_accuracy: 0.9110 - val_auc: 0.9498\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2230 - accuracy: 0.8926 - auc: 0.9697 - val_loss: 0.3380 - val_accuracy: 0.9130 - val_auc: 0.9494\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2211 - accuracy: 0.8910 - auc: 0.9695 - val_loss: 0.3409 - val_accuracy: 0.9127 - val_auc: 0.9493\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2154 - accuracy: 0.8946 - auc: 0.9711 - val_loss: 0.3462 - val_accuracy: 0.9133 - val_auc: 0.9495\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2174 - accuracy: 0.8913 - auc: 0.9703 - val_loss: 0.3534 - val_accuracy: 0.9140 - val_auc: 0.9466\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2115 - accuracy: 0.8954 - auc: 0.9717 - val_loss: 0.3589 - val_accuracy: 0.9151 - val_auc: 0.9468\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2077 - accuracy: 0.8955 - auc: 0.9726 - val_loss: 0.3629 - val_accuracy: 0.9133 - val_auc: 0.9467\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2128 - accuracy: 0.8933 - auc: 0.9711 - val_loss: 0.3700 - val_accuracy: 0.9135 - val_auc: 0.9460\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2122 - accuracy: 0.8940 - auc: 0.9715 - val_loss: 0.3747 - val_accuracy: 0.9153 - val_auc: 0.9460\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2090 - accuracy: 0.8933 - auc: 0.9719 - val_loss: 0.3825 - val_accuracy: 0.9140 - val_auc: 0.9433\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.1931 - accuracy: 0.8961 - auc: 0.9756 - val_loss: 0.3884 - val_accuracy: 0.9200 - val_auc: 0.9439\n",
      "Epoch 36/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.8980 - auc: 0.9724Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.2077 - accuracy: 0.8980 - auc: 0.9725 - val_loss: 0.3946 - val_accuracy: 0.9177 - val_auc: 0.9432\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.5617 - accuracy: 0.8680 - auc: 0.8094 - val_loss: 0.3693 - val_accuracy: 0.9300 - val_auc: 0.9224\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5669 - accuracy: 0.8948 - auc: 0.8273 - val_loss: 0.3899 - val_accuracy: 0.9639 - val_auc: 0.9301\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4949 - accuracy: 0.9154 - auc: 0.8491 - val_loss: 0.3397 - val_accuracy: 0.8801 - val_auc: 0.9445\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4395 - accuracy: 0.9174 - auc: 0.8749 - val_loss: 0.3330 - val_accuracy: 0.9065 - val_auc: 0.9475\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4577 - accuracy: 0.9188 - auc: 0.8830 - val_loss: 0.3616 - val_accuracy: 0.8754 - val_auc: 0.9459\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4455 - accuracy: 0.9184 - auc: 0.8723 - val_loss: 0.3296 - val_accuracy: 0.9176 - val_auc: 0.9436\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4401 - accuracy: 0.9148 - auc: 0.8781 - val_loss: 0.3287 - val_accuracy: 0.9035 - val_auc: 0.9482\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6214 - accuracy: 0.9100 - auc: 0.8579 - val_loss: 0.5414 - val_accuracy: 0.9597 - val_auc: 0.8949\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5235 - accuracy: 0.9307 - auc: 0.8162 - val_loss: 0.3977 - val_accuracy: 0.9012 - val_auc: 0.9431\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4564 - accuracy: 0.9066 - auc: 0.8362 - val_loss: 0.3564 - val_accuracy: 0.8682 - val_auc: 0.9473\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4452 - accuracy: 0.8027 - auc: 0.8526 - val_loss: 0.3475 - val_accuracy: 0.8960 - val_auc: 0.9465\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4722 - accuracy: 0.8860 - auc: 0.8486 - val_loss: 0.3562 - val_accuracy: 0.8392 - val_auc: 0.9473\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4518 - accuracy: 0.8003 - auc: 0.8541 - val_loss: 0.3063 - val_accuracy: 0.9133 - val_auc: 0.9513\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4121 - accuracy: 0.9352 - auc: 0.8856 - val_loss: 0.3350 - val_accuracy: 0.9062 - val_auc: 0.9486\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4043 - accuracy: 0.9275 - auc: 0.8759 - val_loss: 0.3330 - val_accuracy: 0.8940 - val_auc: 0.9500\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4641 - accuracy: 0.8174 - auc: 0.8630 - val_loss: 0.4734 - val_accuracy: 0.9346 - val_auc: 0.9440\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4233 - accuracy: 0.8942 - auc: 0.8814 - val_loss: 0.5482 - val_accuracy: 0.9231 - val_auc: 0.9444\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4853 - accuracy: 0.9251 - auc: 0.8661 - val_loss: 0.5276 - val_accuracy: 0.9420 - val_auc: 0.8907\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5105 - accuracy: 0.5137 - auc: 0.7743 - val_loss: 0.5405 - val_accuracy: 0.6878 - val_auc: 0.8755\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5079 - accuracy: 0.4658 - auc: 0.7631 - val_loss: 0.4550 - val_accuracy: 0.6930 - val_auc: 0.8862\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4652 - accuracy: 0.4842 - auc: 0.7940 - val_loss: 0.4710 - val_accuracy: 0.7214 - val_auc: 0.8908\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4716 - accuracy: 0.4969 - auc: 0.7951 - val_loss: 0.4175 - val_accuracy: 0.6889 - val_auc: 0.8960\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5633 - accuracy: 0.4687 - auc: 0.7691 - val_loss: 0.6834 - val_accuracy: 0.6970 - val_auc: 0.8850\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5021 - accuracy: 0.4670 - auc: 0.7868 - val_loss: 0.6568 - val_accuracy: 0.7032 - val_auc: 0.8838\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4920 - accuracy: 0.4611 - auc: 0.8057 - val_loss: 0.5993 - val_accuracy: 0.7029 - val_auc: 0.8880\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4657 - accuracy: 0.4730 - auc: 0.8079 - val_loss: 0.6229 - val_accuracy: 0.6986 - val_auc: 0.8876\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4539 - accuracy: 0.4784 - auc: 0.8218 - val_loss: 0.5469 - val_accuracy: 0.7160 - val_auc: 0.9403\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4448 - accuracy: 0.6622 - auc: 0.8547 - val_loss: 0.4931 - val_accuracy: 0.6945 - val_auc: 0.9435\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5042 - accuracy: 0.5249 - auc: 0.8132 - val_loss: 0.5138 - val_accuracy: 0.7176 - val_auc: 0.8919\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4651 - accuracy: 0.4948 - auc: 0.7916 - val_loss: 0.5449 - val_accuracy: 0.7286 - val_auc: 0.9145\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4356 - accuracy: 0.5694 - auc: 0.8365 - val_loss: 0.4118 - val_accuracy: 0.7394 - val_auc: 0.9451\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4637 - accuracy: 0.5063 - auc: 0.8351 - val_loss: 0.5795 - val_accuracy: 0.7335 - val_auc: 0.8621\n",
      "Epoch 33/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.4962 - accuracy: 0.5094 - auc: 0.7599Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4964 - accuracy: 0.5094 - auc: 0.7599 - val_loss: 0.4914 - val_accuracy: 0.6980 - val_auc: 0.8675\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 19us/sample - loss: 0.5431 - accuracy: 0.7267 - auc: 0.8216 - val_loss: 0.3808 - val_accuracy: 0.7860 - val_auc: 0.9442\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4819 - accuracy: 0.8814 - auc: 0.8652 - val_loss: 0.4147 - val_accuracy: 0.9193 - val_auc: 0.9365\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4734 - accuracy: 0.8735 - auc: 0.8722 - val_loss: 0.3795 - val_accuracy: 0.7627 - val_auc: 0.9423\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4908 - accuracy: 0.6764 - auc: 0.8653 - val_loss: 0.4759 - val_accuracy: 0.7590 - val_auc: 0.9395\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4804 - accuracy: 0.6560 - auc: 0.8704 - val_loss: 0.5014 - val_accuracy: 0.7401 - val_auc: 0.9411\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5973 - accuracy: 0.6618 - auc: 0.8452 - val_loss: 0.5456 - val_accuracy: 0.6501 - val_auc: 0.9267\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6785 - accuracy: 0.7315 - auc: 0.8262 - val_loss: 0.5447 - val_accuracy: 0.8845 - val_auc: 0.9314\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.7068 - accuracy: 0.6258 - auc: 0.7964 - val_loss: 0.7248 - val_accuracy: 0.6727 - val_auc: 0.8750\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5102 - accuracy: 0.5435 - auc: 0.8192 - val_loss: 0.4775 - val_accuracy: 0.6867 - val_auc: 0.9153\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4421 - accuracy: 0.5602 - auc: 0.8403 - val_loss: 0.4186 - val_accuracy: 0.7194 - val_auc: 0.9407\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5419 - accuracy: 0.5719 - auc: 0.8430 - val_loss: 0.3695 - val_accuracy: 0.7026 - val_auc: 0.9471\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4410 - accuracy: 0.5699 - auc: 0.8550 - val_loss: 0.3792 - val_accuracy: 0.7219 - val_auc: 0.9441\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4526 - accuracy: 0.5821 - auc: 0.8518 - val_loss: 0.4747 - val_accuracy: 0.7184 - val_auc: 0.8672\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4512 - accuracy: 0.5885 - auc: 0.8236 - val_loss: 0.4394 - val_accuracy: 0.7145 - val_auc: 0.8968\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4162 - accuracy: 0.6043 - auc: 0.8553 - val_loss: 0.4762 - val_accuracy: 0.7549 - val_auc: 0.9384\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4569 - accuracy: 0.6088 - auc: 0.8285 - val_loss: 0.5372 - val_accuracy: 0.7383 - val_auc: 0.8698\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4454 - accuracy: 0.6115 - auc: 0.8169 - val_loss: 0.4840 - val_accuracy: 0.7625 - val_auc: 0.8799\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4219 - accuracy: 0.6209 - auc: 0.8339 - val_loss: 0.4561 - val_accuracy: 0.7683 - val_auc: 0.9205\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3979 - accuracy: 0.6261 - auc: 0.8573 - val_loss: 0.4738 - val_accuracy: 0.7663 - val_auc: 0.9225\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3986 - accuracy: 0.6259 - auc: 0.8602 - val_loss: 0.3792 - val_accuracy: 0.7618 - val_auc: 0.9456\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3835 - accuracy: 0.6279 - auc: 0.8720 - val_loss: 0.3997 - val_accuracy: 0.7450 - val_auc: 0.9457\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4002 - accuracy: 0.6088 - auc: 0.8655 - val_loss: 0.5235 - val_accuracy: 0.7721 - val_auc: 0.9355\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4155 - accuracy: 0.6182 - auc: 0.8608 - val_loss: 0.4417 - val_accuracy: 0.7473 - val_auc: 0.9117\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3914 - accuracy: 0.6190 - auc: 0.8614 - val_loss: 0.5024 - val_accuracy: 0.7620 - val_auc: 0.9149\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3802 - accuracy: 0.6280 - auc: 0.8762 - val_loss: 0.4814 - val_accuracy: 0.7788 - val_auc: 0.9196\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3819 - accuracy: 0.6345 - auc: 0.8702 - val_loss: 0.5306 - val_accuracy: 0.7997 - val_auc: 0.9188\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3898 - accuracy: 0.6336 - auc: 0.8727 - val_loss: 0.4567 - val_accuracy: 0.7770 - val_auc: 0.9192\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4169 - accuracy: 0.6286 - auc: 0.8522 - val_loss: 0.5915 - val_accuracy: 0.7860 - val_auc: 0.8927\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4052 - accuracy: 0.6359 - auc: 0.8436 - val_loss: 0.5328 - val_accuracy: 0.7830 - val_auc: 0.9047\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3958 - accuracy: 0.6372 - auc: 0.8514 - val_loss: 0.5185 - val_accuracy: 0.7719 - val_auc: 0.9042\n",
      "Epoch 31/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.4017 - accuracy: 0.6326 - auc: 0.8579Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4015 - accuracy: 0.6325 - auc: 0.8584 - val_loss: 0.4928 - val_accuracy: 0.7675 - val_auc: 0.9085\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 14us/sample - loss: 0.6815 - accuracy: 0.8090 - auc: 0.7559 - val_loss: 0.3948 - val_accuracy: 0.8982 - val_auc: 0.9231\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5545 - accuracy: 0.8782 - auc: 0.8358 - val_loss: 0.3201 - val_accuracy: 0.8681 - val_auc: 0.9466\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4800 - accuracy: 0.8822 - auc: 0.8599 - val_loss: 0.3813 - val_accuracy: 0.8270 - val_auc: 0.9395\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5632 - accuracy: 0.6856 - auc: 0.8320 - val_loss: 0.3894 - val_accuracy: 0.9050 - val_auc: 0.9489\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4831 - accuracy: 0.8245 - auc: 0.8697 - val_loss: 0.3512 - val_accuracy: 0.8720 - val_auc: 0.9501\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4547 - accuracy: 0.8772 - auc: 0.8836 - val_loss: 0.3052 - val_accuracy: 0.9203 - val_auc: 0.9545\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4152 - accuracy: 0.9019 - auc: 0.8893 - val_loss: 0.3573 - val_accuracy: 0.8665 - val_auc: 0.9450\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3924 - accuracy: 0.9015 - auc: 0.8916 - val_loss: 0.3692 - val_accuracy: 0.9050 - val_auc: 0.9434\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3723 - accuracy: 0.8935 - auc: 0.8928 - val_loss: 0.3458 - val_accuracy: 0.8880 - val_auc: 0.9487\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3877 - accuracy: 0.9046 - auc: 0.8897 - val_loss: 0.4252 - val_accuracy: 0.8865 - val_auc: 0.9429\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3935 - accuracy: 0.8691 - auc: 0.8962 - val_loss: 0.3514 - val_accuracy: 0.8682 - val_auc: 0.9488\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3665 - accuracy: 0.9103 - auc: 0.9006 - val_loss: 0.3409 - val_accuracy: 0.8781 - val_auc: 0.9531\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4100 - accuracy: 0.8390 - auc: 0.8915 - val_loss: 0.5375 - val_accuracy: 0.9116 - val_auc: 0.9448\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4426 - accuracy: 0.5904 - auc: 0.8663 - val_loss: 0.4023 - val_accuracy: 0.7468 - val_auc: 0.9508\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4063 - accuracy: 0.5987 - auc: 0.8638 - val_loss: 0.3352 - val_accuracy: 0.7554 - val_auc: 0.9536\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4035 - accuracy: 0.6094 - auc: 0.8721 - val_loss: 0.3398 - val_accuracy: 0.7534 - val_auc: 0.9510\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3876 - accuracy: 0.6054 - auc: 0.8699 - val_loss: 0.4264 - val_accuracy: 0.7544 - val_auc: 0.9493\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3746 - accuracy: 0.6224 - auc: 0.8741 - val_loss: 0.4036 - val_accuracy: 0.7816 - val_auc: 0.9429\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4199 - accuracy: 0.6094 - auc: 0.8629 - val_loss: 0.5233 - val_accuracy: 0.7722 - val_auc: 0.9396\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4011 - accuracy: 0.6055 - auc: 0.8691 - val_loss: 0.4378 - val_accuracy: 0.7360 - val_auc: 0.9458\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4122 - accuracy: 0.5890 - auc: 0.8642 - val_loss: 0.4547 - val_accuracy: 0.7413 - val_auc: 0.9493\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3998 - accuracy: 0.5961 - auc: 0.8679 - val_loss: 0.4216 - val_accuracy: 0.7402 - val_auc: 0.9474\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3981 - accuracy: 0.5967 - auc: 0.8636 - val_loss: 0.5066 - val_accuracy: 0.7437 - val_auc: 0.9283\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4022 - accuracy: 0.5969 - auc: 0.8553 - val_loss: 0.5138 - val_accuracy: 0.7564 - val_auc: 0.9407\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3913 - accuracy: 0.6104 - auc: 0.8603 - val_loss: 0.5012 - val_accuracy: 0.7590 - val_auc: 0.9383\n",
      "Epoch 26/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.4014 - accuracy: 0.6143 - auc: 0.8734Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4015 - accuracy: 0.6142 - auc: 0.8734 - val_loss: 0.5473 - val_accuracy: 0.7627 - val_auc: 0.9414\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.8078 - accuracy: 0.7801 - auc: 0.7008 - val_loss: 0.4973 - val_accuracy: 0.9246 - val_auc: 0.8841\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6264 - accuracy: 0.7749 - auc: 0.7762 - val_loss: 0.5838 - val_accuracy: 0.9377 - val_auc: 0.9197\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6378 - accuracy: 0.6663 - auc: 0.8074 - val_loss: 0.3940 - val_accuracy: 0.6884 - val_auc: 0.9328\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4821 - accuracy: 0.5867 - auc: 0.8435 - val_loss: 0.3470 - val_accuracy: 0.7615 - val_auc: 0.9431\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4316 - accuracy: 0.6613 - auc: 0.8693 - val_loss: 0.3828 - val_accuracy: 0.7335 - val_auc: 0.9447\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5086 - accuracy: 0.6139 - auc: 0.8574 - val_loss: 0.4798 - val_accuracy: 0.7395 - val_auc: 0.8803\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5450 - accuracy: 0.6110 - auc: 0.8110 - val_loss: 0.4690 - val_accuracy: 0.7342 - val_auc: 0.8740\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4454 - accuracy: 0.6354 - auc: 0.8296 - val_loss: 0.4216 - val_accuracy: 0.7614 - val_auc: 0.8933\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4358 - accuracy: 0.6503 - auc: 0.8383 - val_loss: 0.4097 - val_accuracy: 0.7730 - val_auc: 0.9052\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4244 - accuracy: 0.6597 - auc: 0.8490 - val_loss: 0.4496 - val_accuracy: 0.7775 - val_auc: 0.9048\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4147 - accuracy: 0.6729 - auc: 0.8594 - val_loss: 0.4354 - val_accuracy: 0.7651 - val_auc: 0.9068\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4198 - accuracy: 0.6634 - auc: 0.8512 - val_loss: 0.4772 - val_accuracy: 0.7794 - val_auc: 0.9091\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3984 - accuracy: 0.6752 - auc: 0.8648 - val_loss: 0.4570 - val_accuracy: 0.7960 - val_auc: 0.9321\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3661 - accuracy: 0.6883 - auc: 0.8854 - val_loss: 0.4430 - val_accuracy: 0.7959 - val_auc: 0.9431\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3624 - accuracy: 0.6877 - auc: 0.8930 - val_loss: 0.4869 - val_accuracy: 0.8201 - val_auc: 0.9424\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4001 - accuracy: 0.6849 - auc: 0.8890 - val_loss: 0.3792 - val_accuracy: 0.7590 - val_auc: 0.9440\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3533 - accuracy: 0.6980 - auc: 0.8966 - val_loss: 0.5522 - val_accuracy: 0.7901 - val_auc: 0.9333\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3814 - accuracy: 0.6753 - auc: 0.8904 - val_loss: 0.4813 - val_accuracy: 0.7702 - val_auc: 0.9375\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3675 - accuracy: 0.6743 - auc: 0.8908 - val_loss: 0.5366 - val_accuracy: 0.8129 - val_auc: 0.9405\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3618 - accuracy: 0.6815 - auc: 0.8949 - val_loss: 0.4592 - val_accuracy: 0.7935 - val_auc: 0.9434\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3769 - accuracy: 0.6774 - auc: 0.8863 - val_loss: 0.5234 - val_accuracy: 0.7936 - val_auc: 0.9286\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3710 - accuracy: 0.6875 - auc: 0.8888 - val_loss: 0.4227 - val_accuracy: 0.7762 - val_auc: 0.9395\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3578 - accuracy: 0.6850 - auc: 0.8972 - val_loss: 0.4771 - val_accuracy: 0.8199 - val_auc: 0.9389\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3616 - accuracy: 0.6853 - auc: 0.8958 - val_loss: 0.4714 - val_accuracy: 0.8053 - val_auc: 0.9422\n",
      "Epoch 25/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3677 - accuracy: 0.6899 - auc: 0.8948Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3712 - accuracy: 0.6893 - auc: 0.8937 - val_loss: 0.6639 - val_accuracy: 0.8086 - val_auc: 0.9055\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.7202 - accuracy: 0.7146 - auc: 0.7474 - val_loss: 0.7337 - val_accuracy: 0.5514 - val_auc: 0.8213\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5377 - accuracy: 0.6255 - auc: 0.8117 - val_loss: 0.4891 - val_accuracy: 0.6735 - val_auc: 0.9335\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6473 - accuracy: 0.7049 - auc: 0.8066 - val_loss: 0.4874 - val_accuracy: 0.7540 - val_auc: 0.9346\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4915 - accuracy: 0.5963 - auc: 0.8570 - val_loss: 0.3862 - val_accuracy: 0.6970 - val_auc: 0.9413\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4562 - accuracy: 0.6240 - auc: 0.8646 - val_loss: 0.3678 - val_accuracy: 0.6986 - val_auc: 0.9396\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4303 - accuracy: 0.6286 - auc: 0.8711 - val_loss: 0.5250 - val_accuracy: 0.7731 - val_auc: 0.9417\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4383 - accuracy: 0.6443 - auc: 0.8789 - val_loss: 0.4609 - val_accuracy: 0.7547 - val_auc: 0.9422\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3986 - accuracy: 0.6603 - auc: 0.8844 - val_loss: 0.4288 - val_accuracy: 0.7884 - val_auc: 0.9400\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3988 - accuracy: 0.6711 - auc: 0.8864 - val_loss: 0.4106 - val_accuracy: 0.7683 - val_auc: 0.9413\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3915 - accuracy: 0.6816 - auc: 0.8866 - val_loss: 0.4418 - val_accuracy: 0.8089 - val_auc: 0.9414\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3701 - accuracy: 0.6866 - auc: 0.8918 - val_loss: 0.5047 - val_accuracy: 0.8126 - val_auc: 0.9412\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3823 - accuracy: 0.6930 - auc: 0.8904 - val_loss: 0.5381 - val_accuracy: 0.7266 - val_auc: 0.7942\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4256 - accuracy: 0.6742 - auc: 0.8581 - val_loss: 0.5587 - val_accuracy: 0.7870 - val_auc: 0.9046\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3962 - accuracy: 0.6923 - auc: 0.8669 - val_loss: 0.4838 - val_accuracy: 0.7857 - val_auc: 0.9133\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3903 - accuracy: 0.6976 - auc: 0.8687 - val_loss: 0.4996 - val_accuracy: 0.7987 - val_auc: 0.9177\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3743 - accuracy: 0.7007 - auc: 0.8726 - val_loss: 0.5635 - val_accuracy: 0.8000 - val_auc: 0.9136\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4247 - accuracy: 0.6822 - auc: 0.8623 - val_loss: 0.5480 - val_accuracy: 0.7680 - val_auc: 0.8972\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5297 - accuracy: 0.6339 - auc: 0.8323 - val_loss: 1.5395 - val_accuracy: 0.7435 - val_auc: 0.8870\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4979 - accuracy: 0.6023 - auc: 0.8258 - val_loss: 1.2848 - val_accuracy: 0.7336 - val_auc: 0.9041\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4132 - accuracy: 0.6302 - auc: 0.8585 - val_loss: 1.0328 - val_accuracy: 0.7550 - val_auc: 0.9150\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3963 - accuracy: 0.6459 - auc: 0.8744 - val_loss: 0.8169 - val_accuracy: 0.7604 - val_auc: 0.9322\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3894 - accuracy: 0.6539 - auc: 0.8765 - val_loss: 0.9150 - val_accuracy: 0.7652 - val_auc: 0.8822\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3998 - accuracy: 0.6600 - auc: 0.8573 - val_loss: 0.8783 - val_accuracy: 0.7945 - val_auc: 0.9035\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4120 - accuracy: 0.6630 - auc: 0.8558 - val_loss: 0.7274 - val_accuracy: 0.7845 - val_auc: 0.9074\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4155 - accuracy: 0.6670 - auc: 0.8574 - val_loss: 0.9858 - val_accuracy: 0.7746 - val_auc: 0.8968\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4015 - accuracy: 0.6598 - auc: 0.8554 - val_loss: 0.6447 - val_accuracy: 0.7601 - val_auc: 0.9042\n",
      "Epoch 27/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3808 - accuracy: 0.6696 - auc: 0.8602Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3809 - accuracy: 0.6697 - auc: 0.8610 - val_loss: 0.9593 - val_accuracy: 0.7695 - val_auc: 0.9027\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7226 - accuracy: 0.8226 - auc: 0.7996 - val_loss: 0.4448 - val_accuracy: 0.8790 - val_auc: 0.9386\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5897 - accuracy: 0.8769 - auc: 0.8663 - val_loss: 0.3962 - val_accuracy: 0.9034 - val_auc: 0.9428\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4903 - accuracy: 0.8808 - auc: 0.8896 - val_loss: 0.3817 - val_accuracy: 0.9407 - val_auc: 0.9422\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4939 - accuracy: 0.8834 - auc: 0.8902 - val_loss: 0.4038 - val_accuracy: 0.8708 - val_auc: 0.9400\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6844 - accuracy: 0.8803 - auc: 0.8665 - val_loss: 0.4599 - val_accuracy: 0.9205 - val_auc: 0.9401\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6024 - accuracy: 0.9081 - auc: 0.8702 - val_loss: 0.6160 - val_accuracy: 0.9212 - val_auc: 0.9300\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5832 - accuracy: 0.5880 - auc: 0.8373 - val_loss: 0.5698 - val_accuracy: 0.5480 - val_auc: 0.8685\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6592 - accuracy: 0.5950 - auc: 0.8000 - val_loss: 0.5290 - val_accuracy: 0.6670 - val_auc: 0.8745\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4977 - accuracy: 0.5583 - auc: 0.8427 - val_loss: 0.4967 - val_accuracy: 0.6898 - val_auc: 0.9024\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5042 - accuracy: 0.5379 - auc: 0.8376 - val_loss: 0.4953 - val_accuracy: 0.6916 - val_auc: 0.8882\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5021 - accuracy: 0.5416 - auc: 0.8339 - val_loss: 0.4018 - val_accuracy: 0.7055 - val_auc: 0.9161\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4381 - accuracy: 0.5558 - auc: 0.8423 - val_loss: 0.4441 - val_accuracy: 0.7070 - val_auc: 0.9167\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4531 - accuracy: 0.5642 - auc: 0.8548 - val_loss: 0.3921 - val_accuracy: 0.7059 - val_auc: 0.9161\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4264 - accuracy: 0.5628 - auc: 0.8483 - val_loss: 0.3872 - val_accuracy: 0.7032 - val_auc: 0.9156\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3974 - accuracy: 0.5731 - auc: 0.8671 - val_loss: 0.3991 - val_accuracy: 0.7216 - val_auc: 0.9496\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3843 - accuracy: 0.7277 - auc: 0.8965 - val_loss: 0.4460 - val_accuracy: 0.7253 - val_auc: 0.9390\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3751 - accuracy: 0.7102 - auc: 0.8957 - val_loss: 0.4510 - val_accuracy: 0.7197 - val_auc: 0.9448\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3611 - accuracy: 0.6326 - auc: 0.8948 - val_loss: 0.4485 - val_accuracy: 0.7435 - val_auc: 0.9468\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4119 - accuracy: 0.5958 - auc: 0.8761 - val_loss: 0.4917 - val_accuracy: 0.7123 - val_auc: 0.9144\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3970 - accuracy: 0.5952 - auc: 0.8794 - val_loss: 0.4839 - val_accuracy: 0.7346 - val_auc: 0.9128\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4272 - accuracy: 0.5845 - auc: 0.8705 - val_loss: 0.4958 - val_accuracy: 0.7493 - val_auc: 0.9361\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3882 - accuracy: 0.5924 - auc: 0.8931 - val_loss: 0.4450 - val_accuracy: 0.7472 - val_auc: 0.9424\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3801 - accuracy: 0.6341 - auc: 0.9016 - val_loss: 0.3478 - val_accuracy: 0.7373 - val_auc: 0.9432\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4249 - accuracy: 0.6364 - auc: 0.8762 - val_loss: 0.5105 - val_accuracy: 0.7380 - val_auc: 0.9170\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4151 - accuracy: 0.6007 - auc: 0.8718 - val_loss: 0.6154 - val_accuracy: 0.7415 - val_auc: 0.8247\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4218 - accuracy: 0.6036 - auc: 0.8561 - val_loss: 0.4947 - val_accuracy: 0.7377 - val_auc: 0.9128\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4703 - accuracy: 0.5792 - auc: 0.8375 - val_loss: 0.7382 - val_accuracy: 0.7337 - val_auc: 0.9079\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4457 - accuracy: 0.5661 - auc: 0.8503 - val_loss: 0.8030 - val_accuracy: 0.7209 - val_auc: 0.9119\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4144 - accuracy: 0.5793 - auc: 0.8633 - val_loss: 0.7538 - val_accuracy: 0.7142 - val_auc: 0.9055\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4020 - accuracy: 0.5789 - auc: 0.8555 - val_loss: 0.7795 - val_accuracy: 0.7329 - val_auc: 0.9133\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4003 - accuracy: 0.5872 - auc: 0.8696 - val_loss: 0.7836 - val_accuracy: 0.7347 - val_auc: 0.9137\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4052 - accuracy: 0.5927 - auc: 0.8718 - val_loss: 0.7624 - val_accuracy: 0.7476 - val_auc: 0.9109\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4148 - accuracy: 0.5993 - auc: 0.8570 - val_loss: 0.7329 - val_accuracy: 0.7426 - val_auc: 0.9092\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4063 - accuracy: 0.6017 - auc: 0.8836 - val_loss: 0.6217 - val_accuracy: 0.7450 - val_auc: 0.9355\n",
      "Epoch 35/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.6712 - auc: 0.8910Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3907 - accuracy: 0.6711 - auc: 0.8913 - val_loss: 0.6590 - val_accuracy: 0.7484 - val_auc: 0.9269\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7573 - accuracy: 0.7375 - auc: 0.8240 - val_loss: 0.3610 - val_accuracy: 0.9323 - val_auc: 0.9318\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5340 - accuracy: 0.8723 - auc: 0.8765 - val_loss: 0.3400 - val_accuracy: 0.8357 - val_auc: 0.9511\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5418 - accuracy: 0.8743 - auc: 0.8894 - val_loss: 0.4578 - val_accuracy: 0.7550 - val_auc: 0.9294\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4929 - accuracy: 0.7606 - auc: 0.8954 - val_loss: 0.3856 - val_accuracy: 0.8447 - val_auc: 0.9469\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4681 - accuracy: 0.7025 - auc: 0.8997 - val_loss: 0.3827 - val_accuracy: 0.8648 - val_auc: 0.9357\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5486 - accuracy: 0.7258 - auc: 0.8879 - val_loss: 0.4292 - val_accuracy: 0.7918 - val_auc: 0.9345\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4579 - accuracy: 0.7492 - auc: 0.9145 - val_loss: 0.5100 - val_accuracy: 0.8739 - val_auc: 0.9330\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6749 - accuracy: 0.7971 - auc: 0.8889 - val_loss: 0.5576 - val_accuracy: 0.7686 - val_auc: 0.9246\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5229 - accuracy: 0.6791 - auc: 0.8915 - val_loss: 0.9842 - val_accuracy: 0.7304 - val_auc: 0.9258\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.7190 - accuracy: 0.6442 - auc: 0.8707 - val_loss: 1.1342 - val_accuracy: 0.7692 - val_auc: 0.9301\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6245 - accuracy: 0.6500 - auc: 0.8832 - val_loss: 1.0511 - val_accuracy: 0.6981 - val_auc: 0.9058\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5493 - accuracy: 0.6293 - auc: 0.8461 - val_loss: 2.1336 - val_accuracy: 0.7392 - val_auc: 0.8896\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.8021 - accuracy: 0.6229 - auc: 0.8362 - val_loss: 1.8525 - val_accuracy: 0.7141 - val_auc: 0.8489\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5954 - accuracy: 0.6321 - auc: 0.8095 - val_loss: 1.2930 - val_accuracy: 0.7059 - val_auc: 0.8459\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.7245 - accuracy: 0.6219 - auc: 0.8101 - val_loss: 0.8840 - val_accuracy: 0.6983 - val_auc: 0.8637\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4856 - accuracy: 0.6469 - auc: 0.8388 - val_loss: 1.4930 - val_accuracy: 0.7283 - val_auc: 0.8973\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4071 - accuracy: 0.6705 - auc: 0.8702 - val_loss: 1.3512 - val_accuracy: 0.7451 - val_auc: 0.9094\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4203 - accuracy: 0.6701 - auc: 0.8758 - val_loss: 1.4519 - val_accuracy: 0.7581 - val_auc: 0.9126\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3869 - accuracy: 0.6826 - auc: 0.8819 - val_loss: 1.1930 - val_accuracy: 0.7548 - val_auc: 0.9153\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3690 - accuracy: 0.6824 - auc: 0.8856 - val_loss: 1.1239 - val_accuracy: 0.7622 - val_auc: 0.9232\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3348 - accuracy: 0.6939 - auc: 0.9081 - val_loss: 1.0656 - val_accuracy: 0.7781 - val_auc: 0.9369\n",
      "Epoch 22/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3336 - accuracy: 0.7039 - auc: 0.9134Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3333 - accuracy: 0.7039 - auc: 0.9133 - val_loss: 0.9988 - val_accuracy: 0.7770 - val_auc: 0.9344\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 18us/sample - loss: 0.7119 - accuracy: 0.6833 - auc: 0.7836 - val_loss: 0.4433 - val_accuracy: 0.8073 - val_auc: 0.9045\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6211 - accuracy: 0.7830 - auc: 0.8708 - val_loss: 0.5553 - val_accuracy: 0.7786 - val_auc: 0.9263\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6552 - accuracy: 0.7115 - auc: 0.8515 - val_loss: 0.5339 - val_accuracy: 0.6311 - val_auc: 0.9284\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.8183 - accuracy: 0.6615 - auc: 0.8287 - val_loss: 0.5572 - val_accuracy: 0.6023 - val_auc: 0.8898\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6415 - accuracy: 0.6002 - auc: 0.8245 - val_loss: 1.0389 - val_accuracy: 0.7619 - val_auc: 0.9105\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.8357 - accuracy: 0.6244 - auc: 0.8327 - val_loss: 0.8172 - val_accuracy: 0.7235 - val_auc: 0.9097\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.8166 - accuracy: 0.6201 - auc: 0.8157 - val_loss: 1.0619 - val_accuracy: 0.6824 - val_auc: 0.8509\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5886 - accuracy: 0.6208 - auc: 0.8138 - val_loss: 0.9990 - val_accuracy: 0.7349 - val_auc: 0.8623\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5959 - accuracy: 0.6641 - auc: 0.8338 - val_loss: 0.7432 - val_accuracy: 0.7133 - val_auc: 0.8410\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5118 - accuracy: 0.6474 - auc: 0.8187 - val_loss: 0.8036 - val_accuracy: 0.7354 - val_auc: 0.8604\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.0066 - accuracy: 0.6289 - auc: 0.7984 - val_loss: 0.7447 - val_accuracy: 0.6938 - val_auc: 0.8204\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.4084 - accuracy: 0.6111 - auc: 0.7776 - val_loss: 2.0919 - val_accuracy: 0.7286 - val_auc: 0.8426\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5522 - accuracy: 0.6197 - auc: 0.8049 - val_loss: 2.5424 - val_accuracy: 0.6919 - val_auc: 0.8365\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5329 - accuracy: 0.6075 - auc: 0.8032 - val_loss: 1.6465 - val_accuracy: 0.7029 - val_auc: 0.8489\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5038 - accuracy: 0.6142 - auc: 0.8111 - val_loss: 1.3911 - val_accuracy: 0.7093 - val_auc: 0.8540\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.7084 - accuracy: 0.6247 - auc: 0.7991 - val_loss: 1.4830 - val_accuracy: 0.7051 - val_auc: 0.8544\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6075 - accuracy: 0.6281 - auc: 0.8102 - val_loss: 2.5886 - val_accuracy: 0.7274 - val_auc: 0.8584\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5210 - accuracy: 0.6420 - auc: 0.8188 - val_loss: 2.8137 - val_accuracy: 0.7097 - val_auc: 0.8564\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5868 - accuracy: 0.6458 - auc: 0.8221 - val_loss: 2.4042 - val_accuracy: 0.6941 - val_auc: 0.8531\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5210 - accuracy: 0.6129 - auc: 0.8201 - val_loss: 2.0420 - val_accuracy: 0.7061 - val_auc: 0.8768\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4744 - accuracy: 0.6229 - auc: 0.8279 - val_loss: 2.1182 - val_accuracy: 0.7284 - val_auc: 0.8897\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4499 - accuracy: 0.6288 - auc: 0.8344 - val_loss: 2.0780 - val_accuracy: 0.7261 - val_auc: 0.8927\n",
      "Epoch 23/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.6396 - auc: 0.8479Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3999 - accuracy: 0.6396 - auc: 0.8479 - val_loss: 1.9683 - val_accuracy: 0.7403 - val_auc: 0.9002\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.6517 - accuracy: 0.8135 - auc: 0.8111 - val_loss: 0.4137 - val_accuracy: 0.8925 - val_auc: 0.9193\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5581 - accuracy: 0.8725 - auc: 0.8758 - val_loss: 0.3183 - val_accuracy: 0.8909 - val_auc: 0.9435\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6978 - accuracy: 0.8510 - auc: 0.8534 - val_loss: 0.4065 - val_accuracy: 0.8830 - val_auc: 0.9324\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6158 - accuracy: 0.8735 - auc: 0.8680 - val_loss: 0.3855 - val_accuracy: 0.9268 - val_auc: 0.9384\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6843 - accuracy: 0.8804 - auc: 0.8704 - val_loss: 0.4817 - val_accuracy: 0.9327 - val_auc: 0.9316\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6126 - accuracy: 0.7184 - auc: 0.8572 - val_loss: 0.6692 - val_accuracy: 0.6045 - val_auc: 0.8996\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6637 - accuracy: 0.6851 - auc: 0.8572 - val_loss: 0.5292 - val_accuracy: 0.6766 - val_auc: 0.9152\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6625 - accuracy: 0.6940 - auc: 0.8596 - val_loss: 0.5248 - val_accuracy: 0.7190 - val_auc: 0.9349\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5044 - accuracy: 0.5798 - auc: 0.8684 - val_loss: 0.4476 - val_accuracy: 0.6860 - val_auc: 0.9280\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3978 - accuracy: 0.6272 - auc: 0.8887 - val_loss: 0.5559 - val_accuracy: 0.7261 - val_auc: 0.9413\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3571 - accuracy: 0.6453 - auc: 0.9128 - val_loss: 0.5446 - val_accuracy: 0.9365 - val_auc: 0.9447\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3396 - accuracy: 0.8335 - auc: 0.9154 - val_loss: 0.5694 - val_accuracy: 0.9220 - val_auc: 0.9448\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3391 - accuracy: 0.7551 - auc: 0.9193 - val_loss: 0.4988 - val_accuracy: 0.7709 - val_auc: 0.9479\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3577 - accuracy: 0.7619 - auc: 0.9204 - val_loss: 0.4838 - val_accuracy: 0.9353 - val_auc: 0.9505\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3554 - accuracy: 0.8162 - auc: 0.9214 - val_loss: 0.4750 - val_accuracy: 0.9112 - val_auc: 0.9491\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3700 - accuracy: 0.8573 - auc: 0.9165 - val_loss: 0.4847 - val_accuracy: 0.9279 - val_auc: 0.9483\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3548 - accuracy: 0.7053 - auc: 0.9030 - val_loss: 0.5009 - val_accuracy: 0.7601 - val_auc: 0.9471\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3351 - accuracy: 0.6474 - auc: 0.9129 - val_loss: 0.5355 - val_accuracy: 0.7755 - val_auc: 0.9415\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3338 - accuracy: 0.7179 - auc: 0.9145 - val_loss: 0.6120 - val_accuracy: 0.7777 - val_auc: 0.9360\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3782 - accuracy: 0.6548 - auc: 0.8836 - val_loss: 0.6229 - val_accuracy: 0.7653 - val_auc: 0.9360\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4960 - accuracy: 0.6469 - auc: 0.8484 - val_loss: 0.6354 - val_accuracy: 0.7457 - val_auc: 0.8702\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3964 - accuracy: 0.6493 - auc: 0.8486 - val_loss: 0.5650 - val_accuracy: 0.7601 - val_auc: 0.9028\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3853 - accuracy: 0.6593 - auc: 0.8495 - val_loss: 0.5718 - val_accuracy: 0.7707 - val_auc: 0.9075\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4000 - accuracy: 0.6613 - auc: 0.8603 - val_loss: 0.5727 - val_accuracy: 0.7705 - val_auc: 0.9037\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.7811 - accuracy: 0.6296 - auc: 0.8303 - val_loss: 1.8436 - val_accuracy: 0.7466 - val_auc: 0.8891\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6791 - accuracy: 0.5888 - auc: 0.7971 - val_loss: 1.7712 - val_accuracy: 0.5644 - val_auc: 0.7488\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5502 - accuracy: 0.5634 - auc: 0.8069 - val_loss: 2.0722 - val_accuracy: 0.6837 - val_auc: 0.8707\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4480 - accuracy: 0.5631 - auc: 0.8230 - val_loss: 1.8725 - val_accuracy: 0.6739 - val_auc: 0.8753\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4107 - accuracy: 0.5656 - auc: 0.8559 - val_loss: 1.7298 - val_accuracy: 0.6928 - val_auc: 0.9176\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4214 - accuracy: 0.5721 - auc: 0.8706 - val_loss: 1.7954 - val_accuracy: 0.6869 - val_auc: 0.9275\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3935 - accuracy: 0.5722 - auc: 0.8760 - val_loss: 1.5740 - val_accuracy: 0.6899 - val_auc: 0.9404\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5564 - accuracy: 0.5718 - auc: 0.8844 - val_loss: 1.2569 - val_accuracy: 0.6898 - val_auc: 0.9376\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4156 - accuracy: 0.5763 - auc: 0.8560 - val_loss: 1.1589 - val_accuracy: 0.6897 - val_auc: 0.8788\n",
      "Epoch 34/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.4137 - accuracy: 0.5823 - auc: 0.8478Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4134 - accuracy: 0.5823 - auc: 0.8478 - val_loss: 1.0972 - val_accuracy: 0.6985 - val_auc: 0.8841\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.8708 - accuracy: 0.8208 - auc: 0.7969 - val_loss: 0.4431 - val_accuracy: 0.9129 - val_auc: 0.9217\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6363 - accuracy: 0.8124 - auc: 0.8399 - val_loss: 0.7758 - val_accuracy: 0.8696 - val_auc: 0.9271\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.7859 - accuracy: 0.8289 - auc: 0.8364 - val_loss: 0.5989 - val_accuracy: 0.8558 - val_auc: 0.9217\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.7200 - accuracy: 0.7238 - auc: 0.8391 - val_loss: 0.5287 - val_accuracy: 0.7134 - val_auc: 0.9351\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.8724 - accuracy: 0.8240 - auc: 0.8288 - val_loss: 1.3022 - val_accuracy: 0.9011 - val_auc: 0.9363\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.9204 - accuracy: 0.6160 - auc: 0.8594 - val_loss: 0.7314 - val_accuracy: 0.9471 - val_auc: 0.9215\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.7137 - accuracy: 0.6115 - auc: 0.8089 - val_loss: 0.6309 - val_accuracy: 0.7018 - val_auc: 0.8989\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5065 - accuracy: 0.6074 - auc: 0.8489 - val_loss: 0.5996 - val_accuracy: 0.7223 - val_auc: 0.9418\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6838 - accuracy: 0.6077 - auc: 0.8179 - val_loss: 0.8206 - val_accuracy: 0.7589 - val_auc: 0.8767\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6481 - accuracy: 0.6009 - auc: 0.8125 - val_loss: 0.7734 - val_accuracy: 0.7259 - val_auc: 0.8978\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.0223 - accuracy: 0.5691 - auc: 0.7917 - val_loss: 1.3340 - val_accuracy: 0.7200 - val_auc: 0.8697\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5350 - accuracy: 0.5700 - auc: 0.7999 - val_loss: 1.3872 - val_accuracy: 0.7078 - val_auc: 0.8787\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4985 - accuracy: 0.5704 - auc: 0.8149 - val_loss: 1.2655 - val_accuracy: 0.7208 - val_auc: 0.8862\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4753 - accuracy: 0.5833 - auc: 0.8116 - val_loss: 1.0824 - val_accuracy: 0.7040 - val_auc: 0.8851\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5905 - accuracy: 0.5531 - auc: 0.7912 - val_loss: 0.9333 - val_accuracy: 0.7053 - val_auc: 0.8877\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4246 - accuracy: 0.5884 - auc: 0.8328 - val_loss: 0.8796 - val_accuracy: 0.7200 - val_auc: 0.8925\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4166 - accuracy: 0.6069 - auc: 0.8371 - val_loss: 0.8327 - val_accuracy: 0.7248 - val_auc: 0.8944\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4057 - accuracy: 0.6220 - auc: 0.8392 - val_loss: 0.8060 - val_accuracy: 0.7552 - val_auc: 0.8992\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4103 - accuracy: 0.6381 - auc: 0.8454 - val_loss: 0.7608 - val_accuracy: 0.7582 - val_auc: 0.9007\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4049 - accuracy: 0.6413 - auc: 0.8491 - val_loss: 0.6890 - val_accuracy: 0.7593 - val_auc: 0.8990\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3888 - accuracy: 0.6507 - auc: 0.8570 - val_loss: 0.6928 - val_accuracy: 0.7675 - val_auc: 0.9052\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3831 - accuracy: 0.6600 - auc: 0.8657 - val_loss: 0.6631 - val_accuracy: 0.7715 - val_auc: 0.9041\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3873 - accuracy: 0.6600 - auc: 0.8613 - val_loss: 0.6521 - val_accuracy: 0.7633 - val_auc: 0.9034\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3752 - accuracy: 0.6682 - auc: 0.8726 - val_loss: 0.6694 - val_accuracy: 0.7873 - val_auc: 0.9176\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3766 - accuracy: 0.6717 - auc: 0.8729 - val_loss: 0.6117 - val_accuracy: 0.7822 - val_auc: 0.9189\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3596 - accuracy: 0.6834 - auc: 0.8833 - val_loss: 0.6570 - val_accuracy: 0.7944 - val_auc: 0.9190\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3596 - accuracy: 0.6860 - auc: 0.8779 - val_loss: 0.7097 - val_accuracy: 0.7929 - val_auc: 0.9195\n",
      "Epoch 28/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.3589 - accuracy: 0.6882 - auc: 0.8807Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3590 - accuracy: 0.6882 - auc: 0.8806 - val_loss: 0.6339 - val_accuracy: 0.7962 - val_auc: 0.9161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 1.0347 - accuracy: 0.7628 - auc: 0.8257 - val_loss: 0.4983 - val_accuracy: 0.8869 - val_auc: 0.9319\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.7423 - accuracy: 0.8576 - auc: 0.8743 - val_loss: 0.5000 - val_accuracy: 0.9030 - val_auc: 0.9223\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.8468 - accuracy: 0.8357 - auc: 0.8632 - val_loss: 0.7582 - val_accuracy: 0.9020 - val_auc: 0.9052\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.9296 - accuracy: 0.8495 - auc: 0.8748 - val_loss: 0.7029 - val_accuracy: 0.8620 - val_auc: 0.9128\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.1886 - accuracy: 0.8403 - auc: 0.8465 - val_loss: 0.6554 - val_accuracy: 0.8605 - val_auc: 0.9165\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.4288 - accuracy: 0.8515 - auc: 0.8472 - val_loss: 0.9325 - val_accuracy: 0.9268 - val_auc: 0.9242\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.1001 - accuracy: 0.6377 - auc: 0.8416 - val_loss: 0.9736 - val_accuracy: 0.9158 - val_auc: 0.9334\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.6845 - accuracy: 0.6945 - auc: 0.8283 - val_loss: 1.0098 - val_accuracy: 0.6875 - val_auc: 0.8613\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.8703 - accuracy: 0.5669 - auc: 0.8286 - val_loss: 1.3360 - val_accuracy: 0.6620 - val_auc: 0.9118\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.6715 - accuracy: 0.5849 - auc: 0.8292 - val_loss: 1.4648 - val_accuracy: 0.9015 - val_auc: 0.8972\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.1913 - accuracy: 0.7207 - auc: 0.8615 - val_loss: 1.3022 - val_accuracy: 0.6905 - val_auc: 0.9325\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4270 - accuracy: 0.6023 - auc: 0.8848 - val_loss: 1.0612 - val_accuracy: 0.7003 - val_auc: 0.9385\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4718 - accuracy: 0.6145 - auc: 0.8828 - val_loss: 1.2932 - val_accuracy: 0.6957 - val_auc: 0.9136\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.0171 - accuracy: 0.6991 - auc: 0.8657 - val_loss: 1.5917 - val_accuracy: 0.7040 - val_auc: 0.9432oss: 1.0273 - accuracy: 0.6603 - auc\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.0024 - accuracy: 0.6510 - auc: 0.8508 - val_loss: 2.2682 - val_accuracy: 0.6982 - val_auc: 0.9032\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5333 - accuracy: 0.5802 - auc: 0.8724 - val_loss: 2.3712 - val_accuracy: 0.7133 - val_auc: 0.9043\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.0906 - accuracy: 0.6420 - auc: 0.8615 - val_loss: 1.5967 - val_accuracy: 0.6974 - val_auc: 0.9316\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5651 - accuracy: 0.5849 - auc: 0.8627 - val_loss: 1.5560 - val_accuracy: 0.6945 - val_auc: 0.9238\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4979 - accuracy: 0.5825 - auc: 0.8608 - val_loss: 1.3240 - val_accuracy: 0.6976 - val_auc: 0.9212\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4258 - accuracy: 0.5918 - auc: 0.8662 - val_loss: 1.3319 - val_accuracy: 0.7054 - val_auc: 0.9260\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3914 - accuracy: 0.6010 - auc: 0.8843 - val_loss: 1.4589 - val_accuracy: 0.7176 - val_auc: 0.9275\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4184 - accuracy: 0.6028 - auc: 0.8745 - val_loss: 1.5350 - val_accuracy: 0.7086 - val_auc: 0.8936\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4349 - accuracy: 0.6077 - auc: 0.8556 - val_loss: 1.4616 - val_accuracy: 0.7159 - val_auc: 0.8849\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4749 - accuracy: 0.6090 - auc: 0.8509 - val_loss: 1.5858 - val_accuracy: 0.7243 - val_auc: 0.8965\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4357 - accuracy: 0.6174 - auc: 0.8556 - val_loss: 1.4888 - val_accuracy: 0.7281 - val_auc: 0.9033\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4030 - accuracy: 0.6197 - auc: 0.8626 - val_loss: 1.4657 - val_accuracy: 0.7327 - val_auc: 0.9050\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3943 - accuracy: 0.6197 - auc: 0.8730 - val_loss: 1.2658 - val_accuracy: 0.7339 - val_auc: 0.9098\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3790 - accuracy: 0.6246 - auc: 0.8755 - val_loss: 1.2588 - val_accuracy: 0.7438 - val_auc: 0.9115\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3743 - accuracy: 0.6278 - auc: 0.8835 - val_loss: 1.2685 - val_accuracy: 0.7477 - val_auc: 0.9144\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3602 - accuracy: 0.6306 - auc: 0.8962 - val_loss: 1.2077 - val_accuracy: 0.7562 - val_auc: 0.9374\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3581 - accuracy: 0.6337 - auc: 0.9023 - val_loss: 1.1876 - val_accuracy: 0.7606 - val_auc: 0.9383\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3422 - accuracy: 0.6423 - auc: 0.9119 - val_loss: 1.2066 - val_accuracy: 0.7656 - val_auc: 0.9448\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3469 - accuracy: 0.6659 - auc: 0.9151 - val_loss: 1.1073 - val_accuracy: 0.7526 - val_auc: 0.9460\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3187 - accuracy: 0.6695 - auc: 0.9228 - val_loss: 1.1508 - val_accuracy: 0.7640 - val_auc: 0.9411\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3374 - accuracy: 0.7162 - auc: 0.9198 - val_loss: 1.1245 - val_accuracy: 0.7458 - val_auc: 0.9419\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3335 - accuracy: 0.7203 - auc: 0.9170 - val_loss: 1.1243 - val_accuracy: 0.7477 - val_auc: 0.9449\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3454 - accuracy: 0.6380 - auc: 0.9139 - val_loss: 1.0776 - val_accuracy: 0.7461 - val_auc: 0.9450\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3550 - accuracy: 0.6404 - auc: 0.9024 - val_loss: 1.1366 - val_accuracy: 0.7557 - val_auc: 0.9381\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3671 - accuracy: 0.6476 - auc: 0.8963 - val_loss: 1.0216 - val_accuracy: 0.7454 - val_auc: 0.9380\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3501 - accuracy: 0.6455 - auc: 0.8998 - val_loss: 1.1124 - val_accuracy: 0.7597 - val_auc: 0.9276\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3879 - accuracy: 0.6505 - auc: 0.8683 - val_loss: 1.1344 - val_accuracy: 0.7586 - val_auc: 0.8996\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3919 - accuracy: 0.6525 - auc: 0.8642 - val_loss: 1.1833 - val_accuracy: 0.7775 - val_auc: 0.9011\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3942 - accuracy: 0.6517 - auc: 0.8691 - val_loss: 1.1102 - val_accuracy: 0.7493 - val_auc: 0.9008\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3787 - accuracy: 0.6507 - auc: 0.8716 - val_loss: 1.2531 - val_accuracy: 0.7787 - val_auc: 0.9030\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3998 - accuracy: 0.6526 - auc: 0.8677 - val_loss: 0.9967 - val_accuracy: 0.7460 - val_auc: 0.8944\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3860 - accuracy: 0.6370 - auc: 0.8645 - val_loss: 1.0752 - val_accuracy: 0.7443 - val_auc: 0.8965\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3747 - accuracy: 0.6480 - auc: 0.8632 - val_loss: 1.1877 - val_accuracy: 0.7567 - val_auc: 0.9004\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3871 - accuracy: 0.6444 - auc: 0.8683 - val_loss: 1.1285 - val_accuracy: 0.7654 - val_auc: 0.9038\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3658 - accuracy: 0.6507 - auc: 0.8909 - val_loss: 0.8825 - val_accuracy: 0.7644 - val_auc: 0.9347\n",
      "Epoch 50/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3556 - accuracy: 0.6526 - auc: 0.8947 - val_loss: 1.0403 - val_accuracy: 0.7811 - val_auc: 0.9237\n",
      "Epoch 51/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3511 - accuracy: 0.6580 - auc: 0.8972 - val_loss: 0.9628 - val_accuracy: 0.7735 - val_auc: 0.9390\n",
      "Epoch 52/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3708 - accuracy: 0.6597 - auc: 0.8990 - val_loss: 0.8055 - val_accuracy: 0.7885 - val_auc: 0.9405\n",
      "Epoch 53/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.6624 - auc: 0.9000Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3506 - accuracy: 0.6624 - auc: 0.9002 - val_loss: 0.8480 - val_accuracy: 0.7829 - val_auc: 0.9074\n",
      "Epoch 00053: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 1.0158 - accuracy: 0.7728 - auc: 0.8280 - val_loss: 0.3815 - val_accuracy: 0.9012 - val_auc: 0.9287\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.9923 - accuracy: 0.8320 - auc: 0.8597 - val_loss: 0.5023 - val_accuracy: 0.8799 - val_auc: 0.9306\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.8682 - accuracy: 0.8611 - auc: 0.8750 - val_loss: 0.4573 - val_accuracy: 0.8654 - val_auc: 0.9384\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.9856 - accuracy: 0.8393 - auc: 0.8704 - val_loss: 0.8006 - val_accuracy: 0.9067 - val_auc: 0.9251\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.7981 - accuracy: 0.8674 - auc: 0.8801 - val_loss: 0.6224 - val_accuracy: 0.9083 - val_auc: 0.9403\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.8555 - accuracy: 0.8818 - auc: 0.8872 - val_loss: 1.0141 - val_accuracy: 0.8945 - val_auc: 0.9281\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5519 - accuracy: 0.8944 - auc: 0.9024 - val_loss: 0.6584 - val_accuracy: 0.9357 - val_auc: 0.9419\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5396 - accuracy: 0.9045 - auc: 0.9099 - val_loss: 0.5777 - val_accuracy: 0.9250 - val_auc: 0.9414\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5372 - accuracy: 0.9088 - auc: 0.9131 - val_loss: 0.6392 - val_accuracy: 0.9249 - val_auc: 0.9399\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6189 - accuracy: 0.8954 - auc: 0.8944 - val_loss: 1.1572 - val_accuracy: 0.9076 - val_auc: 0.9326\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.9987 - accuracy: 0.8911 - auc: 0.8793 - val_loss: 1.9486 - val_accuracy: 0.9185 - val_auc: 0.9365\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5221 - accuracy: 0.8796 - auc: 0.8908 - val_loss: 1.9381 - val_accuracy: 0.6483 - val_auc: 0.8704\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4536 - accuracy: 0.8703 - auc: 0.8795 - val_loss: 1.5702 - val_accuracy: 0.6690 - val_auc: 0.9376\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4409 - accuracy: 0.7755 - auc: 0.8896 - val_loss: 1.6390 - val_accuracy: 0.7029 - val_auc: 0.9327\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3949 - accuracy: 0.7137 - auc: 0.9007 - val_loss: 1.7108 - val_accuracy: 0.9053 - val_auc: 0.9300\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4288 - accuracy: 0.8313 - auc: 0.9044 - val_loss: 1.8445 - val_accuracy: 0.8918 - val_auc: 0.9284\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3791 - accuracy: 0.7980 - auc: 0.9148 - val_loss: 1.9403 - val_accuracy: 0.9010 - val_auc: 0.9311\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3629 - accuracy: 0.8147 - auc: 0.9171 - val_loss: 1.9532 - val_accuracy: 0.7723 - val_auc: 0.9332\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3832 - accuracy: 0.6326 - auc: 0.9051 - val_loss: 1.9390 - val_accuracy: 0.7616 - val_auc: 0.9336\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3702 - accuracy: 0.6349 - auc: 0.8958 - val_loss: 1.8248 - val_accuracy: 0.7549 - val_auc: 0.9375\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3622 - accuracy: 0.6329 - auc: 0.9066 - val_loss: 1.5953 - val_accuracy: 0.7631 - val_auc: 0.9413\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3745 - accuracy: 0.6328 - auc: 0.8986 - val_loss: 1.5588 - val_accuracy: 0.7618 - val_auc: 0.9389\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3591 - accuracy: 0.6445 - auc: 0.9127 - val_loss: 1.5837 - val_accuracy: 0.7951 - val_auc: 0.9371\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3897 - accuracy: 0.7140 - auc: 0.9055 - val_loss: 1.5620 - val_accuracy: 0.7718 - val_auc: 0.9328\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3507 - accuracy: 0.6531 - auc: 0.9030 - val_loss: 1.6093 - val_accuracy: 0.7769 - val_auc: 0.9326\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3561 - accuracy: 0.6509 - auc: 0.9060 - val_loss: 1.3904 - val_accuracy: 0.7823 - val_auc: 0.9196\n",
      "Epoch 27/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3365 - accuracy: 0.6649 - auc: 0.9079Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3362 - accuracy: 0.6649 - auc: 0.9081 - val_loss: 1.4211 - val_accuracy: 0.7912 - val_auc: 0.9383\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8233 - accuracy: 0.7927 - auc: 0.8276 - val_loss: 0.5252 - val_accuracy: 0.9177 - val_auc: 0.9158\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6810 - accuracy: 0.8559 - auc: 0.8690 - val_loss: 0.7641 - val_accuracy: 0.8284 - val_auc: 0.9200\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.8924 - accuracy: 0.8500 - auc: 0.8495 - val_loss: 0.7263 - val_accuracy: 0.8030 - val_auc: 0.9317\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 6us/sample - loss: 1.0412 - accuracy: 0.8571 - auc: 0.8526 - val_loss: 0.6646 - val_accuracy: 0.8963 - val_auc: 0.9252\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.7673 - accuracy: 0.8707 - auc: 0.8837 - val_loss: 0.5978 - val_accuracy: 0.9437 - val_auc: 0.9353\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.7168 - accuracy: 0.8857 - auc: 0.8951 - val_loss: 0.4600 - val_accuracy: 0.8968 - val_auc: 0.9448\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5747 - accuracy: 0.8915 - auc: 0.8944 - val_loss: 0.5643 - val_accuracy: 0.9282 - val_auc: 0.9416\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.7417 - accuracy: 0.8457 - auc: 0.8746 - val_loss: 0.4925 - val_accuracy: 0.6648 - val_auc: 0.9340\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.9026 - accuracy: 0.7504 - auc: 0.8468 - val_loss: 0.9000 - val_accuracy: 0.9048 - val_auc: 0.9124\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6275 - accuracy: 0.7033 - auc: 0.8652 - val_loss: 0.9253 - val_accuracy: 0.9068 - val_auc: 0.9212\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5872 - accuracy: 0.8521 - auc: 0.8833 - val_loss: 0.8051 - val_accuracy: 0.8953 - val_auc: 0.9215\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5111 - accuracy: 0.9174 - auc: 0.8953 - val_loss: 0.6783 - val_accuracy: 0.9019 - val_auc: 0.9379\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.7827 - accuracy: 0.9013 - auc: 0.8780 - val_loss: 0.6785 - val_accuracy: 0.9250 - val_auc: 0.9308\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.9400 - accuracy: 0.9004 - auc: 0.8661 - val_loss: 1.1407 - val_accuracy: 0.9222 - val_auc: 0.9302\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4546 - accuracy: 0.9100 - auc: 0.8976 - val_loss: 1.2103 - val_accuracy: 0.9124 - val_auc: 0.9342\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4442 - accuracy: 0.8133 - auc: 0.8905 - val_loss: 1.3164 - val_accuracy: 0.9008 - val_auc: 0.9389\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4115 - accuracy: 0.6580 - auc: 0.8871 - val_loss: 1.1724 - val_accuracy: 0.9160 - val_auc: 0.9394\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4275 - accuracy: 0.7286 - auc: 0.8772 - val_loss: 1.0820 - val_accuracy: 0.6886 - val_auc: 0.9402\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5222 - accuracy: 0.6843 - auc: 0.8808 - val_loss: 0.9344 - val_accuracy: 0.7262 - val_auc: 0.9413\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4520 - accuracy: 0.6087 - auc: 0.8650 - val_loss: 1.0874 - val_accuracy: 0.7368 - val_auc: 0.9351\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3940 - accuracy: 0.6388 - auc: 0.8774 - val_loss: 1.0367 - val_accuracy: 0.7520 - val_auc: 0.9400\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4361 - accuracy: 0.6275 - auc: 0.8613 - val_loss: 0.9913 - val_accuracy: 0.7406 - val_auc: 0.9384\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4470 - accuracy: 0.6369 - auc: 0.8713 - val_loss: 1.0132 - val_accuracy: 0.7441 - val_auc: 0.9353\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3837 - accuracy: 0.6417 - auc: 0.8807 - val_loss: 0.9119 - val_accuracy: 0.7411 - val_auc: 0.9383\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3728 - accuracy: 0.6370 - auc: 0.8913 - val_loss: 0.8960 - val_accuracy: 0.7456 - val_auc: 0.9336\n",
      "Epoch 26/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3595 - accuracy: 0.6539 - auc: 0.8875Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3592 - accuracy: 0.6539 - auc: 0.8876 - val_loss: 0.9206 - val_accuracy: 0.7603 - val_auc: 0.9384\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 1.1024 - accuracy: 0.7535 - auc: 0.8144 - val_loss: 0.6091 - val_accuracy: 0.9041 - val_auc: 0.9075\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.8632 - accuracy: 0.8464 - auc: 0.8703 - val_loss: 0.5929 - val_accuracy: 0.9443 - val_auc: 0.9171\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.8122 - accuracy: 0.8431 - auc: 0.8640 - val_loss: 0.5096 - val_accuracy: 0.9075 - val_auc: 0.9199\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.9770 - accuracy: 0.8453 - auc: 0.8471 - val_loss: 1.2106 - val_accuracy: 0.9112 - val_auc: 0.9103\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.1441 - accuracy: 0.8463 - auc: 0.8593 - val_loss: 0.8699 - val_accuracy: 0.8142 - val_auc: 0.9162\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.0667 - accuracy: 0.8566 - auc: 0.8697 - val_loss: 1.3242 - val_accuracy: 0.9111 - val_auc: 0.9336\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.2631 - accuracy: 0.8507 - auc: 0.8638 - val_loss: 1.9967 - val_accuracy: 0.9505 - val_auc: 0.9384\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.8647 - accuracy: 0.9045 - auc: 0.9040 - val_loss: 1.5409 - val_accuracy: 0.9078 - val_auc: 0.9415\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.8719 - accuracy: 0.9029 - auc: 0.9047 - val_loss: 1.0033 - val_accuracy: 0.8984 - val_auc: 0.9361\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5218 - accuracy: 0.9145 - auc: 0.8923 - val_loss: 1.4822 - val_accuracy: 0.9092 - val_auc: 0.9348\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.1866 - accuracy: 0.8970 - auc: 0.8909 - val_loss: 1.9665 - val_accuracy: 0.9041 - val_auc: 0.9345\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6686 - accuracy: 0.8243 - auc: 0.8779 - val_loss: 1.4919 - val_accuracy: 0.6157 - val_auc: 0.9356\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4752 - accuracy: 0.8166 - auc: 0.8970 - val_loss: 2.0153 - val_accuracy: 0.6380 - val_auc: 0.9291\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.8489 - accuracy: 0.5578 - auc: 0.8635 - val_loss: 2.5830 - val_accuracy: 0.6529 - val_auc: 0.9297\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.0469 - accuracy: 0.6477 - auc: 0.8605 - val_loss: 2.9594 - val_accuracy: 0.6601 - val_auc: 0.9398\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4806 - accuracy: 0.6182 - auc: 0.8818 - val_loss: 3.1086 - val_accuracy: 0.8925 - val_auc: 0.9348\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4601 - accuracy: 0.8337 - auc: 0.8919 - val_loss: 2.8414 - val_accuracy: 0.6596 - val_auc: 0.9277\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5698 - accuracy: 0.5661 - auc: 0.8657 - val_loss: 2.1086 - val_accuracy: 0.6596 - val_auc: 0.8809\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.7633 - accuracy: 0.5732 - auc: 0.8468 - val_loss: 2.1416 - val_accuracy: 0.6790 - val_auc: 0.9057\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5551 - accuracy: 0.5935 - auc: 0.8636 - val_loss: 2.6465 - val_accuracy: 0.6823 - val_auc: 0.9102\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4495 - accuracy: 0.6018 - auc: 0.8761 - val_loss: 2.4998 - val_accuracy: 0.6916 - val_auc: 0.9134\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4683 - accuracy: 0.6083 - auc: 0.8817 - val_loss: 2.4409 - val_accuracy: 0.6957 - val_auc: 0.9289\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4301 - accuracy: 0.6077 - auc: 0.8750 - val_loss: 2.3933 - val_accuracy: 0.6975 - val_auc: 0.9112\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3950 - accuracy: 0.6182 - auc: 0.8922 - val_loss: 2.2655 - val_accuracy: 0.6928 - val_auc: 0.9349\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3755 - accuracy: 0.6420 - auc: 0.9029 - val_loss: 1.9635 - val_accuracy: 0.6947 - val_auc: 0.9388\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3619 - accuracy: 0.6155 - auc: 0.9046 - val_loss: 2.0637 - val_accuracy: 0.6982 - val_auc: 0.9399\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3412 - accuracy: 0.7209 - auc: 0.9133 - val_loss: 2.0940 - val_accuracy: 0.7026 - val_auc: 0.9396\n",
      "Epoch 28/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.3688 - accuracy: 0.6794 - auc: 0.9041Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3689 - accuracy: 0.6793 - auc: 0.9040 - val_loss: 2.0932 - val_accuracy: 0.7275 - val_auc: 0.9362\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.9055 - accuracy: 0.7104 - auc: 0.8399 - val_loss: 0.5575 - val_accuracy: 0.9460 - val_auc: 0.9199\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.9918 - accuracy: 0.8242 - auc: 0.8645 - val_loss: 0.6310 - val_accuracy: 0.8537 - val_auc: 0.9038\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.9180 - accuracy: 0.8434 - auc: 0.8580 - val_loss: 0.7231 - val_accuracy: 0.8022 - val_auc: 0.9193\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.5151 - accuracy: 0.8244 - auc: 0.8439 - val_loss: 1.3324 - val_accuracy: 0.9313 - val_auc: 0.9072\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.6991 - accuracy: 0.8343 - auc: 0.8317 - val_loss: 1.2498 - val_accuracy: 0.7855 - val_auc: 0.8802\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.0230 - accuracy: 0.8547 - auc: 0.8596 - val_loss: 1.3437 - val_accuracy: 0.9453 - val_auc: 0.9299\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.7462 - accuracy: 0.9030 - auc: 0.8887 - val_loss: 1.0190 - val_accuracy: 0.9074 - val_auc: 0.9351\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.6809 - accuracy: 0.8615 - auc: 0.8530 - val_loss: 1.3473 - val_accuracy: 0.9356 - val_auc: 0.9200\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.7289 - accuracy: 0.6398 - auc: 0.8246 - val_loss: 1.1295 - val_accuracy: 0.8748 - val_auc: 0.8989\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 2.0737 - accuracy: 0.8597 - auc: 0.8268 - val_loss: 2.5203 - val_accuracy: 0.8830 - val_auc: 0.9297\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.8373 - accuracy: 0.9238 - auc: 0.8869 - val_loss: 2.8934 - val_accuracy: 0.9472 - val_auc: 0.9341\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 1.6091 - accuracy: 0.7240 - auc: 0.8159 - val_loss: 1.9757 - val_accuracy: 0.9543 - val_auc: 0.8967\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.8299 - accuracy: 0.8230 - auc: 0.8455 - val_loss: 2.1564 - val_accuracy: 0.8790 - val_auc: 0.9223\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 1.1067 - accuracy: 0.6665 - auc: 0.7972 - val_loss: 2.1317 - val_accuracy: 0.5996 - val_auc: 0.8651\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.7573 - accuracy: 0.4991 - auc: 0.8344 - val_loss: 2.6180 - val_accuracy: 0.6109 - val_auc: 0.9331\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.7780 - accuracy: 0.6825 - auc: 0.8401 - val_loss: 1.9539 - val_accuracy: 0.6117 - val_auc: 0.8532\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.7875 - accuracy: 0.5219 - auc: 0.8240 - val_loss: 1.9610 - val_accuracy: 0.6258 - val_auc: 0.8644\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6450 - accuracy: 0.5360 - auc: 0.8333 - val_loss: 2.4904 - val_accuracy: 0.6515 - val_auc: 0.8701\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 2s 6us/sample - loss: 0.6162 - accuracy: 0.5409 - auc: 0.8286 - val_loss: 2.6290 - val_accuracy: 0.6572 - val_auc: 0.8745\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5586 - accuracy: 0.5552 - auc: 0.8254 - val_loss: 2.9025 - val_accuracy: 0.6687 - val_auc: 0.8779\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5272 - accuracy: 0.5591 - auc: 0.8425 - val_loss: 2.9302 - val_accuracy: 0.6742 - val_auc: 0.8794\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5189 - accuracy: 0.5642 - auc: 0.8453 - val_loss: 3.0184 - val_accuracy: 0.6977 - val_auc: 0.8876\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6769 - accuracy: 0.5708 - auc: 0.8376 - val_loss: 2.2541 - val_accuracy: 0.6815 - val_auc: 0.8861\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5102 - accuracy: 0.5757 - auc: 0.8451 - val_loss: 2.4082 - val_accuracy: 0.6936 - val_auc: 0.8843\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5020 - accuracy: 0.5814 - auc: 0.8449 - val_loss: 2.5598 - val_accuracy: 0.7087 - val_auc: 0.8894\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5248 - accuracy: 0.5910 - auc: 0.8450 - val_loss: 1.8317 - val_accuracy: 0.6766 - val_auc: 0.8715\n",
      "Epoch 27/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.5996 - accuracy: 0.5780 - auc: 0.8347Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6002 - accuracy: 0.5780 - auc: 0.8347 - val_loss: 1.5648 - val_accuracy: 0.7086 - val_auc: 0.8845\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 1.0744 - accuracy: 0.9472 - auc: 0.6876 - val_loss: 0.5655 - val_accuracy: 0.9497 - val_auc: 0.9013\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6434 - accuracy: 0.9190 - auc: 0.8002 - val_loss: 0.4513 - val_accuracy: 0.9310 - val_auc: 0.9313\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5178 - accuracy: 0.9109 - auc: 0.8231 - val_loss: 0.3815 - val_accuracy: 0.8790 - val_auc: 0.9376\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4763 - accuracy: 0.9017 - auc: 0.8484 - val_loss: 0.3545 - val_accuracy: 0.8562 - val_auc: 0.9418\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4428 - accuracy: 0.8789 - auc: 0.8672 - val_loss: 0.3377 - val_accuracy: 0.8365 - val_auc: 0.9459\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4079 - accuracy: 0.7016 - auc: 0.8804 - val_loss: 0.3039 - val_accuracy: 0.8365 - val_auc: 0.9513\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3918 - accuracy: 0.7131 - auc: 0.8907 - val_loss: 0.3081 - val_accuracy: 0.8477 - val_auc: 0.9516\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3765 - accuracy: 0.7192 - auc: 0.8974 - val_loss: 0.3111 - val_accuracy: 0.8447 - val_auc: 0.9521\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3552 - accuracy: 0.7293 - auc: 0.9056 - val_loss: 0.3143 - val_accuracy: 0.8460 - val_auc: 0.9520\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3655 - accuracy: 0.7370 - auc: 0.9028 - val_loss: 0.3137 - val_accuracy: 0.8469 - val_auc: 0.9518\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3476 - accuracy: 0.7327 - auc: 0.9088 - val_loss: 0.3151 - val_accuracy: 0.8485 - val_auc: 0.9506\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3467 - accuracy: 0.7374 - auc: 0.9084 - val_loss: 0.3145 - val_accuracy: 0.8580 - val_auc: 0.9514\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3549 - accuracy: 0.7454 - auc: 0.9038 - val_loss: 0.3156 - val_accuracy: 0.8538 - val_auc: 0.9514\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3468 - accuracy: 0.7516 - auc: 0.9091 - val_loss: 0.3174 - val_accuracy: 0.8606 - val_auc: 0.9521\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3410 - accuracy: 0.7484 - auc: 0.9143 - val_loss: 0.3130 - val_accuracy: 0.8534 - val_auc: 0.9530\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3418 - accuracy: 0.7484 - auc: 0.9126 - val_loss: 0.3261 - val_accuracy: 0.8503 - val_auc: 0.9522\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3311 - accuracy: 0.7563 - auc: 0.9135 - val_loss: 0.3242 - val_accuracy: 0.8541 - val_auc: 0.9521\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3302 - accuracy: 0.7627 - auc: 0.9168 - val_loss: 0.3287 - val_accuracy: 0.8635 - val_auc: 0.9515\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3390 - accuracy: 0.7584 - auc: 0.9147 - val_loss: 0.3412 - val_accuracy: 0.8568 - val_auc: 0.9495\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3267 - accuracy: 0.7611 - auc: 0.9177 - val_loss: 0.3352 - val_accuracy: 0.8552 - val_auc: 0.9517\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3314 - accuracy: 0.7665 - auc: 0.9188 - val_loss: 0.3254 - val_accuracy: 0.8547 - val_auc: 0.9531\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3274 - accuracy: 0.7644 - auc: 0.9162 - val_loss: 0.3240 - val_accuracy: 0.8631 - val_auc: 0.9524\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3363 - accuracy: 0.7697 - auc: 0.9164 - val_loss: 0.3270 - val_accuracy: 0.8539 - val_auc: 0.9521\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3232 - accuracy: 0.7677 - auc: 0.9204 - val_loss: 0.3371 - val_accuracy: 0.8667 - val_auc: 0.9502\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3204 - accuracy: 0.7759 - auc: 0.9234 - val_loss: 0.3360 - val_accuracy: 0.8739 - val_auc: 0.9500\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3289 - accuracy: 0.7770 - auc: 0.9200 - val_loss: 0.3208 - val_accuracy: 0.8570 - val_auc: 0.9547\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3201 - accuracy: 0.7702 - auc: 0.9258 - val_loss: 0.3266 - val_accuracy: 0.8692 - val_auc: 0.9519\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3214 - accuracy: 0.7750 - auc: 0.9223 - val_loss: 0.3309 - val_accuracy: 0.8729 - val_auc: 0.9509\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3217 - accuracy: 0.7794 - auc: 0.9237 - val_loss: 0.3405 - val_accuracy: 0.8655 - val_auc: 0.9498\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3332 - accuracy: 0.7787 - auc: 0.9176 - val_loss: 0.3335 - val_accuracy: 0.8474 - val_auc: 0.9523\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3239 - accuracy: 0.7707 - auc: 0.9243 - val_loss: 0.3263 - val_accuracy: 0.8678 - val_auc: 0.9529\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3250 - accuracy: 0.7799 - auc: 0.9254 - val_loss: 0.3277 - val_accuracy: 0.8686 - val_auc: 0.9526\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3270 - accuracy: 0.7787 - auc: 0.9234 - val_loss: 0.3314 - val_accuracy: 0.8619 - val_auc: 0.9523\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3119 - accuracy: 0.7754 - auc: 0.9257 - val_loss: 0.3371 - val_accuracy: 0.8741 - val_auc: 0.9510\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3173 - accuracy: 0.7855 - auc: 0.9280 - val_loss: 0.3434 - val_accuracy: 0.8665 - val_auc: 0.9489\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3209 - accuracy: 0.7806 - auc: 0.9247 - val_loss: 0.3471 - val_accuracy: 0.8604 - val_auc: 0.9494\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3187 - accuracy: 0.7830 - auc: 0.9255 - val_loss: 0.3447 - val_accuracy: 0.8700 - val_auc: 0.9490\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3200 - accuracy: 0.7748 - auc: 0.9228 - val_loss: 0.3264 - val_accuracy: 0.8726 - val_auc: 0.9493\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3134 - accuracy: 0.7841 - auc: 0.9261 - val_loss: 0.3351 - val_accuracy: 0.8742 - val_auc: 0.9470\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3310 - accuracy: 0.7829 - auc: 0.9206 - val_loss: 0.3270 - val_accuracy: 0.8687 - val_auc: 0.9508\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3117 - accuracy: 0.7842 - auc: 0.9243 - val_loss: 0.3353 - val_accuracy: 0.8739 - val_auc: 0.9498\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3156 - accuracy: 0.7821 - auc: 0.9255 - val_loss: 0.3383 - val_accuracy: 0.8682 - val_auc: 0.9493\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3013 - accuracy: 0.7877 - auc: 0.9287 - val_loss: 0.3658 - val_accuracy: 0.8782 - val_auc: 0.9452\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3252 - accuracy: 0.7784 - auc: 0.9210 - val_loss: 0.3422 - val_accuracy: 0.8673 - val_auc: 0.9482\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3189 - accuracy: 0.7831 - auc: 0.9235 - val_loss: 0.3343 - val_accuracy: 0.8668 - val_auc: 0.9488\n",
      "Epoch 46/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.3154 - accuracy: 0.7789 - auc: 0.9229Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3153 - accuracy: 0.7789 - auc: 0.9230 - val_loss: 0.3404 - val_accuracy: 0.8798 - val_auc: 0.9493\n",
      "Epoch 00046: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.5226 - accuracy: 0.5856 - auc: 0.8650 - val_loss: 0.3554 - val_accuracy: 0.8741 - val_auc: 0.9373\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3872 - accuracy: 0.8775 - auc: 0.9178 - val_loss: 0.2957 - val_accuracy: 0.8936 - val_auc: 0.9540\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3685 - accuracy: 0.8996 - auc: 0.9190 - val_loss: 0.2854 - val_accuracy: 0.9016 - val_auc: 0.9547\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3676 - accuracy: 0.9020 - auc: 0.9191 - val_loss: 0.2821 - val_accuracy: 0.9170 - val_auc: 0.9561\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3618 - accuracy: 0.9126 - auc: 0.9169 - val_loss: 0.2818 - val_accuracy: 0.9106 - val_auc: 0.9572\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3559 - accuracy: 0.9138 - auc: 0.9248 - val_loss: 0.2781 - val_accuracy: 0.9184 - val_auc: 0.9572\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3326 - accuracy: 0.9178 - auc: 0.9316 - val_loss: 0.2736 - val_accuracy: 0.9123 - val_auc: 0.9580\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3371 - accuracy: 0.9204 - auc: 0.9330 - val_loss: 0.2679 - val_accuracy: 0.9196 - val_auc: 0.9594\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3318 - accuracy: 0.9216 - auc: 0.9305 - val_loss: 0.2803 - val_accuracy: 0.9310 - val_auc: 0.9558\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3546 - accuracy: 0.9193 - auc: 0.9205 - val_loss: 0.2807 - val_accuracy: 0.9179 - val_auc: 0.9534\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3271 - accuracy: 0.9213 - auc: 0.9345 - val_loss: 0.2788 - val_accuracy: 0.9223 - val_auc: 0.9540\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3211 - accuracy: 0.9196 - auc: 0.9396 - val_loss: 0.2779 - val_accuracy: 0.9231 - val_auc: 0.9540\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3521 - accuracy: 0.9224 - auc: 0.9219 - val_loss: 0.2790 - val_accuracy: 0.9219 - val_auc: 0.9555\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3318 - accuracy: 0.9218 - auc: 0.9366 - val_loss: 0.2794 - val_accuracy: 0.9181 - val_auc: 0.9543\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3398 - accuracy: 0.9227 - auc: 0.9274 - val_loss: 0.2830 - val_accuracy: 0.9225 - val_auc: 0.9545\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3337 - accuracy: 0.9257 - auc: 0.9288 - val_loss: 0.2881 - val_accuracy: 0.9245 - val_auc: 0.9528\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3297 - accuracy: 0.9250 - auc: 0.9309 - val_loss: 0.2922 - val_accuracy: 0.9262 - val_auc: 0.9521\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3204 - accuracy: 0.9271 - auc: 0.9362 - val_loss: 0.2989 - val_accuracy: 0.9178 - val_auc: 0.9520\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3323 - accuracy: 0.9205 - auc: 0.9313 - val_loss: 0.2959 - val_accuracy: 0.9310 - val_auc: 0.9538\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3275 - accuracy: 0.9258 - auc: 0.9334 - val_loss: 0.2892 - val_accuracy: 0.9199 - val_auc: 0.9540\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3126 - accuracy: 0.9263 - auc: 0.9388 - val_loss: 0.2971 - val_accuracy: 0.9240 - val_auc: 0.9542\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3294 - accuracy: 0.9256 - auc: 0.9311 - val_loss: 0.3056 - val_accuracy: 0.9237 - val_auc: 0.9518\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3217 - accuracy: 0.9279 - auc: 0.9371 - val_loss: 0.3088 - val_accuracy: 0.9108 - val_auc: 0.9525\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3304 - accuracy: 0.9276 - auc: 0.9330 - val_loss: 0.3166 - val_accuracy: 0.9238 - val_auc: 0.9526\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3260 - accuracy: 0.9250 - auc: 0.9322 - val_loss: 0.3191 - val_accuracy: 0.9220 - val_auc: 0.9529\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3306 - accuracy: 0.9275 - auc: 0.9294 - val_loss: 0.3231 - val_accuracy: 0.9256 - val_auc: 0.9522\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3216 - accuracy: 0.9275 - auc: 0.9370 - val_loss: 0.3168 - val_accuracy: 0.9106 - val_auc: 0.9537\n",
      "Epoch 28/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.9265 - auc: 0.9352Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3257 - accuracy: 0.9266 - auc: 0.9358 - val_loss: 0.3014 - val_accuracy: 0.9239 - val_auc: 0.9543\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.5119 - accuracy: 0.8473 - auc: 0.8339 - val_loss: 0.3581 - val_accuracy: 0.9113 - val_auc: 0.9398\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4013 - accuracy: 0.9123 - auc: 0.9039 - val_loss: 0.3214 - val_accuracy: 0.9246 - val_auc: 0.9527\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3924 - accuracy: 0.9141 - auc: 0.8994 - val_loss: 0.3006 - val_accuracy: 0.9055 - val_auc: 0.9555\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3654 - accuracy: 0.9172 - auc: 0.9176 - val_loss: 0.2964 - val_accuracy: 0.9109 - val_auc: 0.9517\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3542 - accuracy: 0.9146 - auc: 0.9187 - val_loss: 0.2899 - val_accuracy: 0.9150 - val_auc: 0.9528\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3531 - accuracy: 0.9146 - auc: 0.9199 - val_loss: 0.2933 - val_accuracy: 0.9292 - val_auc: 0.9500\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3543 - accuracy: 0.9175 - auc: 0.9268 - val_loss: 0.2831 - val_accuracy: 0.9244 - val_auc: 0.9530\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3503 - accuracy: 0.9195 - auc: 0.9208 - val_loss: 0.2712 - val_accuracy: 0.9136 - val_auc: 0.9584\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3478 - accuracy: 0.9175 - auc: 0.9223 - val_loss: 0.2685 - val_accuracy: 0.9190 - val_auc: 0.9583\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3259 - accuracy: 0.9162 - auc: 0.9352 - val_loss: 0.2738 - val_accuracy: 0.9240 - val_auc: 0.9566\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3267 - accuracy: 0.9194 - auc: 0.9355 - val_loss: 0.2695 - val_accuracy: 0.9127 - val_auc: 0.9569\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3450 - accuracy: 0.9208 - auc: 0.9264 - val_loss: 0.2703 - val_accuracy: 0.9128 - val_auc: 0.9563\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3489 - accuracy: 0.9197 - auc: 0.9212 - val_loss: 0.2692 - val_accuracy: 0.9141 - val_auc: 0.9565\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3326 - accuracy: 0.9167 - auc: 0.9318 - val_loss: 0.2719 - val_accuracy: 0.9183 - val_auc: 0.9563\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3151 - accuracy: 0.9218 - auc: 0.9391 - val_loss: 0.2627 - val_accuracy: 0.9067 - val_auc: 0.9583\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3405 - accuracy: 0.9189 - auc: 0.9262 - val_loss: 0.2731 - val_accuracy: 0.9193 - val_auc: 0.9557\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3324 - accuracy: 0.9212 - auc: 0.9295 - val_loss: 0.2790 - val_accuracy: 0.9143 - val_auc: 0.9556\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3348 - accuracy: 0.9199 - auc: 0.9304 - val_loss: 0.2790 - val_accuracy: 0.9276 - val_auc: 0.9553\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3445 - accuracy: 0.9190 - auc: 0.9208 - val_loss: 0.2768 - val_accuracy: 0.9205 - val_auc: 0.9565\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3283 - accuracy: 0.9231 - auc: 0.9330 - val_loss: 0.2785 - val_accuracy: 0.9148 - val_auc: 0.9556\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3288 - accuracy: 0.9212 - auc: 0.9327 - val_loss: 0.2843 - val_accuracy: 0.9233 - val_auc: 0.9545\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3305 - accuracy: 0.9223 - auc: 0.9277 - val_loss: 0.2848 - val_accuracy: 0.9260 - val_auc: 0.9545\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3336 - accuracy: 0.9215 - auc: 0.9313 - val_loss: 0.2857 - val_accuracy: 0.9163 - val_auc: 0.9540\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3279 - accuracy: 0.9214 - auc: 0.9307 - val_loss: 0.2882 - val_accuracy: 0.9273 - val_auc: 0.9541\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3184 - accuracy: 0.9198 - auc: 0.9382 - val_loss: 0.2870 - val_accuracy: 0.9264 - val_auc: 0.9545\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3273 - accuracy: 0.9243 - auc: 0.9311 - val_loss: 0.2862 - val_accuracy: 0.9160 - val_auc: 0.9546\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3302 - accuracy: 0.9269 - auc: 0.9248 - val_loss: 0.2941 - val_accuracy: 0.9197 - val_auc: 0.9534\n",
      "Epoch 28/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3226 - accuracy: 0.9232 - auc: 0.9332 ETA: 0s - loss: 0.2910 - accuracy: Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3210 - accuracy: 0.9232 - auc: 0.9328 - val_loss: 0.2954 - val_accuracy: 0.9259 - val_auc: 0.9544\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.6112 - accuracy: 0.8330 - auc: 0.7816 - val_loss: 0.3721 - val_accuracy: 0.9013 - val_auc: 0.9328\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4460 - accuracy: 0.9063 - auc: 0.8737 - val_loss: 0.3209 - val_accuracy: 0.9045 - val_auc: 0.9454\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4029 - accuracy: 0.9056 - auc: 0.8974 - val_loss: 0.3106 - val_accuracy: 0.9282 - val_auc: 0.9471\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3785 - accuracy: 0.9169 - auc: 0.9071 - val_loss: 0.2986 - val_accuracy: 0.9171 - val_auc: 0.9500\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3653 - accuracy: 0.9162 - auc: 0.9139 - val_loss: 0.2936 - val_accuracy: 0.9073 - val_auc: 0.9493\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3614 - accuracy: 0.9163 - auc: 0.9121 - val_loss: 0.2891 - val_accuracy: 0.9134 - val_auc: 0.9510\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3524 - accuracy: 0.9108 - auc: 0.9161 - val_loss: 0.2906 - val_accuracy: 0.9156 - val_auc: 0.9501\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3469 - accuracy: 0.9173 - auc: 0.9230 - val_loss: 0.2870 - val_accuracy: 0.9128 - val_auc: 0.9513\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3493 - accuracy: 0.9102 - auc: 0.9195 - val_loss: 0.3011 - val_accuracy: 0.9048 - val_auc: 0.9474\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3433 - accuracy: 0.9043 - auc: 0.9207 - val_loss: 0.2926 - val_accuracy: 0.9063 - val_auc: 0.9492\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3328 - accuracy: 0.9131 - auc: 0.9271 - val_loss: 0.2981 - val_accuracy: 0.9113 - val_auc: 0.9487\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3333 - accuracy: 0.9191 - auc: 0.9245 - val_loss: 0.2948 - val_accuracy: 0.9144 - val_auc: 0.9504\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3275 - accuracy: 0.9152 - auc: 0.9263 - val_loss: 0.2913 - val_accuracy: 0.9174 - val_auc: 0.9527\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3477 - accuracy: 0.9135 - auc: 0.9189 - val_loss: 0.3199 - val_accuracy: 0.9094 - val_auc: 0.9447\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3263 - accuracy: 0.9151 - auc: 0.9263 - val_loss: 0.3132 - val_accuracy: 0.9097 - val_auc: 0.9477\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3257 - accuracy: 0.9105 - auc: 0.9274 - val_loss: 0.3109 - val_accuracy: 0.9160 - val_auc: 0.9489\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3318 - accuracy: 0.9176 - auc: 0.9248 - val_loss: 0.3179 - val_accuracy: 0.9138 - val_auc: 0.9483\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3338 - accuracy: 0.9101 - auc: 0.9232 - val_loss: 0.3148 - val_accuracy: 0.9196 - val_auc: 0.9509\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3303 - accuracy: 0.9176 - auc: 0.9225 - val_loss: 0.3147 - val_accuracy: 0.9133 - val_auc: 0.9508\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3237 - accuracy: 0.9159 - auc: 0.9300 - val_loss: 0.3238 - val_accuracy: 0.9131 - val_auc: 0.9491\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3220 - accuracy: 0.9163 - auc: 0.9288 - val_loss: 0.3356 - val_accuracy: 0.9123 - val_auc: 0.9480\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3193 - accuracy: 0.9206 - auc: 0.9277 - val_loss: 0.3456 - val_accuracy: 0.9157 - val_auc: 0.9470\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3356 - accuracy: 0.9192 - auc: 0.9205 - val_loss: 0.3350 - val_accuracy: 0.9206 - val_auc: 0.9486\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3261 - accuracy: 0.9194 - auc: 0.9318 - val_loss: 0.3161 - val_accuracy: 0.9152 - val_auc: 0.9489\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3144 - accuracy: 0.9205 - auc: 0.9327 - val_loss: 0.3231 - val_accuracy: 0.9124 - val_auc: 0.9485\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3159 - accuracy: 0.9178 - auc: 0.9318 - val_loss: 0.3323 - val_accuracy: 0.9179 - val_auc: 0.9464\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3185 - accuracy: 0.9248 - auc: 0.9311 - val_loss: 0.3419 - val_accuracy: 0.9188 - val_auc: 0.9465\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3169 - accuracy: 0.9202 - auc: 0.9311 - val_loss: 0.3410 - val_accuracy: 0.9235 - val_auc: 0.9472\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3125 - accuracy: 0.9216 - auc: 0.9300 - val_loss: 0.3583 - val_accuracy: 0.9182 - val_auc: 0.9454\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3160 - accuracy: 0.9232 - auc: 0.9356 - val_loss: 0.3615 - val_accuracy: 0.9153 - val_auc: 0.9445\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3284 - accuracy: 0.9241 - auc: 0.9231 - val_loss: 0.3679 - val_accuracy: 0.9084 - val_auc: 0.9450\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3160 - accuracy: 0.9179 - auc: 0.9322 - val_loss: 0.3875 - val_accuracy: 0.9234 - val_auc: 0.9453\n",
      "Epoch 33/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3181 - accuracy: 0.9234 - auc: 0.9296Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3167 - accuracy: 0.9234 - auc: 0.9311 - val_loss: 0.3790 - val_accuracy: 0.9175 - val_auc: 0.9426\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.7573 - accuracy: 0.9313 - auc: 0.6918 - val_loss: 0.4136 - val_accuracy: 0.8854 - val_auc: 0.9365\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4969 - accuracy: 0.8766 - auc: 0.8454 - val_loss: 0.3564 - val_accuracy: 0.9113 - val_auc: 0.9468\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4347 - accuracy: 0.9067 - auc: 0.8748 - val_loss: 0.3182 - val_accuracy: 0.8929 - val_auc: 0.9510\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4128 - accuracy: 0.9081 - auc: 0.8834 - val_loss: 0.3120 - val_accuracy: 0.9095 - val_auc: 0.9493\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4093 - accuracy: 0.9078 - auc: 0.8936 - val_loss: 0.3018 - val_accuracy: 0.9000 - val_auc: 0.9527\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3817 - accuracy: 0.9072 - auc: 0.9025 - val_loss: 0.2934 - val_accuracy: 0.8953 - val_auc: 0.9529\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3523 - accuracy: 0.9038 - auc: 0.9148 - val_loss: 0.3057 - val_accuracy: 0.9006 - val_auc: 0.9493\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3763 - accuracy: 0.8993 - auc: 0.9021 - val_loss: 0.3078 - val_accuracy: 0.8924 - val_auc: 0.9516\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3450 - accuracy: 0.9000 - auc: 0.9181 - val_loss: 0.3151 - val_accuracy: 0.8932 - val_auc: 0.9507\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3516 - accuracy: 0.8975 - auc: 0.9139 - val_loss: 0.3176 - val_accuracy: 0.8776 - val_auc: 0.9503\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3286 - accuracy: 0.8962 - auc: 0.9254 - val_loss: 0.3204 - val_accuracy: 0.8804 - val_auc: 0.9510\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3335 - accuracy: 0.7554 - auc: 0.9202 - val_loss: 0.3365 - val_accuracy: 0.8555 - val_auc: 0.9477\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3583 - accuracy: 0.6756 - auc: 0.9094 - val_loss: 0.3448 - val_accuracy: 0.8196 - val_auc: 0.9498\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3386 - accuracy: 0.6824 - auc: 0.9160 - val_loss: 0.3309 - val_accuracy: 0.8511 - val_auc: 0.9517\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3364 - accuracy: 0.6939 - auc: 0.9178 - val_loss: 0.3409 - val_accuracy: 0.8438 - val_auc: 0.9509\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3274 - accuracy: 0.6918 - auc: 0.9255 - val_loss: 0.3498 - val_accuracy: 0.8395 - val_auc: 0.9517\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3222 - accuracy: 0.6919 - auc: 0.9254 - val_loss: 0.3560 - val_accuracy: 0.8477 - val_auc: 0.9517\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3213 - accuracy: 0.6972 - auc: 0.9287 - val_loss: 0.3614 - val_accuracy: 0.8506 - val_auc: 0.9515\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3280 - accuracy: 0.7010 - auc: 0.9221 - val_loss: 0.3667 - val_accuracy: 0.8496 - val_auc: 0.9512\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3186 - accuracy: 0.6959 - auc: 0.9268 - val_loss: 0.3745 - val_accuracy: 0.8487 - val_auc: 0.9514\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3195 - accuracy: 0.7041 - auc: 0.9277 - val_loss: 0.3777 - val_accuracy: 0.8519 - val_auc: 0.9513\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3155 - accuracy: 0.7065 - auc: 0.9259 - val_loss: 0.3912 - val_accuracy: 0.8606 - val_auc: 0.9502\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3109 - accuracy: 0.7111 - auc: 0.9302 - val_loss: 0.3793 - val_accuracy: 0.8578 - val_auc: 0.9514\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3133 - accuracy: 0.7071 - auc: 0.9307 - val_loss: 0.3836 - val_accuracy: 0.8502 - val_auc: 0.9517\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3192 - accuracy: 0.7057 - auc: 0.9289 - val_loss: 0.4028 - val_accuracy: 0.8496 - val_auc: 0.9491\n",
      "Epoch 26/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.7081 - auc: 0.9322Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3094 - accuracy: 0.7080 - auc: 0.9327 - val_loss: 0.4116 - val_accuracy: 0.8560 - val_auc: 0.9480\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 5s 18us/sample - loss: 0.6648 - accuracy: 0.5065 - auc: 0.8238 - val_loss: 0.3359 - val_accuracy: 0.8277 - val_auc: 0.9377\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3981 - accuracy: 0.7558 - auc: 0.9195 - val_loss: 0.2834 - val_accuracy: 0.8655 - val_auc: 0.9520\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3170 - accuracy: 0.8026 - auc: 0.9447 - val_loss: 0.2916 - val_accuracy: 0.8877 - val_auc: 0.9525\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3219 - accuracy: 0.8166 - auc: 0.9398 - val_loss: 0.2869 - val_accuracy: 0.8568 - val_auc: 0.9515\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2965 - accuracy: 0.8181 - auc: 0.9485 - val_loss: 0.2791 - val_accuracy: 0.8752 - val_auc: 0.9550\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2958 - accuracy: 0.8223 - auc: 0.9495 - val_loss: 0.2785 - val_accuracy: 0.8835 - val_auc: 0.9548\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2821 - accuracy: 0.8258 - auc: 0.9536 - val_loss: 0.2921 - val_accuracy: 0.8949 - val_auc: 0.9528\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2836 - accuracy: 0.8342 - auc: 0.9526 - val_loss: 0.2913 - val_accuracy: 0.8771 - val_auc: 0.9525\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2757 - accuracy: 0.8156 - auc: 0.9546 - val_loss: 0.3057 - val_accuracy: 0.8828 - val_auc: 0.9499\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2766 - accuracy: 0.8258 - auc: 0.9539 - val_loss: 0.3115 - val_accuracy: 0.8898 - val_auc: 0.9500\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2688 - accuracy: 0.8278 - auc: 0.9567 - val_loss: 0.3141 - val_accuracy: 0.8831 - val_auc: 0.9513\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2748 - accuracy: 0.8239 - auc: 0.9554 - val_loss: 0.3102 - val_accuracy: 0.8870 - val_auc: 0.9508\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2798 - accuracy: 0.8203 - auc: 0.9534 - val_loss: 0.3136 - val_accuracy: 0.8802 - val_auc: 0.9504\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2675 - accuracy: 0.8234 - auc: 0.9560 - val_loss: 0.3188 - val_accuracy: 0.8813 - val_auc: 0.9508\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2648 - accuracy: 0.8210 - auc: 0.9574 - val_loss: 0.3298 - val_accuracy: 0.8886 - val_auc: 0.9488\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2649 - accuracy: 0.8236 - auc: 0.9567 - val_loss: 0.3300 - val_accuracy: 0.8878 - val_auc: 0.9495\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2627 - accuracy: 0.8286 - auc: 0.9589 - val_loss: 0.3468 - val_accuracy: 0.8886 - val_auc: 0.9468\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2589 - accuracy: 0.8207 - auc: 0.9598 - val_loss: 0.3479 - val_accuracy: 0.8931 - val_auc: 0.9472\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2626 - accuracy: 0.8273 - auc: 0.9573 - val_loss: 0.3569 - val_accuracy: 0.8925 - val_auc: 0.9467\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2634 - accuracy: 0.8247 - auc: 0.9584 - val_loss: 0.3632 - val_accuracy: 0.8948 - val_auc: 0.9447\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2551 - accuracy: 0.8266 - auc: 0.9599 - val_loss: 0.3626 - val_accuracy: 0.8961 - val_auc: 0.9466\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2593 - accuracy: 0.8295 - auc: 0.9598 - val_loss: 0.3712 - val_accuracy: 0.8937 - val_auc: 0.9445\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2552 - accuracy: 0.8229 - auc: 0.9603 - val_loss: 0.3780 - val_accuracy: 0.8957 - val_auc: 0.9457\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2558 - accuracy: 0.8273 - auc: 0.9596 - val_loss: 0.3863 - val_accuracy: 0.8981 - val_auc: 0.9447\n",
      "Epoch 25/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2595 - accuracy: 0.8205 - auc: 0.9586Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2576 - accuracy: 0.8204 - auc: 0.9593 - val_loss: 0.3703 - val_accuracy: 0.8903 - val_auc: 0.9467\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5442 - accuracy: 0.5265 - auc: 0.8691 - val_loss: 0.3375 - val_accuracy: 0.8146 - val_auc: 0.9391\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3712 - accuracy: 0.7156 - auc: 0.9300 - val_loss: 0.2886 - val_accuracy: 0.8588 - val_auc: 0.9518\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3467 - accuracy: 0.7801 - auc: 0.9378 - val_loss: 0.2830 - val_accuracy: 0.8847 - val_auc: 0.9529\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3070 - accuracy: 0.8636 - auc: 0.9467 - val_loss: 0.2806 - val_accuracy: 0.8900 - val_auc: 0.9535\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3015 - accuracy: 0.8753 - auc: 0.9496 - val_loss: 0.2859 - val_accuracy: 0.8844 - val_auc: 0.9521\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2900 - accuracy: 0.8853 - auc: 0.9525 - val_loss: 0.2894 - val_accuracy: 0.9018 - val_auc: 0.9522\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2829 - accuracy: 0.8920 - auc: 0.9540 - val_loss: 0.2892 - val_accuracy: 0.9040 - val_auc: 0.9525\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2665 - accuracy: 0.8939 - auc: 0.9586 - val_loss: 0.2977 - val_accuracy: 0.9115 - val_auc: 0.9512\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2689 - accuracy: 0.9041 - auc: 0.9580 - val_loss: 0.2964 - val_accuracy: 0.9088 - val_auc: 0.9518\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.2625 - accuracy: 0.9033 - auc: 0.9603 - val_loss: 0.3084 - val_accuracy: 0.9082 - val_auc: 0.9498\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2638 - accuracy: 0.9048 - auc: 0.9608 - val_loss: 0.3193 - val_accuracy: 0.9155 - val_auc: 0.9500\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2641 - accuracy: 0.9096 - auc: 0.9600 - val_loss: 0.3203 - val_accuracy: 0.9098 - val_auc: 0.9484\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2652 - accuracy: 0.9056 - auc: 0.9592 - val_loss: 0.3225 - val_accuracy: 0.9147 - val_auc: 0.9458\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2724 - accuracy: 0.9114 - auc: 0.9573 - val_loss: 0.3312 - val_accuracy: 0.9135 - val_auc: 0.9456\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2672 - accuracy: 0.9082 - auc: 0.9594 - val_loss: 0.3178 - val_accuracy: 0.9208 - val_auc: 0.9478\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2583 - accuracy: 0.9096 - auc: 0.9608 - val_loss: 0.3150 - val_accuracy: 0.9141 - val_auc: 0.9493\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2558 - accuracy: 0.9116 - auc: 0.9617 - val_loss: 0.3156 - val_accuracy: 0.9139 - val_auc: 0.9515\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2526 - accuracy: 0.9126 - auc: 0.9629 - val_loss: 0.3172 - val_accuracy: 0.9073 - val_auc: 0.9508\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2556 - accuracy: 0.9070 - auc: 0.9612 - val_loss: 0.3296 - val_accuracy: 0.9219 - val_auc: 0.9486\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2672 - accuracy: 0.9078 - auc: 0.9577 - val_loss: 0.3308 - val_accuracy: 0.9120 - val_auc: 0.9477\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2551 - accuracy: 0.9096 - auc: 0.9620 - val_loss: 0.3387 - val_accuracy: 0.9139 - val_auc: 0.9463\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2508 - accuracy: 0.9125 - auc: 0.9624 - val_loss: 0.3618 - val_accuracy: 0.9183 - val_auc: 0.9439\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2500 - accuracy: 0.9086 - auc: 0.9626 - val_loss: 0.3582 - val_accuracy: 0.9171 - val_auc: 0.9455\n",
      "Epoch 24/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2467 - accuracy: 0.9120 - auc: 0.9641 ETA: 0s - loss: 0.2317 - accuraRestoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2491 - accuracy: 0.9122 - auc: 0.9633 - val_loss: 0.3724 - val_accuracy: 0.9206 - val_auc: 0.9457\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.4665 - accuracy: 0.7948 - auc: 0.8708 - val_loss: 0.3272 - val_accuracy: 0.8890 - val_auc: 0.9371\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3558 - accuracy: 0.8866 - auc: 0.9306 - val_loss: 0.2874 - val_accuracy: 0.8864 - val_auc: 0.9543\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3226 - accuracy: 0.8967 - auc: 0.9385 - val_loss: 0.2665 - val_accuracy: 0.9129 - val_auc: 0.9582\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3085 - accuracy: 0.9037 - auc: 0.9446 - val_loss: 0.2640 - val_accuracy: 0.9121 - val_auc: 0.9589\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3058 - accuracy: 0.9036 - auc: 0.9452 - val_loss: 0.2650 - val_accuracy: 0.9089 - val_auc: 0.9578\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3012 - accuracy: 0.9000 - auc: 0.9464 - val_loss: 0.2680 - val_accuracy: 0.9040 - val_auc: 0.9563\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2993 - accuracy: 0.9019 - auc: 0.9492 - val_loss: 0.2663 - val_accuracy: 0.9013 - val_auc: 0.9573\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2894 - accuracy: 0.9059 - auc: 0.9509 - val_loss: 0.2760 - val_accuracy: 0.9002 - val_auc: 0.9551\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2861 - accuracy: 0.8991 - auc: 0.9526 - val_loss: 0.2733 - val_accuracy: 0.9084 - val_auc: 0.9556\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2780 - accuracy: 0.9021 - auc: 0.9539 - val_loss: 0.2810 - val_accuracy: 0.9086 - val_auc: 0.9555\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2696 - accuracy: 0.9027 - auc: 0.9570 - val_loss: 0.2961 - val_accuracy: 0.9072 - val_auc: 0.9532\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2693 - accuracy: 0.9009 - auc: 0.9569 - val_loss: 0.2876 - val_accuracy: 0.9001 - val_auc: 0.9555\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2729 - accuracy: 0.9045 - auc: 0.9563 - val_loss: 0.2946 - val_accuracy: 0.8914 - val_auc: 0.9548\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2775 - accuracy: 0.9017 - auc: 0.9545 - val_loss: 0.2898 - val_accuracy: 0.8984 - val_auc: 0.9550\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2728 - accuracy: 0.9007 - auc: 0.9556 - val_loss: 0.2932 - val_accuracy: 0.9017 - val_auc: 0.9550\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2803 - accuracy: 0.8955 - auc: 0.9552 - val_loss: 0.3067 - val_accuracy: 0.9189 - val_auc: 0.9530\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2745 - accuracy: 0.9061 - auc: 0.9559 - val_loss: 0.3049 - val_accuracy: 0.9107 - val_auc: 0.9529\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2715 - accuracy: 0.9067 - auc: 0.9561 - val_loss: 0.3074 - val_accuracy: 0.9045 - val_auc: 0.9525\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2655 - accuracy: 0.9040 - auc: 0.9577 - val_loss: 0.3085 - val_accuracy: 0.8985 - val_auc: 0.9521\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2677 - accuracy: 0.9030 - auc: 0.9581 - val_loss: 0.3093 - val_accuracy: 0.9109 - val_auc: 0.9539\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2645 - accuracy: 0.9030 - auc: 0.9586 - val_loss: 0.3243 - val_accuracy: 0.9162 - val_auc: 0.9527\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2607 - accuracy: 0.9090 - auc: 0.9587 - val_loss: 0.3340 - val_accuracy: 0.9129 - val_auc: 0.9513\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2546 - accuracy: 0.9073 - auc: 0.9619 - val_loss: 0.3301 - val_accuracy: 0.9113 - val_auc: 0.9527\n",
      "Epoch 24/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.9096 - auc: 0.9613Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2546 - accuracy: 0.9096 - auc: 0.9613 - val_loss: 0.3398 - val_accuracy: 0.9160 - val_auc: 0.9526\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.5180 - accuracy: 0.8562 - auc: 0.8462 - val_loss: 0.3212 - val_accuracy: 0.8979 - val_auc: 0.9412\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3772 - accuracy: 0.9021 - auc: 0.9248 - val_loss: 0.2964 - val_accuracy: 0.9151 - val_auc: 0.9510\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3418 - accuracy: 0.9096 - auc: 0.9328 - val_loss: 0.2759 - val_accuracy: 0.9197 - val_auc: 0.9552\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3390 - accuracy: 0.9023 - auc: 0.9334 - val_loss: 0.2801 - val_accuracy: 0.9039 - val_auc: 0.9532\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3235 - accuracy: 0.9066 - auc: 0.9410 - val_loss: 0.2768 - val_accuracy: 0.9072 - val_auc: 0.9550\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2982 - accuracy: 0.9116 - auc: 0.9503 - val_loss: 0.2687 - val_accuracy: 0.9139 - val_auc: 0.9573\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3131 - accuracy: 0.9020 - auc: 0.9456 - val_loss: 0.2708 - val_accuracy: 0.9267 - val_auc: 0.9577\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2986 - accuracy: 0.9136 - auc: 0.9495 - val_loss: 0.2755 - val_accuracy: 0.9166 - val_auc: 0.9552\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2942 - accuracy: 0.9112 - auc: 0.9495 - val_loss: 0.2730 - val_accuracy: 0.9073 - val_auc: 0.9569\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2856 - accuracy: 0.9095 - auc: 0.9539 - val_loss: 0.2721 - val_accuracy: 0.9175 - val_auc: 0.9574\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2697 - accuracy: 0.9120 - auc: 0.9566 - val_loss: 0.2837 - val_accuracy: 0.9102 - val_auc: 0.9561\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2890 - accuracy: 0.9044 - auc: 0.9515 - val_loss: 0.2819 - val_accuracy: 0.9005 - val_auc: 0.9559\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2752 - accuracy: 0.9072 - auc: 0.9553 - val_loss: 0.2876 - val_accuracy: 0.9049 - val_auc: 0.9550\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2783 - accuracy: 0.8998 - auc: 0.9539 - val_loss: 0.2996 - val_accuracy: 0.9191 - val_auc: 0.9526\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2782 - accuracy: 0.9054 - auc: 0.9549 - val_loss: 0.2957 - val_accuracy: 0.9127 - val_auc: 0.9529\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2756 - accuracy: 0.9113 - auc: 0.9559 - val_loss: 0.3059 - val_accuracy: 0.9055 - val_auc: 0.9526\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2659 - accuracy: 0.9033 - auc: 0.9585 - val_loss: 0.3010 - val_accuracy: 0.9097 - val_auc: 0.9533\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2567 - accuracy: 0.9077 - auc: 0.9596 - val_loss: 0.3122 - val_accuracy: 0.9066 - val_auc: 0.9530\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2561 - accuracy: 0.9017 - auc: 0.9607 - val_loss: 0.3235 - val_accuracy: 0.9159 - val_auc: 0.9531\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2581 - accuracy: 0.9065 - auc: 0.9593 - val_loss: 0.3420 - val_accuracy: 0.9070 - val_auc: 0.9505\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2554 - accuracy: 0.9064 - auc: 0.9612 - val_loss: 0.3416 - val_accuracy: 0.9051 - val_auc: 0.9506\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2573 - accuracy: 0.9012 - auc: 0.9588 - val_loss: 0.3497 - val_accuracy: 0.9064 - val_auc: 0.9496\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2558 - accuracy: 0.8999 - auc: 0.9600 - val_loss: 0.3521 - val_accuracy: 0.9051 - val_auc: 0.9502\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2629 - accuracy: 0.8982 - auc: 0.9578 - val_loss: 0.3521 - val_accuracy: 0.9079 - val_auc: 0.9494\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2515 - accuracy: 0.8972 - auc: 0.9608 - val_loss: 0.3663 - val_accuracy: 0.9092 - val_auc: 0.9496\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2458 - accuracy: 0.9013 - auc: 0.9625 - val_loss: 0.3765 - val_accuracy: 0.9128 - val_auc: 0.9479\n",
      "Epoch 27/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.9024 - auc: 0.9636Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2444 - accuracy: 0.9023 - auc: 0.9634 - val_loss: 0.3975 - val_accuracy: 0.9114 - val_auc: 0.9463\n",
      "Epoch 00027: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.5830 - accuracy: 0.4853 - auc: 0.8651 - val_loss: 0.2962 - val_accuracy: 0.8449 - val_auc: 0.9490\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3827 - accuracy: 0.7172 - auc: 0.9307 - val_loss: 0.2804 - val_accuracy: 0.8576 - val_auc: 0.9537\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3519 - accuracy: 0.7538 - auc: 0.9400 - val_loss: 0.2713 - val_accuracy: 0.8660 - val_auc: 0.9565\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3152 - accuracy: 0.7674 - auc: 0.9491 - val_loss: 0.2753 - val_accuracy: 0.8799 - val_auc: 0.9556\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2995 - accuracy: 0.7819 - auc: 0.9503 - val_loss: 0.2694 - val_accuracy: 0.8811 - val_auc: 0.9572\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2882 - accuracy: 0.7786 - auc: 0.9536 - val_loss: 0.2937 - val_accuracy: 0.9005 - val_auc: 0.9522\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2905 - accuracy: 0.8356 - auc: 0.9518 - val_loss: 0.2924 - val_accuracy: 0.8898 - val_auc: 0.9518\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2769 - accuracy: 0.8701 - auc: 0.9558 - val_loss: 0.2906 - val_accuracy: 0.9001 - val_auc: 0.9541\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2750 - accuracy: 0.8811 - auc: 0.9554 - val_loss: 0.2962 - val_accuracy: 0.9030 - val_auc: 0.9530\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2673 - accuracy: 0.8874 - auc: 0.9587 - val_loss: 0.3005 - val_accuracy: 0.9013 - val_auc: 0.9514\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2812 - accuracy: 0.8975 - auc: 0.9560 - val_loss: 0.2997 - val_accuracy: 0.8981 - val_auc: 0.9504\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2639 - accuracy: 0.8972 - auc: 0.9604 - val_loss: 0.3085 - val_accuracy: 0.9099 - val_auc: 0.9502\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2640 - accuracy: 0.9033 - auc: 0.9600 - val_loss: 0.3182 - val_accuracy: 0.9151 - val_auc: 0.9490\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2726 - accuracy: 0.9028 - auc: 0.9589 - val_loss: 0.3078 - val_accuracy: 0.9099 - val_auc: 0.9510\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2687 - accuracy: 0.9032 - auc: 0.9579 - val_loss: 0.3251 - val_accuracy: 0.9029 - val_auc: 0.9489\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2594 - accuracy: 0.9012 - auc: 0.9606 - val_loss: 0.3366 - val_accuracy: 0.9151 - val_auc: 0.9466\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2647 - accuracy: 0.9102 - auc: 0.9592 - val_loss: 0.3289 - val_accuracy: 0.9033 - val_auc: 0.9478\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2506 - accuracy: 0.9095 - auc: 0.9638 - val_loss: 0.3395 - val_accuracy: 0.9102 - val_auc: 0.9477\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2669 - accuracy: 0.9031 - auc: 0.9588 - val_loss: 0.3513 - val_accuracy: 0.9044 - val_auc: 0.9431\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2577 - accuracy: 0.9026 - auc: 0.9600 - val_loss: 0.3705 - val_accuracy: 0.9107 - val_auc: 0.9432\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2565 - accuracy: 0.9107 - auc: 0.9622 - val_loss: 0.3679 - val_accuracy: 0.9053 - val_auc: 0.9444\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2540 - accuracy: 0.9016 - auc: 0.9620 - val_loss: 0.3739 - val_accuracy: 0.9149 - val_auc: 0.9423\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2450 - accuracy: 0.9076 - auc: 0.9637 - val_loss: 0.3786 - val_accuracy: 0.9121 - val_auc: 0.9430\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2493 - accuracy: 0.9105 - auc: 0.9637 - val_loss: 0.3886 - val_accuracy: 0.9115 - val_auc: 0.9415\n",
      "Epoch 25/100\n",
      "245760/250291 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 0.9086 - auc: 0.9637Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2495 - accuracy: 0.9087 - auc: 0.9633 - val_loss: 0.4059 - val_accuracy: 0.9115 - val_auc: 0.9414\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.5512 - accuracy: 0.7083 - auc: 0.8641 - val_loss: 0.3006 - val_accuracy: 0.8682 - val_auc: 0.9479\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3303 - accuracy: 0.8464 - auc: 0.9398 - val_loss: 0.2799 - val_accuracy: 0.8731 - val_auc: 0.9535\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3129 - accuracy: 0.8448 - auc: 0.9453 - val_loss: 0.2712 - val_accuracy: 0.9082 - val_auc: 0.9567\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2861 - accuracy: 0.8821 - auc: 0.9528 - val_loss: 0.2657 - val_accuracy: 0.8926 - val_auc: 0.9575\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2760 - accuracy: 0.8774 - auc: 0.9554 - val_loss: 0.2722 - val_accuracy: 0.8907 - val_auc: 0.9559\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2641 - accuracy: 0.8868 - auc: 0.9589 - val_loss: 0.2625 - val_accuracy: 0.8918 - val_auc: 0.9593\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2756 - accuracy: 0.8780 - auc: 0.9558 - val_loss: 0.2613 - val_accuracy: 0.8818 - val_auc: 0.9593\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2608 - accuracy: 0.8881 - auc: 0.9596 - val_loss: 0.2658 - val_accuracy: 0.8953 - val_auc: 0.9589\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2493 - accuracy: 0.8860 - auc: 0.9637 - val_loss: 0.2613 - val_accuracy: 0.9074 - val_auc: 0.9607\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2442 - accuracy: 0.8963 - auc: 0.9645 - val_loss: 0.2666 - val_accuracy: 0.9152 - val_auc: 0.9603\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2448 - accuracy: 0.9008 - auc: 0.9645 - val_loss: 0.2699 - val_accuracy: 0.9042 - val_auc: 0.9583\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2406 - accuracy: 0.8966 - auc: 0.9653 - val_loss: 0.2760 - val_accuracy: 0.9069 - val_auc: 0.9569\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2519 - accuracy: 0.8921 - auc: 0.9622 - val_loss: 0.2695 - val_accuracy: 0.9083 - val_auc: 0.9590\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2324 - accuracy: 0.8988 - auc: 0.9674 - val_loss: 0.2865 - val_accuracy: 0.9108 - val_auc: 0.9551\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2343 - accuracy: 0.8965 - auc: 0.9674 - val_loss: 0.2952 - val_accuracy: 0.9097 - val_auc: 0.9542\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2402 - accuracy: 0.8979 - auc: 0.9652 - val_loss: 0.3072 - val_accuracy: 0.9161 - val_auc: 0.9526\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2359 - accuracy: 0.8976 - auc: 0.9660 - val_loss: 0.2977 - val_accuracy: 0.9128 - val_auc: 0.9537\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2282 - accuracy: 0.8969 - auc: 0.9679 - val_loss: 0.3048 - val_accuracy: 0.9094 - val_auc: 0.9542\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2239 - accuracy: 0.8955 - auc: 0.9691 - val_loss: 0.3190 - val_accuracy: 0.9145 - val_auc: 0.9531\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2318 - accuracy: 0.8970 - auc: 0.9670 - val_loss: 0.3227 - val_accuracy: 0.9067 - val_auc: 0.9537\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2305 - accuracy: 0.8905 - auc: 0.9677 - val_loss: 0.3301 - val_accuracy: 0.9123 - val_auc: 0.9527\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2231 - accuracy: 0.8905 - auc: 0.9691 - val_loss: 0.3493 - val_accuracy: 0.9122 - val_auc: 0.9522\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2302 - accuracy: 0.8925 - auc: 0.9679 - val_loss: 0.3458 - val_accuracy: 0.9065 - val_auc: 0.9504\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2188 - accuracy: 0.8982 - auc: 0.9702 - val_loss: 0.3664 - val_accuracy: 0.9205 - val_auc: 0.9498\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2156 - accuracy: 0.9012 - auc: 0.9711 - val_loss: 0.3688 - val_accuracy: 0.9118 - val_auc: 0.9519\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2267 - accuracy: 0.8933 - auc: 0.9690 - val_loss: 0.3785 - val_accuracy: 0.9084 - val_auc: 0.9486\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2191 - accuracy: 0.8965 - auc: 0.9707 - val_loss: 0.3977 - val_accuracy: 0.9177 - val_auc: 0.9470\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2142 - accuracy: 0.8989 - auc: 0.9717 - val_loss: 0.4240 - val_accuracy: 0.9156 - val_auc: 0.9456\n",
      "Epoch 29/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2221 - accuracy: 0.8966 - auc: 0.9707Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2208 - accuracy: 0.8963 - auc: 0.9706 - val_loss: 0.4324 - val_accuracy: 0.9147 - val_auc: 0.9465\n",
      "Epoch 00029: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 4s 18us/sample - loss: 0.6734 - accuracy: 0.8473 - auc: 0.8339 - val_loss: 0.3745 - val_accuracy: 0.8868 - val_auc: 0.9403\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4019 - accuracy: 0.8871 - auc: 0.9234 - val_loss: 0.3126 - val_accuracy: 0.9168 - val_auc: 0.9443\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3378 - accuracy: 0.9044 - auc: 0.9384 - val_loss: 0.2829 - val_accuracy: 0.9179 - val_auc: 0.9556\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3152 - accuracy: 0.9094 - auc: 0.9467 - val_loss: 0.2752 - val_accuracy: 0.9123 - val_auc: 0.9551\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2962 - accuracy: 0.9130 - auc: 0.9518 - val_loss: 0.2776 - val_accuracy: 0.9119 - val_auc: 0.9533\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3050 - accuracy: 0.9084 - auc: 0.9495 - val_loss: 0.2774 - val_accuracy: 0.9026 - val_auc: 0.9542\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2865 - accuracy: 0.9095 - auc: 0.9557 - val_loss: 0.2852 - val_accuracy: 0.9122 - val_auc: 0.9516\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2796 - accuracy: 0.9090 - auc: 0.9570 - val_loss: 0.2844 - val_accuracy: 0.9180 - val_auc: 0.9532\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2748 - accuracy: 0.9138 - auc: 0.9571 - val_loss: 0.2948 - val_accuracy: 0.9216 - val_auc: 0.9506\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2802 - accuracy: 0.9104 - auc: 0.9573 - val_loss: 0.2900 - val_accuracy: 0.9209 - val_auc: 0.9519\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2642 - accuracy: 0.9160 - auc: 0.9608 - val_loss: 0.3038 - val_accuracy: 0.9215 - val_auc: 0.9491\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2713 - accuracy: 0.9089 - auc: 0.9586 - val_loss: 0.3071 - val_accuracy: 0.9076 - val_auc: 0.9502\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2650 - accuracy: 0.9141 - auc: 0.9612 - val_loss: 0.3084 - val_accuracy: 0.9197 - val_auc: 0.9506\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2608 - accuracy: 0.9149 - auc: 0.9618 - val_loss: 0.3163 - val_accuracy: 0.9175 - val_auc: 0.9499\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2441 - accuracy: 0.9194 - auc: 0.9660 - val_loss: 0.3378 - val_accuracy: 0.9194 - val_auc: 0.9479\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2674 - accuracy: 0.9116 - auc: 0.9601 - val_loss: 0.3302 - val_accuracy: 0.9273 - val_auc: 0.9493\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2435 - accuracy: 0.9137 - auc: 0.9662 - val_loss: 0.3340 - val_accuracy: 0.9163 - val_auc: 0.9478\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2388 - accuracy: 0.9153 - auc: 0.9674 - val_loss: 0.3433 - val_accuracy: 0.9242 - val_auc: 0.9472\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2385 - accuracy: 0.9150 - auc: 0.9669 - val_loss: 0.3572 - val_accuracy: 0.9166 - val_auc: 0.9484\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2484 - accuracy: 0.9146 - auc: 0.9647 - val_loss: 0.3582 - val_accuracy: 0.9124 - val_auc: 0.9488\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2365 - accuracy: 0.9078 - auc: 0.9665 - val_loss: 0.3726 - val_accuracy: 0.9219 - val_auc: 0.9479\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2304 - accuracy: 0.9121 - auc: 0.9685 - val_loss: 0.3814 - val_accuracy: 0.9286 - val_auc: 0.9481\n",
      "Epoch 23/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2370 - accuracy: 0.9132 - auc: 0.9667Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2368 - accuracy: 0.9131 - auc: 0.9666 - val_loss: 0.3741 - val_accuracy: 0.9181 - val_auc: 0.9474\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.4843 - accuracy: 0.8570 - auc: 0.8751 - val_loss: 0.3094 - val_accuracy: 0.8979 - val_auc: 0.9493\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3259 - accuracy: 0.9054 - auc: 0.9401 - val_loss: 0.2891 - val_accuracy: 0.9043 - val_auc: 0.9549\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3062 - accuracy: 0.9065 - auc: 0.9486 - val_loss: 0.2756 - val_accuracy: 0.8966 - val_auc: 0.9578\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2954 - accuracy: 0.9086 - auc: 0.9520 - val_loss: 0.2775 - val_accuracy: 0.9280 - val_auc: 0.9564\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2890 - accuracy: 0.9114 - auc: 0.9548 - val_loss: 0.2704 - val_accuracy: 0.9213 - val_auc: 0.9571\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2898 - accuracy: 0.9079 - auc: 0.9535 - val_loss: 0.2728 - val_accuracy: 0.9154 - val_auc: 0.9562\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2711 - accuracy: 0.9140 - auc: 0.9599 - val_loss: 0.2699 - val_accuracy: 0.9044 - val_auc: 0.9573\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2752 - accuracy: 0.9138 - auc: 0.9587 - val_loss: 0.2773 - val_accuracy: 0.9118 - val_auc: 0.9541\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2769 - accuracy: 0.9090 - auc: 0.9566 - val_loss: 0.2705 - val_accuracy: 0.9200 - val_auc: 0.9570\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2638 - accuracy: 0.9144 - auc: 0.9609 - val_loss: 0.2709 - val_accuracy: 0.9257 - val_auc: 0.9567\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2695 - accuracy: 0.9154 - auc: 0.9590 - val_loss: 0.2744 - val_accuracy: 0.9160 - val_auc: 0.9561\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2759 - accuracy: 0.9094 - auc: 0.9583 - val_loss: 0.2803 - val_accuracy: 0.8986 - val_auc: 0.9558\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2722 - accuracy: 0.9128 - auc: 0.9579 - val_loss: 0.2906 - val_accuracy: 0.9159 - val_auc: 0.9534\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2624 - accuracy: 0.9120 - auc: 0.9610 - val_loss: 0.2957 - val_accuracy: 0.9159 - val_auc: 0.9527\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2605 - accuracy: 0.9131 - auc: 0.9614 - val_loss: 0.2932 - val_accuracy: 0.9152 - val_auc: 0.9549\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2596 - accuracy: 0.9148 - auc: 0.9618 - val_loss: 0.3027 - val_accuracy: 0.9305 - val_auc: 0.9516\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2453 - accuracy: 0.9148 - auc: 0.9653 - val_loss: 0.3085 - val_accuracy: 0.9260 - val_auc: 0.9504\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2499 - accuracy: 0.9143 - auc: 0.9634 - val_loss: 0.3182 - val_accuracy: 0.9257 - val_auc: 0.9499\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2486 - accuracy: 0.9175 - auc: 0.9636 - val_loss: 0.3300 - val_accuracy: 0.9263 - val_auc: 0.9478\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2473 - accuracy: 0.9194 - auc: 0.9653 - val_loss: 0.3300 - val_accuracy: 0.9060 - val_auc: 0.9497\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2457 - accuracy: 0.9189 - auc: 0.9650 - val_loss: 0.3191 - val_accuracy: 0.9045 - val_auc: 0.9525\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2459 - accuracy: 0.9139 - auc: 0.9648 - val_loss: 0.3271 - val_accuracy: 0.9237 - val_auc: 0.9526\n",
      "Epoch 23/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.9147 - auc: 0.9654Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2469 - accuracy: 0.9147 - auc: 0.9655 - val_loss: 0.3411 - val_accuracy: 0.9265 - val_auc: 0.9499\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 14us/sample - loss: 0.5330 - accuracy: 0.8619 - auc: 0.8626 - val_loss: 0.3400 - val_accuracy: 0.9253 - val_auc: 0.9340\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3881 - accuracy: 0.9047 - auc: 0.9195 - val_loss: 0.3121 - val_accuracy: 0.9127 - val_auc: 0.9492\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3460 - accuracy: 0.9088 - auc: 0.9394 - val_loss: 0.2868 - val_accuracy: 0.9157 - val_auc: 0.9546\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3220 - accuracy: 0.9103 - auc: 0.9443 - val_loss: 0.2776 - val_accuracy: 0.9134 - val_auc: 0.9555\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2955 - accuracy: 0.9132 - auc: 0.9514 - val_loss: 0.2791 - val_accuracy: 0.9101 - val_auc: 0.9546\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3040 - accuracy: 0.9112 - auc: 0.9507 - val_loss: 0.2769 - val_accuracy: 0.9084 - val_auc: 0.9552\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2892 - accuracy: 0.9125 - auc: 0.9531 - val_loss: 0.2822 - val_accuracy: 0.9251 - val_auc: 0.9532\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2832 - accuracy: 0.9115 - auc: 0.9568 - val_loss: 0.2844 - val_accuracy: 0.9304 - val_auc: 0.9532\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2892 - accuracy: 0.9120 - auc: 0.9555 - val_loss: 0.2884 - val_accuracy: 0.9234 - val_auc: 0.9513\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2816 - accuracy: 0.9157 - auc: 0.9570 - val_loss: 0.2820 - val_accuracy: 0.9134 - val_auc: 0.9530\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2577 - accuracy: 0.9136 - auc: 0.9621 - val_loss: 0.2921 - val_accuracy: 0.9127 - val_auc: 0.9520\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2716 - accuracy: 0.9115 - auc: 0.9596 - val_loss: 0.2968 - val_accuracy: 0.9208 - val_auc: 0.9500\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2698 - accuracy: 0.9140 - auc: 0.9597 - val_loss: 0.3091 - val_accuracy: 0.9192 - val_auc: 0.9479\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2509 - accuracy: 0.9183 - auc: 0.9637 - val_loss: 0.3185 - val_accuracy: 0.9230 - val_auc: 0.9495\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2519 - accuracy: 0.9159 - auc: 0.9630 - val_loss: 0.3063 - val_accuracy: 0.9165 - val_auc: 0.9501\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2451 - accuracy: 0.9112 - auc: 0.9649 - val_loss: 0.3205 - val_accuracy: 0.9255 - val_auc: 0.9493\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2523 - accuracy: 0.9145 - auc: 0.9629 - val_loss: 0.3268 - val_accuracy: 0.9189 - val_auc: 0.9467\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2363 - accuracy: 0.9138 - auc: 0.9667 - val_loss: 0.3433 - val_accuracy: 0.9164 - val_auc: 0.9463\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2318 - accuracy: 0.9130 - auc: 0.9684 - val_loss: 0.3448 - val_accuracy: 0.9148 - val_auc: 0.9474\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2324 - accuracy: 0.9139 - auc: 0.9684 - val_loss: 0.3656 - val_accuracy: 0.9265 - val_auc: 0.9450\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2394 - accuracy: 0.9139 - auc: 0.9667 - val_loss: 0.3753 - val_accuracy: 0.9246 - val_auc: 0.9431\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2325 - accuracy: 0.9137 - auc: 0.9674 - val_loss: 0.3802 - val_accuracy: 0.9110 - val_auc: 0.9442\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2306 - accuracy: 0.9070 - auc: 0.9676 - val_loss: 0.3854 - val_accuracy: 0.9179 - val_auc: 0.9456\n",
      "Epoch 24/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9094 - auc: 0.9686Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2286 - accuracy: 0.9093 - auc: 0.9686 - val_loss: 0.4008 - val_accuracy: 0.9104 - val_auc: 0.9428\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.5280 - accuracy: 0.7747 - auc: 0.8642 - val_loss: 0.3284 - val_accuracy: 0.8898 - val_auc: 0.9426\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3357 - accuracy: 0.8908 - auc: 0.9383 - val_loss: 0.2833 - val_accuracy: 0.8945 - val_auc: 0.9524\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3081 - accuracy: 0.8956 - auc: 0.9475 - val_loss: 0.2683 - val_accuracy: 0.9148 - val_auc: 0.9552\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2878 - accuracy: 0.9063 - auc: 0.9532 - val_loss: 0.2645 - val_accuracy: 0.9024 - val_auc: 0.9576\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2861 - accuracy: 0.9067 - auc: 0.9535 - val_loss: 0.2680 - val_accuracy: 0.9088 - val_auc: 0.9572\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2639 - accuracy: 0.9091 - auc: 0.9601 - val_loss: 0.2747 - val_accuracy: 0.9061 - val_auc: 0.9555\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2711 - accuracy: 0.8995 - auc: 0.9583 - val_loss: 0.2820 - val_accuracy: 0.9159 - val_auc: 0.9535\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2583 - accuracy: 0.9099 - auc: 0.9616 - val_loss: 0.2879 - val_accuracy: 0.9074 - val_auc: 0.9517\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2470 - accuracy: 0.9124 - auc: 0.9647 - val_loss: 0.3017 - val_accuracy: 0.9133 - val_auc: 0.9500\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2469 - accuracy: 0.9102 - auc: 0.9644 - val_loss: 0.3122 - val_accuracy: 0.9171 - val_auc: 0.9474\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2378 - accuracy: 0.9118 - auc: 0.9666 - val_loss: 0.3209 - val_accuracy: 0.9094 - val_auc: 0.9479\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2364 - accuracy: 0.9074 - auc: 0.9668 - val_loss: 0.3245 - val_accuracy: 0.9150 - val_auc: 0.9485\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2296 - accuracy: 0.9105 - auc: 0.9689 - val_loss: 0.3368 - val_accuracy: 0.9191 - val_auc: 0.9475\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2318 - accuracy: 0.9088 - auc: 0.9675 - val_loss: 0.3400 - val_accuracy: 0.9130 - val_auc: 0.9483\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2359 - accuracy: 0.9056 - auc: 0.9667 - val_loss: 0.3470 - val_accuracy: 0.9168 - val_auc: 0.9476\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2277 - accuracy: 0.9087 - auc: 0.9683 - val_loss: 0.3503 - val_accuracy: 0.9092 - val_auc: 0.9489\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2277 - accuracy: 0.9052 - auc: 0.9691 - val_loss: 0.3492 - val_accuracy: 0.9181 - val_auc: 0.9516\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2167 - accuracy: 0.9081 - auc: 0.9715 - val_loss: 0.3837 - val_accuracy: 0.9175 - val_auc: 0.9448\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2170 - accuracy: 0.9036 - auc: 0.9703 - val_loss: 0.4032 - val_accuracy: 0.9204 - val_auc: 0.9443\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2190 - accuracy: 0.9061 - auc: 0.9710 - val_loss: 0.4222 - val_accuracy: 0.9111 - val_auc: 0.9434\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2153 - accuracy: 0.9029 - auc: 0.9716 - val_loss: 0.4326 - val_accuracy: 0.9209 - val_auc: 0.9434\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2066 - accuracy: 0.9067 - auc: 0.9732 - val_loss: 0.4537 - val_accuracy: 0.9237 - val_auc: 0.9420\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2115 - accuracy: 0.9025 - auc: 0.9715 - val_loss: 0.4426 - val_accuracy: 0.9245 - val_auc: 0.9457\n",
      "Epoch 24/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9061 - auc: 0.9701Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2210 - accuracy: 0.9061 - auc: 0.9700 - val_loss: 0.4470 - val_accuracy: 0.9097 - val_auc: 0.9451\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.9006 - accuracy: 0.5404 - auc: 0.6656 - val_loss: 0.5417 - val_accuracy: 0.5629 - val_auc: 0.8974\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6048 - accuracy: 0.6629 - auc: 0.8011 - val_loss: 0.4596 - val_accuracy: 0.7401 - val_auc: 0.9214\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5523 - accuracy: 0.7598 - auc: 0.8168 - val_loss: 0.4224 - val_accuracy: 0.8255 - val_auc: 0.9313\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4920 - accuracy: 0.8136 - auc: 0.8674 - val_loss: 0.3960 - val_accuracy: 0.8536 - val_auc: 0.9369\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4669 - accuracy: 0.8442 - auc: 0.8819 - val_loss: 0.3763 - val_accuracy: 0.8752 - val_auc: 0.9393\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4386 - accuracy: 0.8637 - auc: 0.8933 - val_loss: 0.3604 - val_accuracy: 0.8894 - val_auc: 0.9420\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4254 - accuracy: 0.8818 - auc: 0.8972 - val_loss: 0.3463 - val_accuracy: 0.8959 - val_auc: 0.9482\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4072 - accuracy: 0.8860 - auc: 0.9067 - val_loss: 0.3372 - val_accuracy: 0.8973 - val_auc: 0.9489\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3983 - accuracy: 0.8948 - auc: 0.9072 - val_loss: 0.3304 - val_accuracy: 0.9044 - val_auc: 0.9511\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3844 - accuracy: 0.8962 - auc: 0.9190 - val_loss: 0.3225 - val_accuracy: 0.9030 - val_auc: 0.9527\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3915 - accuracy: 0.8995 - auc: 0.9121 - val_loss: 0.3180 - val_accuracy: 0.9049 - val_auc: 0.9524\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3631 - accuracy: 0.9034 - auc: 0.9268 - val_loss: 0.3137 - val_accuracy: 0.9088 - val_auc: 0.9522\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3750 - accuracy: 0.9060 - auc: 0.9201 - val_loss: 0.3084 - val_accuracy: 0.9089 - val_auc: 0.9538\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3655 - accuracy: 0.9083 - auc: 0.9242 - val_loss: 0.3043 - val_accuracy: 0.9081 - val_auc: 0.9540\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3699 - accuracy: 0.9072 - auc: 0.9240 - val_loss: 0.3006 - val_accuracy: 0.9079 - val_auc: 0.9547\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3569 - accuracy: 0.9093 - auc: 0.9302 - val_loss: 0.2961 - val_accuracy: 0.9087 - val_auc: 0.9553\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3549 - accuracy: 0.9040 - auc: 0.9273 - val_loss: 0.2926 - val_accuracy: 0.9070 - val_auc: 0.9564\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3572 - accuracy: 0.9088 - auc: 0.9269 - val_loss: 0.2925 - val_accuracy: 0.9111 - val_auc: 0.9563\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3576 - accuracy: 0.9147 - auc: 0.9226 - val_loss: 0.2920 - val_accuracy: 0.9144 - val_auc: 0.9564\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3436 - accuracy: 0.9155 - auc: 0.9310 - val_loss: 0.2893 - val_accuracy: 0.9173 - val_auc: 0.9570\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3515 - accuracy: 0.9175 - auc: 0.9257 - val_loss: 0.2869 - val_accuracy: 0.9182 - val_auc: 0.9576\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3497 - accuracy: 0.9196 - auc: 0.9273 - val_loss: 0.2851 - val_accuracy: 0.9140 - val_auc: 0.9572\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3564 - accuracy: 0.9147 - auc: 0.9241 - val_loss: 0.2841 - val_accuracy: 0.9158 - val_auc: 0.9570\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3388 - accuracy: 0.9181 - auc: 0.9352 - val_loss: 0.2820 - val_accuracy: 0.9179 - val_auc: 0.9577\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3286 - accuracy: 0.9164 - auc: 0.9394 - val_loss: 0.2781 - val_accuracy: 0.9164 - val_auc: 0.9585\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3350 - accuracy: 0.9180 - auc: 0.9339 - val_loss: 0.2770 - val_accuracy: 0.9168 - val_auc: 0.9588\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3363 - accuracy: 0.9195 - auc: 0.9351 - val_loss: 0.2757 - val_accuracy: 0.9166 - val_auc: 0.9590\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3398 - accuracy: 0.9191 - auc: 0.9297 - val_loss: 0.2739 - val_accuracy: 0.9171 - val_auc: 0.9594\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3348 - accuracy: 0.9175 - auc: 0.9366 - val_loss: 0.2742 - val_accuracy: 0.9179 - val_auc: 0.9595\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3348 - accuracy: 0.9227 - auc: 0.9327 - val_loss: 0.2732 - val_accuracy: 0.9179 - val_auc: 0.9597\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3417 - accuracy: 0.9198 - auc: 0.9309 - val_loss: 0.2719 - val_accuracy: 0.9194 - val_auc: 0.9602\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3268 - accuracy: 0.9173 - auc: 0.9377 - val_loss: 0.2697 - val_accuracy: 0.9179 - val_auc: 0.9609\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3360 - accuracy: 0.9209 - auc: 0.9321 - val_loss: 0.2700 - val_accuracy: 0.9206 - val_auc: 0.9605\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3249 - accuracy: 0.9224 - auc: 0.9357 - val_loss: 0.2700 - val_accuracy: 0.9197 - val_auc: 0.9600\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3334 - accuracy: 0.9213 - auc: 0.9290 - val_loss: 0.2698 - val_accuracy: 0.9196 - val_auc: 0.9600\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3327 - accuracy: 0.9225 - auc: 0.9350 - val_loss: 0.2694 - val_accuracy: 0.9202 - val_auc: 0.9597\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3285 - accuracy: 0.9223 - auc: 0.9336 - val_loss: 0.2676 - val_accuracy: 0.9186 - val_auc: 0.9602\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3327 - accuracy: 0.9205 - auc: 0.9333 - val_loss: 0.2680 - val_accuracy: 0.9183 - val_auc: 0.9600\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3330 - accuracy: 0.9192 - auc: 0.9339 - val_loss: 0.2670 - val_accuracy: 0.9198 - val_auc: 0.9604\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3371 - accuracy: 0.9227 - auc: 0.9314 - val_loss: 0.2681 - val_accuracy: 0.9181 - val_auc: 0.9599\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3221 - accuracy: 0.9230 - auc: 0.9391 - val_loss: 0.2672 - val_accuracy: 0.9195 - val_auc: 0.9602\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3326 - accuracy: 0.9213 - auc: 0.9339 - val_loss: 0.2662 - val_accuracy: 0.9195 - val_auc: 0.9604\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3214 - accuracy: 0.9235 - auc: 0.9370 - val_loss: 0.2649 - val_accuracy: 0.9205 - val_auc: 0.9610\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3366 - accuracy: 0.9229 - auc: 0.9312 - val_loss: 0.2650 - val_accuracy: 0.9208 - val_auc: 0.9610\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3193 - accuracy: 0.9236 - auc: 0.9429 - val_loss: 0.2651 - val_accuracy: 0.9214 - val_auc: 0.9607\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3192 - accuracy: 0.9225 - auc: 0.9408 - val_loss: 0.2677 - val_accuracy: 0.9217 - val_auc: 0.9598\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3331 - accuracy: 0.9256 - auc: 0.9333 - val_loss: 0.2670 - val_accuracy: 0.9224 - val_auc: 0.9596\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3318 - accuracy: 0.9248 - auc: 0.9340 - val_loss: 0.2688 - val_accuracy: 0.9230 - val_auc: 0.9592\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3250 - accuracy: 0.9253 - auc: 0.9392 - val_loss: 0.2674 - val_accuracy: 0.9216 - val_auc: 0.9594\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3222 - accuracy: 0.9248 - auc: 0.9384 - val_loss: 0.2683 - val_accuracy: 0.9214 - val_auc: 0.9592\n",
      "Epoch 51/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3237 - accuracy: 0.9240 - auc: 0.9389 - val_loss: 0.2689 - val_accuracy: 0.9215 - val_auc: 0.9596\n",
      "Epoch 52/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3279 - accuracy: 0.9256 - auc: 0.9359 - val_loss: 0.2660 - val_accuracy: 0.9214 - val_auc: 0.9594\n",
      "Epoch 53/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3251 - accuracy: 0.9241 - auc: 0.9389 - val_loss: 0.2696 - val_accuracy: 0.9215 - val_auc: 0.9581\n",
      "Epoch 54/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3481 - accuracy: 0.9250 - auc: 0.9224 - val_loss: 0.2684 - val_accuracy: 0.9236 - val_auc: 0.9588\n",
      "Epoch 55/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3153 - accuracy: 0.9268 - auc: 0.9417 - val_loss: 0.2676 - val_accuracy: 0.9247 - val_auc: 0.9589\n",
      "Epoch 56/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3247 - accuracy: 0.9275 - auc: 0.9348 - val_loss: 0.2685 - val_accuracy: 0.9236 - val_auc: 0.9584\n",
      "Epoch 57/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3227 - accuracy: 0.9256 - auc: 0.9375 - val_loss: 0.2699 - val_accuracy: 0.9220 - val_auc: 0.9580\n",
      "Epoch 58/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3117 - accuracy: 0.9268 - auc: 0.9414 - val_loss: 0.2668 - val_accuracy: 0.9244 - val_auc: 0.9587\n",
      "Epoch 59/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3376 - accuracy: 0.9270 - auc: 0.9278 - val_loss: 0.2660 - val_accuracy: 0.9246 - val_auc: 0.9586\n",
      "Epoch 60/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3089 - accuracy: 0.9269 - auc: 0.9427 - val_loss: 0.2664 - val_accuracy: 0.9241 - val_auc: 0.9584\n",
      "Epoch 61/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3287 - accuracy: 0.9267 - auc: 0.9323 - val_loss: 0.2675 - val_accuracy: 0.9240 - val_auc: 0.9588\n",
      "Epoch 62/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3188 - accuracy: 0.9279 - auc: 0.9366 - val_loss: 0.2672 - val_accuracy: 0.9256 - val_auc: 0.9585\n",
      "Epoch 63/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3268 - accuracy: 0.9278 - auc: 0.9342 - val_loss: 0.2686 - val_accuracy: 0.9249 - val_auc: 0.9583\n",
      "Epoch 64/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.9286 - auc: 0.9374Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3213 - accuracy: 0.9284 - auc: 0.9380 - val_loss: 0.2667 - val_accuracy: 0.9237 - val_auc: 0.9588\n",
      "Epoch 00064: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.9372 - accuracy: 0.0099 - auc: 0.6850 - val_loss: 0.8265 - val_accuracy: 0.0049 - val_auc: 0.8010\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.7996 - accuracy: 0.0280 - auc: 0.7715 - val_loss: 0.7134 - val_accuracy: 0.0131 - val_auc: 0.8877\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.7025 - accuracy: 0.1066 - auc: 0.8355 - val_loss: 0.6266 - val_accuracy: 0.0891 - val_auc: 0.9105\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6309 - accuracy: 0.2342 - auc: 0.8673 - val_loss: 0.5555 - val_accuracy: 0.2681 - val_auc: 0.9173\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5817 - accuracy: 0.3452 - auc: 0.8765 - val_loss: 0.4952 - val_accuracy: 0.4544 - val_auc: 0.9246\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5457 - accuracy: 0.4159 - auc: 0.8747 - val_loss: 0.4472 - val_accuracy: 0.5846 - val_auc: 0.9334\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5086 - accuracy: 0.4619 - auc: 0.8953 - val_loss: 0.4102 - val_accuracy: 0.6692 - val_auc: 0.9381\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4874 - accuracy: 0.4936 - auc: 0.8929 - val_loss: 0.3819 - val_accuracy: 0.7199 - val_auc: 0.9430\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4629 - accuracy: 0.5181 - auc: 0.9022 - val_loss: 0.3575 - val_accuracy: 0.7600 - val_auc: 0.9463\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4432 - accuracy: 0.5396 - auc: 0.9082 - val_loss: 0.3400 - val_accuracy: 0.7812 - val_auc: 0.9489\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4383 - accuracy: 0.5543 - auc: 0.9034 - val_loss: 0.3272 - val_accuracy: 0.7979 - val_auc: 0.9503\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4151 - accuracy: 0.5664 - auc: 0.9172 - val_loss: 0.3146 - val_accuracy: 0.8128 - val_auc: 0.9515\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4093 - accuracy: 0.5746 - auc: 0.9161 - val_loss: 0.3063 - val_accuracy: 0.8195 - val_auc: 0.9525\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4082 - accuracy: 0.5806 - auc: 0.9076 - val_loss: 0.2991 - val_accuracy: 0.8270 - val_auc: 0.9534\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3949 - accuracy: 0.5845 - auc: 0.9145 - val_loss: 0.2940 - val_accuracy: 0.8322 - val_auc: 0.9540\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4004 - accuracy: 0.5895 - auc: 0.9083 - val_loss: 0.2899 - val_accuracy: 0.8366 - val_auc: 0.9547\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3784 - accuracy: 0.5956 - auc: 0.9201 - val_loss: 0.2851 - val_accuracy: 0.8428 - val_auc: 0.9554\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3821 - accuracy: 0.5990 - auc: 0.9197 - val_loss: 0.2808 - val_accuracy: 0.8482 - val_auc: 0.9561\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3695 - accuracy: 0.6036 - auc: 0.9226 - val_loss: 0.2784 - val_accuracy: 0.8525 - val_auc: 0.9564\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3836 - accuracy: 0.6065 - auc: 0.9133 - val_loss: 0.2766 - val_accuracy: 0.8511 - val_auc: 0.9572\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3583 - accuracy: 0.6085 - auc: 0.9270 - val_loss: 0.2747 - val_accuracy: 0.8561 - val_auc: 0.9569\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3654 - accuracy: 0.6094 - auc: 0.9214 - val_loss: 0.2739 - val_accuracy: 0.8565 - val_auc: 0.9570\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3622 - accuracy: 0.6113 - auc: 0.9250 - val_loss: 0.2721 - val_accuracy: 0.8601 - val_auc: 0.9572\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3628 - accuracy: 0.6144 - auc: 0.9258 - val_loss: 0.2715 - val_accuracy: 0.8606 - val_auc: 0.9577\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3535 - accuracy: 0.6136 - auc: 0.9226 - val_loss: 0.2703 - val_accuracy: 0.8642 - val_auc: 0.9579\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3491 - accuracy: 0.6150 - auc: 0.9276 - val_loss: 0.2686 - val_accuracy: 0.8656 - val_auc: 0.9582\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3513 - accuracy: 0.6167 - auc: 0.9245 - val_loss: 0.2671 - val_accuracy: 0.8687 - val_auc: 0.9586\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3439 - accuracy: 0.6179 - auc: 0.9277 - val_loss: 0.2664 - val_accuracy: 0.8716 - val_auc: 0.9588\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3471 - accuracy: 0.6219 - auc: 0.9285 - val_loss: 0.2659 - val_accuracy: 0.8709 - val_auc: 0.9588\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3428 - accuracy: 0.6198 - auc: 0.9258 - val_loss: 0.2658 - val_accuracy: 0.8720 - val_auc: 0.9589\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3619 - accuracy: 0.6199 - auc: 0.9191 - val_loss: 0.2651 - val_accuracy: 0.8709 - val_auc: 0.9592\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3377 - accuracy: 0.6204 - auc: 0.9320 - val_loss: 0.2658 - val_accuracy: 0.8714 - val_auc: 0.9589\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3440 - accuracy: 0.6224 - auc: 0.9274 - val_loss: 0.2662 - val_accuracy: 0.8729 - val_auc: 0.9593\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3541 - accuracy: 0.6182 - auc: 0.9197 - val_loss: 0.2677 - val_accuracy: 0.8705 - val_auc: 0.9586\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3390 - accuracy: 0.6196 - auc: 0.9269 - val_loss: 0.2674 - val_accuracy: 0.8738 - val_auc: 0.9589\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3382 - accuracy: 0.6213 - auc: 0.9310 - val_loss: 0.2662 - val_accuracy: 0.8723 - val_auc: 0.9588\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3275 - accuracy: 0.7434 - auc: 0.9326 - val_loss: 0.2662 - val_accuracy: 0.8996 - val_auc: 0.9589\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3309 - accuracy: 0.8885 - auc: 0.9302 - val_loss: 0.2671 - val_accuracy: 0.9020 - val_auc: 0.9584\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3275 - accuracy: 0.8968 - auc: 0.9347 - val_loss: 0.2651 - val_accuracy: 0.9022 - val_auc: 0.9593\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3242 - accuracy: 0.8930 - auc: 0.9344 - val_loss: 0.2639 - val_accuracy: 0.9021 - val_auc: 0.9595\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3443 - accuracy: 0.8967 - auc: 0.9270 - val_loss: 0.2634 - val_accuracy: 0.9029 - val_auc: 0.9600\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3329 - accuracy: 0.8982 - auc: 0.9307 - val_loss: 0.2640 - val_accuracy: 0.9042 - val_auc: 0.9596\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3316 - accuracy: 0.8987 - auc: 0.9297 - val_loss: 0.2647 - val_accuracy: 0.9044 - val_auc: 0.9595\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3261 - accuracy: 0.9011 - auc: 0.9331 - val_loss: 0.2673 - val_accuracy: 0.9083 - val_auc: 0.9589\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3244 - accuracy: 0.9056 - auc: 0.9325 - val_loss: 0.2663 - val_accuracy: 0.9103 - val_auc: 0.9594\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3297 - accuracy: 0.9078 - auc: 0.9279 - val_loss: 0.2650 - val_accuracy: 0.9097 - val_auc: 0.9598\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3390 - accuracy: 0.9065 - auc: 0.9265 - val_loss: 0.2670 - val_accuracy: 0.9091 - val_auc: 0.9592\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3320 - accuracy: 0.9103 - auc: 0.9307 - val_loss: 0.2672 - val_accuracy: 0.9094 - val_auc: 0.9587\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3313 - accuracy: 0.9092 - auc: 0.9306 - val_loss: 0.2681 - val_accuracy: 0.9102 - val_auc: 0.9586\n",
      "Epoch 50/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3274 - accuracy: 0.9119 - auc: 0.9310 - val_loss: 0.2672 - val_accuracy: 0.9117 - val_auc: 0.9591\n",
      "Epoch 51/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3257 - accuracy: 0.9137 - auc: 0.9321 - val_loss: 0.2674 - val_accuracy: 0.9124 - val_auc: 0.9589\n",
      "Epoch 52/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3241 - accuracy: 0.9124 - auc: 0.9330 - val_loss: 0.2671 - val_accuracy: 0.9119 - val_auc: 0.9586\n",
      "Epoch 53/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3269 - accuracy: 0.9098 - auc: 0.9267 - val_loss: 0.2669 - val_accuracy: 0.9121 - val_auc: 0.9586\n",
      "Epoch 54/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3244 - accuracy: 0.9148 - auc: 0.9288 - val_loss: 0.2680 - val_accuracy: 0.9161 - val_auc: 0.9590\n",
      "Epoch 55/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3286 - accuracy: 0.9168 - auc: 0.9287 - val_loss: 0.2683 - val_accuracy: 0.9163 - val_auc: 0.9588\n",
      "Epoch 56/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3134 - accuracy: 0.9180 - auc: 0.9402 - val_loss: 0.2705 - val_accuracy: 0.9172 - val_auc: 0.9582\n",
      "Epoch 57/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3194 - accuracy: 0.9184 - auc: 0.9347 - val_loss: 0.2707 - val_accuracy: 0.9163 - val_auc: 0.9583\n",
      "Epoch 58/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3300 - accuracy: 0.9162 - auc: 0.9272 - val_loss: 0.2688 - val_accuracy: 0.9154 - val_auc: 0.9585\n",
      "Epoch 59/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3313 - accuracy: 0.9163 - auc: 0.9276 - val_loss: 0.2676 - val_accuracy: 0.9144 - val_auc: 0.9588\n",
      "Epoch 60/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3215 - accuracy: 0.9190 - auc: 0.9324 - val_loss: 0.2687 - val_accuracy: 0.9181 - val_auc: 0.9588\n",
      "Epoch 61/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.3192 - accuracy: 0.9197 - auc: 0.9318Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3181 - accuracy: 0.9197 - auc: 0.9323 - val_loss: 0.2681 - val_accuracy: 0.9172 - val_auc: 0.9589\n",
      "Epoch 00061: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.9307 - accuracy: 0.9465 - auc: 0.6069 - val_loss: 0.7039 - val_accuracy: 0.9772 - val_auc: 0.7317\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.7242 - accuracy: 0.9508 - auc: 0.7053 - val_loss: 0.5947 - val_accuracy: 0.9740 - val_auc: 0.8094 loss: 0.7528 - accuracy: 0.9510\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6819 - accuracy: 0.9461 - auc: 0.7235 - val_loss: 0.5124 - val_accuracy: 0.9700 - val_auc: 0.8660\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.6142 - accuracy: 0.9392 - auc: 0.7716 - val_loss: 0.4355 - val_accuracy: 0.9623 - val_auc: 0.9033\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5400 - accuracy: 0.9241 - auc: 0.8122 - val_loss: 0.3801 - val_accuracy: 0.9496 - val_auc: 0.9243\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5432 - accuracy: 0.9219 - auc: 0.8114 - val_loss: 0.3581 - val_accuracy: 0.9460 - val_auc: 0.9345\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4929 - accuracy: 0.9202 - auc: 0.8372 - val_loss: 0.3427 - val_accuracy: 0.9419 - val_auc: 0.9418\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4894 - accuracy: 0.9213 - auc: 0.8398 - val_loss: 0.3313 - val_accuracy: 0.9387 - val_auc: 0.9461\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4973 - accuracy: 0.9181 - auc: 0.8330 - val_loss: 0.3244 - val_accuracy: 0.9367 - val_auc: 0.9489\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4642 - accuracy: 0.9203 - auc: 0.8596 - val_loss: 0.3193 - val_accuracy: 0.9367 - val_auc: 0.9506\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4617 - accuracy: 0.9205 - auc: 0.8613 - val_loss: 0.3168 - val_accuracy: 0.9386 - val_auc: 0.9521\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4683 - accuracy: 0.9228 - auc: 0.8549 - val_loss: 0.3124 - val_accuracy: 0.9368 - val_auc: 0.9525\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4478 - accuracy: 0.9242 - auc: 0.8706 - val_loss: 0.3106 - val_accuracy: 0.9376 - val_auc: 0.9525\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4334 - accuracy: 0.9250 - auc: 0.8780 - val_loss: 0.3051 - val_accuracy: 0.9339 - val_auc: 0.9531\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4393 - accuracy: 0.9219 - auc: 0.8747 - val_loss: 0.3039 - val_accuracy: 0.9350 - val_auc: 0.9532\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4112 - accuracy: 0.9238 - auc: 0.8946 - val_loss: 0.3000 - val_accuracy: 0.9329 - val_auc: 0.9535\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4262 - accuracy: 0.9229 - auc: 0.8859 - val_loss: 0.2999 - val_accuracy: 0.9326 - val_auc: 0.9536\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4173 - accuracy: 0.9222 - auc: 0.8905 - val_loss: 0.2943 - val_accuracy: 0.9284 - val_auc: 0.9549\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4082 - accuracy: 0.9212 - auc: 0.8938 - val_loss: 0.2924 - val_accuracy: 0.9307 - val_auc: 0.9552\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4301 - accuracy: 0.9248 - auc: 0.8849 - val_loss: 0.2932 - val_accuracy: 0.9314 - val_auc: 0.9552\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3974 - accuracy: 0.9241 - auc: 0.9004 - val_loss: 0.2889 - val_accuracy: 0.9315 - val_auc: 0.9559\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3973 - accuracy: 0.9257 - auc: 0.9017 - val_loss: 0.2870 - val_accuracy: 0.9312 - val_auc: 0.9563\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3954 - accuracy: 0.9243 - auc: 0.9008 - val_loss: 0.2848 - val_accuracy: 0.9283 - val_auc: 0.9563\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3836 - accuracy: 0.9227 - auc: 0.9077 - val_loss: 0.2832 - val_accuracy: 0.9273 - val_auc: 0.9558\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3849 - accuracy: 0.9232 - auc: 0.9080 - val_loss: 0.2811 - val_accuracy: 0.9266 - val_auc: 0.9565\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4058 - accuracy: 0.9226 - auc: 0.8956 - val_loss: 0.2824 - val_accuracy: 0.9264 - val_auc: 0.9560\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4059 - accuracy: 0.9218 - auc: 0.8969 - val_loss: 0.2806 - val_accuracy: 0.9231 - val_auc: 0.9557\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3809 - accuracy: 0.9198 - auc: 0.9055 - val_loss: 0.2798 - val_accuracy: 0.9212 - val_auc: 0.9555\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3718 - accuracy: 0.9183 - auc: 0.9103 - val_loss: 0.2813 - val_accuracy: 0.9203 - val_auc: 0.9553\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3769 - accuracy: 0.9191 - auc: 0.9073 - val_loss: 0.2811 - val_accuracy: 0.9194 - val_auc: 0.9549\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3737 - accuracy: 0.9178 - auc: 0.9069 - val_loss: 0.2806 - val_accuracy: 0.9198 - val_auc: 0.9555\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3635 - accuracy: 0.9179 - auc: 0.9136 - val_loss: 0.2792 - val_accuracy: 0.9167 - val_auc: 0.9556\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3709 - accuracy: 0.9160 - auc: 0.9083 - val_loss: 0.2803 - val_accuracy: 0.9167 - val_auc: 0.9554\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3563 - accuracy: 0.9156 - auc: 0.9147 - val_loss: 0.2788 - val_accuracy: 0.9144 - val_auc: 0.9551\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3573 - accuracy: 0.9149 - auc: 0.9159 - val_loss: 0.2801 - val_accuracy: 0.9140 - val_auc: 0.9553\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3512 - accuracy: 0.9149 - auc: 0.9175 - val_loss: 0.2794 - val_accuracy: 0.9123 - val_auc: 0.9550\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3605 - accuracy: 0.9152 - auc: 0.9107 - val_loss: 0.2789 - val_accuracy: 0.9127 - val_auc: 0.9559\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3521 - accuracy: 0.9139 - auc: 0.9160 - val_loss: 0.2793 - val_accuracy: 0.9097 - val_auc: 0.9559\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3483 - accuracy: 0.9127 - auc: 0.9173 - val_loss: 0.2771 - val_accuracy: 0.9095 - val_auc: 0.9560\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3415 - accuracy: 0.9141 - auc: 0.9195 - val_loss: 0.2779 - val_accuracy: 0.9099 - val_auc: 0.9559\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3529 - accuracy: 0.9118 - auc: 0.9128 - val_loss: 0.2767 - val_accuracy: 0.9075 - val_auc: 0.9560\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3345 - accuracy: 0.9118 - auc: 0.9216 - val_loss: 0.2768 - val_accuracy: 0.9078 - val_auc: 0.9564\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3426 - accuracy: 0.9105 - auc: 0.9180 - val_loss: 0.2751 - val_accuracy: 0.9070 - val_auc: 0.9563\n",
      "Epoch 44/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3301 - accuracy: 0.9087 - auc: 0.9236 - val_loss: 0.2755 - val_accuracy: 0.9078 - val_auc: 0.9572\n",
      "Epoch 45/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3417 - accuracy: 0.9102 - auc: 0.9171 - val_loss: 0.2746 - val_accuracy: 0.9060 - val_auc: 0.9573\n",
      "Epoch 46/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3269 - accuracy: 0.9103 - auc: 0.9237 - val_loss: 0.2782 - val_accuracy: 0.9061 - val_auc: 0.9558\n",
      "Epoch 47/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3242 - accuracy: 0.9082 - auc: 0.9251 - val_loss: 0.2768 - val_accuracy: 0.9044 - val_auc: 0.9560\n",
      "Epoch 48/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3335 - accuracy: 0.9069 - auc: 0.9212 - val_loss: 0.2774 - val_accuracy: 0.9025 - val_auc: 0.9562\n",
      "Epoch 49/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3489 - accuracy: 0.9060 - auc: 0.9127 - val_loss: 0.2806 - val_accuracy: 0.9023 - val_auc: 0.9556\n",
      "Epoch 50/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3217 - accuracy: 0.9061 - auc: 0.9276 - val_loss: 0.2809 - val_accuracy: 0.8996 - val_auc: 0.9556\n",
      "Epoch 51/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3190 - accuracy: 0.9054 - auc: 0.9275 - val_loss: 0.2800 - val_accuracy: 0.9033 - val_auc: 0.9560\n",
      "Epoch 52/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3345 - accuracy: 0.9080 - auc: 0.9189 - val_loss: 0.2802 - val_accuracy: 0.9005 - val_auc: 0.9557\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3252 - accuracy: 0.9033 - auc: 0.9237 - val_loss: 0.2839 - val_accuracy: 0.8986 - val_auc: 0.9556\n",
      "Epoch 54/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3240 - accuracy: 0.9028 - auc: 0.9254 - val_loss: 0.2843 - val_accuracy: 0.8965 - val_auc: 0.9556\n",
      "Epoch 55/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3198 - accuracy: 0.9034 - auc: 0.9270 - val_loss: 0.2867 - val_accuracy: 0.8976 - val_auc: 0.9556\n",
      "Epoch 56/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3252 - accuracy: 0.9048 - auc: 0.9238 - val_loss: 0.2866 - val_accuracy: 0.8957 - val_auc: 0.9555\n",
      "Epoch 57/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3196 - accuracy: 0.9026 - auc: 0.9286 - val_loss: 0.2867 - val_accuracy: 0.8944 - val_auc: 0.9557\n",
      "Epoch 58/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3146 - accuracy: 0.9042 - auc: 0.9269 - val_loss: 0.2875 - val_accuracy: 0.8965 - val_auc: 0.9563\n",
      "Epoch 59/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3157 - accuracy: 0.9038 - auc: 0.9282 - val_loss: 0.2873 - val_accuracy: 0.8943 - val_auc: 0.9564\n",
      "Epoch 60/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3083 - accuracy: 0.9021 - auc: 0.9315 - val_loss: 0.2857 - val_accuracy: 0.8943 - val_auc: 0.9567\n",
      "Epoch 61/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3082 - accuracy: 0.9023 - auc: 0.9326 - val_loss: 0.2883 - val_accuracy: 0.8930 - val_auc: 0.9563\n",
      "Epoch 62/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3226 - accuracy: 0.9025 - auc: 0.9245 - val_loss: 0.2914 - val_accuracy: 0.8917 - val_auc: 0.9561\n",
      "Epoch 63/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3250 - accuracy: 0.9013 - auc: 0.9231 - val_loss: 0.2945 - val_accuracy: 0.8911 - val_auc: 0.9559\n",
      "Epoch 64/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3118 - accuracy: 0.9010 - auc: 0.9302 - val_loss: 0.2954 - val_accuracy: 0.8885 - val_auc: 0.9553accuracy: 0.9012 - auc: 0.\n",
      "Epoch 65/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.3182 - accuracy: 0.9011 - auc: 0.9241Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3191 - accuracy: 0.9012 - auc: 0.9241 - val_loss: 0.2954 - val_accuracy: 0.8902 - val_auc: 0.9558\n",
      "Epoch 00065: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 1.0194 - accuracy: 0.9945 - auc: 0.5843 - val_loss: 0.7932 - val_accuracy: 0.9943 - val_auc: 0.8013\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.7708 - accuracy: 0.9851 - auc: 0.7197 - val_loss: 0.5870 - val_accuracy: 0.9823 - val_auc: 0.8693\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6240 - accuracy: 0.9662 - auc: 0.7744 - val_loss: 0.4884 - val_accuracy: 0.9721 - val_auc: 0.8958\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6003 - accuracy: 0.9462 - auc: 0.7787 - val_loss: 0.4386 - val_accuracy: 0.9574 - val_auc: 0.9144\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5696 - accuracy: 0.9310 - auc: 0.7881 - val_loss: 0.4119 - val_accuracy: 0.9455 - val_auc: 0.9234\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5430 - accuracy: 0.9236 - auc: 0.7957 - val_loss: 0.3971 - val_accuracy: 0.9396 - val_auc: 0.9275\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5240 - accuracy: 0.9210 - auc: 0.8129 - val_loss: 0.3874 - val_accuracy: 0.9368 - val_auc: 0.9308\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5197 - accuracy: 0.9205 - auc: 0.8144 - val_loss: 0.3796 - val_accuracy: 0.9346 - val_auc: 0.9339\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5014 - accuracy: 0.9196 - auc: 0.8304 - val_loss: 0.3706 - val_accuracy: 0.9316 - val_auc: 0.9362\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4727 - accuracy: 0.9159 - auc: 0.8600 - val_loss: 0.3548 - val_accuracy: 0.9268 - val_auc: 0.9376\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4576 - accuracy: 0.9137 - auc: 0.8629 - val_loss: 0.3480 - val_accuracy: 0.9250 - val_auc: 0.9393\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4486 - accuracy: 0.9155 - auc: 0.8666 - val_loss: 0.3429 - val_accuracy: 0.9242 - val_auc: 0.9405\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4639 - accuracy: 0.9147 - auc: 0.8566 - val_loss: 0.3389 - val_accuracy: 0.9250 - val_auc: 0.9428\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4385 - accuracy: 0.9153 - auc: 0.8724 - val_loss: 0.3336 - val_accuracy: 0.9239 - val_auc: 0.9444\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4376 - accuracy: 0.9141 - auc: 0.8753 - val_loss: 0.3277 - val_accuracy: 0.9211 - val_auc: 0.9453\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4321 - accuracy: 0.9138 - auc: 0.8769 - val_loss: 0.3242 - val_accuracy: 0.9209 - val_auc: 0.9468\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4275 - accuracy: 0.9132 - auc: 0.8779 - val_loss: 0.3195 - val_accuracy: 0.9190 - val_auc: 0.9474\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3860 - accuracy: 0.9132 - auc: 0.9026 - val_loss: 0.3149 - val_accuracy: 0.9175 - val_auc: 0.9479\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4243 - accuracy: 0.9129 - auc: 0.8832 - val_loss: 0.3111 - val_accuracy: 0.9181 - val_auc: 0.9488\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4038 - accuracy: 0.9142 - auc: 0.8922 - val_loss: 0.3070 - val_accuracy: 0.9172 - val_auc: 0.9495\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4088 - accuracy: 0.9128 - auc: 0.8887 - val_loss: 0.3059 - val_accuracy: 0.9177 - val_auc: 0.9495\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4097 - accuracy: 0.9140 - auc: 0.8909 - val_loss: 0.3043 - val_accuracy: 0.9175 - val_auc: 0.9499\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4096 - accuracy: 0.9131 - auc: 0.8910 - val_loss: 0.3016 - val_accuracy: 0.9165 - val_auc: 0.9506\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3922 - accuracy: 0.9147 - auc: 0.8996 - val_loss: 0.2992 - val_accuracy: 0.9154 - val_auc: 0.9503\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4052 - accuracy: 0.9092 - auc: 0.8923 - val_loss: 0.2961 - val_accuracy: 0.9105 - val_auc: 0.9509\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3950 - accuracy: 0.9097 - auc: 0.8972 - val_loss: 0.2954 - val_accuracy: 0.9108 - val_auc: 0.9511\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3835 - accuracy: 0.9113 - auc: 0.9039 - val_loss: 0.2936 - val_accuracy: 0.9125 - val_auc: 0.9516\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3791 - accuracy: 0.9105 - auc: 0.9069 - val_loss: 0.2916 - val_accuracy: 0.9097 - val_auc: 0.9518\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3953 - accuracy: 0.9081 - auc: 0.8948 - val_loss: 0.2909 - val_accuracy: 0.9084 - val_auc: 0.9520\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3767 - accuracy: 0.9110 - auc: 0.9066 - val_loss: 0.2918 - val_accuracy: 0.9107 - val_auc: 0.9521\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3749 - accuracy: 0.9110 - auc: 0.9076 - val_loss: 0.2893 - val_accuracy: 0.9095 - val_auc: 0.9522\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3690 - accuracy: 0.9107 - auc: 0.9092 - val_loss: 0.2902 - val_accuracy: 0.9087 - val_auc: 0.9520\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3672 - accuracy: 0.9096 - auc: 0.9118 - val_loss: 0.2893 - val_accuracy: 0.9078 - val_auc: 0.9520\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3678 - accuracy: 0.9088 - auc: 0.9098 - val_loss: 0.2879 - val_accuracy: 0.9060 - val_auc: 0.9523\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3580 - accuracy: 0.9077 - auc: 0.9149 - val_loss: 0.2865 - val_accuracy: 0.9039 - val_auc: 0.9527\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3553 - accuracy: 0.9070 - auc: 0.9158 - val_loss: 0.2870 - val_accuracy: 0.9048 - val_auc: 0.9526\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3618 - accuracy: 0.9086 - auc: 0.9108 - val_loss: 0.2855 - val_accuracy: 0.9050 - val_auc: 0.9532\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3549 - accuracy: 0.9079 - auc: 0.9151 - val_loss: 0.2861 - val_accuracy: 0.9056 - val_auc: 0.9529\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3643 - accuracy: 0.9095 - auc: 0.9109 - val_loss: 0.2864 - val_accuracy: 0.9061 - val_auc: 0.9526\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3443 - accuracy: 0.9093 - auc: 0.9208 - val_loss: 0.2853 - val_accuracy: 0.9039 - val_auc: 0.9529\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3417 - accuracy: 0.9062 - auc: 0.9200 - val_loss: 0.2859 - val_accuracy: 0.9015 - val_auc: 0.9526\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3611 - accuracy: 0.9056 - auc: 0.9128 - val_loss: 0.2880 - val_accuracy: 0.9001 - val_auc: 0.9519\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3578 - accuracy: 0.9044 - auc: 0.9118 - val_loss: 0.2891 - val_accuracy: 0.9000 - val_auc: 0.9520\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3712 - accuracy: 0.9055 - auc: 0.9032 - val_loss: 0.2880 - val_accuracy: 0.9000 - val_auc: 0.9523\n",
      "Epoch 45/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3384 - accuracy: 0.9038 - auc: 0.9219 - val_loss: 0.2864 - val_accuracy: 0.8986 - val_auc: 0.9527\n",
      "Epoch 46/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3449 - accuracy: 0.9034 - auc: 0.9174 - val_loss: 0.2872 - val_accuracy: 0.8987 - val_auc: 0.9523\n",
      "Epoch 47/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3558 - accuracy: 0.9031 - auc: 0.9120 - val_loss: 0.2869 - val_accuracy: 0.8984 - val_auc: 0.9530\n",
      "Epoch 48/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3429 - accuracy: 0.9039 - auc: 0.9179 - val_loss: 0.2864 - val_accuracy: 0.8980 - val_auc: 0.9532\n",
      "Epoch 49/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3294 - accuracy: 0.9036 - auc: 0.9225 - val_loss: 0.2847 - val_accuracy: 0.8973 - val_auc: 0.9534\n",
      "Epoch 50/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3332 - accuracy: 0.9027 - auc: 0.9236 - val_loss: 0.2844 - val_accuracy: 0.8969 - val_auc: 0.9537\n",
      "Epoch 51/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3317 - accuracy: 0.9023 - auc: 0.9242 - val_loss: 0.2855 - val_accuracy: 0.8969 - val_auc: 0.9535\n",
      "Epoch 52/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3343 - accuracy: 0.9037 - auc: 0.9211 - val_loss: 0.2844 - val_accuracy: 0.8976 - val_auc: 0.9539\n",
      "Epoch 53/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3326 - accuracy: 0.9030 - auc: 0.9240 - val_loss: 0.2860 - val_accuracy: 0.8965 - val_auc: 0.9532\n",
      "Epoch 54/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3367 - accuracy: 0.9019 - auc: 0.9201 - val_loss: 0.2891 - val_accuracy: 0.8968 - val_auc: 0.9530\n",
      "Epoch 55/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3308 - accuracy: 0.9028 - auc: 0.9246 - val_loss: 0.2879 - val_accuracy: 0.8946 - val_auc: 0.9527\n",
      "Epoch 56/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3236 - accuracy: 0.9001 - auc: 0.9268 - val_loss: 0.2877 - val_accuracy: 0.8936 - val_auc: 0.9531\n",
      "Epoch 57/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3313 - accuracy: 0.8985 - auc: 0.9225 - val_loss: 0.2900 - val_accuracy: 0.8911 - val_auc: 0.9525\n",
      "Epoch 58/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3220 - accuracy: 0.8995 - auc: 0.9252 - val_loss: 0.2886 - val_accuracy: 0.8918 - val_auc: 0.9528\n",
      "Epoch 59/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3168 - accuracy: 0.9007 - auc: 0.9306 - val_loss: 0.2900 - val_accuracy: 0.8928 - val_auc: 0.9527\n",
      "Epoch 60/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3330 - accuracy: 0.9006 - auc: 0.9220 - val_loss: 0.2914 - val_accuracy: 0.8915 - val_auc: 0.9524\n",
      "Epoch 61/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3189 - accuracy: 0.9002 - auc: 0.9275 - val_loss: 0.2909 - val_accuracy: 0.8931 - val_auc: 0.9527\n",
      "Epoch 62/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3242 - accuracy: 0.9012 - auc: 0.9242 - val_loss: 0.2929 - val_accuracy: 0.8933 - val_auc: 0.9527\n",
      "Epoch 63/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3258 - accuracy: 0.9003 - auc: 0.9253 - val_loss: 0.2934 - val_accuracy: 0.8923 - val_auc: 0.9523\n",
      "Epoch 64/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3223 - accuracy: 0.9022 - auc: 0.9267 - val_loss: 0.2925 - val_accuracy: 0.8922 - val_auc: 0.9529\n",
      "Epoch 65/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3110 - accuracy: 0.9013 - auc: 0.9309 - val_loss: 0.2933 - val_accuracy: 0.8931 - val_auc: 0.9530\n",
      "Epoch 66/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3167 - accuracy: 0.9011 - auc: 0.9289 - val_loss: 0.2952 - val_accuracy: 0.8934 - val_auc: 0.9519\n",
      "Epoch 67/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3184 - accuracy: 0.9009 - auc: 0.9273 - val_loss: 0.2942 - val_accuracy: 0.8920 - val_auc: 0.9522\n",
      "Epoch 68/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3214 - accuracy: 0.9032 - auc: 0.9266 - val_loss: 0.2948 - val_accuracy: 0.8920 - val_auc: 0.9524\n",
      "Epoch 69/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3161 - accuracy: 0.8212 - auc: 0.9284 - val_loss: 0.2969 - val_accuracy: 0.8777 - val_auc: 0.9521\n",
      "Epoch 70/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3223 - accuracy: 0.7246 - auc: 0.9243 - val_loss: 0.2986 - val_accuracy: 0.8758 - val_auc: 0.9519\n",
      "Epoch 71/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3105 - accuracy: 0.7240 - auc: 0.9317 - val_loss: 0.2984 - val_accuracy: 0.8760 - val_auc: 0.9521\n",
      "Epoch 72/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3203 - accuracy: 0.7257 - auc: 0.9261 ETA: 0s - loss: 0.3127 - accuracy: Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3189 - accuracy: 0.7254 - auc: 0.9264 - val_loss: 0.3003 - val_accuracy: 0.8752 - val_auc: 0.9518\n",
      "Epoch 00072: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.7353 - accuracy: 0.7188 - auc: 0.6701 - val_loss: 0.5234 - val_accuracy: 0.7568 - val_auc: 0.8262\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6087 - accuracy: 0.8082 - auc: 0.7596 - val_loss: 0.4549 - val_accuracy: 0.8652 - val_auc: 0.8760\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5458 - accuracy: 0.8681 - auc: 0.8073 - val_loss: 0.4119 - val_accuracy: 0.9000 - val_auc: 0.9053\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5120 - accuracy: 0.8928 - auc: 0.8317 - val_loss: 0.3845 - val_accuracy: 0.9108 - val_auc: 0.9226\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4648 - accuracy: 0.9072 - auc: 0.8696 - val_loss: 0.3619 - val_accuracy: 0.9130 - val_auc: 0.9325\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4757 - accuracy: 0.9074 - auc: 0.8681 - val_loss: 0.3408 - val_accuracy: 0.9101 - val_auc: 0.9408\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4393 - accuracy: 0.9057 - auc: 0.8850 - val_loss: 0.3235 - val_accuracy: 0.9077 - val_auc: 0.9462\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4248 - accuracy: 0.8998 - auc: 0.8888 - val_loss: 0.3117 - val_accuracy: 0.9057 - val_auc: 0.9494\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4164 - accuracy: 0.9038 - auc: 0.8898 - val_loss: 0.3029 - val_accuracy: 0.9064 - val_auc: 0.9523\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3864 - accuracy: 0.9054 - auc: 0.9081 - val_loss: 0.2918 - val_accuracy: 0.9066 - val_auc: 0.9545\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3951 - accuracy: 0.9057 - auc: 0.9052 - val_loss: 0.2869 - val_accuracy: 0.9082 - val_auc: 0.9555\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3764 - accuracy: 0.9055 - auc: 0.9106 - val_loss: 0.2825 - val_accuracy: 0.9060 - val_auc: 0.9560\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3832 - accuracy: 0.9043 - auc: 0.9073 - val_loss: 0.2785 - val_accuracy: 0.9056 - val_auc: 0.9568\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3701 - accuracy: 0.9053 - auc: 0.9121 - val_loss: 0.2768 - val_accuracy: 0.9042 - val_auc: 0.9578\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3723 - accuracy: 0.9031 - auc: 0.9117 - val_loss: 0.2737 - val_accuracy: 0.9049 - val_auc: 0.9581\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3702 - accuracy: 0.9067 - auc: 0.9112 - val_loss: 0.2742 - val_accuracy: 0.9083 - val_auc: 0.9584\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3650 - accuracy: 0.9075 - auc: 0.9128 - val_loss: 0.2723 - val_accuracy: 0.9084 - val_auc: 0.9587\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3621 - accuracy: 0.9088 - auc: 0.9142 - val_loss: 0.2673 - val_accuracy: 0.9061 - val_auc: 0.9590\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3554 - accuracy: 0.9055 - auc: 0.9184 - val_loss: 0.2664 - val_accuracy: 0.9053 - val_auc: 0.9596\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3581 - accuracy: 0.9063 - auc: 0.9174 - val_loss: 0.2648 - val_accuracy: 0.9056 - val_auc: 0.9597\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3510 - accuracy: 0.9061 - auc: 0.9193 - val_loss: 0.2641 - val_accuracy: 0.9050 - val_auc: 0.9599\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3520 - accuracy: 0.9066 - auc: 0.9212 - val_loss: 0.2620 - val_accuracy: 0.9038 - val_auc: 0.9604\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3442 - accuracy: 0.9074 - auc: 0.9213 - val_loss: 0.2624 - val_accuracy: 0.9055 - val_auc: 0.9605\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3370 - accuracy: 0.9085 - auc: 0.9259 - val_loss: 0.2604 - val_accuracy: 0.9064 - val_auc: 0.9605\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3452 - accuracy: 0.9062 - auc: 0.9215 - val_loss: 0.2579 - val_accuracy: 0.9054 - val_auc: 0.9610\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3302 - accuracy: 0.9057 - auc: 0.9280 - val_loss: 0.2581 - val_accuracy: 0.9038 - val_auc: 0.9608\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3436 - accuracy: 0.9075 - auc: 0.9207 - val_loss: 0.2582 - val_accuracy: 0.9062 - val_auc: 0.9608\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3377 - accuracy: 0.9085 - auc: 0.9234 - val_loss: 0.2582 - val_accuracy: 0.9043 - val_auc: 0.9609\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3438 - accuracy: 0.9073 - auc: 0.9216 - val_loss: 0.2579 - val_accuracy: 0.9062 - val_auc: 0.9609\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3291 - accuracy: 0.9100 - auc: 0.9298 - val_loss: 0.2606 - val_accuracy: 0.9056 - val_auc: 0.9601\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3436 - accuracy: 0.9050 - auc: 0.9219 - val_loss: 0.2622 - val_accuracy: 0.9009 - val_auc: 0.9600\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3294 - accuracy: 0.9059 - auc: 0.9278 - val_loss: 0.2604 - val_accuracy: 0.9020 - val_auc: 0.9602\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3341 - accuracy: 0.9071 - auc: 0.9264 - val_loss: 0.2600 - val_accuracy: 0.9034 - val_auc: 0.9603\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3230 - accuracy: 0.9066 - auc: 0.9297 - val_loss: 0.2631 - val_accuracy: 0.9031 - val_auc: 0.9603\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3342 - accuracy: 0.9070 - auc: 0.9263 - val_loss: 0.2613 - val_accuracy: 0.9049 - val_auc: 0.9604\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3214 - accuracy: 0.7980 - auc: 0.9309 - val_loss: 0.2605 - val_accuracy: 0.8895 - val_auc: 0.9603\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3342 - accuracy: 0.7333 - auc: 0.9269 - val_loss: 0.2605 - val_accuracy: 0.8870 - val_auc: 0.9607\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3285 - accuracy: 0.7307 - auc: 0.9285 - val_loss: 0.2598 - val_accuracy: 0.8867 - val_auc: 0.9605\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3307 - accuracy: 0.7305 - auc: 0.9232 - val_loss: 0.2605 - val_accuracy: 0.8873 - val_auc: 0.9608\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3316 - accuracy: 0.7310 - auc: 0.9253 - val_loss: 0.2622 - val_accuracy: 0.8856 - val_auc: 0.9604\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3290 - accuracy: 0.7313 - auc: 0.9258 - val_loss: 0.2627 - val_accuracy: 0.8874 - val_auc: 0.9598\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3260 - accuracy: 0.7325 - auc: 0.9284 - val_loss: 0.2642 - val_accuracy: 0.8883 - val_auc: 0.9597\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3217 - accuracy: 0.7321 - auc: 0.9291 - val_loss: 0.2627 - val_accuracy: 0.8869 - val_auc: 0.9600\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3208 - accuracy: 0.7305 - auc: 0.9301 - val_loss: 0.2633 - val_accuracy: 0.8852 - val_auc: 0.9598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.3112 - accuracy: 0.7325 - auc: 0.9336Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3131 - accuracy: 0.7322 - auc: 0.9336 - val_loss: 0.2637 - val_accuracy: 0.8873 - val_auc: 0.9600\n",
      "Epoch 00045: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7653 - accuracy: 0.6081 - auc: 0.6826 - val_loss: 0.4852 - val_accuracy: 0.7170 - val_auc: 0.8731\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5423 - accuracy: 0.7236 - auc: 0.8311 - val_loss: 0.4049 - val_accuracy: 0.8162 - val_auc: 0.9219\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4654 - accuracy: 0.7929 - auc: 0.8814 - val_loss: 0.3658 - val_accuracy: 0.8557 - val_auc: 0.9363\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4329 - accuracy: 0.8346 - auc: 0.8967 - val_loss: 0.3413 - val_accuracy: 0.8749 - val_auc: 0.9443\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4006 - accuracy: 0.8540 - auc: 0.9131 - val_loss: 0.3255 - val_accuracy: 0.8856 - val_auc: 0.9486\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3861 - accuracy: 0.8679 - auc: 0.9179 - val_loss: 0.3099 - val_accuracy: 0.8894 - val_auc: 0.9524\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3621 - accuracy: 0.8756 - auc: 0.9277 - val_loss: 0.3005 - val_accuracy: 0.8945 - val_auc: 0.9548\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3416 - accuracy: 0.8831 - auc: 0.9380 - val_loss: 0.2926 - val_accuracy: 0.8983 - val_auc: 0.9557\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3412 - accuracy: 0.8851 - auc: 0.9372 - val_loss: 0.2871 - val_accuracy: 0.9001 - val_auc: 0.9573\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3399 - accuracy: 0.8888 - auc: 0.9378 - val_loss: 0.2817 - val_accuracy: 0.9033 - val_auc: 0.9580\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3370 - accuracy: 0.8935 - auc: 0.9356 - val_loss: 0.2786 - val_accuracy: 0.9031 - val_auc: 0.9583\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3180 - accuracy: 0.8966 - auc: 0.9456 - val_loss: 0.2736 - val_accuracy: 0.9046 - val_auc: 0.9589\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3098 - accuracy: 0.8986 - auc: 0.9496 - val_loss: 0.2716 - val_accuracy: 0.9071 - val_auc: 0.9593\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2973 - accuracy: 0.9011 - auc: 0.9520 - val_loss: 0.2692 - val_accuracy: 0.9079 - val_auc: 0.9593\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3148 - accuracy: 0.9016 - auc: 0.9455 - val_loss: 0.2688 - val_accuracy: 0.9059 - val_auc: 0.9594\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2989 - accuracy: 0.9004 - auc: 0.9515 - val_loss: 0.2664 - val_accuracy: 0.9074 - val_auc: 0.9596\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2884 - accuracy: 0.9042 - auc: 0.9545 - val_loss: 0.2637 - val_accuracy: 0.9118 - val_auc: 0.9602\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2925 - accuracy: 0.9068 - auc: 0.9523 - val_loss: 0.2638 - val_accuracy: 0.9089 - val_auc: 0.9599\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2984 - accuracy: 0.9054 - auc: 0.9515 - val_loss: 0.2624 - val_accuracy: 0.9108 - val_auc: 0.9601\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2898 - accuracy: 0.9040 - auc: 0.9550 - val_loss: 0.2640 - val_accuracy: 0.9092 - val_auc: 0.9598\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2923 - accuracy: 0.9036 - auc: 0.9527 - val_loss: 0.2625 - val_accuracy: 0.9108 - val_auc: 0.9598\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2893 - accuracy: 0.9094 - auc: 0.9532 - val_loss: 0.2622 - val_accuracy: 0.9135 - val_auc: 0.9597\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2818 - accuracy: 0.9088 - auc: 0.9567 - val_loss: 0.2629 - val_accuracy: 0.9123 - val_auc: 0.9595\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2829 - accuracy: 0.9078 - auc: 0.9560 - val_loss: 0.2621 - val_accuracy: 0.9106 - val_auc: 0.9594\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2803 - accuracy: 0.9055 - auc: 0.9556 - val_loss: 0.2610 - val_accuracy: 0.9108 - val_auc: 0.9596\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2752 - accuracy: 0.9089 - auc: 0.9573 - val_loss: 0.2613 - val_accuracy: 0.9129 - val_auc: 0.9595\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2759 - accuracy: 0.9088 - auc: 0.9577 - val_loss: 0.2607 - val_accuracy: 0.9131 - val_auc: 0.9598\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2733 - accuracy: 0.9085 - auc: 0.9590 - val_loss: 0.2617 - val_accuracy: 0.9111 - val_auc: 0.9592\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2624 - accuracy: 0.9087 - auc: 0.9618 - val_loss: 0.2626 - val_accuracy: 0.9135 - val_auc: 0.9590\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2758 - accuracy: 0.9108 - auc: 0.9579 - val_loss: 0.2633 - val_accuracy: 0.9135 - val_auc: 0.9587\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2724 - accuracy: 0.9112 - auc: 0.9594 - val_loss: 0.2637 - val_accuracy: 0.9140 - val_auc: 0.9585\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2748 - accuracy: 0.9124 - auc: 0.9578 - val_loss: 0.2644 - val_accuracy: 0.9131 - val_auc: 0.9586\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2661 - accuracy: 0.9101 - auc: 0.9603 - val_loss: 0.2647 - val_accuracy: 0.9139 - val_auc: 0.9583\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2683 - accuracy: 0.9099 - auc: 0.9600 - val_loss: 0.2650 - val_accuracy: 0.9155 - val_auc: 0.9582\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2628 - accuracy: 0.9127 - auc: 0.9617 - val_loss: 0.2643 - val_accuracy: 0.9135 - val_auc: 0.9586\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2642 - accuracy: 0.9093 - auc: 0.9613 - val_loss: 0.2598 - val_accuracy: 0.9140 - val_auc: 0.9598\n",
      "Epoch 37/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2668 - accuracy: 0.9115 - auc: 0.9603Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2663 - accuracy: 0.9116 - auc: 0.9606 - val_loss: 0.2619 - val_accuracy: 0.9146 - val_auc: 0.9596\n",
      "Epoch 00037: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8048 - accuracy: 0.8755 - auc: 0.6774 - val_loss: 0.4769 - val_accuracy: 0.9303 - val_auc: 0.8617\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5878 - accuracy: 0.8678 - auc: 0.7912 - val_loss: 0.4011 - val_accuracy: 0.9247 - val_auc: 0.9177\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5209 - accuracy: 0.8737 - auc: 0.8294 - val_loss: 0.3648 - val_accuracy: 0.9197 - val_auc: 0.9328\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4763 - accuracy: 0.8814 - auc: 0.8695 - val_loss: 0.3479 - val_accuracy: 0.9192 - val_auc: 0.9361\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4412 - accuracy: 0.8926 - auc: 0.8848 - val_loss: 0.3345 - val_accuracy: 0.9223 - val_auc: 0.9380\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4077 - accuracy: 0.8968 - auc: 0.9065 - val_loss: 0.3198 - val_accuracy: 0.9193 - val_auc: 0.9426\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4047 - accuracy: 0.9010 - auc: 0.9082 - val_loss: 0.3089 - val_accuracy: 0.9183 - val_auc: 0.9454\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3769 - accuracy: 0.8994 - auc: 0.9203 - val_loss: 0.3032 - val_accuracy: 0.9157 - val_auc: 0.9462\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3541 - accuracy: 0.9042 - auc: 0.9284 - val_loss: 0.2973 - val_accuracy: 0.9178 - val_auc: 0.9476\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3564 - accuracy: 0.9027 - auc: 0.9266 - val_loss: 0.2936 - val_accuracy: 0.9155 - val_auc: 0.9479\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3409 - accuracy: 0.9035 - auc: 0.9363 - val_loss: 0.2894 - val_accuracy: 0.9132 - val_auc: 0.9489\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3401 - accuracy: 0.9050 - auc: 0.9348 - val_loss: 0.2874 - val_accuracy: 0.9157 - val_auc: 0.9491\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3320 - accuracy: 0.9071 - auc: 0.9373 - val_loss: 0.2877 - val_accuracy: 0.9157 - val_auc: 0.9489\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3298 - accuracy: 0.9039 - auc: 0.9375 - val_loss: 0.2882 - val_accuracy: 0.9132 - val_auc: 0.9484\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3263 - accuracy: 0.9063 - auc: 0.9399 - val_loss: 0.2871 - val_accuracy: 0.9136 - val_auc: 0.9485\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3294 - accuracy: 0.9067 - auc: 0.9366 - val_loss: 0.2875 - val_accuracy: 0.9147 - val_auc: 0.9485\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3305 - accuracy: 0.9083 - auc: 0.9386 - val_loss: 0.2881 - val_accuracy: 0.9135 - val_auc: 0.9483\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3200 - accuracy: 0.9084 - auc: 0.9415 - val_loss: 0.2898 - val_accuracy: 0.9154 - val_auc: 0.9481\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3047 - accuracy: 0.9090 - auc: 0.9473 - val_loss: 0.2909 - val_accuracy: 0.9152 - val_auc: 0.9475\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3183 - accuracy: 0.9098 - auc: 0.9428 - val_loss: 0.2920 - val_accuracy: 0.9162 - val_auc: 0.9472\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2985 - accuracy: 0.9095 - auc: 0.9497 - val_loss: 0.2918 - val_accuracy: 0.9164 - val_auc: 0.9473\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3003 - accuracy: 0.9111 - auc: 0.9487 - val_loss: 0.2926 - val_accuracy: 0.9153 - val_auc: 0.9475\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2918 - accuracy: 0.9103 - auc: 0.9513 - val_loss: 0.2958 - val_accuracy: 0.9147 - val_auc: 0.9469\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2894 - accuracy: 0.9084 - auc: 0.9525 - val_loss: 0.2971 - val_accuracy: 0.9141 - val_auc: 0.9468\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2869 - accuracy: 0.9090 - auc: 0.9529 - val_loss: 0.2978 - val_accuracy: 0.9166 - val_auc: 0.9473\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2824 - accuracy: 0.9100 - auc: 0.9545 - val_loss: 0.2977 - val_accuracy: 0.9162 - val_auc: 0.9476\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2837 - accuracy: 0.9102 - auc: 0.9537 - val_loss: 0.2980 - val_accuracy: 0.9155 - val_auc: 0.9477\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2814 - accuracy: 0.9087 - auc: 0.9544 - val_loss: 0.2998 - val_accuracy: 0.9145 - val_auc: 0.9479\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2808 - accuracy: 0.9095 - auc: 0.9544 - val_loss: 0.3028 - val_accuracy: 0.9163 - val_auc: 0.9475\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2797 - accuracy: 0.9090 - auc: 0.9545 - val_loss: 0.3049 - val_accuracy: 0.9158 - val_auc: 0.9468\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2816 - accuracy: 0.9084 - auc: 0.9537 - val_loss: 0.3015 - val_accuracy: 0.9160 - val_auc: 0.9483\n",
      "Epoch 32/100\n",
      "245760/250290 [============================>.] - ETA: 0s - loss: 0.2778 - accuracy: 0.9096 - auc: 0.9550Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2777 - accuracy: 0.9095 - auc: 0.9548 - val_loss: 0.3017 - val_accuracy: 0.9153 - val_auc: 0.9484\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.7490 - accuracy: 0.7356 - auc: 0.6890 - val_loss: 0.4628 - val_accuracy: 0.8479 - val_auc: 0.8713\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.5423 - accuracy: 0.8150 - auc: 0.8121 - val_loss: 0.4004 - val_accuracy: 0.8832 - val_auc: 0.9113\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4782 - accuracy: 0.8469 - auc: 0.8633 - val_loss: 0.3670 - val_accuracy: 0.8924 - val_auc: 0.9300\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4305 - accuracy: 0.8678 - auc: 0.8952 - val_loss: 0.3468 - val_accuracy: 0.9034 - val_auc: 0.9372\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4006 - accuracy: 0.8836 - auc: 0.9113 - val_loss: 0.3321 - val_accuracy: 0.9078 - val_auc: 0.9417\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3836 - accuracy: 0.8874 - auc: 0.9167 - val_loss: 0.3182 - val_accuracy: 0.9098 - val_auc: 0.9467\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3549 - accuracy: 0.8952 - auc: 0.9298 - val_loss: 0.3090 - val_accuracy: 0.9114 - val_auc: 0.9498\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3579 - accuracy: 0.8967 - auc: 0.9280 - val_loss: 0.3038 - val_accuracy: 0.9113 - val_auc: 0.9511\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3453 - accuracy: 0.9046 - auc: 0.9319 - val_loss: 0.2984 - val_accuracy: 0.9132 - val_auc: 0.9517\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3348 - accuracy: 0.9032 - auc: 0.9365 - val_loss: 0.2942 - val_accuracy: 0.9122 - val_auc: 0.9521\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3261 - accuracy: 0.9025 - auc: 0.9427 - val_loss: 0.2927 - val_accuracy: 0.9123 - val_auc: 0.9526\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3303 - accuracy: 0.9043 - auc: 0.9384 - val_loss: 0.2889 - val_accuracy: 0.9111 - val_auc: 0.9531\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3058 - accuracy: 0.9067 - auc: 0.9484 - val_loss: 0.2858 - val_accuracy: 0.9154 - val_auc: 0.9533\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3097 - accuracy: 0.9089 - auc: 0.9470 - val_loss: 0.2842 - val_accuracy: 0.9137 - val_auc: 0.9531\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3045 - accuracy: 0.9093 - auc: 0.9498 - val_loss: 0.2840 - val_accuracy: 0.9148 - val_auc: 0.9531\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3050 - accuracy: 0.9106 - auc: 0.9487 - val_loss: 0.2830 - val_accuracy: 0.9151 - val_auc: 0.9528\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3006 - accuracy: 0.9097 - auc: 0.9499 - val_loss: 0.2800 - val_accuracy: 0.9171 - val_auc: 0.9534\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2973 - accuracy: 0.9111 - auc: 0.9500 - val_loss: 0.2798 - val_accuracy: 0.9156 - val_auc: 0.9532\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3001 - accuracy: 0.9090 - auc: 0.9493 - val_loss: 0.2783 - val_accuracy: 0.9143 - val_auc: 0.9531\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2939 - accuracy: 0.9126 - auc: 0.9514 - val_loss: 0.2788 - val_accuracy: 0.9164 - val_auc: 0.9534\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2848 - accuracy: 0.9130 - auc: 0.9547 - val_loss: 0.2782 - val_accuracy: 0.9184 - val_auc: 0.9532\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2866 - accuracy: 0.9140 - auc: 0.9533 - val_loss: 0.2769 - val_accuracy: 0.9205 - val_auc: 0.9537\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2897 - accuracy: 0.9154 - auc: 0.9528 - val_loss: 0.2764 - val_accuracy: 0.9206 - val_auc: 0.9538\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2816 - accuracy: 0.9160 - auc: 0.9554 - val_loss: 0.2742 - val_accuracy: 0.9187 - val_auc: 0.9545\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2813 - accuracy: 0.9157 - auc: 0.9559 - val_loss: 0.2741 - val_accuracy: 0.9187 - val_auc: 0.9544\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2780 - accuracy: 0.9134 - auc: 0.9547 - val_loss: 0.2744 - val_accuracy: 0.9188 - val_auc: 0.9541\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2802 - accuracy: 0.9140 - auc: 0.9545 - val_loss: 0.2759 - val_accuracy: 0.9182 - val_auc: 0.9534\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2810 - accuracy: 0.9146 - auc: 0.9542 - val_loss: 0.2761 - val_accuracy: 0.9184 - val_auc: 0.9538\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2777 - accuracy: 0.9147 - auc: 0.9562 - val_loss: 0.2761 - val_accuracy: 0.9199 - val_auc: 0.9537\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2649 - accuracy: 0.9171 - auc: 0.9616 - val_loss: 0.2777 - val_accuracy: 0.9193 - val_auc: 0.9534\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2700 - accuracy: 0.9135 - auc: 0.9583 - val_loss: 0.2781 - val_accuracy: 0.9166 - val_auc: 0.9530\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2676 - accuracy: 0.9147 - auc: 0.9590 - val_loss: 0.2799 - val_accuracy: 0.9183 - val_auc: 0.9524\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2731 - accuracy: 0.9151 - auc: 0.9582 - val_loss: 0.2797 - val_accuracy: 0.9168 - val_auc: 0.9527\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2745 - accuracy: 0.9138 - auc: 0.9570 - val_loss: 0.2809 - val_accuracy: 0.9188 - val_auc: 0.9524\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2693 - accuracy: 0.9166 - auc: 0.9571 - val_loss: 0.2822 - val_accuracy: 0.9202 - val_auc: 0.9523\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2701 - accuracy: 0.9159 - auc: 0.9581 - val_loss: 0.2825 - val_accuracy: 0.9201 - val_auc: 0.9521\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2730 - accuracy: 0.9158 - auc: 0.9577 - val_loss: 0.2827 - val_accuracy: 0.9186 - val_auc: 0.9526\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2634 - accuracy: 0.9178 - auc: 0.9607 - val_loss: 0.2841 - val_accuracy: 0.9188 - val_auc: 0.9513\n",
      "Epoch 39/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2689 - accuracy: 0.9162 - auc: 0.9586 - val_loss: 0.2866 - val_accuracy: 0.9185 - val_auc: 0.9509\n",
      "Epoch 40/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2616 - accuracy: 0.9169 - auc: 0.9613 - val_loss: 0.2878 - val_accuracy: 0.9187 - val_auc: 0.9507\n",
      "Epoch 41/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2603 - accuracy: 0.9143 - auc: 0.9622 - val_loss: 0.2893 - val_accuracy: 0.9192 - val_auc: 0.9507\n",
      "Epoch 42/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2569 - accuracy: 0.9183 - auc: 0.9628 - val_loss: 0.2913 - val_accuracy: 0.9206 - val_auc: 0.9508\n",
      "Epoch 43/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2637 - accuracy: 0.9165 - auc: 0.9600 - val_loss: 0.2912 - val_accuracy: 0.9196 - val_auc: 0.9509\n",
      "Epoch 44/100\n",
      "241664/250290 [===========================>..] - ETA: 0s - loss: 0.2632 - accuracy: 0.9158 - auc: 0.9603Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2647 - accuracy: 0.9159 - auc: 0.9603 - val_loss: 0.2923 - val_accuracy: 0.9196 - val_auc: 0.9505\n",
      "Epoch 00044: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 0.8054 - accuracy: 0.7193 - auc: 0.6549 - val_loss: 0.5619 - val_accuracy: 0.8249 - val_auc: 0.8136\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5974 - accuracy: 0.7148 - auc: 0.7809 - val_loss: 0.4612 - val_accuracy: 0.8283 - val_auc: 0.8872\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5244 - accuracy: 0.7427 - auc: 0.8384 - val_loss: 0.4094 - val_accuracy: 0.8382 - val_auc: 0.9109\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4775 - accuracy: 0.7788 - auc: 0.8651 - val_loss: 0.3814 - val_accuracy: 0.8525 - val_auc: 0.9208\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4298 - accuracy: 0.8346 - auc: 0.8931 - val_loss: 0.3580 - val_accuracy: 0.8625 - val_auc: 0.9289\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4027 - accuracy: 0.8447 - auc: 0.9060 - val_loss: 0.3384 - val_accuracy: 0.8706 - val_auc: 0.9350\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3906 - accuracy: 0.8551 - auc: 0.9113 - val_loss: 0.3249 - val_accuracy: 0.8788 - val_auc: 0.9389\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3656 - accuracy: 0.8658 - auc: 0.9212 - val_loss: 0.3145 - val_accuracy: 0.8835 - val_auc: 0.9417\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3736 - accuracy: 0.8687 - auc: 0.9184 - val_loss: 0.3070 - val_accuracy: 0.8833 - val_auc: 0.9443\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3571 - accuracy: 0.8715 - auc: 0.9249 - val_loss: 0.2984 - val_accuracy: 0.8867 - val_auc: 0.9470\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3558 - accuracy: 0.8765 - auc: 0.9273 - val_loss: 0.2940 - val_accuracy: 0.8918 - val_auc: 0.9481\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3471 - accuracy: 0.8775 - auc: 0.9299 - val_loss: 0.2917 - val_accuracy: 0.8921 - val_auc: 0.9489\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3276 - accuracy: 0.8801 - auc: 0.9363 - val_loss: 0.2876 - val_accuracy: 0.8938 - val_auc: 0.9500\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3340 - accuracy: 0.8823 - auc: 0.9346 - val_loss: 0.2838 - val_accuracy: 0.8937 - val_auc: 0.9511\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3184 - accuracy: 0.8810 - auc: 0.9402 - val_loss: 0.2808 - val_accuracy: 0.8950 - val_auc: 0.9523\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3228 - accuracy: 0.8848 - auc: 0.9406 - val_loss: 0.2791 - val_accuracy: 0.8965 - val_auc: 0.9527\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3035 - accuracy: 0.8871 - auc: 0.9459 - val_loss: 0.2776 - val_accuracy: 0.9006 - val_auc: 0.9534\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3113 - accuracy: 0.8886 - auc: 0.9429 - val_loss: 0.2756 - val_accuracy: 0.9004 - val_auc: 0.9542\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2996 - accuracy: 0.8887 - auc: 0.9468 - val_loss: 0.2743 - val_accuracy: 0.9021 - val_auc: 0.9549\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3047 - accuracy: 0.8893 - auc: 0.9444 - val_loss: 0.2736 - val_accuracy: 0.9005 - val_auc: 0.9550\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2906 - accuracy: 0.8898 - auc: 0.9490 - val_loss: 0.2732 - val_accuracy: 0.9025 - val_auc: 0.9551\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2961 - accuracy: 0.8916 - auc: 0.9481 - val_loss: 0.2734 - val_accuracy: 0.9021 - val_auc: 0.9551\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2956 - accuracy: 0.8895 - auc: 0.9473 - val_loss: 0.2724 - val_accuracy: 0.9000 - val_auc: 0.9552\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2948 - accuracy: 0.8916 - auc: 0.9477 - val_loss: 0.2730 - val_accuracy: 0.9037 - val_auc: 0.9555\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2861 - accuracy: 0.8923 - auc: 0.9507 - val_loss: 0.2739 - val_accuracy: 0.9050 - val_auc: 0.9556\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2840 - accuracy: 0.8930 - auc: 0.9513 - val_loss: 0.2751 - val_accuracy: 0.9039 - val_auc: 0.9551\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2754 - accuracy: 0.8921 - auc: 0.9542 - val_loss: 0.2766 - val_accuracy: 0.9033 - val_auc: 0.9550\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2839 - accuracy: 0.8906 - auc: 0.9514 - val_loss: 0.2788 - val_accuracy: 0.9041 - val_auc: 0.9541\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2704 - accuracy: 0.8715 - auc: 0.9559 - val_loss: 0.2808 - val_accuracy: 0.9065 - val_auc: 0.9533\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2768 - accuracy: 0.8636 - auc: 0.9540 - val_loss: 0.2809 - val_accuracy: 0.9074 - val_auc: 0.9536\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2792 - accuracy: 0.8618 - auc: 0.9529 - val_loss: 0.2834 - val_accuracy: 0.9066 - val_auc: 0.9527\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2733 - accuracy: 0.8598 - auc: 0.9550 - val_loss: 0.2842 - val_accuracy: 0.9047 - val_auc: 0.9528\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2681 - accuracy: 0.8617 - auc: 0.9560 - val_loss: 0.2860 - val_accuracy: 0.9056 - val_auc: 0.9526\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2704 - accuracy: 0.8623 - auc: 0.9551 - val_loss: 0.2869 - val_accuracy: 0.9063 - val_auc: 0.9530\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2679 - accuracy: 0.8617 - auc: 0.9558 - val_loss: 0.2875 - val_accuracy: 0.9076 - val_auc: 0.9533\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2626 - accuracy: 0.8611 - auc: 0.9575 - val_loss: 0.2895 - val_accuracy: 0.9063 - val_auc: 0.9528\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2597 - accuracy: 0.8609 - auc: 0.9581 - val_loss: 0.2915 - val_accuracy: 0.9071 - val_auc: 0.9527\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2641 - accuracy: 0.8624 - auc: 0.9570 - val_loss: 0.2912 - val_accuracy: 0.9072 - val_auc: 0.9528\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2517 - accuracy: 0.8617 - auc: 0.9605 - val_loss: 0.2942 - val_accuracy: 0.9086 - val_auc: 0.9528\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2621 - accuracy: 0.8620 - auc: 0.9577 - val_loss: 0.2942 - val_accuracy: 0.9060 - val_auc: 0.9530\n",
      "Epoch 41/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2561 - accuracy: 0.8611 - auc: 0.9590 - val_loss: 0.2960 - val_accuracy: 0.9054 - val_auc: 0.9521\n",
      "Epoch 42/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2567 - accuracy: 0.8604 - auc: 0.9595 - val_loss: 0.2983 - val_accuracy: 0.9061 - val_auc: 0.9511\n",
      "Epoch 43/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2570 - accuracy: 0.8602 - auc: 0.9587 - val_loss: 0.2999 - val_accuracy: 0.9041 - val_auc: 0.9509\n",
      "Epoch 44/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2577 - accuracy: 0.8574 - auc: 0.9586 - val_loss: 0.3049 - val_accuracy: 0.9036 - val_auc: 0.9501\n",
      "Epoch 45/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2512 - accuracy: 0.8587 - auc: 0.9609Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2490 - accuracy: 0.8588 - auc: 0.9614 - val_loss: 0.3073 - val_accuracy: 0.9044 - val_auc: 0.9508\n",
      "Epoch 00045: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 5s 18us/sample - loss: 1.0200 - accuracy: 0.8506 - auc: 0.5407 - val_loss: 0.6682 - val_accuracy: 0.8911 - val_auc: 0.7286\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.6792 - accuracy: 0.8277 - auc: 0.7209 - val_loss: 0.4878 - val_accuracy: 0.8738 - val_auc: 0.8757\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5984 - accuracy: 0.8409 - auc: 0.7930 - val_loss: 0.4135 - val_accuracy: 0.8782 - val_auc: 0.9134\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.5047 - accuracy: 0.8558 - auc: 0.8573 - val_loss: 0.3762 - val_accuracy: 0.8880 - val_auc: 0.9274\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4405 - accuracy: 0.8677 - auc: 0.8935 - val_loss: 0.3536 - val_accuracy: 0.8980 - val_auc: 0.9368\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.4195 - accuracy: 0.8824 - auc: 0.8991 - val_loss: 0.3321 - val_accuracy: 0.9071 - val_auc: 0.9424\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3942 - accuracy: 0.8901 - auc: 0.9112 - val_loss: 0.3173 - val_accuracy: 0.9115 - val_auc: 0.9452\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3736 - accuracy: 0.8933 - auc: 0.9213 - val_loss: 0.3063 - val_accuracy: 0.9121 - val_auc: 0.9469\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3622 - accuracy: 0.8997 - auc: 0.9252 - val_loss: 0.2955 - val_accuracy: 0.9158 - val_auc: 0.9489\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3448 - accuracy: 0.9041 - auc: 0.9352 - val_loss: 0.2883 - val_accuracy: 0.9186 - val_auc: 0.9501\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3440 - accuracy: 0.9061 - auc: 0.9331 - val_loss: 0.2837 - val_accuracy: 0.9189 - val_auc: 0.9511\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3368 - accuracy: 0.9063 - auc: 0.9364 - val_loss: 0.2793 - val_accuracy: 0.9159 - val_auc: 0.9524\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3373 - accuracy: 0.9018 - auc: 0.9363 - val_loss: 0.2773 - val_accuracy: 0.9122 - val_auc: 0.9531\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3278 - accuracy: 0.9039 - auc: 0.9388 - val_loss: 0.2761 - val_accuracy: 0.9149 - val_auc: 0.9535\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3094 - accuracy: 0.9066 - auc: 0.9461 - val_loss: 0.2758 - val_accuracy: 0.9142 - val_auc: 0.9531\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3194 - accuracy: 0.9071 - auc: 0.9421 - val_loss: 0.2757 - val_accuracy: 0.9146 - val_auc: 0.9532\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3159 - accuracy: 0.9072 - auc: 0.9420 - val_loss: 0.2760 - val_accuracy: 0.9137 - val_auc: 0.9531\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3116 - accuracy: 0.9059 - auc: 0.9444 - val_loss: 0.2763 - val_accuracy: 0.9133 - val_auc: 0.9531\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3049 - accuracy: 0.9040 - auc: 0.9467 - val_loss: 0.2760 - val_accuracy: 0.9123 - val_auc: 0.9531\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.3024 - accuracy: 0.9065 - auc: 0.9478 - val_loss: 0.2770 - val_accuracy: 0.9139 - val_auc: 0.9530\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2992 - accuracy: 0.9058 - auc: 0.9492 - val_loss: 0.2777 - val_accuracy: 0.9128 - val_auc: 0.9529\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2911 - accuracy: 0.9052 - auc: 0.9512 - val_loss: 0.2797 - val_accuracy: 0.9137 - val_auc: 0.9526\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2854 - accuracy: 0.9068 - auc: 0.9529 - val_loss: 0.2818 - val_accuracy: 0.9124 - val_auc: 0.9522\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2803 - accuracy: 0.9073 - auc: 0.9551 - val_loss: 0.2835 - val_accuracy: 0.9143 - val_auc: 0.9517\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2895 - accuracy: 0.9079 - auc: 0.9519 - val_loss: 0.2828 - val_accuracy: 0.9126 - val_auc: 0.9524\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2814 - accuracy: 0.9043 - auc: 0.9542 - val_loss: 0.2841 - val_accuracy: 0.9098 - val_auc: 0.9521\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2830 - accuracy: 0.9049 - auc: 0.9539 - val_loss: 0.2859 - val_accuracy: 0.9110 - val_auc: 0.9522\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2909 - accuracy: 0.9045 - auc: 0.9507 - val_loss: 0.2863 - val_accuracy: 0.9115 - val_auc: 0.9518\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2868 - accuracy: 0.9040 - auc: 0.9519 - val_loss: 0.2865 - val_accuracy: 0.9104 - val_auc: 0.9517\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2704 - accuracy: 0.9057 - auc: 0.9574 - val_loss: 0.2881 - val_accuracy: 0.9116 - val_auc: 0.9518\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2754 - accuracy: 0.9044 - auc: 0.9556 - val_loss: 0.2902 - val_accuracy: 0.9111 - val_auc: 0.9514\n",
      "Epoch 32/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2661 - accuracy: 0.9056 - auc: 0.9588 - val_loss: 0.2936 - val_accuracy: 0.9124 - val_auc: 0.9509\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2664 - accuracy: 0.9040 - auc: 0.9584 - val_loss: 0.2929 - val_accuracy: 0.9111 - val_auc: 0.9516\n",
      "Epoch 34/100\n",
      "241664/250291 [===========================>..] - ETA: 0s - loss: 0.2658 - accuracy: 0.9059 - auc: 0.9589 ETA: 0s - loss: 0.2618 - accuracy: 0.9056 - aRestoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2667 - accuracy: 0.9058 - auc: 0.9584 - val_loss: 0.2942 - val_accuracy: 0.9128 - val_auc: 0.9516\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8704 - accuracy: 0.2173 - auc: 0.7086 - val_loss: 0.5853 - val_accuracy: 0.2987 - val_auc: 0.8811\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6188 - accuracy: 0.4550 - auc: 0.8463 - val_loss: 0.4463 - val_accuracy: 0.6740 - val_auc: 0.9202\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4795 - accuracy: 0.6346 - auc: 0.8904 - val_loss: 0.3746 - val_accuracy: 0.8095 - val_auc: 0.9337\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4326 - accuracy: 0.7324 - auc: 0.9094 - val_loss: 0.3335 - val_accuracy: 0.8509 - val_auc: 0.9413\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3829 - accuracy: 0.7805 - auc: 0.9231 - val_loss: 0.3095 - val_accuracy: 0.8732 - val_auc: 0.9463\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3605 - accuracy: 0.8097 - auc: 0.9277 - val_loss: 0.2958 - val_accuracy: 0.8789 - val_auc: 0.9492\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3510 - accuracy: 0.8197 - auc: 0.9326 - val_loss: 0.2844 - val_accuracy: 0.8846 - val_auc: 0.9530\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3214 - accuracy: 0.8331 - auc: 0.9427 - val_loss: 0.2750 - val_accuracy: 0.8918 - val_auc: 0.9555\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3257 - accuracy: 0.8434 - auc: 0.9383 - val_loss: 0.2718 - val_accuracy: 0.8921 - val_auc: 0.9559\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3067 - accuracy: 0.8464 - auc: 0.9475 - val_loss: 0.2681 - val_accuracy: 0.8935 - val_auc: 0.9566\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.2930 - accuracy: 0.8545 - auc: 0.9515 - val_loss: 0.2657 - val_accuracy: 0.9014 - val_auc: 0.9570\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.2897 - accuracy: 0.8637 - auc: 0.9526 - val_loss: 0.2614 - val_accuracy: 0.9029 - val_auc: 0.9583\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.2832 - accuracy: 0.8653 - auc: 0.9533 - val_loss: 0.2603 - val_accuracy: 0.9033 - val_auc: 0.9587\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.2828 - accuracy: 0.8677 - auc: 0.9531 - val_loss: 0.2587 - val_accuracy: 0.9023 - val_auc: 0.9593\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2719 - accuracy: 0.8719 - auc: 0.9575 - val_loss: 0.2579 - val_accuracy: 0.9053 - val_auc: 0.9597\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2703 - accuracy: 0.8734 - auc: 0.9568 - val_loss: 0.2586 - val_accuracy: 0.9053 - val_auc: 0.9594\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2672 - accuracy: 0.8746 - auc: 0.9581 - val_loss: 0.2582 - val_accuracy: 0.9034 - val_auc: 0.9595\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2644 - accuracy: 0.8726 - auc: 0.9585 - val_loss: 0.2589 - val_accuracy: 0.9031 - val_auc: 0.9593\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2586 - accuracy: 0.8746 - auc: 0.9602 - val_loss: 0.2598 - val_accuracy: 0.9058 - val_auc: 0.9591\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2553 - accuracy: 0.8779 - auc: 0.9612 - val_loss: 0.2591 - val_accuracy: 0.9072 - val_auc: 0.9591\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2500 - accuracy: 0.8802 - auc: 0.9626 - val_loss: 0.2589 - val_accuracy: 0.9078 - val_auc: 0.9595\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2551 - accuracy: 0.8805 - auc: 0.9611 - val_loss: 0.2616 - val_accuracy: 0.9068 - val_auc: 0.9588\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2587 - accuracy: 0.8807 - auc: 0.9616 - val_loss: 0.2636 - val_accuracy: 0.9073 - val_auc: 0.9586\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2486 - accuracy: 0.8813 - auc: 0.9629 - val_loss: 0.2652 - val_accuracy: 0.9095 - val_auc: 0.9584\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2466 - accuracy: 0.8838 - auc: 0.9633 - val_loss: 0.2664 - val_accuracy: 0.9079 - val_auc: 0.9583\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2434 - accuracy: 0.8829 - auc: 0.9639 - val_loss: 0.2653 - val_accuracy: 0.9099 - val_auc: 0.9585\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2451 - accuracy: 0.8833 - auc: 0.9643 - val_loss: 0.2675 - val_accuracy: 0.9098 - val_auc: 0.9582\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2446 - accuracy: 0.8842 - auc: 0.9639 - val_loss: 0.2666 - val_accuracy: 0.9098 - val_auc: 0.9586\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2487 - accuracy: 0.8832 - auc: 0.9626 - val_loss: 0.2702 - val_accuracy: 0.9068 - val_auc: 0.9576\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2457 - accuracy: 0.8832 - auc: 0.9636 - val_loss: 0.2704 - val_accuracy: 0.9074 - val_auc: 0.9573\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2453 - accuracy: 0.8843 - auc: 0.9637 - val_loss: 0.2688 - val_accuracy: 0.9077 - val_auc: 0.9573\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2382 - accuracy: 0.8833 - auc: 0.9657 - val_loss: 0.2714 - val_accuracy: 0.9108 - val_auc: 0.9569\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2336 - accuracy: 0.8899 - auc: 0.9668 - val_loss: 0.2723 - val_accuracy: 0.9122 - val_auc: 0.9570\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2351 - accuracy: 0.8864 - auc: 0.9666 - val_loss: 0.2735 - val_accuracy: 0.9101 - val_auc: 0.9568\n",
      "Epoch 35/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.8876 - auc: 0.9674Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2318 - accuracy: 0.8877 - auc: 0.9675 - val_loss: 0.2761 - val_accuracy: 0.9135 - val_auc: 0.9559\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 13us/sample - loss: 0.8595 - accuracy: 0.7721 - auc: 0.6725 - val_loss: 0.4649 - val_accuracy: 0.8294 - val_auc: 0.8719\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5502 - accuracy: 0.7899 - auc: 0.8390 - val_loss: 0.3897 - val_accuracy: 0.8652 - val_auc: 0.9202\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4578 - accuracy: 0.8339 - auc: 0.8852 - val_loss: 0.3507 - val_accuracy: 0.8797 - val_auc: 0.9351\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.4230 - accuracy: 0.8560 - auc: 0.9039 - val_loss: 0.3329 - val_accuracy: 0.8868 - val_auc: 0.9406\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3738 - accuracy: 0.8704 - auc: 0.9257 - val_loss: 0.3215 - val_accuracy: 0.8982 - val_auc: 0.9423\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3674 - accuracy: 0.8827 - auc: 0.9297 - val_loss: 0.3156 - val_accuracy: 0.9053 - val_auc: 0.9433\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3400 - accuracy: 0.8912 - auc: 0.9379 - val_loss: 0.3046 - val_accuracy: 0.9102 - val_auc: 0.9461\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3212 - accuracy: 0.8980 - auc: 0.9434 - val_loss: 0.2972 - val_accuracy: 0.9100 - val_auc: 0.9495\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3151 - accuracy: 0.8989 - auc: 0.9435 - val_loss: 0.2911 - val_accuracy: 0.9136 - val_auc: 0.9503\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.3073 - accuracy: 0.8996 - auc: 0.9478 - val_loss: 0.2887 - val_accuracy: 0.9139 - val_auc: 0.9510\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2942 - accuracy: 0.9045 - auc: 0.9523 - val_loss: 0.2858 - val_accuracy: 0.9146 - val_auc: 0.9519\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2893 - accuracy: 0.9047 - auc: 0.9550 - val_loss: 0.2830 - val_accuracy: 0.9152 - val_auc: 0.9523\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2803 - accuracy: 0.9078 - auc: 0.9569 - val_loss: 0.2814 - val_accuracy: 0.9153 - val_auc: 0.9530\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2884 - accuracy: 0.9082 - auc: 0.9526 - val_loss: 0.2802 - val_accuracy: 0.9152 - val_auc: 0.9533\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2710 - accuracy: 0.9076 - auc: 0.9595 - val_loss: 0.2800 - val_accuracy: 0.9174 - val_auc: 0.9534\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2751 - accuracy: 0.9111 - auc: 0.9570 - val_loss: 0.2807 - val_accuracy: 0.9189 - val_auc: 0.9532\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2584 - accuracy: 0.9133 - auc: 0.9632 - val_loss: 0.2802 - val_accuracy: 0.9189 - val_auc: 0.9533\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2606 - accuracy: 0.9137 - auc: 0.9617 - val_loss: 0.2801 - val_accuracy: 0.9195 - val_auc: 0.9534\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2587 - accuracy: 0.9133 - auc: 0.9619 - val_loss: 0.2811 - val_accuracy: 0.9201 - val_auc: 0.9534\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2585 - accuracy: 0.9147 - auc: 0.9619 - val_loss: 0.2821 - val_accuracy: 0.9215 - val_auc: 0.9529\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2549 - accuracy: 0.9132 - auc: 0.9632 - val_loss: 0.2819 - val_accuracy: 0.9201 - val_auc: 0.9530\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2594 - accuracy: 0.9126 - auc: 0.9615 - val_loss: 0.2823 - val_accuracy: 0.9200 - val_auc: 0.9529\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2523 - accuracy: 0.9133 - auc: 0.9640 - val_loss: 0.2832 - val_accuracy: 0.9198 - val_auc: 0.9531\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2493 - accuracy: 0.9153 - auc: 0.9646 - val_loss: 0.2837 - val_accuracy: 0.9210 - val_auc: 0.9528\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2520 - accuracy: 0.9152 - auc: 0.9639 - val_loss: 0.2844 - val_accuracy: 0.9213 - val_auc: 0.9528\n",
      "Epoch 26/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2419 - accuracy: 0.9159 - auc: 0.9659 - val_loss: 0.2854 - val_accuracy: 0.9242 - val_auc: 0.9525\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2431 - accuracy: 0.9179 - auc: 0.9662 - val_loss: 0.2859 - val_accuracy: 0.9225 - val_auc: 0.9525\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2409 - accuracy: 0.9183 - auc: 0.9668 - val_loss: 0.2888 - val_accuracy: 0.9242 - val_auc: 0.9525\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2368 - accuracy: 0.9160 - auc: 0.9673 - val_loss: 0.2888 - val_accuracy: 0.9227 - val_auc: 0.9519\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2344 - accuracy: 0.9158 - auc: 0.9678 - val_loss: 0.2886 - val_accuracy: 0.9230 - val_auc: 0.9519\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2409 - accuracy: 0.9186 - auc: 0.9664 - val_loss: 0.2895 - val_accuracy: 0.9218 - val_auc: 0.9517\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2391 - accuracy: 0.9175 - auc: 0.9667 - val_loss: 0.2884 - val_accuracy: 0.9226 - val_auc: 0.9522\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2427 - accuracy: 0.9156 - auc: 0.9657 - val_loss: 0.2899 - val_accuracy: 0.9209 - val_auc: 0.9520\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2279 - accuracy: 0.9161 - auc: 0.9697 - val_loss: 0.2909 - val_accuracy: 0.9223 - val_auc: 0.9522\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2374 - accuracy: 0.9157 - auc: 0.9668 - val_loss: 0.2931 - val_accuracy: 0.9249 - val_auc: 0.9520\n",
      "Epoch 36/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2358 - accuracy: 0.9197 - auc: 0.9673 - val_loss: 0.2950 - val_accuracy: 0.9258 - val_auc: 0.9522\n",
      "Epoch 37/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2301 - accuracy: 0.9188 - auc: 0.9690 - val_loss: 0.2953 - val_accuracy: 0.9245 - val_auc: 0.9525\n",
      "Epoch 38/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2265 - accuracy: 0.9211 - auc: 0.9696 - val_loss: 0.2962 - val_accuracy: 0.9245 - val_auc: 0.9526\n",
      "Epoch 39/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2314 - accuracy: 0.9194 - auc: 0.9685 ETA: 0s - loss: 0.191Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2313 - accuracy: 0.9193 - auc: 0.9687 - val_loss: 0.2990 - val_accuracy: 0.9231 - val_auc: 0.9524\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250290 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250290/250290 [==============================] - 3s 14us/sample - loss: 0.9576 - accuracy: 0.2736 - auc: 0.6761 - val_loss: 0.5832 - val_accuracy: 0.3512 - val_auc: 0.9002\n",
      "Epoch 2/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.6488 - accuracy: 0.4662 - auc: 0.8402 - val_loss: 0.4515 - val_accuracy: 0.6300 - val_auc: 0.9222\n",
      "Epoch 3/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.5145 - accuracy: 0.6215 - auc: 0.8728 - val_loss: 0.3868 - val_accuracy: 0.7689 - val_auc: 0.9335\n",
      "Epoch 4/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4713 - accuracy: 0.6992 - auc: 0.8937 - val_loss: 0.3505 - val_accuracy: 0.8172 - val_auc: 0.9416\n",
      "Epoch 5/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.4051 - accuracy: 0.7544 - auc: 0.9126 - val_loss: 0.3255 - val_accuracy: 0.8509 - val_auc: 0.9455\n",
      "Epoch 6/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3778 - accuracy: 0.7878 - auc: 0.9214 - val_loss: 0.3074 - val_accuracy: 0.8689 - val_auc: 0.9489\n",
      "Epoch 7/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3515 - accuracy: 0.8045 - auc: 0.9324 - val_loss: 0.2943 - val_accuracy: 0.8783 - val_auc: 0.9508\n",
      "Epoch 8/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3412 - accuracy: 0.8196 - auc: 0.9335 - val_loss: 0.2863 - val_accuracy: 0.8798 - val_auc: 0.9531\n",
      "Epoch 9/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3296 - accuracy: 0.8307 - auc: 0.9392 - val_loss: 0.2786 - val_accuracy: 0.8854 - val_auc: 0.9548\n",
      "Epoch 10/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3082 - accuracy: 0.8418 - auc: 0.9460 - val_loss: 0.2755 - val_accuracy: 0.8940 - val_auc: 0.9547\n",
      "Epoch 11/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.3002 - accuracy: 0.8456 - auc: 0.9478 - val_loss: 0.2712 - val_accuracy: 0.8919 - val_auc: 0.9559\n",
      "Epoch 12/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.2902 - accuracy: 0.8519 - auc: 0.9512 - val_loss: 0.2683 - val_accuracy: 0.8994 - val_auc: 0.9567\n",
      "Epoch 13/100\n",
      "250290/250290 [==============================] - 1s 6us/sample - loss: 0.2946 - accuracy: 0.8576 - auc: 0.9495 - val_loss: 0.2666 - val_accuracy: 0.9019 - val_auc: 0.9570\n",
      "Epoch 14/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2834 - accuracy: 0.8652 - auc: 0.9526 - val_loss: 0.2676 - val_accuracy: 0.9020 - val_auc: 0.9567\n",
      "Epoch 15/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2707 - accuracy: 0.8683 - auc: 0.9567 - val_loss: 0.2663 - val_accuracy: 0.9051 - val_auc: 0.9570\n",
      "Epoch 16/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2793 - accuracy: 0.8700 - auc: 0.9534 - val_loss: 0.2640 - val_accuracy: 0.9037 - val_auc: 0.9575\n",
      "Epoch 17/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2608 - accuracy: 0.8716 - auc: 0.9594 - val_loss: 0.2650 - val_accuracy: 0.9063 - val_auc: 0.9574\n",
      "Epoch 18/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2731 - accuracy: 0.8737 - auc: 0.9548 - val_loss: 0.2681 - val_accuracy: 0.9056 - val_auc: 0.9566\n",
      "Epoch 19/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2623 - accuracy: 0.8768 - auc: 0.9587 - val_loss: 0.2678 - val_accuracy: 0.9077 - val_auc: 0.9569\n",
      "Epoch 20/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2558 - accuracy: 0.8769 - auc: 0.9606 - val_loss: 0.2660 - val_accuracy: 0.9081 - val_auc: 0.9574\n",
      "Epoch 21/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2484 - accuracy: 0.8789 - auc: 0.9628 - val_loss: 0.2677 - val_accuracy: 0.9095 - val_auc: 0.9568\n",
      "Epoch 22/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2516 - accuracy: 0.8799 - auc: 0.9614 - val_loss: 0.2662 - val_accuracy: 0.9087 - val_auc: 0.9575\n",
      "Epoch 23/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2485 - accuracy: 0.8794 - auc: 0.9625 - val_loss: 0.2701 - val_accuracy: 0.9090 - val_auc: 0.9568\n",
      "Epoch 24/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2524 - accuracy: 0.8813 - auc: 0.9612 - val_loss: 0.2727 - val_accuracy: 0.9097 - val_auc: 0.9557\n",
      "Epoch 25/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2417 - accuracy: 0.8803 - auc: 0.9644 - val_loss: 0.2749 - val_accuracy: 0.9099 - val_auc: 0.9555\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2444 - accuracy: 0.8828 - auc: 0.9635 - val_loss: 0.2773 - val_accuracy: 0.9093 - val_auc: 0.9548\n",
      "Epoch 27/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2413 - accuracy: 0.8818 - auc: 0.9644 - val_loss: 0.2809 - val_accuracy: 0.9090 - val_auc: 0.9537\n",
      "Epoch 28/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2387 - accuracy: 0.8808 - auc: 0.9652 - val_loss: 0.2795 - val_accuracy: 0.9098 - val_auc: 0.9542\n",
      "Epoch 29/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2322 - accuracy: 0.8849 - auc: 0.9671 - val_loss: 0.2844 - val_accuracy: 0.9129 - val_auc: 0.9539\n",
      "Epoch 30/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2400 - accuracy: 0.8858 - auc: 0.9645 - val_loss: 0.2825 - val_accuracy: 0.9098 - val_auc: 0.9541\n",
      "Epoch 31/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2423 - accuracy: 0.8823 - auc: 0.9635 - val_loss: 0.2857 - val_accuracy: 0.9105 - val_auc: 0.9534\n",
      "Epoch 32/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2347 - accuracy: 0.8866 - auc: 0.9662 - val_loss: 0.2870 - val_accuracy: 0.9125 - val_auc: 0.9539\n",
      "Epoch 33/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2208 - accuracy: 0.8868 - auc: 0.9701 - val_loss: 0.2897 - val_accuracy: 0.9117 - val_auc: 0.9533\n",
      "Epoch 34/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2292 - accuracy: 0.8866 - auc: 0.9675 - val_loss: 0.2929 - val_accuracy: 0.9120 - val_auc: 0.9532\n",
      "Epoch 35/100\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2291 - accuracy: 0.8858 - auc: 0.9673 - val_loss: 0.2956 - val_accuracy: 0.9118 - val_auc: 0.9519\n",
      "Epoch 36/100\n",
      "249856/250290 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.8881 - auc: 0.9687Restoring model weights from the end of the best epoch.\n",
      "250290/250290 [==============================] - 1s 5us/sample - loss: 0.2241 - accuracy: 0.8881 - auc: 0.9687 - val_loss: 0.2880 - val_accuracy: 0.9122 - val_auc: 0.9551\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 3s 13us/sample - loss: 1.1913 - accuracy: 0.2025 - auc: 0.5324 - val_loss: 0.7046 - val_accuracy: 0.2088 - val_auc: 0.7968\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.7177 - accuracy: 0.3451 - auc: 0.7992 - val_loss: 0.5290 - val_accuracy: 0.4802 - val_auc: 0.8953\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5794 - accuracy: 0.5211 - auc: 0.8583 - val_loss: 0.4272 - val_accuracy: 0.6928 - val_auc: 0.9199\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4894 - accuracy: 0.6342 - auc: 0.8943 - val_loss: 0.3699 - val_accuracy: 0.7925 - val_auc: 0.9307\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4467 - accuracy: 0.7005 - auc: 0.9060 - val_loss: 0.3372 - val_accuracy: 0.8314 - val_auc: 0.9379\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3894 - accuracy: 0.7430 - auc: 0.9204 - val_loss: 0.3147 - val_accuracy: 0.8553 - val_auc: 0.9425\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3638 - accuracy: 0.7707 - auc: 0.9310 - val_loss: 0.3012 - val_accuracy: 0.8718 - val_auc: 0.9452\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3489 - accuracy: 0.7895 - auc: 0.9338 - val_loss: 0.2951 - val_accuracy: 0.8782 - val_auc: 0.9467\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3295 - accuracy: 0.8027 - auc: 0.9403 - val_loss: 0.2901 - val_accuracy: 0.8847 - val_auc: 0.9486\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3265 - accuracy: 0.8143 - auc: 0.9394 - val_loss: 0.2876 - val_accuracy: 0.8843 - val_auc: 0.9494\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3238 - accuracy: 0.8167 - auc: 0.9422 - val_loss: 0.2829 - val_accuracy: 0.8862 - val_auc: 0.9510\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3193 - accuracy: 0.8229 - auc: 0.9428 - val_loss: 0.2812 - val_accuracy: 0.8877 - val_auc: 0.9518\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3045 - accuracy: 0.8215 - auc: 0.9481 - val_loss: 0.2831 - val_accuracy: 0.8869 - val_auc: 0.9515\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2922 - accuracy: 0.8314 - auc: 0.9509 - val_loss: 0.2816 - val_accuracy: 0.8934 - val_auc: 0.9520\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2957 - accuracy: 0.8384 - auc: 0.9506 - val_loss: 0.2793 - val_accuracy: 0.8941 - val_auc: 0.9530\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2808 - accuracy: 0.8449 - auc: 0.9538 - val_loss: 0.2797 - val_accuracy: 0.8960 - val_auc: 0.9534\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2862 - accuracy: 0.8415 - auc: 0.9533 - val_loss: 0.2788 - val_accuracy: 0.8946 - val_auc: 0.9539\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2667 - accuracy: 0.8488 - auc: 0.9591 - val_loss: 0.2807 - val_accuracy: 0.9000 - val_auc: 0.9537\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2640 - accuracy: 0.8534 - auc: 0.9594 - val_loss: 0.2804 - val_accuracy: 0.9019 - val_auc: 0.9539\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2640 - accuracy: 0.8524 - auc: 0.9587 - val_loss: 0.2802 - val_accuracy: 0.9004 - val_auc: 0.9544\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2600 - accuracy: 0.8593 - auc: 0.9596 - val_loss: 0.2785 - val_accuracy: 0.9024 - val_auc: 0.9550\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2621 - accuracy: 0.8602 - auc: 0.9593 - val_loss: 0.2793 - val_accuracy: 0.9009 - val_auc: 0.9549\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2550 - accuracy: 0.8599 - auc: 0.9613 - val_loss: 0.2828 - val_accuracy: 0.9013 - val_auc: 0.9541\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2544 - accuracy: 0.8610 - auc: 0.9610 - val_loss: 0.2836 - val_accuracy: 0.9013 - val_auc: 0.9542\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2549 - accuracy: 0.8624 - auc: 0.9608 - val_loss: 0.2846 - val_accuracy: 0.9005 - val_auc: 0.9542\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2525 - accuracy: 0.8622 - auc: 0.9615 - val_loss: 0.2857 - val_accuracy: 0.8999 - val_auc: 0.9540\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2508 - accuracy: 0.8618 - auc: 0.9620 - val_loss: 0.2870 - val_accuracy: 0.8997 - val_auc: 0.9541\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2439 - accuracy: 0.8638 - auc: 0.9641 - val_loss: 0.2889 - val_accuracy: 0.9018 - val_auc: 0.9532\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2419 - accuracy: 0.8669 - auc: 0.9648 - val_loss: 0.2900 - val_accuracy: 0.9040 - val_auc: 0.9524\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2507 - accuracy: 0.8677 - auc: 0.9619 - val_loss: 0.2924 - val_accuracy: 0.9043 - val_auc: 0.9522\n",
      "Epoch 31/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2466 - accuracy: 0.8682 - auc: 0.9636 - val_loss: 0.2947 - val_accuracy: 0.9020 - val_auc: 0.9517\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2470 - accuracy: 0.8668 - auc: 0.9634 - val_loss: 0.2959 - val_accuracy: 0.9021 - val_auc: 0.9518\n",
      "Epoch 33/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2316 - accuracy: 0.8691 - auc: 0.9679 - val_loss: 0.2981 - val_accuracy: 0.9047 - val_auc: 0.9519\n",
      "Epoch 34/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2333 - accuracy: 0.8710 - auc: 0.9670 - val_loss: 0.2990 - val_accuracy: 0.9048 - val_auc: 0.9522\n",
      "Epoch 35/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2324 - accuracy: 0.8736 - auc: 0.9671 - val_loss: 0.3001 - val_accuracy: 0.9055 - val_auc: 0.9522\n",
      "Epoch 36/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2364 - accuracy: 0.8738 - auc: 0.9658 - val_loss: 0.3017 - val_accuracy: 0.9047 - val_auc: 0.9520\n",
      "Epoch 37/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2350 - accuracy: 0.8701 - auc: 0.9665 - val_loss: 0.2985 - val_accuracy: 0.9015 - val_auc: 0.9528\n",
      "Epoch 38/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2363 - accuracy: 0.8709 - auc: 0.9670 - val_loss: 0.3020 - val_accuracy: 0.9037 - val_auc: 0.9524\n",
      "Epoch 39/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2360 - accuracy: 0.8752 - auc: 0.9663 - val_loss: 0.3014 - val_accuracy: 0.9050 - val_auc: 0.9522\n",
      "Epoch 40/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2313 - accuracy: 0.8722 - auc: 0.9674 - val_loss: 0.3038 - val_accuracy: 0.9045 - val_auc: 0.9518\n",
      "Epoch 41/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2248 - accuracy: 0.8755 - auc: 0.9690 ETA: 0s - loss: 0.2189 - acRestoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2246 - accuracy: 0.8755 - auc: 0.9690 - val_loss: 0.3048 - val_accuracy: 0.9070 - val_auc: 0.9531\n",
      "Epoch 00041: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 250291 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "250291/250291 [==============================] - 4s 14us/sample - loss: 0.9614 - accuracy: 0.2585 - auc: 0.6586 - val_loss: 0.6498 - val_accuracy: 0.3220 - val_auc: 0.8265\n",
      "Epoch 2/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.6555 - accuracy: 0.4324 - auc: 0.8115 - val_loss: 0.4887 - val_accuracy: 0.6065 - val_auc: 0.9114\n",
      "Epoch 3/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.5338 - accuracy: 0.5875 - auc: 0.8711 - val_loss: 0.4069 - val_accuracy: 0.7609 - val_auc: 0.9278\n",
      "Epoch 4/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4404 - accuracy: 0.6819 - auc: 0.9064 - val_loss: 0.3603 - val_accuracy: 0.8247 - val_auc: 0.9373\n",
      "Epoch 5/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.4198 - accuracy: 0.7412 - auc: 0.9169 - val_loss: 0.3300 - val_accuracy: 0.8626 - val_auc: 0.9413\n",
      "Epoch 6/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3917 - accuracy: 0.7790 - auc: 0.9274 - val_loss: 0.3048 - val_accuracy: 0.8779 - val_auc: 0.9477\n",
      "Epoch 7/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3321 - accuracy: 0.8041 - auc: 0.9418 - val_loss: 0.2898 - val_accuracy: 0.8916 - val_auc: 0.9507\n",
      "Epoch 8/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3219 - accuracy: 0.8213 - auc: 0.9439 - val_loss: 0.2829 - val_accuracy: 0.8954 - val_auc: 0.9518\n",
      "Epoch 9/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3264 - accuracy: 0.8284 - auc: 0.9422 - val_loss: 0.2738 - val_accuracy: 0.8966 - val_auc: 0.9551\n",
      "Epoch 10/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3047 - accuracy: 0.8387 - auc: 0.9477 - val_loss: 0.2686 - val_accuracy: 0.8997 - val_auc: 0.9564\n",
      "Epoch 11/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.3013 - accuracy: 0.8464 - auc: 0.9492 - val_loss: 0.2665 - val_accuracy: 0.9014 - val_auc: 0.9568\n",
      "Epoch 12/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2760 - accuracy: 0.8512 - auc: 0.9572 - val_loss: 0.2660 - val_accuracy: 0.9053 - val_auc: 0.9567\n",
      "Epoch 13/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2807 - accuracy: 0.8556 - auc: 0.9551 - val_loss: 0.2670 - val_accuracy: 0.9041 - val_auc: 0.9564\n",
      "Epoch 14/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2875 - accuracy: 0.8525 - auc: 0.9524 - val_loss: 0.2679 - val_accuracy: 0.8992 - val_auc: 0.9559\n",
      "Epoch 15/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2706 - accuracy: 0.8596 - auc: 0.9578 - val_loss: 0.2678 - val_accuracy: 0.9043 - val_auc: 0.9563\n",
      "Epoch 16/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2726 - accuracy: 0.8605 - auc: 0.9565 - val_loss: 0.2672 - val_accuracy: 0.9030 - val_auc: 0.9563\n",
      "Epoch 17/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2751 - accuracy: 0.8637 - auc: 0.9560 - val_loss: 0.2675 - val_accuracy: 0.9035 - val_auc: 0.9566\n",
      "Epoch 18/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2713 - accuracy: 0.8652 - auc: 0.9572 - val_loss: 0.2686 - val_accuracy: 0.9030 - val_auc: 0.9562\n",
      "Epoch 19/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2505 - accuracy: 0.8653 - auc: 0.9634 - val_loss: 0.2712 - val_accuracy: 0.9066 - val_auc: 0.9554\n",
      "Epoch 20/100\n",
      "250291/250291 [==============================] - 1s 6us/sample - loss: 0.2512 - accuracy: 0.8682 - auc: 0.9630 - val_loss: 0.2727 - val_accuracy: 0.9073 - val_auc: 0.9556\n",
      "Epoch 21/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2473 - accuracy: 0.8727 - auc: 0.9640 - val_loss: 0.2737 - val_accuracy: 0.9076 - val_auc: 0.9556\n",
      "Epoch 22/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2525 - accuracy: 0.8721 - auc: 0.9620 - val_loss: 0.2735 - val_accuracy: 0.9056 - val_auc: 0.9557\n",
      "Epoch 23/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2483 - accuracy: 0.8719 - auc: 0.9636 - val_loss: 0.2775 - val_accuracy: 0.9080 - val_auc: 0.9552\n",
      "Epoch 24/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2403 - accuracy: 0.8729 - auc: 0.9660 - val_loss: 0.2801 - val_accuracy: 0.9086 - val_auc: 0.9541\n",
      "Epoch 25/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2395 - accuracy: 0.8762 - auc: 0.9658 - val_loss: 0.2823 - val_accuracy: 0.9105 - val_auc: 0.9537\n",
      "Epoch 26/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2396 - accuracy: 0.8761 - auc: 0.9656 - val_loss: 0.2838 - val_accuracy: 0.9096 - val_auc: 0.9536\n",
      "Epoch 27/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2371 - accuracy: 0.8780 - auc: 0.9662 - val_loss: 0.2857 - val_accuracy: 0.9103 - val_auc: 0.9538\n",
      "Epoch 28/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2348 - accuracy: 0.8797 - auc: 0.9672 - val_loss: 0.2878 - val_accuracy: 0.9114 - val_auc: 0.9538\n",
      "Epoch 29/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2379 - accuracy: 0.8788 - auc: 0.9664 - val_loss: 0.2895 - val_accuracy: 0.9102 - val_auc: 0.9536\n",
      "Epoch 30/100\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2346 - accuracy: 0.8769 - auc: 0.9671 - val_loss: 0.2899 - val_accuracy: 0.9086 - val_auc: 0.9529\n",
      "Epoch 31/100\n",
      "249856/250291 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.8782 - auc: 0.9681Restoring model weights from the end of the best epoch.\n",
      "250291/250291 [==============================] - 1s 5us/sample - loss: 0.2343 - accuracy: 0.8782 - auc: 0.9681 - val_loss: 0.2933 - val_accuracy: 0.9101 - val_auc: 0.9526\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 312863 samples, validate on 78216 samples\n",
      "Epoch 1/100\n",
      "312863/312863 [==============================] - 4s 12us/sample - loss: 0.4713 - accuracy: 0.7701 - auc: 0.8788 - val_loss: 0.2926 - val_accuracy: 0.8881 - val_auc: 0.9507\n",
      "Epoch 2/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.3344 - accuracy: 0.8917 - auc: 0.9365 - val_loss: 0.2667 - val_accuracy: 0.9039 - val_auc: 0.95830.\n",
      "Epoch 3/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.3414 - accuracy: 0.8940 - auc: 0.9355 - val_loss: 0.2650 - val_accuracy: 0.9048 - val_auc: 0.9582\n",
      "Epoch 4/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.3067 - accuracy: 0.9007 - auc: 0.9469 - val_loss: 0.2574 - val_accuracy: 0.9105 - val_auc: 0.9605\n",
      "Epoch 5/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.3144 - accuracy: 0.8999 - auc: 0.9445 - val_loss: 0.2636 - val_accuracy: 0.8932 - val_auc: 0.9583\n",
      "Epoch 6/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.3069 - accuracy: 0.9037 - auc: 0.9483 - val_loss: 0.2707 - val_accuracy: 0.8924 - val_auc: 0.9555\n",
      "Epoch 7/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2961 - accuracy: 0.9008 - auc: 0.9493 - val_loss: 0.2678 - val_accuracy: 0.9027 - val_auc: 0.9566\n",
      "Epoch 8/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2868 - accuracy: 0.9000 - auc: 0.9526 - val_loss: 0.2836 - val_accuracy: 0.9141 - val_auc: 0.9547\n",
      "Epoch 9/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2933 - accuracy: 0.8990 - auc: 0.9505 - val_loss: 0.2950 - val_accuracy: 0.8949 - val_auc: 0.9517\n",
      "Epoch 10/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2806 - accuracy: 0.8989 - auc: 0.9545 - val_loss: 0.3054 - val_accuracy: 0.9064 - val_auc: 0.9503\n",
      "Epoch 11/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2866 - accuracy: 0.9000 - auc: 0.9517 - val_loss: 0.3036 - val_accuracy: 0.8986 - val_auc: 0.9502\n",
      "Epoch 12/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2711 - accuracy: 0.8986 - auc: 0.9565 - val_loss: 0.3094 - val_accuracy: 0.8962 - val_auc: 0.9506\n",
      "Epoch 13/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2692 - accuracy: 0.8942 - auc: 0.9559 - val_loss: 0.3530 - val_accuracy: 0.9208 - val_auc: 0.9482\n",
      "Epoch 14/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2798 - accuracy: 0.8966 - auc: 0.9547 - val_loss: 0.3216 - val_accuracy: 0.8969 - val_auc: 0.9520\n",
      "Epoch 15/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2682 - accuracy: 0.8963 - auc: 0.9569 - val_loss: 0.3438 - val_accuracy: 0.9119 - val_auc: 0.9486\n",
      "Epoch 16/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2583 - accuracy: 0.9008 - auc: 0.9600 - val_loss: 0.3428 - val_accuracy: 0.9071 - val_auc: 0.9462\n",
      "Epoch 17/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2634 - accuracy: 0.9038 - auc: 0.9604 - val_loss: 0.3430 - val_accuracy: 0.9100 - val_auc: 0.9455\n",
      "Epoch 18/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2527 - accuracy: 0.9027 - auc: 0.9608 - val_loss: 0.3703 - val_accuracy: 0.9110 - val_auc: 0.9464\n",
      "Epoch 19/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2699 - accuracy: 0.8945 - auc: 0.9568 - val_loss: 0.3339 - val_accuracy: 0.8980 - val_auc: 0.9463\n",
      "Epoch 20/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2580 - accuracy: 0.8994 - auc: 0.9605 - val_loss: 0.3469 - val_accuracy: 0.9085 - val_auc: 0.9473\n",
      "Epoch 21/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2610 - accuracy: 0.8973 - auc: 0.9585 - val_loss: 0.3512 - val_accuracy: 0.8995 - val_auc: 0.9469\n",
      "Epoch 22/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2687 - accuracy: 0.8974 - auc: 0.9584 - val_loss: 0.3750 - val_accuracy: 0.9048 - val_auc: 0.9444\n",
      "Epoch 23/100\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2564 - accuracy: 0.9012 - auc: 0.9609 - val_loss: 0.3896 - val_accuracy: 0.9133 - val_auc: 0.9452\n",
      "Epoch 24/100\n",
      "305152/312863 [============================>.] - ETA: 0s - loss: 0.2607 - accuracy: 0.9037 - auc: 0.9600Restoring model weights from the end of the best epoch.\n",
      "312863/312863 [==============================] - 2s 6us/sample - loss: 0.2616 - accuracy: 0.9036 - auc: 0.9597 - val_loss: 0.3920 - val_accuracy: 0.9039 - val_auc: 0.9435\n",
      "Epoch 00024: early stopping\n",
      "END\n",
      "123.05430715084076\n",
      "minutes\n"
     ]
    }
   ],
   "source": [
    "model= KerasClassifier(build_fn = create_model)\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_options,\n",
    "                    scoring=scores,\n",
    "                    refit='AUC'\n",
    "                   )\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train,\n",
    "                       callbacks=[es],\n",
    "                       epochs=100,\n",
    "                       class_weight=class_weight,\n",
    "                       validation_data = (X_val,y_val),verbose = 1)\n",
    "end_time=time.time()\n",
    "print('END')\n",
    "print((end_time-start_time)/60)\n",
    "print('minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T00:47:00.047503Z",
     "start_time": "2020-05-22T00:46:56.904333Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "J_IMch4MjhLO"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(grid_result.cv_results_).to_excel('GS_weights_3metrics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "VCA-ID-Tuning for weight.ipynb",
   "provenance": [
    {
     "file_id": "1feXHQjiqioLl47_p65uRpdSv6vX9EnAr",
     "timestamp": 1589212555597
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
